

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>5.1 LLM agents &#8212; Understanding LLMs</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'tutorials/05a-agents';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Attribution methods" href="../lectures/07-attribution.html" />
    <link rel="prev" title="LLM systems &amp; agents" href="../lectures/06-agents.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo-ULM-2024.png" class="logo__image only-light" alt="Understanding LLMs - Home"/>
    <script>document.write(`<img src="../_static/logo-ULM-2024.png" class="logo__image only-dark" alt="Understanding LLMs - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Course overview: Understanding LLMs
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">01 Introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/01-introduction.html">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="01-introduction.html">Sheet 1.1: Practical set-up &amp; Training data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">02 ANNs &amp; RNNs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/02-torch-ANNs-RNNs.html">PyTorch, ANNs &amp; LMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="02a-pytorch-intro.html">Sheet 2.1: PyTorch essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="02b-MLE.html">Sheet 2.2: ML-estimation</a></li>
<li class="toctree-l1"><a class="reference internal" href="02c-MLP-pytorch.html">Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)</a></li>
<li class="toctree-l1"><a class="reference internal" href="02d-char-level-RNN.html">Sheet 2.4: Character-level sequence modeling w/ RNNs</a></li>
<li class="toctree-l1"><a class="reference internal" href="02e-intro-to-hf.html">Sheet 2.5: Introduction to HuggingFace &amp; LMs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">03 LSTMs &amp; transformers</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/03-LSTMs-Transformers.html">LSTMs &amp; Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="03a-tokenization-transformers.html">Sheet 3.1: Tokenization &amp; Transformers</a></li>
<li class="toctree-l1"><a class="reference internal" href="03b-transformers-heads-training.html">Sheet 3.2: Transformer configurations &amp; Training utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/04-LLMs-Prompting.html">Prompting &amp; Current LMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="03c-decoding-prompting.html">Sheet 3.3: Prompting &amp; Decoding</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">04 Fine-tuning &amp; RLHF</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../lectures/05-finetuning-RLHF.html">Fine-tuning and RLHF</a></li>
<li class="toctree-l1"><a class="reference internal" href="04a-finetuning-RL.html">4.1 Supervised fine-tuning and RL fine-tuning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/06-agents.html">LLM systems &amp; agents</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5.1 LLM agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../lectures/07-attribution.html">Attribution methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="06a-attribution.html">Sheet 6.1 LLM probing &amp; attribution</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Homework</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../homework/01-language-modeling.html">Homework 1: Language models (50 points)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../homework/02-prompting.html">Homework 2: Prompting &amp; Generation with LMs (50 points)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../homework/03-agents-RL.html">Homework 3: LLM agents &amp; RL fine-tuning</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/CogSciPrag/Understanding-LLMs-course/main?urlpath=tree/understanding-llms/tutorials/05a-agents.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/CogSciPrag/Understanding-LLMs-course/blob/main/understanding-llms/tutorials/05a-agents.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/CogSciPrag/Understanding-LLMs-course" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/CogSciPrag/Understanding-LLMs-course/issues/new?title=Issue%20on%20page%20%2Ftutorials/05a-agents.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/tutorials/05a-agents.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>5.1 LLM agents</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain">LangChain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agents">Agents</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain-agent-with-tools">LangChain agent with tools</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-parsing">Output parsing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-handling">Memory handling</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="llm-agents">
<h1>5.1 LLM agents<a class="headerlink" href="#llm-agents" title="Permalink to this heading">#</a></h1>
<p><strong>Author:</strong> Polina Tsvilodub</p>
<p>This sheet takes a closer look at more complex LLM-based systems and <em>LLM agents</em>. Specifically, we will use the package <a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/"><code class="docutils literal notranslate"><span class="pre">langchain</span></code></a> and its extensions to build our own LLM systems and explore their functionality. The learning goals for this sheet are:</p>
<ul class="simple">
<li><p>understanding basics of langchain</p></li>
<li><p>trying out langchain agents and tools</p></li>
<li><p>understanding the basics of output processing</p></li>
<li><p>familiarization with basic handling of agent memory</p></li>
</ul>
<p>Langchain is under heavy development. Sometimes examples provided in the docs break with version updates, so one needs to be somewhat patient.</p>
<p><strong>NOTE</strong>: At this point it provides quite vast functionality (and docs, respectively) – of course, we do NOT expect you to study or understand all of that. The examples below will provide links to some relevant parts of the documentation, and the examples serve a little demo / inspiration of what is out there, as a starting point for you to learn more, if you are interested.</p>
<section id="langchain">
<h2>LangChain<a class="headerlink" href="#langchain" title="Permalink to this heading">#</a></h2>
<p>The lecture discussed that modern LLMs can be viewed as building blocks of larger systems, be it for engineering or research purposes. In particular, one might want to use an LLM and make several calls (i.e., several inference passses) to it, and somehow use the predicted results together to complete one’s task. Note that when we talk about such systems, we (almost always) use the LLM for <em>inference</em>, i.e., the LLM is already pretrained / fine-tuned.</p>
<p>Using the terminology of langchain, a sequence of such LLM calls is called a <em>chain</em>. For each call, one minimally needs to specify a (pretrained / fine-tuned) LLM and a prompt that specifies what exactly the call should accomplish. For the prompt, oftentimes <em>prompt templates</em> are used. These prompt templates usually specify <em>variables</em> which are filled with inputs when the respective LLM call is invoked. The idea behind this is that the calls can be re-used, e.g., with various user inputs, without having to re-type the entire prompt. Further, these inputs may come from a previous LLM call. One neat feature of langchain is that it allows to seamlessly chain LLM calls and stream outputs from one call into the next. Specific types of templates (e.g., chat prompt templates) also take care of formatting text in the way expected by the model, e.g., adding the required special tokens and format for chat models.</p>
<p>[Disclaimer: Not sponsored by LangChain – there are other very useful tools for doing such things, for instance, <a class="reference external" href="https://github.com/deepset-ai/haystack">Haystack</a>. This is just one popular example.]</p>
<p>Below, we will first look at a an example of a simple sequence of LLM calls. In particular, we will build a system that helps us to come up with a dinner menu, given some ingredients that we already have.</p>
<p>We will be using the OpenAI API to get optimal performance (specifically, the GPT-3.5-turbo model). Instructions for retreiving the an API key will be provided in class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># please install the following packages and versions</span>

<span class="c1">#!pip install langchain==0.2.2 langchain-core==0.2.4 langchain-openai==0.1.7 wikipedia==1.4.0 langchainhub==0.1.17 langchain-community==0.2.1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">langchain_openai</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain_core.output_parsers</span> <span class="kn">import</span> <span class="n">StrOutputParser</span>
<span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set some hyperparameters for the generation</span>
<span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">ingredients</span> <span class="o">=</span> <span class="s2">&quot;cauliflower, tomatoes.&quot;</span>

<span class="n">instructions_text_appetizer</span> <span class="o">=</span> <span class="s2">&quot;I have the following ingredients in my fridge: </span><span class="se">\n</span><span class="si">{ingredients}</span><span class="se">\n\n</span><span class="s2">Which Italian appetizer can I make for dinner with these ingredients?&quot;</span>

<span class="n">instructions_text_main</span> <span class="o">=</span> <span class="s2">&quot;I am planning to make the following appetizer: </span><span class="se">\n</span><span class="si">{appetizer}</span><span class="se">\n\n</span><span class="s2">Which Italian main course can I make for my dinner?&quot;</span>

<span class="n">instructions_menu_summary</span> <span class="o">=</span> <span class="s2">&quot;I am planning the following recipes for my dinner: </span><span class="se">\n</span><span class="s2">Appetizer: </span><span class="si">{appetizer}</span><span class="se">\n</span><span class="s2">Main course: </span><span class="si">{main_course}</span><span class="se">\n\n</span><span class="s2">Please write a menu summary for my dinner.&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># instantiate model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span>
    <span class="n">openai_api_key</span><span class="o">=</span><span class="c1">### YOUR KEY HERE,</span>
    <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span>   
<span class="p">)</span> 

<span class="c1"># construct prompts for our calls</span>
<span class="n">prompt_template_appetizer</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">template</span> <span class="o">=</span> <span class="n">instructions_text_appetizer</span><span class="p">,</span>
    <span class="n">input_variables</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ingredients&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">prompt_template_main</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">template</span> <span class="o">=</span> <span class="n">instructions_text_main</span><span class="p">,</span>
    <span class="n">input_variables</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;appetizer&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="n">prompt_template_summary</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">(</span>
    <span class="n">template</span> <span class="o">=</span> <span class="n">instructions_menu_summary</span><span class="p">,</span>
    <span class="n">input_variables</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;appetizer&#39;</span><span class="p">,</span> <span class="s1">&#39;main_course&#39;</span><span class="p">],</span>
<span class="p">)</span>
<span class="c1"># construct sub-chains for each course</span>
<span class="n">appetizer_chain</span> <span class="o">=</span> <span class="n">prompt_template_appetizer</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">main_chain</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;appetizer&quot;</span><span class="p">:</span> <span class="n">appetizer_chain</span><span class="p">}</span> <span class="o">|</span> <span class="n">prompt_template_main</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>
<span class="n">composed_chain</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;appetizer&quot;</span><span class="p">:</span> <span class="n">appetizer_chain</span><span class="p">,</span> <span class="s2">&quot;main_course&quot;</span><span class="p">:</span> <span class="n">main_chain</span><span class="p">}</span> <span class="o">|</span> <span class="n">prompt_template_summary</span> <span class="o">|</span> <span class="n">model</span> <span class="o">|</span> <span class="n">StrOutputParser</span><span class="p">()</span>

<span class="c1"># actually call the execution of the entire chain</span>
<span class="n">composed_result</span> <span class="o">=</span> <span class="n">composed_chain</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;ingredients&quot;</span><span class="p">:</span> <span class="n">ingredients</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Result: &quot;</span><span class="p">,</span> <span class="n">composed_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.1: LLM chain</span></strong></p>
<ol class="arabic simple">
<li><p>Please look at the code above and try to understand what it does. Relevant docs about LLM calls can be found <a class="reference external" href="https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/">here</a>, about chains <a class="reference external" href="https://python.langchain.com/v0.1/docs/expression_language/primitives/sequence/">here</a>.</p></li>
<li><p>Add a third course to our menu! Of course, you can also play around with the other prompts and the sequence.</p></li>
</ol>
</div></blockquote>
<section id="agents">
<h3>Agents<a class="headerlink" href="#agents" title="Permalink to this heading">#</a></h3>
<p>In the system above, we have decomposed the task of creating a dinner menu into “bite-sized” pieces for LLM calls ourselves; i.e., we have specified the order and the specific prompt for the single calls ourselves. Next, we will try to avoid these steps, and use an <em>agent</em> instead: i.e., we will pass our overall task description to an LLM and let it figure out the necessary substeps on its own. Specifically, we will use a <a class="reference external" href="https://react-lm.github.io/">React agent</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># same task with agent</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">hub</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">AgentExecutor</span>
<span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">create_react_agent</span>

<span class="c1"># initialize the backbone model for the agent</span>
<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0125&quot;</span><span class="p">,</span> 
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">openai_api_key</span><span class="o">=</span><span class="c1">### YOUR KEY HERE,</span>
<span class="p">)</span>

<span class="c1"># Get an example prompt from langchain that was constructed for this agent architecture. you can modify this!</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">hub</span><span class="o">.</span><span class="n">pull</span><span class="p">(</span><span class="s2">&quot;hwchase17/react&quot;</span><span class="p">)</span>
<span class="c1"># inspect the prompt</span>
<span class="n">prompt</span><span class="o">.</span><span class="n">template</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load the agent</span>
<span class="n">agent</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[],</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
<span class="c1"># initialize the agent</span>
<span class="n">agent_executor</span> <span class="o">=</span> <span class="n">AgentExecutor</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># actually call the agent with the same task as above</span>
<span class="n">agent_executor</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.2: LLM agents</span></strong></p>
<ol class="arabic simple">
<li><p>Please look at the code above and try to understand what it does. Relevant information about agents can be found <a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/agents/">here</a>. Please also try to get an overview of the React architecture (see link above).</p></li>
<li><p>What steps does the agent (try to) perform in order to accomplish the task? How does it “know” which steps to do when?</p></li>
<li><p>Compare the results to the chain above. Do you observe differences?</p></li>
</ol>
</div></blockquote>
</section>
<section id="langchain-agent-with-tools">
<h3>LangChain agent with tools<a class="headerlink" href="#langchain-agent-with-tools" title="Permalink to this heading">#</a></h3>
<p>As you might have seen above, the agent instantiation accepts a list of <em>tools</em> (which we have left empty above). The agent tried to make use of the tools above. This time, let us add a tool to agent – specifically, we will provide it with a tool to call the Wikipedia API for real time searches.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.agents</span> <span class="kn">import</span> <span class="n">load_tools</span>
<span class="n">tools</span> <span class="o">=</span> <span class="n">load_tools</span><span class="p">([</span><span class="s2">&quot;wikipedia&quot;</span><span class="p">],</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tools&#39;</span><span class="p">,</span>  <span class="n">tools</span><span class="p">)</span>

<span class="c1"># create an agent with tools</span>
<span class="n">agent_with_tools</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>

<span class="c1"># instantiate and call the agent</span>
<span class="n">agent_executor</span> <span class="o">=</span> <span class="n">AgentExecutor</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent_with_tools</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="n">tools</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">agent_executor</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.3: LLM agents with tools</span></strong></p>
<ol class="arabic simple">
<li><p>Please look at the code above and try to understand what it does. A list of various tools can be found here <a class="reference external" href="https://python.langchain.com/v0.1/docs/integrations/tools/">here</a>.</p></li>
<li><p>What steps does the agent (try to) perform in order to accomplish the task? How does it “know” which steps to do when? When does it execute searhces?</p></li>
<li><p>Compare the results to the chain above. Do you observe differences?</p></li>
<li><p>Is the Wikipedia tool a good choice for the task at hand? What else might we consider?</p></li>
</ol>
</div></blockquote>
<p>For the sake of seeing the top possible performance of agents, we have used OpenAI models. But since they are behind a paywall, we might also want to use open-source models as a backbone for the agent. LangChain also provides integration with many <a class="reference external" href="https://python.langchain.com/v0.1/docs/integrations/llms/">various</a> LLMs, including HuggingFace models that can be used via the HF <a class="reference external" href="https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_endpoint/">API endpoint</a> which might not always be available and requires and HuggingFace <a class="reference external" href="https://huggingface.co/welcome">account</a>, or with a <a class="reference external" href="https://python.langchain.com/v0.1/docs/integrations/llms/huggingface_pipelines/">local</a> model loaded via <code class="docutils literal notranslate"><span class="pre">transformers</span></code> as we have learned. The latter requires downloading the model; since agent LLM systems require good performance of the backbone LLM, it can rather be tested with large models with at least a few billion parameters (mind their size for downloads!).</p>
<p>In case you do have a HuggingFace account or don’t mind signing up for one, you can optionally test the example below which uses the HF API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">getpass</span> <span class="kn">import</span> <span class="n">getpass</span>

<span class="n">HUGGINGFACEHUB_API_TOKEN</span> <span class="o">=</span> <span class="n">getpass</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set up huggingface LLM</span>
<span class="kn">from</span> <span class="nn">langchain_community.llms</span> <span class="kn">import</span> <span class="n">HuggingFaceEndpoint</span>
<span class="c1"># insert your huggingface API token here (DO NOT PUBLICLY SHARE IT!!!!)</span>
<span class="n">HUGGINGFACEHUB_API_TOKEN</span> <span class="o">=</span> <span class="c1">### YOUR API TOKEN</span>
<span class="c1"># define which model to query</span>
<span class="n">repo_id</span> <span class="o">=</span> <span class="s2">&quot;mistralai/Mistral-7B-Instruct-v0.2&quot;</span>

<span class="n">llm_hf</span> <span class="o">=</span> <span class="n">HuggingFaceEndpoint</span><span class="p">(</span>
    <span class="n">repo_id</span><span class="o">=</span><span class="n">repo_id</span><span class="p">,</span> 
    <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> 
    <span class="n">temperature</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
    <span class="n">huggingfacehub_api_token</span><span class="o">=</span><span class="n">HUGGINGFACEHUB_API_TOKEN</span>
<span class="p">)</span>

<span class="n">agent_hf</span> <span class="o">=</span> <span class="n">create_react_agent</span><span class="p">(</span><span class="n">llm_hf</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[],</span> <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">)</span>
<span class="c1"># initialize the agent</span>
<span class="n">agent_hf_executor</span> <span class="o">=</span> <span class="n">AgentExecutor</span><span class="p">(</span><span class="n">agent</span><span class="o">=</span><span class="n">agent_hf</span><span class="p">,</span> <span class="n">tools</span><span class="o">=</span><span class="p">[],</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># actually call the agent with the same task as above</span>
<span class="n">agent_hf_executor</span><span class="o">.</span><span class="n">invoke</span><span class="p">({</span><span class="s2">&quot;input&quot;</span><span class="p">:</span> <span class="s2">&quot;Please help me come up with a three course Italian dinner menu. It should be vegetarian. I have cauliflower and tomatoes in my fridge.&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="output-parsing">
<h2>Output parsing<a class="headerlink" href="#output-parsing" title="Permalink to this heading">#</a></h2>
<p>One of the core bottlenecks of chaining LLM calls is the potential necessity to <em>process outputs</em> in a specific (structured) way. <a class="reference external" href="https://python.langchain.com/v0.2/docs/how_to/structured_output/">This</a> page provides an overview of how this can be approached. This is step is key for enabling integration of LLMs into automatic systems where other components depend on outputs of LLMs and usually expect particular input types or formats.</p>
<p>There are also packages / frameworks specialized in interfacing with LLMs and properly parsing their outputs like, e.g., <a class="reference external" href="https://lmql.ai/">LMQL</a> and <a class="reference external" href="https://github.com/microsoft/aici">this</a> controller framework from Microsoft.</p>
<p>These resources are intended as optional useful information, in case you will explore and build your own agents; you are not expected to have looked at them in detail.</p>
</section>
<section id="memory-handling">
<h2>Memory handling<a class="headerlink" href="#memory-handling" title="Permalink to this heading">#</a></h2>
<p>One of the main issues of agents is that they are by default <em>stateless</em>; i.e., at each step of execution there is no memory of what happened before. This is handled by adding <em>memory components</em>. An overview of this can be found <a class="reference external" href="https://python.langchain.com/v0.2/docs/tutorials/agents/#adding-in-memory">here</a>.</p>
<blockquote>
<div><p><strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 5.1.4: Memory</span></strong></p>
<ol class="arabic simple">
<li><p>Take a look at the approach for handling message memory above. Recall the <em>generative agnet</em> architecture that was discussed in the lecture. What is the difference between this simple approach and the memory implementation in the generative agents? What are respective (dis)advantages of either approach?</p></li>
</ol>
</div></blockquote>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "CogSciPrag/Understanding-LLMs-course",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../lectures/06-agents.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">LLM systems &amp; agents</p>
      </div>
    </a>
    <a class="right-next"
       href="../lectures/07-attribution.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Attribution methods</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain">LangChain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agents">Agents</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain-agent-with-tools">LangChain agent with tools</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#output-parsing">Output parsing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-handling">Memory handling</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael Franke, Carsten Eickhoff, Polina Tsvilodub
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>