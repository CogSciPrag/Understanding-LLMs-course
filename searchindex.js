Search.setIndex({"alltitles": {"Activation patching": [[31, "activation-patching"]], "Additional materials": [[7, "additional-materials"], [8, "additional-materials"], [9, "additional-materials"], [10, "additional-materials"], [11, "additional-materials"], [12, "additional-materials"], [13, "additional-materials"], [14, "additional-materials"], [15, "additional-materials"], [16, "additional-materials"]], "Advanced outlook: PyTorch Autograd and computational graph [optional]": [[20, "advanced-outlook-pytorch-autograd-and-computational-graph-optional"]], "Agents": [[27, "agents"]], "Assessing just the values of a tensor": [[18, "assessing-just-the-values-of-a-tensor"]], "Assistant evaluation": [[30, "assistant-evaluation"]], "Attention masks": [[23, "attention-masks"]], "Attention visualization": [[28, "attention-visualization"]], "Attributes of a tensor": [[18, "attributes-of-a-tensor"]], "Attribution methods": [[13, null], [28, "attribution-methods"]], "BPE tokenization": [[23, "bpe-tokenization"]], "Background": [[7, null]], "Benchmark testing": [[29, "benchmark-testing"]], "Best practices for writing code": [[17, "best-practices-for-writing-code"]], "Broadcasting": [[18, "broadcasting"]], "Colab": [[17, "colab"]], "Core concepts": [[17, "core-concepts"]], "Course formalia": [[6, "course-formalia"]], "Course overview: Understanding LMs": [[6, null]], "Creating a tensor": [[18, "creating-a-tensor"]], "Dataset documentation": [[17, "dataset-documentation"]], "Decoding schemes": [[25, "decoding-schemes"]], "Defining the MLP using PyTorch\u2019s built-in modules": [[20, "defining-the-mlp-using-pytorchs-built-in-modules"]], "Defining the model": [[21, "defining-the-model"]], "Early decoding": [[31, "early-decoding"]], "Evaluation": [[28, "evaluation"]], "Evaluation & behavioral assessment": [[14, null]], "Evaluation & inference": [[21, "evaluation-inference"]], "Excercise 5.1.1.2": [[27, "excercise-5-1-1-2"]], "Exercise 1: Advanced prompting strategies (16 points)": [[1, "exercise-1-advanced-prompting-strategies-16-points"], [3, "exercise-1-advanced-prompting-strategies-16-points"]], "Exercise 1: Building a retrieval-augmented generation system (30 points)": [[4, "exercise-1-building-a-retrieval-augmented-generation-system-30-points"]], "Exercise 1: Understanding grammatical capabilities of LLMs (10 points)": [[5, "exercise-1-understanding-grammatical-capabilities-of-llms-10-points"]], "Exercise 1: Understanding language modeling (12 points)": [[0, "exercise-1-understanding-language-modeling-12-points"], [2, "exercise-1-understanding-language-modeling-12-points"]], "Exercise 2: Evaluating societal biases (13 points)": [[5, "exercise-2-evaluating-societal-biases-13-points"]], "Exercise 2: Extracting LLM fingerprints (15 points)": [[2, "exercise-2-extracting-llm-fingerprints-15-points"]], "Exercise 2: Prompting for NLI & Multiple-choice QA (14 points)": [[3, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"]], "Exercise 2: RLHF for summarization (15 points)": [[1, "exercise-2-rlhf-for-summarization-15-points"], [4, "exercise-2-rlhf-for-summarization-15-points"]], "Exercise 2: Understanding LLM configuration (8 points)": [[0, "exercise-2-understanding-llm-configuration-8-points"]], "Exercise 3 (15 points):": [[0, "exercise-3-15-points"]], "Exercise 3.3.3.1.": [[25, "exercise-3-3-3-1"]], "Exercise 3.3.3.2.": [[25, "exercise-3-3-3-2"]], "Exercise 3.3.3.3": [[25, "exercise-3-3-3-3"]], "Exercise 3: Aspects of fine-tuning (5 points)": [[4, "exercise-3-aspects-of-fine-tuning-5-points"]], "Exercise 3: Fine-tuning GPT-2 for QA (23 points)": [[2, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"]], "Exercise 3: First neural LM (20 points)": [[1, "exercise-3-first-neural-lm-20-points"], [3, "exercise-3-first-neural-lm-20-points"]], "Exercise 3: LLM evaluations with LLMs (5 points)": [[5, "exercise-3-llm-evaluations-with-llms-5-points"]], "Exercise 4: Fine-tuning Pythia for Question Answering (23 points)": [[0, "exercise-4-fine-tuning-pythia-for-question-answering-23-points"]], "Exercise 4: How human-like are Llama\u2019s surprisals? (22 points)": [[5, "exercise-4-how-human-like-are-llama-s-surprisals-22-points"]], "Fine-tuning and RLHF": [[11, null]], "Flavours of fine-tuning": [[26, "flavours-of-fine-tuning"]], "Further materials": [[6, "further-materials"]], "Hallucinations": [[30, "hallucinations"]], "Helper functions for training": [[21, "helper-functions-for-training"]], "Homework 1: Language models (50 points)": [[2, null]], "Homework 1: Language models (58 points)": [[0, null]], "Homework 2: Fine-tuning & Prompting of LMs (51 points)": [[1, null]], "Homework 2: Prompting & Generation with LMs (50 points)": [[3, null]], "Homework 3: LLM agents & RL fine-tuning": [[4, null]], "Homework 4: LLM evaluation": [[5, null]], "HuggingFace \ud83e\udd17": [[22, "huggingface"]], "Implications, Understanding & Philosophy": [[15, null]], "Indexing and slicing": [[18, "indexing-and-slicing"]], "Inference": [[21, "inference"]], "Installing requirements": [[17, "installing-requirements"]], "Intended audience": [[6, "intended-audience"]], "Interpreting training dynamics": [[24, "interpreting-training-dynamics"]], "Introduction: ML models": [[22, "introduction-ml-models"]], "Inverting the generation model": [[21, "inverting-the-generation-model"]], "Joining tensors": [[18, "joining-tensors"]], "Knowledge & Problem solving benchmarks": [[30, "knowledge-problem-solving-benchmarks"]], "LLM systems & agents": [[12, null]], "LSTMs & Transformers": [[9, null]], "LangChain": [[27, "langchain"]], "LangChain agent with tools": [[27, "langchain-agent-with-tools"]], "Loading & inspecting the data": [[21, "loading-inspecting-the-data"]], "Local installation": [[17, "local-installation"]], "Logistics": [[0, "logistics"], [1, "logistics"], [2, "logistics"], [3, "logistics"], [4, "logistics"], [5, "logistics"]], "MLM masking": [[24, "mlm-masking"]], "Machine psychology": [[29, "machine-psychology"]], "Main training data processing steps": [[17, "main-training-data-processing-steps"]], "Matrix Multiplication": [[18, "matrix-multiplication"]], "Mechanistic Interpretability": [[16, null]], "Memory handling": [[27, "memory-handling"]], "Metrics": [[29, "metrics"]], "Model heads": [[24, "model-heads"]], "More concise definition of NN module": [[20, "more-concise-definition-of-nn-module"]], "More explicit definition NN module": [[20, "more-explicit-definition-nn-module"]], "NVIDIA API": [[17, "nvidia-api"]], "Operations on tensors": [[18, "operations-on-tensors"]], "Optimizing a parameter: gradients, optimizers, loss & backprop": [[19, "optimizing-a-parameter-gradients-optimizers-loss-backprop"]], "Optional outlook": [[26, "optional-outlook"]], "Outlook": [[22, "outlook"], [29, "outlook"]], "Outlook (optional)": [[23, "outlook-optional"]], "Outlook (optional): EOS tokens": [[23, "outlook-optional-eos-tokens"]], "Outlook and optional exercises": [[24, "outlook-and-optional-exercises"]], "Outlook: PEFT in practice": [[26, "outlook-peft-in-practice"]], "Outlook: PyTorch layers and utils [optional]": [[20, "outlook-pytorch-layers-and-utils-optional"]], "Output parsing": [[27, "output-parsing"]], "PPO training": [[26, "ppo-training"]], "Packages": [[19, "packages"]], "Packages & global parameters": [[20, "packages-global-parameters"], [21, "packages-global-parameters"]], "Part 1: Compute the predictions for current parameter value": [[19, "part-1-compute-the-predictions-for-current-parameter-value"]], "Part 2: Computing the loss for the current prediction": [[19, "part-2-computing-the-loss-for-the-current-prediction"]], "Part 3: Backpropagate the error signal": [[19, "part-3-backpropagate-the-error-signal"]], "Part 4: Update the parameter values": [[19, "part-4-update-the-parameter-values"]], "Part 5: Reset the gradient information": [[19, "part-5-reset-the-gradient-information"]], "Policy": [[26, "policy"]], "Preparing the training data": [[20, "preparing-the-training-data"]], "Pretrained tokenizers": [[23, "pretrained-tokenizers"]], "Pretrained transformers": [[23, "pretrained-transformers"]], "Previous iterations of the course": [[6, "previous-iterations-of-the-course"]], "Probing": [[28, "probing"]], "Process consistency": [[30, "process-consistency"]], "Prompting & Current LMs": [[10, null]], "Prompting strategies": [[25, "prompting-strategies"]], "PyTorch": [[23, "pytorch"]], "PyTorch, ANNs & LMs": [[8, null]], "RL fine-tuning": [[26, "rl-fine-tuning"]], "Reasoning benchmarks": [[30, "reasoning-benchmarks"]], "Reshaping": [[18, "reshaping"]], "Residual stream": [[31, "residual-stream"]], "Reward modeling": [[26, "reward-modeling"]], "Row & column vectors": [[18, "row-column-vectors"]], "Schedule": [[6, "schedule"]], "Sheet 1.1: Practical set-up & Training data": [[17, null]], "Sheet 2.1: PyTorch essentials": [[18, null]], "Sheet 2.2: ML-estimation": [[19, null]], "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)": [[20, null]], "Sheet 2.4: Character-level sequence modeling w/ RNNs": [[21, null]], "Sheet 2.5: Introduction to HuggingFace & LMs": [[22, null]], "Sheet 3.1: Tokenization & Transformers": [[23, null]], "Sheet 3.2: Transformer configurations & Training utilities": [[24, null]], "Sheet 3.3: Prompting & Decoding": [[25, null]], "Sheet 4.1 Supervised fine-tuning and RL fine-tuning": [[26, null]], "Sheet 5.1 LLM agents": [[27, null]], "Sheet 6.1 LLM probing & attribution": [[28, null]], "Sheet 7.1: Behavioral assessment & Evaluation": [[29, null]], "Sheet 7.2: Advanced evaluation": [[30, null]], "Sheet 8.1: Mechanistic interpretability": [[31, null]], "Social aspects": [[30, "social-aspects"]], "Special tokens": [[23, "special-tokens"]], "Supervised fine-tuning": [[26, "supervised-fine-tuning"]], "Tensor arithmetic": [[18, "tensor-arithmetic"]], "Tensor data types": [[18, "tensor-data-types"]], "Tensors": [[18, "tensors"]], "Tokenization": [[23, "tokenization"]], "Train-test split": [[21, "train-test-split"]], "Training": [[28, "training"]], "Training loop": [[19, "training-loop"]], "Training the model": [[20, "training-the-model"]], "Training the network": [[21, "training-the-network"]], "Training utilities": [[24, "training-utilities"]], "Transformers": [[23, "transformers"]], "Transformers: Part 2": [[9, "transformers-part-2"]], "Transposing": [[18, "transposing"]], "True distribution & training data": [[19, "true-distribution-training-data"]], "True model & training data": [[20, "true-model-training-data"]], "Understanding training data": [[17, "understanding-training-data"]], "Verifying requirement installation": [[17, "verifying-requirement-installation"]], "Working with LMs via \ud83e\udd17 Transformers": [[22, "working-with-lms-via-transformers"]], "bwJupyter": [[17, "bwjupyter"]]}, "docnames": ["homework/01-language-modeling", "homework/02-fine-tuning", "homework/archive_2024/01-language-modeling", "homework/archive_2024/02-prompting", "homework/archive_2024/03-agents-RL", "homework/archive_2024/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/09-philosophy", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["homework/01-language-modeling.ipynb", "homework/02-fine-tuning.ipynb", "homework/archive_2024/01-language-modeling.ipynb", "homework/archive_2024/02-prompting.ipynb", "homework/archive_2024/03-agents-RL.ipynb", "homework/archive_2024/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/09-philosophy.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 4, 6, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "0": [0, 1, 2, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "00": [17, 31], "000": [5, 17], "0000": 18, "00000": 19, "0000001": 19, "00001": 32, "00005": 19, "00007": 19, "00012": 19, "00020": 19, "00033": 19, "0005": 21, "00055": 19, "00059": 19, "00091": 19, "00095": 19, "00097": 19, "001": 32, "00117": 19, "0013": 20, "00130": 19, "00138": 19, "00143": 19, "00146": 19, "00150": 19, "0017": 20, "002": 32, "0024": 20, "00248": 19, "00258": 19, "0032": 23, "0037": 20, "0039": 23, "004": [20, 32], "00408": 19, "0044": 20, "0046": 23, "00523": 19, "0059": 20, "006": 19, "0066": 20, "00673": 19, "0070": 23, "0076": 20, "009": 32, "0095": 23, "00960": 19, "0109": 20, "011": 19, "01110": 19, "0113": 23, "01171875": 25, "012": 32, "0125": 27, "0126": 23, "013": 32, "0143": 23, "0149": 20, "0155": 20, "0156": 23, "016": 20, "0164": 23, "0166": 20, "01680": 19, "01831": 19, "0195": 20, "0198": 23, "0199": 20, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 31, "02": [0, 2, 23, 25], "0211": 20, "0225": 20, "0226": 23, "0227": 20, "023": 20, "0235": 20, "0246": 20, "0250": 23, "0257": 20, "0279": 20, "0282": 20, "02869": 19, "0292": 20, "0293": 23, "03": 23, "03019": 19, "0304": 23, "0309": 20, "0312": [19, 23], "0318": 23, "0319": 23, "033": 20, "033587316144933": 21, "0338": 20, "034": 20, "0348": 20, "0363": 23, "0365": 20, "0369": 20, "0370": 20, "0374": 20, "0383": 20, "0386": 20, "039": 20, "0419": 20, "042": 32, "0421": 20, "0429": [20, 23], "043": 20, "0434": 20, "0436": 20, "044040465112291": 21, "0445": 23, "0446": 20, "0447": 20, "045": 32, "0451": 20, "0453": 20, "0454": 20, "0458984375": 19, "046": 20, "0475": 23, "0479": 20, "04828": 19, "049187345280759": 21, "0493": 20, "04979": 19, "0499": 23, "05": [1, 4, 21, 23], "0505": 20, "0509": 20, "0513": [20, 23], "0516": 23, "0519": 20, "05221": 29, "0523": 20, "0525": 23, "0526": 23, "0528": 20, "0534": 23, "0546": 20, "0547": 20, "0552": 20, "0556": 20, "0562": 20, "0575": 20, "0584": 23, "0588": 20, "059": 19, "0591": 20, "0592": 20, "06": 0, "0602": 23, "0622": 20, "0631": 23, "0644": 20, "0646": 20, "0653": 23, "0655": 20, "0663": 20, "06640625": 25, "0666": 20, "0671": 20, "0675": 20, "0679": 20, "0695": 23, "0706": 20, "071": 20, "0721": 18, "074": 20, "0758": 21, "076368400920858": 21, "0769": 20, "077": 32, "0787130945986387": 21, "0789": 20, "08": 32, "0803": 23, "08060": 19, "08073": 26, "081": 32, "0819": 23, "08211": 19, "0848": 23, "0849": 20, "0853": 20, "0854": 20, "086": 32, "0874": 23, "089089898243062": 21, "08965344": 32, "0905": 23, "0909": 20, "0912": 20, "0915": 20, "0917557944550413": 21, "0924": 20, "0928": 20, "0934": 20, "0936": 20, "094": 32, "0947": 20, "095": [20, 32], "0955": 20, "0964": 20, "0968": 20, "0972": 20, "0978": 23, "0994": 20, "0_0": 32, "0_1": 32, "0_4": 32, "0m": 21, "1": [20, 21, 22, 24, 30, 32], "10": [0, 2, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "100": [17, 18, 19, 20, 21, 24, 25, 27, 29, 31], "1000": [0, 2, 19, 20, 25], "10000": [19, 20, 21, 23], "100000": 21, "10015": 19, "100257": 0, "100277": 0, "100352": 0, "1006": 20, "1007": 20, "1009": 20, "101": 18, "1014": 20, "102": 20, "1023": 32, "1024": [0, 1, 4, 23, 26, 28], "1025": 20, "1031": 20, "1035": 23, "104": 20, "1041": 20, "1043": 23, "1050": 32, "1051": 20, "1068": 32, "107": 20, "1071": 32, "108": 18, "1081": 21, "1083": 23, "10x1": 20, "10x10": 20, "11": [18, 20, 21, 23, 26, 32], "1107": 23, "111": [18, 32], "1116": 20, "1128": 20, "1129": 20, "113": 20, "1132": 31, "1136": 20, "114": 18, "1143": 23, "1146": 20, "1149": [20, 32], "1161": 20, "1163": 20, "1174": 32, "1179": 20, "118": 20, "119": 20, "1196": 20, "12": [6, 17, 18, 21, 23, 31, 32], "121": 20, "122": 20, "1222": 20, "1229": 20, "124": 26, "1241": 20, "125": [20, 21], "12500": 20, "1255": 32, "1258": 23, "1259": 20, "1264": 20, "1269": 20, "1277": 20, "128": [1, 4, 21, 23, 27], "1287": 23, "129": 20, "1292": 23, "1293": 20, "13": [0, 2, 20, 21, 25, 32], "1302": 25, "1304": 21, "1305": 20, "131": 20, "1315": 20, "1321": 20, "1324": 23, "1327": 23, "133": 20, "1331": 23, "13390": 19, "1344274634863063": 21, "13540": 19, "1359": 20, "1371": 20, "137311827640074": 21, "139": 21, "1394": 20, "1396": 20, "13th": [0, 5], "14": [6, 17, 18, 20, 21, 32], "140": 20, "1407": 20, "1408": 20, "1417": 20, "14258": 19, "14259": 19, "1426": 20, "14260": 19, "14263": 19, "1427": 20, "14271": 19, "1428": 20, "14292": 19, "1431": 23, "1432": 32, "1433": 20, "14350": 19, "1447": 20, "1449": 20, "14508": 19, "1452": 20, "1462": 20, "1464": 20, "147": 20, "1473": 23, "1481": 20, "149": 32, "1491": 20, "14937": 19, "15": [17, 19, 20, 21, 24, 25, 32], "1500": 19, "15000": [20, 21], "151": 20, "151007538987999": 21, "1517": 23, "1518": 20, "1524": 20, "1527": 20, "156": 32, "1574": 20, "1587": 20, "15948522": 32, "1596": 20, "15th": 2, "16": [0, 6, 18, 20, 21, 22, 32], "1600": 20, "160m": [0, 5], "16102": 19, "1630": 20, "1632": 20, "1638": 20, "1640625": 25, "1652": [20, 25], "1660": 23, "1676781420602698": 21, "1682": 20, "17": [21, 27, 32], "1701001434279856": 21, "1726": 23, "1727": 20, "1732": [20, 23], "1744": 20, "175": 32, "17500": 20, "1754": 23, "176395016805715": 21, "1773": 32, "1774": 20, "1777": 21, "17835062349366": 17, "1784": 20, "179": 20, "1793": 20, "1796": 20, "1796875": 25, "18": [17, 20, 21], "1800": 21, "1811": 18, "1827": 23, "183": 21, "1834": 23, "1839": 20, "184": 32, "1851": 32, "1861": 20, "1871": 20, "1895": 23, "1897": 20, "19": [21, 31], "1908": 20, "1909": 17, "191": 20, "1912": 23, "192": 32, "1924": 23, "1926": 32, "19274": 19, "1927830372943777": 21, "1944": 23, "1945": 20, "195": 20, "1959": 20, "1961": 20, "1962": 20, "1967": 20, "1969": 20, "1976": 20, "1980": 23, "1986": 8, "1991": 23, "1997": 8, "19pt": [0, 2], "1b": 26, "1e": [0, 20, 23], "1f": [0, 2], "1gb": 2, "1h": 6, "1m": 21, "1x1": 20, "1x10": 20, "1x18": 21, "2": [10, 16, 17, 23, 26, 28, 29, 31, 32], "20": [4, 17, 18, 20, 21, 23, 29, 32], "200": [0, 18, 21, 29], "2000": [18, 19, 21], "20000": [20, 21], "2003": [1, 3], "2009": 20, "201": [19, 32], "2011": 20, "2013": 7, "2016": 8, "2017": 9, "2018": [0, 2, 11], "2019": [1, 3, 9, 13, 28, 29, 30], "202": 32, "2020": [1, 4, 7, 16, 17], "2021": [5, 10, 13, 16, 30], "2022": [5, 10, 11, 12, 15, 16, 23, 25, 26, 29, 30], "2023": [7, 10, 11, 12, 15, 16, 26, 30], "2024": [6, 7, 12, 16, 31], "2025": 6, "2027": 20, "2028": 20, "2029": 20, "203": 21, "203125": 25, "2032": 29, "2034": 32, "2037": 20, "2046": 23, "2050": 2, "205616125930776": 21, "2063": 20, "2064": 32, "2068": 20, "2073": 20, "2081": 20, "209": [20, 21], "2095": 20, "2097": 20, "2099": 20, "21": [0, 2, 17, 18, 20, 22, 32], "2106": 20, "21096220730527": 21, "212": 20, "2122": 21, "2133": 20, "214": 32, "2143": 20, "2154": 20, "2155": 23, "2165": 20, "2170": [23, 32], "2174": 32, "21778265": 32, "2180": 20, "2182": 20, "2186": 20, "2188": 20, "2198": 20, "22": 32, "2201": 20, "2205": 18, "2207": 29, "2208": 20, "2212": 26, "22179": 19, "2232": 20, "22330": 19, "2239": 20, "22500": 20, "2256": 20, "2263": 32, "2276": 20, "2283": 20, "23": [1, 3, 4, 5, 20, 21, 31, 32], "2304": [23, 26], "2313": 20, "2317": 20, "232": 21, "2323": 20, "2333": 20, "2337": 20, "2353": 20, "237": 20, "2371": 20, "2373": 20, "2380": 32, "2387": 23, "2389": 20, "2393": 20, "24": [18, 19, 20, 21, 31, 32], "2400": 23, "2406": 20, "241": 21, "2411": 32, "2425": 20, "2455": 20, "2462": 20, "2468": 20, "247": 32, "2478": 20, "2482": 32, "249": [21, 32], "24b": 1, "25": [17, 20, 21, 25], "250": [1, 4], "2500": [19, 20], "25000": [20, 21], "251": 20, "2518": 20, "25248486": 32, "253": [20, 32], "2532": 20, "2536": 20, "2537": 20, "2543": 20, "255": 20, "2557": 20, "256": [20, 26], "2564": 20, "2576": 20, "2579": 20, "2591": 20, "2592": 23, "2595": 20, "25966188": 32, "2614": 23, "2615": 20, "262053290805339": 21, "2630": 20, "2633": 20, "264": 32, "2647": 20, "26594367422115": 21, "2664": 20, "267": 21, "268": 21, "2682": 20, "2689": 20, "269": 32, "2698": 20, "27": [4, 20, 21, 26, 32], "2706": 20, "2711": 20, "2712": 20, "2719710113848373": 21, "2738": 20, "2739": 25, "2746": 21, "27500": 20, "2758": 20, "276": [20, 31], "27648": 0, "277": 21, "279": 32, "28": 21, "2815": 20, "284": 19, "2842": 20, "2846": 20, "2852": 20, "286": 20, "2862": 20, "2865": 20, "2872": 20, "289": 32, "28th": 4, "29": [0, 2, 23, 26, 32], "2919": 20, "2934": 20, "2941": 20, "2944": 20, "295": 32, "2954": 20, "2955": 20, "2956": 20, "2958": 21, "2965": 20, "297": 21, "2971": 20, "2976": 20, "298": [20, 21, 32], "2984": 20, "2986": 20, "2d": [0, 2], "2gb": 17, "2i": 23, "2m": 21, "2nd": 3, "2pt": [0, 1, 2, 4], "3": [17, 18, 21, 22, 26, 27, 28, 29, 30, 31, 32], "30": [18, 20, 21, 32], "3000": 19, "30000": [20, 21], "3001": 20, "3009": 20, "300px": 18, "3011": 20, "3013": 20, "3025": 20, "3049": 20, "305": 32, "3072": [23, 31], "3073": 18, "309": 20, "3099": 20, "31": [18, 32], "3114": 20, "313": 32, "315": 20, "3162": 20, "32": [1, 2, 17, 18, 20, 21, 23, 28, 32], "323": 32, "32500": 20, "32869": 17, "329": 32, "329154273345582": 21, "32b": 1, "33": [18, 21, 32], "3301": 21, "33044753": 32, "337": 32, "33744430690024": 21, "338": 32, "33836474": 32, "34": [18, 32], "3403": 20, "342": 20, "3442": 20, "3451": 20, "3486": 32, "3488": 20, "349": 32, "35": [2, 21, 29], "3500": 19, "35000": [20, 21], "350m": 26, "3515625": 25, "352": 25, "3523": 18, "353": 32, "36": [20, 21, 32], "3607": 21, "36674": 19, "3668": [21, 23], "367": 21, "368": 19, "36825": 19, "37": [20, 23], "3746": 20, "3750": 18, "37500": 20, "3759": 32, "3773": 20, "3793": 20, "3797": 20, "38": [20, 32], "383": 32, "384112744200534": 21, "3842": 20, "385": 23, "3850": 21, "3875": 20, "3889435308678326": 21, "3915": 20, "3927": 20, "3931": 20, "3938": 20, "394": 32, "3945": 32, "39453125": 25, "3946": 20, "3973": 20, "3f": [19, 20, 31], "3m": 21, "3rd": 1, "3x5": [0, 2], "4": [1, 2, 3, 4, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "40": [0, 2, 18, 21], "400": 18, "4000": [18, 19], "40000": [20, 21], "4001": 20, "4005": 20, "4007": 20, "402": 32, "4070479577071051": 21, "4075": 20, "4078": 20, "4096": 0, "41": [20, 21, 23, 32], "4100": 23, "410m": 3, "4118": 20, "4123": 32, "4126": 20, "4141": 20, "415": 20, "41515987": 32, "4155": 20, "416": 20, "4167": 20, "417": 20, "419": 20, "41e": [1, 4], "42": [18, 20, 32], "422": 20, "4230": 20, "424": [20, 32], "425": 20, "42500": 20, "4264": 20, "427": 20, "428": 20, "4293": 23, "43": [18, 20, 21, 32], "430": 20, "4315": 20, "432": 20, "433": 20, "436": 20, "4374993423367664": 21, "44": 32, "441": 20, "444": 32, "444657022227277": 21, "445": 32, "447": 20, "448": [25, 32], "4495": 20, "45": [20, 21, 24], "450": 20, "4500": [19, 20], "45000": [20, 21], "453125": 25, "454367770907213": 21, "4591": 21, "4592": 20, "46": [20, 28], "461": 32, "4612": 20, "4614": 20, "4619": 20, "462": 20, "4622": 32, "46240755": 32, "4627": 32, "467": 21, "47": [20, 32], "4716": 20, "473": 20, "4738": 23, "475": 20, "47500": 20, "4765625": 25, "4786": 20, "479": 20, "4803": 23, "4812": 20, "4826": 21, "484375": 25, "49": 21, "4921": 20, "4921875": 25, "497": 20, "4b": [3, 25], "4f": 21, "4gb": [1, 4], "4k": [4, 26], "4m": 21, "4pt": [0, 2], "5": [0, 1, 2, 17, 18, 20, 21, 23, 25, 26, 29, 30, 32], "50": [1, 18, 21, 29], "500": [1, 4, 19, 21, 22], "5000": [18, 19, 20, 21, 23], "50000": [20, 21], "500000": 0, "501": 32, "50257": 23, "503078942968957": 21, "5045": 20, "51": [20, 22], "512": [1, 4, 18, 26], "5120": 0, "5127": 20, "5181813091977734": 21, "519": 21, "52": [20, 21, 32], "520": 32, "5211": 20, "522": 20, "5242": 25, "5254": 23, "53": 32, "531": 32, "5318": 20, "5321": 20, "533": 19, "5336": 18, "5347": 25, "5388": 20, "539": 32, "5396": 20, "54": 21, "5437": 20, "5453": 20, "5473": 18, "5489": 18, "55": [20, 21], "5500": [19, 20], "55000": 21, "550px": 21, "5510": 20, "557712239995114": 21, "5580": 20, "56": [18, 23, 32], "560m": 5, "5617": 20, "5625": 25, "5653": 20, "5669": 32, "57": 32, "570": 32, "5707610099012776": 21, "5713": 20, "5756": 20, "57964344": 32, "58": [2, 21], "5819": 20, "582685867418279": 21, "5863": 20, "5894": 21, "59": [0, 1, 2, 3, 4, 5], "591": 19, "5931": 20, "595": 20, "5973": 20, "5975": 20, "5995": 18, "5_000": 22, "5d": [19, 20], "5e": [0, 2, 22], "5f": 19, "5m": 21, "6": [0, 6, 18, 20, 21, 22, 23, 25, 26, 30, 31, 32], "60": [18, 21, 23], "600": 18, "6000": 19, "60000": 21, "6013": 20, "6017": 20, "6051": 20, "60579": 19, "606": 32, "607": 32, "60729": 19, "6076": 20, "6087": 20, "6096": 20, "61": 20, "6114": 20, "61173964": 32, "612": 32, "6135": 20, "6166": 20, "6175335252350447": 21, "6177": 20, "6194": 20, "6196": 20, "6199": 20, "62": 23, "621": 32, "6223": 20, "625": 25, "6265": 20, "628": 20, "638": [20, 21], "6393": 21, "64": [0, 2, 19, 22, 23, 24], "6406": 25, "6411": 20, "642": 20, "64202727": 32, "6423": 20, "645": 19, "6464": 20, "65": [20, 21], "650": 19, "6500": 19, "65000": 21, "6514": 20, "652": 21, "6531856900705275": 21, "6555": 20, "66": [20, 21], "6612294775126752": 21, "664": [20, 32], "6654": 20, "6659": 20, "666": 32, "6692703950843093": 21, "67": [0, 2, 5, 20, 21], "67534827": 32, "68": 32, "682": 19, "6834": [20, 32], "6843": 20, "6880": 20, "69": 20, "6925": 20, "695": 32, "6955": 20, "6gb": 17, "6pt": [0, 2], "7": [4, 5, 17, 18, 20, 21, 25, 26, 27, 31, 32], "70": [18, 21], "7000": 19, "70000": 21, "7046": 21, "7086": 20, "709": 21, "70b": [1, 26], "71": 21, "7110": 20, "7121": 20, "713": 32, "716": 32, "716580436309544": 21, "7169": 20, "7172": 20, "7179": 20, "7180": 21, "72": [18, 20, 21, 32], "724": 21, "726918229927053": 21, "7288": 20, "7293": 20, "7298": [20, 25], "73": [21, 32], "7308": 21, "738": [31, 32], "73959792": 32, "74": [21, 32], "740": 20, "743693795963553": 21, "7454": 20, "746094297468178": 21, "7494": 20, "7496": 20, "75": [0, 2, 21, 28, 32], "7500": [19, 20], "75000": 21, "7501": 20, "7502": 20, "7523": 20, "7530": 20, "7552": 20, "76": [1, 4, 20, 29], "7634": 17, "7650": 20, "765625": 25, "7672": 18, "768": [23, 26, 28], "77": 20, "7734": 20, "7734375": 25, "7743": 20, "7748951742793246": 21, "7764": 20, "7767": 20, "78": [1, 4, 32], "7873": 20, "79754031778924": 21, "798": 32, "7b": [3, 23, 27], "8": [17, 18, 21, 25, 26, 32], "80": [17, 18, 21], "8000": 19, "80000": 21, "8005": 20, "8015": 32, "8022": 20, "8029": 21, "8063146353260925e": 32, "8089478089254367": 21, "8123": 20, "816": 20, "8176": 20, "819": 32, "8191": 20, "819255000074138": 21, "82": 20, "8224": 20, "8238": 25, "8264": 20, "83": [0, 2, 20], "8325": 21, "8344": 21, "8362": 32, "83683439539813": 21, "8398610504968342": 21, "8415": 20, "843": 32, "84375": 25, "8441": 20, "8467": 21, "84765625": 25, "85": [21, 24], "8500": 19, "85000": 21, "8540": 20, "8546": 20, "85546875": 25, "857054710388184": 21, "8589": 20, "859375": 25, "863": 32, "864": 32, "8666": 20, "8668": 20, "8697": 20, "87": [18, 20], "879318062464732": 21, "88": [20, 32], "89": [20, 23, 32], "892": 21, "8970": 20, "8981": 20, "8gb": 17, "9": [6, 17, 18, 21, 25, 32], "90": [18, 20, 21], "9000": 19, "90000": 21, "9023": 20, "9025": 20, "90373899401307": 21, "9046": 20, "905": 32, "9068": 18, "9079": 20, "908905029296875": 21, "909": 32, "91": [0, 2, 32], "9101": 20, "9163": 20, "9164": 20, "9166837202752751": 21, "9185": 20, "9190526549711127": 21, "921": 32, "9245": 20, "9253905269010243": 21, "94": [20, 21], "9408": 21, "941": 21, "943814170795518": 21, "9443": 18, "9444": 20, "9450": 20, "945132093597879": 21, "9468": 20, "9476": 20, "95": 21, "9500": 19, "95000": 21, "9520": 20, "9521": 20, "9536": 20, "9538": 20, "9543": 17, "955": 32, "9574": 20, "959": 20, "96": 23, "9640": 20, "9653": 20, "9675": 21, "97": 31, "975": 19, "975641382951965": 21, "976": 19, "977": 19, "979": 19, "9820": 32, "9830674364599212": 21, "98336813": 32, "984375": 25, "986": 19, "987": [20, 32], "988": 19, "989767319373302": 21, "99": 21, "991": 21, "9920": 20, "9964": 20, "9989984954101563": 19, "9994": 20, "9999999999999994": 21, "A": [0, 2, 3, 4, 5, 7, 9, 12, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32], "AND": [0, 2, 5], "And": [18, 27], "As": [12, 20, 22, 23, 25, 26, 27, 28, 29, 30], "At": [23, 27], "Be": [1, 4], "Being": 19, "But": [18, 25, 27], "By": [19, 23, 26], "FOR": 5, "For": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "IT": [0, 2, 27], "If": [0, 2, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 29, 30, 31], "In": [0, 1, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "It": [4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "Its": [18, 26], "NOT": [1, 2, 4, 17, 22, 26, 27, 30], "Not": [12, 21, 27], "Of": [25, 26, 27], "On": [0, 2, 15, 17, 22, 25], "One": [17, 21, 24, 26, 27, 28, 29, 30, 31], "Or": 18, "Such": [17, 29], "THE": 29, "TO": [0, 2], "That": [17, 20, 22, 23, 26, 30], "The": [0, 1, 2, 3, 4, 5, 6, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "Their": [10, 31], "Then": [1, 4, 23, 24], "There": [0, 2, 3, 6, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "These": [1, 4, 17, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31], "To": [1, 3, 4, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "With": [0, 2, 18, 22, 25], "_": [4, 26, 31], "__dict__": 23, "__future__": 21, "__getitem__": [2, 20], "__init__": [2, 20, 21, 23, 28, 31], "__len__": [2, 20], "_backward_hook": 23, "_backward_pre_hook": 23, "_buffer": 23, "_forward_hook": 23, "_forward_hooks_always_cal": 23, "_forward_hooks_with_kwarg": 23, "_forward_pre_hook": 23, "_forward_pre_hooks_with_kwarg": 23, "_is_full_backward_hook": 23, "_is_hf_initi": 23, "_load_state_dict_post_hook": 23, "_load_state_dict_pre_hook": 23, "_modul": 23, "_non_persistent_buffers_set": 23, "_paramet": 23, "_qkv_same_embed_dim": 23, "_state_dict_hook": 23, "_state_dict_pre_hook": 23, "a_i": 25, "a_list": 18, "ab": [2, 19, 20, 29], "abbrevi": 22, "abil": 30, "abise": [1, 4], "abl": [0, 2, 17, 18, 21, 22, 23, 24, 26, 30, 31], "about": [0, 1, 3, 4, 5, 6, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "abov": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "absenc": 30, "absolut": [22, 23, 26, 28], "abstract": [17, 22, 26, 30], "ac": 20, "acccess": 23, "acceler": [0, 1, 2, 3, 4, 22, 26], "accept": [0, 2, 5, 27], "access": [1, 2, 4, 17, 20, 22, 23, 24, 25, 26, 28, 31], "accid": 3, "accompani": 31, "accomplish": [17, 22, 27], "accord": [0, 2, 17, 23, 30], "accordingli": 25, "account": [17, 22, 27], "accumul": [0, 2, 19], "accur": 4, "accuraci": [0, 2, 3, 5, 24, 28, 29, 30], "achiev": [3, 25, 26], "acquir": [0, 2, 17], "across": [4, 5, 16, 28, 29], "act": [22, 23, 31], "action": [1, 4, 26], "activ": [0, 2, 16, 19, 20, 21, 22, 26], "activations_": 31, "actual": [0, 1, 2, 3, 4, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "acycl": 20, "ad": [17, 19, 22, 23, 24, 25, 27], "adam": [20, 21, 28], "adamw": [0, 2], "adapt": 31, "add": [17, 18, 20, 21, 23, 27, 31], "add_hook": 31, "add_mid_attn_hook": 31, "add_zero_attn": 23, "addit": [1, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29], "additioanli": 22, "additioanlli": [0, 2], "addition": [0, 2, 4, 17, 21, 26, 28, 30], "additional_dim": 22, "address": [25, 28, 29], "adequ": 17, "adher": 17, "adjust": [17, 22, 23, 25, 30], "admir": 26, "advanc": [4, 6, 17, 22, 25], "advantag": [4, 17, 24, 26, 27, 29], "affect": [1, 4, 25, 26, 31], "afford": 12, "after": [0, 2, 17, 19, 20, 22, 23, 24, 25, 26, 31], "again": [17, 19, 20, 23, 24, 25, 26, 27, 31], "against": [1, 4, 21, 24, 29], "agent": [2, 6, 26], "agent_executor": 27, "agent_hf": 27, "agent_hf_executor": 27, "agent_with_tool": 27, "agentexecutor": 27, "aggress": 19, "agnet": 27, "agre": [5, 21], "agreement": 5, "ahead": 17, "ahn": 12, "ahv": 28, "ai": [4, 6, 15, 26], "aim": [29, 30], "aimia": 17, "airplan": 3, "airport": 3, "aka": 16, "al": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "algebra": 18, "algorithm": [1, 4, 5, 23, 24, 25, 26, 30, 31], "alic": 26, "alien": 26, "align": [6, 26], "all": [0, 2, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "all_hidden_st": 28, "all_lett": 21, "all_loss": 21, "alloc": 21, "allow": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31], "allrecip": 27, "almost": [17, 25, 27], "along": 25, "alpha": 20, "alphabet": [17, 23], "alreadi": [1, 4, 17, 18, 22, 23, 25, 26, 27, 29, 30, 31], "also": [0, 1, 2, 3, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "alter": 21, "altern": [17, 18, 21, 22, 24, 26, 28, 29], "although": [17, 25, 26, 29, 30], "alwai": [0, 2, 17, 21, 25, 27, 29, 31], "am": 27, "american": 5, "amnes": 13, "among": 6, "amount": [17, 21], "an": [0, 1, 2, 3, 4, 5, 6, 7, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "anaconda3": [0, 2, 17, 22, 31], "analog": 5, "analys": [1, 3], "analysi": [5, 16, 24, 31], "anaphor_gender_agr": 5, "ander": 29, "anderen": 29, "andrej": [6, 9], "ani": [0, 1, 2, 3, 5, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31], "animate_subject_pass": 5, "annot": [17, 26, 28, 30, 31], "anoth": [1, 3, 5, 20, 21, 22, 23, 24, 28, 29, 30, 31], "another_tensor": 18, "answer": [1, 2, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "answer_id": 31, "answer_kei": 5, "answer_log_prob": 25, "answer_opt": [0, 2, 5, 29], "answer_options_list": [0, 2, 29], "answer_options_str": [0, 2], "answer_prob": 31, "answer_scor": 29, "answer_scores_bloom": 5, "answer_scores_gpt2": 5, "answerkei": [0, 2, 29], "anthrop": 26, "anticip": 17, "anymor": 21, "anyth": [0, 2, 17, 20, 23, 26], "apart": 19, "apect": 26, "api": [22, 27, 28], "api_wrapp": 17, "appar": 30, "append": [0, 1, 2, 4, 21, 22, 23, 25, 26, 29, 31], "appet": 27, "appetizer_chain": 27, "appli": [17, 18, 20, 21, 22, 23, 24, 28, 29, 31, 32], "applic": [2, 4, 20, 21, 22, 23, 24, 28, 29, 30], "approach": [4, 5, 6, 17, 23, 24, 25, 26, 27, 28, 29, 30], "appropi": [5, 17], "appropri": [5, 24, 29], "approxim": [17, 25, 29], "ar": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "arab": 21, "arang": 23, "arc": 30, "architectur": [1, 2, 3, 6, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31], "architecture_quirk": 2, "architecture_typ": 2, "archiv": 17, "area": [17, 26, 30], "aren": 23, "arg": [1, 4, 17, 22, 23], "argmax": [25, 29], "argsort": 31, "arguabl": [17, 29], "argument": [0, 2, 18, 22, 23, 24, 26, 28, 29, 30], "aris": 24, "arithmet": 16, "around": [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 25, 26, 27], "arrai": [18, 20, 28, 31, 32], "arriv": [0, 2, 28, 31], "art": [0, 2, 3, 6, 17, 22, 23, 25, 26], "articl": [1, 4, 17], "artifici": 8, "arxiv": [2, 26, 29], "as_query_engin": 4, "ascii": [21, 23], "ascii_lett": 21, "ask": [4, 5, 17, 20, 22, 26, 29, 30, 31], "aspect": [5, 17, 23, 25, 26, 28, 29, 31], "aspet": 5, "assert": 28, "assess": [1, 3, 5, 17, 28, 30, 31], "assign": [2, 5, 6, 17, 19, 21, 23, 24, 25, 26, 29, 30, 31], "assisst": 29, "assist": [4, 11, 23, 26], "assit": 30, "associ": [16, 19, 25], "asssess": 0, "assum": [0, 2, 22, 23, 24, 25], "assumpt": [29, 31], "atom": 30, "attempt": [28, 30], "attend": [3, 22, 23, 24], "attent": [0, 2, 9, 17, 20, 24, 25, 26, 31, 32], "attention_bia": 0, "attention_dropout": 0, "attention_mask": [0, 2, 17, 22, 23, 24, 25], "attic": 3, "attiont": 28, "attn": [23, 31], "attn_": 31, "attn_dropout": 23, "attn_weight": 31, "attribut": [6, 23, 29, 31], "attribute_target": 28, "attributed_fn": 28, "attribution_model": 28, "audio": 22, "author": [5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "auto": [0, 2, 4, 17, 22, 23, 26], "autoag": 12, "autoclass": [22, 24], "autom": [22, 29], "automat": [0, 2, 4, 12, 20, 22, 23, 24, 27, 29], "automodelforcausallm": [0, 2, 22, 24, 25, 26, 29, 31], "automodelforcausallmwithvaluehead": [1, 4], "automodelforseq2seqlm": 28, "automodelforsequenceclassif": 26, "autonom": 12, "autonotebook": [0, 2, 17, 22], "autotoken": [0, 1, 2, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "auxiliari": [21, 28], "avail": [0, 1, 2, 3, 4, 5, 9, 17, 18, 22, 25, 26, 27, 28, 29], "averag": [0, 2, 5, 17, 21, 25, 29], "average_tweet_length": 17, "avoid": [0, 1, 4, 23, 24, 25, 26, 27, 31], "aw": 25, "awai": [17, 23], "awak": 3, "awar": [26, 30], "awesom": 25, "axi": [0, 2, 32], "b": [0, 2, 4, 5, 17, 18, 20, 23, 26, 28, 29], "b_f": 32, "baai": 4, "bachelor": 6, "back": [8, 18, 22, 23, 25, 31], "backbon": [4, 24, 26, 27], "backend": [0, 2, 5, 17, 22, 25, 28, 29], "background": [3, 4, 5, 11, 22], "backpropag": [8, 9, 28], "backward": [0, 2, 19, 20, 21, 22, 28], "bad": [17, 19, 26], "baden": 17, "bag": 3, "baggag": 3, "bai": [11, 26], "balanc": 24, "bank": 17, "bar": [5, 30], "barplot": 5, "base": [0, 1, 2, 3, 4, 5, 6, 10, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "baselin": [1, 4], "basic": [7, 17, 18, 19, 20, 21, 22, 27], "batch": [0, 1, 2, 4, 17, 20, 22, 23, 24, 26, 28, 31], "batch_first": 23, "batch_label": 28, "batch_repr": 28, "batch_siz": [0, 1, 2, 4, 20, 22, 28], "bay": 21, "bayesian": [10, 24], "bbq": 30, "bc": 20, "bd": 20, "bd0xbfgjkt": 17, "beam": [3, 25], "bear": 30, "becam": [29, 30], "becaus": [0, 1, 2, 4, 17, 19, 20, 21, 22, 23, 24, 26, 29, 31], "becom": [19, 20, 29], "been": [4, 5, 17, 22, 23, 24, 25, 26, 28, 29, 30, 31], "befor": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 26, 27, 29, 31], "begin": [17, 22, 23, 25, 26, 32], "behav": 31, "behavior": [4, 5, 12, 13, 20, 25, 26, 30], "behind": [17, 19, 20, 23, 26, 27, 28, 29, 31], "behvaior": [9, 30], "being": [0, 2, 4, 19, 22, 24, 25, 26, 30, 31], "beings": 25, "believ": 30, "belong": 22, "below": [1, 2, 4, 5, 6, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "bench": [29, 30], "benchmark": [5, 14, 17, 25], "bender": 30, "benefici": 30, "benefit": 24, "bengio": [1, 3, 8], "berlin": 28, "bert": [1, 3, 9, 20, 22, 23, 24, 28], "bert_tok": 24, "bertmodel": 28, "berttoken": 28, "bertviz": [17, 28], "besid": 3, "best": [1, 3, 4, 19, 24, 25, 26, 29], "beta": [29, 32], "better": [3, 6, 17, 19, 21, 23, 27, 29], "between": [1, 3, 4, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 31], "beyond": [10, 17, 23, 29, 30], "bfloat16": 18, "bge": 4, "bia": [5, 16, 20, 23, 26, 29, 30, 32], "bias": [17, 20, 22, 26, 29, 30], "bias_k": 23, "bias_v": 23, "bidirect": [1, 3, 9, 24], "big": [3, 29, 30], "bigger": 20, "bigram": 29, "bigscienc": 5, "billion": 27, "bin": 17, "binari": [24, 26, 29], "biologi": 30, "bird": [0, 25], "bit": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21], "bite": 27, "bitsandbyt": 4, "black": 17, "blackbox": [22, 29, 31], "blank": 21, "bleu": 29, "bleu_scor": 29, "blimp": 5, "blob": [26, 31], "block": [4, 17, 20, 22, 23, 26, 27, 28, 31], "blog": [4, 9, 25, 26], "blogpost": [11, 12, 16, 20, 26, 29, 30], "bloom": 5, "bloom_predict": 5, "bloom_scor": 5, "bloomtokenizerfast": 31, "blueprint": 22, "bmatrix": [23, 32], "bnb_4bit_compute_dtyp": 26, "bnb_4bit_quant_typ": 26, "bnb_4bit_use_double_qu": 26, "bnc": 17, "bo": [23, 25, 32], "boe": 17, "boi": 3, "bommasani": 15, "bonu": [1, 4], "book": [2, 6, 17], "bool": 18, "boolean": 18, "boolq": 29, "boredom": 3, "born": 5, "borrow": 21, "bos_token_id": 0, "bot": 17, "both": [4, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 29, 30], "bottl": 31, "bottleneck": 27, "bpe": 2, "braun": 23, "break": 27, "brian": 6, "bridg": 3, "brief": [0, 2, 3, 5, 7, 25], "briefli": [1, 3, 4, 5, 23, 24, 26], "bright": 3, "bring": 5, "british": 17, "broad": 26, "broadli": 26, "broken": 3, "brown": [17, 23, 24, 28], "brows": 22, "bruckner": 21, "brun": 28, "brush": 26, "btig": 17, "bug": [1, 4], "bui": 17, "build": [1, 3, 5, 9, 17, 18, 20, 22, 23, 25, 26, 27, 28, 29], "build_classifi": 28, "build_dataset": [1, 4], "bullet": 26, "bullish": 17, "bye": 5, "bynd": 17, "byte": 23, "c": [0, 2, 4, 5, 18, 20, 21, 23, 26, 29], "c_attn": 23, "c_fc": 23, "c_proj": 23, "cach": 31, "cage": 27, "calcul": [0, 1, 2, 4, 5, 20, 21, 23, 24, 26, 29, 31, 32], "calculu": 20, "calibr": 29, "call": [1, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "came": 5, "camera": 3, "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "candid": 19, "cannot": [3, 17, 22, 23, 28, 29], "cap": [17, 20], "capabl": [29, 30], "capac": 26, "capit": [25, 28, 31], "caption": 23, "captur": [5, 21, 22, 24, 26], "carcass": 22, "care": [1, 3, 4, 17, 18, 22, 27, 29, 31], "carefulli": [0, 1, 2, 3, 23, 28], "caribbean": 17, "carniv": 17, "carperai": 26, "carri": [17, 23], "case": [0, 2, 4, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31], "cashier": 5, "cast": 18, "cat": [0, 2, 18, 21, 22], "catastroph": 26, "categori": [2, 5, 21, 24, 26, 29], "category_tensor": 21, "category_tensor_": 21, "cauliflow": 27, "caus": 5, "causal": [0, 2, 16, 22, 23, 24, 25, 28, 29, 31], "causallm": 24, "cc": 17, "ccl": 17, "cdot": 29, "ce": 20, "cell": [0, 4, 5, 17, 22, 24, 31], "celoss": 22, "cemex": 17, "center": 25, "central": 17, "ceo": 17, "certain": [5, 17, 19, 20, 22, 23, 24, 25, 28, 29, 31], "cfg": 31, "cg": 20, "chain": [0, 1, 2, 10, 20, 25, 27, 30], "challeng": 30, "chanc": 29, "chang": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 22, 24, 25, 26, 28, 29, 30], "char": [17, 18, 32], "charact": [17, 18, 23, 24], "character": 16, "charactersitc": 2, "chat": [4, 10, 23, 26, 27], "chatgpt": 11, "chatopenai": 27, "cheat": 7, "check": [3, 4, 5, 17, 18, 20, 23, 24, 25, 26, 28, 29, 30, 31], "checkpoint": [22, 29], "chek": 23, "chen": 12, "chicago": 25, "chien": 28, "childhood": 30, "children": [3, 30], "chimnei": 29, "chines": 21, "chip": 17, "choic": [0, 2, 4, 5, 17, 22, 24, 25, 26, 27, 29, 30], "chollet": 30, "choos": [17, 19, 21, 24, 25, 26, 29, 31], "chop": 4, "chosen": [4, 25, 26, 29], "christian": 6, "chunk": [17, 29], "ci": 5, "circuit": 16, "cite": [1, 4], "citi": [3, 24, 25], "cl": [24, 28], "claim": 2, "class": [0, 1, 2, 3, 4, 7, 10, 11, 12, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "classif": [3, 11, 17, 20, 22, 24, 26, 29], "classifi": [3, 21, 22, 28], "claus": 5, "clean": [0, 2, 3, 17, 20, 31], "clean_cach": 31, "clean_logit": 31, "clean_logit_diff": 31, "clean_prompt": 31, "clean_resid_pr": 31, "clean_token": 31, "clean_tweet": 17, "cleaned_dataset": 17, "cleaned_dataset_split": 17, "cleaned_tweet": 17, "cleanest": 29, "clear": 20, "clear_output": 4, "click": [17, 18, 19, 20, 21, 22, 24, 26, 28], "clip": [20, 24], "clip_grad_value_": 20, "clone": 26, "close": [22, 24, 25, 26, 29], "closer": [20, 23, 25, 27, 30], "cloth": 3, "cnn": [1, 4], "cnn_dailymail": [1, 4], "co": [4, 17, 23], "code": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "coder": 1, "coeffici": [1, 4, 5], "coffe": 3, "cognit": [6, 29], "cogsci": 6, "col": 18, "col_vector": 18, "colab": [0, 1, 2, 3, 4, 5, 22, 24, 25, 26, 28], "cold": 3, "collabor": 17, "collat": [0, 1, 4, 22], "collate_fn": 0, "collect": [2, 17, 21, 22, 26], "color": [3, 20, 26, 28], "color_continuous_midpoint": 31, "color_continuous_scal": 31, "column": [0, 2, 17, 21, 22, 29], "column_nam": [17, 22, 24], "com": [21, 26, 31], "comaprison": 29, "combin": [0, 2, 17, 21, 23, 24, 25, 29], "come": [3, 5, 17, 21, 22, 23, 25, 26, 27, 29, 30], "comfort": 17, "commend": 0, "comment": [0, 1, 2, 4, 5, 17, 22, 23], "commerici": 26, "commit": 17, "common": [0, 2, 4, 17, 20, 22, 23, 24, 25, 26, 29, 30], "commonli": [4, 17, 20, 22, 23, 24, 26, 29, 30], "commonsens": [0, 2, 10], "commonsense_qa": [0, 2, 29], "commonsenseqa": [0, 2, 25, 29, 30], "commonsenseqadataset": 2, "commun": [17, 22, 26, 27, 30], "comp": [0, 2], "compact": 4, "compani": 29, "compar": [0, 1, 2, 3, 4, 5, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31], "comparis": [25, 27], "comparison": [1, 2, 3, 26, 29, 30, 31], "compelt": 5, "competit": 3, "complementari": 25, "complet": [0, 1, 2, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31], "completion_to_prompt": 4, "complex": [18, 25, 27], "complex_np_island": 5, "complic": [20, 23], "compon": [0, 1, 3, 4, 16, 20, 23, 26, 27], "composed_chain": 27, "composed_result": 27, "composit": 30, "comprehens": 2, "compulsori": 6, "comput": [0, 1, 2, 4, 6, 10, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "compute_loss": 22, "con": 25, "concaten": [18, 25, 28], "concentr": 27, "concept": [4, 6, 8, 18, 20, 22, 23, 24, 25, 26, 30, 31], "conceptu": [0, 2, 3, 4, 5, 6, 22, 23, 24, 26, 29, 30, 31], "concern": 5, "concis": [1, 4], "conclud": 30, "conclus": 30, "concpetu": 0, "concret": [1, 3, 19, 22, 23, 26, 27], "cond_prob_nam": 21, "conda": [17, 20], "condens": 20, "condit": [5, 17, 19, 21, 29], "conditional_scor": [5, 29], "conduct": 6, "confid": [5, 25, 29], "config": [0, 1, 4, 22, 24], "configr": 0, "configur": [2, 3, 4, 22, 23, 25, 26], "configut": [0, 2], "confus": 24, "connect": [17, 20, 30, 31, 32], "consecut": 21, "consent": 2, "consequ": 25, "consid": [0, 1, 2, 3, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "consist": [1, 4, 5, 6, 10, 17, 19, 20, 21, 22, 23, 26, 29, 31], "constitu": 17, "constitut": [20, 22, 26], "constraint": 29, "construct": [0, 2, 4, 5, 18, 20, 21, 22, 25, 26, 27, 29, 30], "construct_test_sampl": [0, 2], "contain": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30], "contamin": 29, "content": [1, 3, 17, 22, 23, 26, 30], "context": [0, 1, 3, 4, 5, 6, 10, 11, 13, 17, 18, 20, 22, 23, 24, 25, 26, 29, 30, 31], "context_input_id": 25, "context_prompt": 25, "context_window": 4, "contextev": 28, "contextu": [0, 13, 23], "continu": [5, 21, 22, 24, 28, 29], "contradict": 3, "contrast": [5, 22, 23, 28, 29, 30], "contrast_prob_diff": 28, "contrast_target": 28, "contribut": [2, 17, 23, 28, 31], "control": 27, "conv1d": 23, "conveni": [20, 22], "convent": 17, "converg": [24, 26], "convers": [23, 26], "converst": [0, 2], "convert": [0, 2, 4, 17, 18, 22, 23, 28, 29], "convert_ids_to_token": 28, "cook": 26, "core": [0, 4, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "corner": 3, "coronaviru": 17, "corpor": 3, "corpora": [17, 29, 30], "corpu": [0, 2, 17, 22, 23, 30], "correct": [0, 2, 3, 23, 24, 25, 26, 27, 29, 30, 31], "correct_answ": 31, "correct_index": 31, "correcti": 29, "correctli": [4, 20, 21, 22, 23, 24, 26, 29], "correl": [5, 28, 29], "correspond": [0, 2, 5, 20, 22, 23, 24, 26, 28, 29], "corrupt": 31, "corrupted_logit": 31, "corrupted_logit_diff": 31, "corrupted_prompt": 31, "corrupted_token": 31, "cosin": [20, 22, 23, 24, 26], "cosinesimilar": 20, "cost": 24, "costli": [22, 26], "cot": 3, "cotterel": 6, "could": [4, 5, 17, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "count": [29, 30], "counterfactu": 13, "countri": [3, 21], "country2idx": 21, "cours": [2, 7, 17, 22, 25, 26, 27, 31], "court": 25, "couru": 28, "courvil": 8, "cover": [0, 6, 10, 11, 12, 17, 22, 24, 25, 29], "coverag": 29, "cpu": [0, 1, 2, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "craft": 21, "crawl": [17, 29], "creat": [0, 2, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31], "create_react_ag": 27, "creation": 26, "creativ": [3, 25], "credit": 17, "crisp": 17, "criteria": [17, 30], "criterion": [21, 28], "critic": [1, 3, 4, 6, 17, 20, 22, 28, 29, 30, 31], "cross": [24, 28], "cross_attent": 28, "crossentropi": 24, "crossentropyloss": [20, 22, 28], "crowd": 3, "crucial": [17, 28, 29], "csv": [2, 5, 25, 29], "cuda": [0, 1, 2, 4, 5, 17, 22, 25, 26, 28, 29, 31], "cultur": 5, "cumbersom": 26, "cumul": 21, "curat": [22, 29], "curiou": [23, 25, 31], "current": [2, 20, 21, 23, 26, 28, 31], "current_loss": 20, "curs": [1, 3], "curv": [0, 2], "custom": [0, 2, 4, 20, 22, 26, 28], "customiz": 17, "cut": 17, "cv": 22, "cx": 17, "cycl": 19, "czech": 21, "d": [0, 1, 2, 4, 18, 20, 21, 22, 24, 26, 29], "d83d2b": 26, "d_h": 32, "d_model": 23, "d_wide": 20, "dai": 25, "daili": 17, "danger": 3, "data": [0, 1, 2, 3, 4, 5, 22, 23, 24, 26, 28, 29, 30], "data_col": [1, 4, 22, 24], "data_dir": 28, "data_pref": 28, "data_typ": 28, "databas": [4, 26], "datacol": 24, "datacollatorforlanguagemodel": [0, 22, 24], "datacollatorformlm": 24, "datafil": 21, "datafram": [1, 4, 20, 21, 22], "dataload": [0, 1, 2, 4, 17, 20, 22], "datapoint": [21, 24], "datas": 18, "dataset": [0, 1, 2, 4, 5, 20, 21, 22, 24, 26, 29, 30], "dataset_batch_s": 26, "dataset_df": 4, "dataset_nam": [1, 4], "dataset_s": 17, "dataset_split": 2, "datatyp": 18, "datset": [1, 4], "daughter": 3, "db": 4, "de": [17, 20], "deactiv": 21, "deadli": 3, "deadlin": [0, 1, 2, 3, 4, 5], "deadlock": 31, "deal": [6, 20, 23, 29], "debat": [15, 17, 29], "debug": [25, 31], "debugg": 31, "decad": 24, "decai": 22, "decid": 26, "decim": 32, "declar": 18, "decod": [0, 1, 2, 3, 4, 21, 22, 23, 26, 28, 29], "decoder_attent": 28, "decoder_token": 28, "decompos": [27, 30], "decreas": [0, 2, 20, 22, 24, 26], "dedic": [1, 3, 22], "deem": 28, "deep": [1, 3, 6, 8, 9, 17, 24], "deeper": [1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 23, 30], "deepli": 5, "def": [0, 1, 2, 4, 17, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "default": [2, 18, 19, 21, 22, 23, 26, 27, 28, 29, 31], "defin": [0, 2, 4, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31], "definit": [17, 21, 22, 23, 25], "degre": 19, "deliber": 10, "delin": 23, "deliv": 20, "demo": [27, 31], "demonstr": [10, 17, 26, 28], "den": 23, "densiti": [1, 3, 19], "depedn": 26, "depend": [0, 2, 17, 18, 21, 22, 23, 24, 26, 27, 28, 30], "deploi": 4, "deploy": [26, 29], "depnd": 4, "deprec": 31, "depth": 22, "der": 23, "deriv": [19, 20], "descend": 31, "descent": 19, "describ": [0, 2, 4, 5, 17, 21, 22, 25, 26, 29, 30], "descript": [0, 1, 2, 4, 5, 27], "design": [20, 29], "desir": [17, 18, 23, 24, 26, 30], "dessert": 27, "dessert_chain": 27, "detach": [18, 20, 21, 31], "detail": [4, 17, 22, 23, 24, 25, 26, 27, 29, 30], "detect": 30, "determin": [17, 18, 20, 21, 23, 24, 29], "determiner_noun_agreement_with_adjective_1": 5, "determinisit": 25, "determinist": 21, "detial": 25, "develop": [0, 2, 7, 19, 21, 22, 23, 24, 26, 27, 28, 30], "deviat": 19, "devic": [0, 1, 2, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "device_map": [4, 26], "devlin": [1, 3, 9], "df": 5, "df_boolq": 29, "dh": 20, "di": [17, 27], "diagnos": 13, "diagram": 25, "dialogu": [26, 30], "dict": [0, 1, 2, 4, 17, 21, 28, 29], "dict_kei": [0, 2], "dictionari": [2, 21, 23], "did": [0, 1, 2, 4, 17, 20, 22, 24, 25, 26, 31], "diff": 19, "differ": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "differenti": 20, "difficult": [5, 17, 20, 26, 29], "difficulti": [5, 17, 25], "dig": [1, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20], "digit": 17, "digraph": 20, "dim": [21, 22, 23, 31, 32], "dim_feedforward": 23, "dimens": [0, 2, 17, 18, 20, 22, 23, 24, 26], "dimension": [1, 3, 18, 23], "dimes": 18, "ding": 11, "dinner": 27, "dinnerplan": 27, "direct": [19, 20, 26], "directli": [4, 17, 18, 23, 24], "directori": [22, 28], "disabl": 31, "disadvantag": 4, "disclaim": [27, 30], "discov": 26, "discuss": [1, 3, 5, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "dish": 4, "disk": 17, "displai": 4, "dissect": [1, 3], "dissid": 17, "dissoci": 15, "dist": 23, "distilbert": 26, "distinct": 26, "distinctli": 30, "distinguish": [21, 24, 29, 30], "distractor": 29, "distribut": [20, 21, 24, 25, 29], "div_term": 23, "dive": [4, 22, 23, 30], "diverg": [1, 4, 24], "divers": [17, 29], "diviat": 17, "divid": [29, 32], "divis": [18, 21], "dm": 21, "do": [0, 1, 2, 3, 4, 5, 10, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "do_sampl": [0, 1, 2, 4, 22, 25], "doc": [4, 18, 21, 22, 26, 27, 29], "docstr": [17, 23], "document": [1, 3, 4, 18, 20, 21, 22, 23, 24, 25, 27, 29], "documet": 18, "doe": [0, 1, 2, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "doesn": [22, 24, 25, 26, 29, 31], "dog": [0, 2, 23, 24, 28], "domain": [22, 23, 29, 30], "don": [0, 1, 2, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 29, 31], "done": [17, 22, 23, 24, 25, 29, 30, 31], "dot": [18, 24, 28], "dotenv": 17, "doubl": 28, "doubt": 22, "doveski": 21, "down": [0, 1, 2, 3, 17, 20, 23, 26, 28], "downaload": [0, 2], "download": [0, 1, 2, 4, 5, 17, 22, 23, 24, 27, 28, 31], "downstream": 31, "draw": [20, 25, 29, 30], "drawn": 18, "drawstr": 3, "dream": 3, "dreamwork": 3, "drink": 3, "drive": [3, 17], "driven": 30, "drop": [17, 23, 25, 28], "dropout": [21, 23], "dropout1": 23, "dropout2": 23, "dropout3": 23, "dtype": [18, 19, 23], "du": 23, "due": [5, 17, 31], "duplic": [21, 31], "dure": [1, 2, 3, 4, 5, 17, 19, 21, 23, 24, 26, 29, 31], "dust": 3, "dutch": 21, "dv": 20, "dw": 20, "dx": 20, "dy": 20, "dynam": 22, "dz": 20, "e": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "each": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "ear": 21, "earli": [8, 24, 26, 28], "earlier": [26, 28], "eas": 28, "easi": [20, 22, 29], "easier": [22, 26, 31], "easiest": 5, "easili": [17, 22, 29, 31], "eat": 25, "ect": 6, "edg": 20, "edit": 16, "educ": [9, 17], "ef": 20, "effect": [17, 20, 22, 26, 29, 31], "effici": [4, 10, 11, 20, 22, 26], "effienc": 21, "eighth": 14, "either": [5, 17, 24, 27, 31], "elazar": 13, "electron": 17, "element": [18, 21], "elementari": 30, "elementwise_affin": 23, "eleutherai": [0, 25], "elhag": 16, "elicit": [5, 10, 25, 26, 30], "elif": [0, 2, 5, 17, 22, 25, 28, 29, 31, 32], "els": [0, 1, 2, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32], "elsewher": 21, "email": [2, 17], "emb": 23, "emb_dim": 28, "embed": [4, 17, 20, 21, 23, 25, 28, 29, 30, 31, 32], "embed_dim": 23, "embed_model": 4, "emerg": 29, "emoji": [17, 23], "empir": 19, "empirical_mean": 19, "emploi": [29, 30], "employe": 3, "empti": [21, 27], "en": [0, 2, 4, 17, 22, 28], "enabl": [20, 23, 27], "enable_nested_tensor": 23, "enc1": 23, "enc2": 23, "enc3": 23, "encod": [1, 4, 17, 21, 22, 23, 26, 28, 29, 31], "encoder_attent": 28, "encoder_lay": 23, "encoder_token": 28, "encoding_d": 29, "encoding_en": 29, "encount": 24, "encourag": [6, 17], "end": [0, 1, 2, 4, 18, 21, 23, 24, 25, 26, 29, 30, 31, 32], "endofsequ": 23, "endors": 30, "endpoint": [25, 27, 28], "engin": [4, 17, 20, 23, 24, 27, 29, 31], "english": [17, 21, 28, 29], "eniron": 26, "enrich": 17, "ensur": [17, 23, 24], "entail": [3, 24], "entir": [0, 5, 17, 20, 22, 23, 24, 27], "entiti": 24, "entor": 2, "entropi": 24, "enumer": [1, 4, 20, 21, 31, 32], "env": [0, 2, 17, 22, 27, 31], "environ": [0, 2, 4, 17, 22, 26, 31], "eo": [21, 22, 25, 32], "eos_tensor": 22, "eos_token": [0, 1, 2, 4, 22], "eos_token_id": [0, 1, 4, 22, 25], "eosindex": 21, "ep": 23, "epoch": [0, 1, 2, 4, 17, 20, 22, 24, 26, 28], "epsilon": 32, "eq": 28, "equal": [18, 21, 29], "equip": [6, 17, 23, 24], "equival": [17, 25], "eras": 19, "error": [0, 2, 8, 17, 22, 26, 31], "especi": [0, 2, 17, 21, 26, 29, 30], "ess": 17, "essenti": [17, 21, 22, 23, 24, 31], "essentiali": 22, "establish": 17, "estat": 17, "et": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "etc": [0, 2, 4, 17, 20, 22, 23, 24, 28, 29, 30], "ethic": [5, 30], "eval": [0, 2, 31], "eval_dataset": 22, "eval_loss": 22, "eval_step": 22, "eval_strategi": 22, "evalu": [0, 1, 2, 4, 6, 22, 24, 26], "evalut": 29, "evas": 4, "even": [17, 18, 20, 22, 24, 26, 27, 28, 29], "eventu": 20, "everi": [0, 2, 17, 20, 21, 22, 23, 24, 25, 26, 28], "everyth": 26, "evid": [5, 29], "evolv": [1, 3], "ex": [2, 3, 4, 24], "ex1": 18, "ex1_col": 18, "ex1_col_tran": 18, "ex1_row": 18, "exact": 20, "exactli": [21, 22, 23, 25, 26, 27, 31], "exam": [6, 30], "exampl": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "examples_df": 25, "exce": [17, 24, 25], "exceed": 25, "excel": [6, 9, 17, 31], "except": [21, 29, 31], "exclud": [0, 22], "exclus": [6, 20, 21], "execis": [0, 2], "execut": [0, 1, 2, 3, 4, 5, 17, 26, 27, 31], "exemplifi": [24, 29], "exercis": [17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31], "exercise1a": 18, "exercise1b": 18, "exercise2": 18, "exercise3": 18, "exerpt": 29, "exhaust": [21, 24, 25, 30], "exhibit": [5, 24, 29, 30], "exist": [17, 20], "existential_there_object_rais": 5, "exp": [21, 23, 25, 29, 32], "expect": [0, 1, 2, 4, 17, 21, 22, 25, 26, 27, 28, 29], "experi": [6, 17, 25, 26, 27, 28], "experienc": 25, "experiment": 29, "expert": 30, "explain": [0, 1, 3, 4, 5, 20, 21, 26], "explan": [4, 5, 10, 13, 22, 26, 28, 29], "explanatori": 21, "explicit": [22, 23, 30], "explicit_train": 22, "explicitli": [17, 18, 22, 31], "explor": [0, 2, 3, 4, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28], "express": 31, "extend": [4, 17, 18, 20, 30], "extens": [0, 17, 27], "extent": 29, "extern": 17, "extract": [17, 23, 24, 28], "extrem": 26, "f": [0, 2, 4, 17, 18, 19, 20, 21, 22, 25, 26, 28, 29, 31, 32], "f1": 29, "f1_score": 29, "f_": 29, "face": [28, 29, 30], "facebook": 26, "facet": 28, "fact": [23, 30], "facto": 17, "factscor": 30, "factual": [16, 29, 30], "fail": 24, "fair": 30, "faith": 30, "fals": [0, 1, 4, 18, 20, 21, 22, 23, 25, 26, 28, 29, 31], "false_neg": 29, "false_posit": 29, "famili": 25, "familiar": [4, 17, 18, 21, 22, 27, 28, 29, 30], "far": [17, 22, 24, 26, 30], "fashion": 3, "fast": 25, "faulen": 23, "favor": 21, "favour": 17, "favourit": 25, "fct": 17, "featur": [17, 21, 27, 28], "fed": [17, 21], "feed": [20, 25], "feedback": [1, 11, 26], "feel": [0, 1, 2, 3, 5, 19, 22, 23, 25, 26], "few": [0, 1, 2, 3, 6, 7, 10, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29], "few_shot_predict": 25, "few_shot_prompt": 25, "few_shot_templ": 25, "fewer": 26, "ffn": [31, 32], "ffnn": 31, "fg": 20, "field": [5, 17, 26, 30], "fifth": 11, "fig": 5, "figur": [1, 4, 20, 21, 24, 26, 27], "file": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 27, 28, 29], "file_download": 31, "fill": [5, 18, 27], "filter": [17, 26], "filterwarn": [19, 20, 21], "final": [0, 2, 6, 17, 19, 21, 22, 25, 26, 28, 29, 30], "final_lay": 31, "financi": 17, "find": [1, 2, 4, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30], "fine": [6, 10, 17, 22, 25, 27, 28, 29, 30], "finetun": [1, 4, 26], "finetuning_data": 2, "finetuning_data_s": 2, "finetuning_typ": 2, "finish": [20, 23], "finit": 23, "first": [0, 2, 4, 7, 8, 9, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "first_top": 31, "firt": 27, "fit": [19, 20, 22, 24, 26, 29], "five": 23, "fix": [0, 19, 21, 22, 26, 29, 31], "flan": [28, 29], "flask_serv": 31, "flatten": [18, 20], "flaw": 21, "flexibl": [20, 23], "flexibli": [18, 24], "float": [18, 19, 23, 31], "float16": [4, 18, 25, 26, 31], "float32": [0, 18, 19], "float64": [18, 19], "floattensor": 28, "floor": 21, "flow": [3, 20, 31], "flu": 3, "fluenci": 29, "fluent": [17, 22, 29], "fnko": 17, "focu": [1, 23, 26, 29, 30], "focus": [0, 2, 22, 26, 27, 29], "fold": 26, "follow": [0, 1, 2, 3, 4, 5, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "fonder": 30, "food": [25, 27], "footbal": 3, "forc": [25, 28, 31], "force_download": 31, "forget": [0, 2, 20, 22, 26], "fork": 31, "form": [0, 2, 3, 4, 17, 18, 26, 29, 30], "formal": [0, 2, 9, 23, 26, 30], "format": [0, 2, 4, 5, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29], "formatt": 17, "formatting_func": 26, "formatting_prompts_func": 26, "former": 24, "formul": [0, 1, 2, 3, 5], "formula": 23, "forsequenceclassif": 24, "forum": [1, 3], "forward": [0, 2, 20, 21, 22, 23, 28, 31, 32], "forwat": [0, 2], "foster": 17, "found": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29], "foundat": [10, 15, 17, 30], "four": [0, 2, 25], "fourth": 10, "fox": [23, 24, 32], "fp16": 22, "frac": [24, 25, 26, 28, 29], "fraction": 28, "framework": [12, 16, 25, 26, 27], "franc": [28, 31], "frank": [6, 18, 19, 20, 21, 25], "free": [0, 1, 2, 3, 5, 17, 22, 23, 25, 26, 29], "freeli": 22, "freez": [26, 31], "french": [21, 28], "freq_of_first_el": 23, "freq_of_pair": 23, "freq_of_second_el": 23, "frequenc": 23, "frequent": [17, 18, 22, 23], "fresh": 21, "fridai": 17, "fridg": 27, "friendli": 23, "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "from_dict": 21, "from_docu": 4, "from_pretrain": [0, 1, 2, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "from_prtetrain": 22, "front": 2, "frozen": [22, 26, 29], "ftfy": 28, "fuch": 23, "fulfil": 26, "full": [1, 4, 17, 18, 20, 23, 24, 25, 28, 31], "full_prompt": 25, "fuller": 29, "fulli": [17, 22, 28], "fun": [2, 3], "function": [0, 1, 2, 4, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31], "functool": 31, "funko": 17, "further": [0, 2, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 31], "furthermor": [1, 3, 5, 9, 17, 20, 21, 28, 29, 30, 31], "futur": [22, 25, 26], "futurewarn": 31, "fwd_hook": 31, "fyi": 17, "g": [0, 1, 2, 4, 5, 6, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "gain": [3, 17, 24, 26, 28], "game": 3, "gamma": 32, "gao": [17, 26], "garbag": [3, 26], "gaussian": [19, 20], "gave": 31, "gavin124": [1, 4], "ge": 20, "gebru": 17, "gelu": 20, "gender": [16, 30], "gener": [0, 1, 2, 5, 6, 7, 8, 9, 10, 12, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "generate_kwarg": 4, "generated_text": 28, "generation_kwarg": [1, 4], "ger": 5, "german": [0, 1, 2, 3, 4, 5, 21, 23, 29], "germani": 5, "get": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "get_act_nam": 31, "get_activ": 31, "get_cont": 4, "get_data": 28, "get_devic": 31, "get_lay": 31, "get_layers_w_attn": 31, "get_model_and_token": 28, "get_past_lay": 31, "get_pos_data": 28, "get_pre_wo_activ": 31, "get_prob": 21, "get_sentence_repr": 28, "get_surprisal_dataset": 21, "get_surprisal_item": 21, "getpass": 27, "giagant": 26, "giant": 14, "git": 17, "github": [17, 26, 31], "githubusercont": 21, "give": [1, 3, 4, 17, 18, 25, 26, 27, 28, 31], "given": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "glare": 3, "glimps": 17, "glue": 29, "go": [0, 1, 2, 4, 17, 18, 19, 22, 23, 25, 26, 29, 30], "goal": [0, 2, 4, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "goal_fun": 20, "goe": [21, 26, 29], "gold": [1, 3, 4, 17, 20, 21, 29], "gone": 19, "good": [1, 3, 4, 5, 17, 19, 21, 22, 25, 26, 27, 29, 30], "goodfellow": 8, "googl": [17, 28, 29], "got": [30, 31], "govern": 3, "gpt": [1, 3, 4, 5, 6, 9, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "gpt2": [1, 2, 4, 5, 17, 22, 23, 24, 26, 28, 29, 31], "gpt2_lm": 23, "gpt2_model": 26, "gpt2_predict": 5, "gpt2_scorer": 5, "gpt2attent": 23, "gpt2block": 23, "gpt2doubleheadsmodel": 24, "gpt2forsequenceclassif": 24, "gpt2fortokenclassif": 24, "gpt2lmheadmodel": [0, 2, 22, 23, 24], "gpt2mlp": 23, "gpt2model": 23, "gpt2token": [0, 2, 22], "gpt2wrapper": 31, "gpt35": 2, "gpt_metaphor_result": 29, "gpu": [0, 1, 2, 3, 4, 5, 17, 18, 22, 25, 31], "grad": [19, 26], "grad_fn": 19, "grade": [0, 2], "gradient": [0, 2, 20, 21, 24, 26, 28], "gradient_accumulation_step": 22, "gram": 17, "gramamt": [5, 17], "grammar": 29, "grammat": 29, "grammatical_log_prob": 29, "grammatical_sent": 29, "grammaticality_df": 29, "grammaticality_predict": 29, "grammaticality_test": 29, "graph": 21, "graphic": 2, "graphviz": 20, "great": [0, 2, 17, 20, 29], "greedi": [21, 22, 25], "greek": 21, "greet": 5, "grid": 24, "ground": [0, 1, 2, 3, 4, 12, 20, 26, 29], "group": 6, "grow": 30, "gru": 20, "grucel": 20, "gsm8k": 30, "guess": [20, 21, 22, 24], "guid": [5, 17, 22, 31], "guidelin": 17, "h": [20, 23, 26, 31], "h1": 20, "h2": 20, "h3": 20, "ha": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "had": [3, 26], "hallmark": 30, "hand": [0, 4, 6, 17, 21, 25, 27, 28], "handi": 17, "handl": [20, 21, 22], "happen": [0, 2, 21, 22, 27, 29], "hardwar": 9, "harm": [26, 30], "harmless": [4, 11, 26, 30], "harmon": 29, "haskel": 17, "hasn": 30, "have": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "haven": [4, 26], "haystack": 27, "he": [3, 24], "head": [0, 1, 3, 4, 5, 18, 22, 23, 26, 28, 29], "head_and_tail": 18, "head_dim": 23, "head_view": 28, "heard": [17, 29], "heart": 30, "heavi": [1, 4, 22, 27, 30], "heavili": 22, "heck": 4, "heimersheim": 16, "held": [17, 24], "hellaswag": 30, "hello": [5, 18], "hello_tensor": 18, "helm": 14, "help": [4, 11, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31], "helper": [0, 2, 22, 24, 29, 31], "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "heurist": 13, "hf": [0, 2, 3, 4, 20, 22, 23, 24, 25, 27, 28], "hi": [3, 23, 25], "hidden": [0, 2, 20, 21, 23, 24, 31], "hidden_act": 0, "hidden_s": [0, 21, 28], "hidden_st": [28, 31], "hide": [17, 23], "high": [1, 3, 4, 17, 18, 22, 24, 25, 26, 28, 29, 30], "higher": [5, 17, 18, 19, 21, 22, 23, 24, 26, 30, 31], "highest": [5, 25, 29], "highlevel": 22, "highli": [6, 26], "highlight": [22, 30], "hint": [0, 1, 2, 4, 5, 17, 20, 22, 23, 24, 25, 29, 30], "hist": 17, "histogram": 17, "histori": [7, 22, 30], "hit": 17, "hoc": 28, "hochreit": 8, "hold": 5, "holist": [14, 19, 20], "homework": [6, 17, 26, 29], "honest": [26, 30], "honesti": 30, "hood": [17, 22, 23, 24, 28], "hook": [28, 31], "hookedtransform": 31, "hookpoint": 31, "hors": [3, 20], "host": [6, 17, 22], "hot": [21, 23, 32], "hour": 25, "hous": [3, 29], "how": [0, 1, 2, 3, 4, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "howard": 11, "howev": [4, 17, 19, 20, 22, 23, 24, 26, 29, 30], "html": [0, 2, 17, 18, 22, 28], "http": [0, 2, 4, 17, 18, 21, 22, 26, 28, 29, 31], "httpstcobdxbfgjkt": 17, "httpstcogymzyzi": 17, "httpstcoyfehvc": 17, "httpstcozzaplmfa": 17, "hu": 29, "hub": [22, 27], "hue": 20, "hug": 28, "huggingfac": [0, 2, 4, 11, 17, 23, 26, 27, 28, 31], "huggingface_hub": [4, 31], "huggingface_model_id": 2, "huggingfaceembed": 4, "huggingfaceendpoint": 27, "huggingfacehub_api_token": 27, "huggingfacellm": 4, "human": [1, 4, 11, 12, 17, 22, 23, 25, 26, 27, 28, 29, 30], "human_metaphor": 29, "humanev": 30, "hund": 23, "hungarian": 17, "hungri": 22, "hw": 29, "hw1": [24, 29], "hw1_model2group_assign": 2, "hw2": 29, "hwchase17": 27, "hyperparam": 2, "hyperparamet": [0, 17, 24, 26, 27], "hypothes": [16, 29], "hypothesi": 5, "i": [0, 1, 2, 3, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "i2h": 21, "i2o": 21, "icon": 17, "id": [17, 22, 23, 24, 25, 28, 29, 31], "id_var": 20, "idea": [2, 5, 17, 20, 21, 24, 25, 26, 27, 28, 29, 31], "ideal": [17, 20, 22, 23, 24, 26, 29], "ident": 19, "identif": [16, 31], "identifi": [23, 24, 26, 28, 29, 30, 31], "idx": [2, 20, 23], "ignor": [19, 20, 21, 25], "illeg": 3, "illustr": 24, "imag": [4, 17, 22, 23, 24], "imagenet": 22, "imagin": 3, "imbal": 5, "imdb": [22, 24, 26], "imdb_gpt2": 22, "imdbtrain": 22, "immedi": 17, "impact": 29, "implement": [0, 1, 2, 3, 4, 8, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "implic": 5, "implicit": [10, 22], "implicitli": [18, 20, 26], "import": [0, 1, 2, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "importantli": [0, 2, 17, 26, 29], "imposs": 26, "impress": [17, 26, 29], "improv": [0, 2, 4, 10, 17, 20, 21, 22, 25], "imshow": 31, "in_": 31, "in_featur": 23, "in_proj_bia": 23, "in_proj_weight": 23, "in_sln": 31, "in_sln_": 31, "inappropri": 5, "incld": 22, "includ": [0, 1, 3, 4, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "inclus": 21, "incom": 23, "incompat": 28, "inconsist": [25, 30], "incorpor": 29, "incorrect": [28, 29, 31], "incorrect_answ": 31, "incorrect_index": 31, "increas": [1, 3, 19, 21, 23, 24, 29], "increasingli": [4, 30], "incrementallmscor": [5, 29], "inde": 30, "indent": 17, "index": [0, 2, 4, 17, 20, 21, 23, 24, 29, 31], "indic": [0, 2, 5, 21, 22, 23, 25, 26, 28, 29, 30], "indirect": [16, 31], "individu": [0, 1, 2, 3, 4, 5, 28], "inf": 32, "infer": [0, 3, 4, 10, 13, 17, 19, 22, 23, 25, 27, 29], "infix": 18, "inflat": 29, "influenc": [5, 19], "influenti": 29, "info": 4, "infor": 17, "inform": [0, 1, 2, 4, 5, 9, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "infrastructur": [17, 22], "ing": [19, 23], "ingredi": [4, 27], "inherit": [17, 20], "init": [0, 2, 23], "init_hidden": 21, "init_weight": 28, "initi": [0, 1, 2, 4, 5, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29], "initial_sequ": 21, "initialis": 18, "initializer_rang": 0, "inject": [23, 31], "injur": 5, "innat": 29, "inner": 17, "innov": 26, "inoffici": 25, "inp_id": 31, "inpid": 31, "inplac": 23, "inpsect": 4, "input": [0, 1, 2, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "input_combin": 21, "input_dim": 28, "input_emb": 23, "input_id": [0, 1, 2, 4, 17, 22, 23, 24, 25, 28, 29, 31], "input_ids_instruct": 26, "input_ids_lm": 26, "input_line_tensor": 21, "input_neg": 26, "input_po": 26, "input_s": 21, "input_tensor": 21, "input_text": [0, 2, 22, 24, 25, 28], "input_token": [28, 29], "input_vari": 27, "ins": 4, "inscrut": 31, "inseq": 28, "insert": [1, 4, 5, 27], "insid": [22, 23], "insight": [17, 28, 29], "inspect": [0, 1, 2, 4, 5, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "inspir": [3, 5, 21, 22, 23, 25, 26, 27, 29], "instal": [0, 1, 2, 4, 18, 20, 22, 24, 26, 27, 28, 29, 31], "instanc": [5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "instanti": [0, 2, 19, 20, 21, 22, 23, 24, 27], "instati": [20, 22], "instead": [17, 20, 22, 24, 26, 27, 28, 29, 31], "institut": 3, "instruct": [0, 1, 2, 3, 4, 11, 17, 18, 26, 27, 28, 29], "instruction_text": 26, "instructions_menu_summari": 27, "instructions_text_appet": 27, "instructions_text_dessert": 27, "instructions_text_main": 27, "int": [2, 17, 18], "int64": 18, "intang": 17, "integ": [18, 23], "integr": [17, 20, 22, 25, 26, 27, 28], "integrated_gradi": 28, "intellig": 30, "intend": [17, 19, 24, 26, 27, 30], "intens": [17, 30], "inter": 17, "interact": [3, 12, 28], "intercept": 20, "interchang": [17, 25, 26], "interconnect": 5, "interdisciplinari": 6, "interest": [4, 6, 19, 27, 28, 29, 30], "interestingli": 30, "interfac": [4, 20, 22, 27], "intermedi": [0, 2, 10, 29, 30, 31], "intermediate_residual_": 31, "intermediate_s": 0, "intern": 17, "internet": [17, 29], "interpret": [0, 1, 2, 4, 5, 6, 21, 28, 29, 30], "intersect": 29, "interv": [5, 18], "interven": 31, "intervent": 31, "intric": 30, "intro": [3, 4], "introduc": [0, 2, 3, 6, 8, 9, 10, 17, 18, 19, 21, 23, 24, 25, 26, 29, 30], "introduct": [6, 7, 17, 23, 25], "intuit": [1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30], "intuititv": 5, "invers": 20, "investig": [2, 5, 21, 29], "invok": 27, "involv": [17, 23], "io": [0, 2, 4, 17, 22], "ioi": 31, "ioi_patching_result": 31, "iprogress": [0, 2, 17, 22], "ipynb": [0, 1, 2, 3, 4, 5], "ipython": 4, "ipywidget": [0, 2, 17, 22, 28], "irish": 21, "iron": 30, "is_avail": [0, 1, 2, 4, 5, 17, 22, 25, 26, 28, 29, 31], "is_correct": 29, "is_grammat": 29, "is_top_at_end": 31, "is_tru": 29, "isalpha": 17, "isdigit": 32, "ish": 31, "isol": [5, 29], "isspac": 17, "issu": [0, 4, 17, 24, 27, 29, 30], "itali": 25, "italian": [21, 25, 27], "italien": 27, "item": [0, 2, 5, 18, 19, 20, 21, 23, 24, 25, 28, 29, 31], "item_id": 29, "item_surpr": 21, "itemnum": 29, "iter": [0, 2, 5, 17, 19, 20, 21, 25, 26, 29], "iterrow": [4, 29], "ith": 29, "its": [0, 1, 2, 3, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "itself": [19, 21, 26, 27], "j": [0, 2, 17, 29], "jackson": 21, "jaffrai": 17, "japanes": 21, "jewelri": 3, "jo": 17, "job": [0, 1, 2, 4, 17, 20, 25, 29], "john": 31, "join": [0, 2, 17, 25, 28, 29], "joint": 18, "jpg": 2, "jpmorgan": 17, "json": [0, 2, 21, 22, 31], "judgement": 17, "juic": 3, "juli": 5, "jump": [3, 23, 24, 32], "june": [1, 3, 4], "jupyt": [0, 2, 17, 22], "jurafski": 7, "just": [0, 2, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 31], "justext": 17, "justif": 5, "justifi": [1, 28], "k": [18, 21, 23, 25, 31, 32], "k_2": 0, "k_proj_weight": 23, "k_q": 25, "k_x": 32, "kadavath": 29, "kaplan": 7, "karpathi": [6, 9], "kdeplot": 19, "kdim": 23, "keep": [0, 17, 19, 21, 22, 25, 26], "kei": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32], "kept": 26, "kernel": [0, 2, 22], "kind": [0, 1, 2, 3, 4, 17, 20, 22, 23, 24, 25, 26, 28], "kindli": 17, "kl": [1, 4], "kn1g4awfib": 17, "know": [5, 17, 19, 20, 22, 23, 25, 26, 27, 28, 30, 31], "knowledg": [5, 6, 10, 25, 26, 28, 29], "knowledge_exampl": 25, "knowledge_examples_chain": 25, "knowledge_examples_chain_incorrect": 25, "knowledge_stat": 25, "known": [5, 17, 19, 22, 23, 26, 28, 29], "kojima": 10, "korean": 21, "krakauer": 15, "kwarg": [27, 31], "l": [21, 26, 28, 31, 32], "l57": 31, "lab": 6, "label": [0, 1, 2, 3, 4, 17, 20, 21, 22, 24, 25, 26, 28, 29, 31], "label2index": 28, "ladi": 3, "lambada": 30, "lambd": 31, "lambda": [0, 2, 17, 29], "lambdalay": 31, "lampinen": 10, "langaug": [1, 3], "langchain": [17, 25], "langchain_commun": [17, 27], "langchain_cor": 27, "langchain_nvidia_ai_endpoint": 17, "langchain_openai": 27, "langchainhub": 27, "languag": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30], "laptop": 17, "larg": [2, 6, 10, 11, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 31], "larger": [5, 17, 18, 27, 28, 29], "last": [5, 17, 19, 20, 21, 22, 24, 26, 28, 29, 30, 31], "last_past": 31, "lastli": 24, "later": [1, 4, 17, 20, 21, 31], "latest": [2, 28], "latg": 29, "latter": [17, 22, 24, 27, 28, 30], "law": [7, 21, 26, 30], "lawsuit": 17, "layer": [0, 2, 21, 22, 23, 24, 26, 28, 31, 32], "layer_decod": 31, "layer_logit": 31, "layer_past": 31, "layer_residual_": 31, "layernorm": 23, "layers_to_unfreez": 26, "layout": 29, "lazi": [23, 24], "ldquo": 26, "le": 28, "lead": [3, 21, 25, 26, 29, 31], "leader": 3, "learn": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "learnabl": 29, "learner": 9, "learning_r": [1, 4, 19, 21, 22], "least": [18, 22, 25, 26, 27], "leav": 21, "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "led": 26, "left": [0, 1, 2, 4, 22, 23, 27], "leg": 25, "legend": 22, "len": [2, 16, 17, 20, 21, 25, 26, 28, 29, 31], "lend": 26, "lenght": 17, "length": [0, 2, 5, 17, 18, 20, 21, 23, 25, 26, 29], "lens": 5, "less": [18, 20, 23, 25], "lesson": 17, "let": [0, 2, 3, 4, 17, 18, 19, 21, 23, 24, 26, 27, 29], "letter": [21, 23], "letter_index": 21, "level": [22, 23, 24, 28, 30], "levi": 29, "lharri": 17, "li": [21, 29], "liang": 6, "lib": [0, 2, 17, 22, 23, 31], "librari": [0, 1, 3, 4, 18, 23, 26, 31], "light": [28, 29], "like": [0, 1, 2, 3, 4, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "likelihood": [19, 21, 29], "limb": 25, "limit": [17, 21, 23, 25, 27, 29, 30], "line": [0, 1, 2, 4, 17, 20, 21, 22, 23, 24, 28], "linear": [0, 2, 18, 21, 23, 24, 28, 31], "linear1": [20, 23], "linear2": [20, 23], "linear3": 20, "linear4": 20, "lineplot": 20, "ling": 17, "linguist": [5, 6, 17, 28, 29, 30], "lingusit": 17, "link": [0, 2, 4, 5, 27], "linspac": 20, "list": [0, 1, 2, 4, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "list_decod": 31, "liter": 29, "literari": 17, "literatur": [1, 3, 17], "littl": [25, 27], "liu": [10, 25], "live": 29, "ll": 28, "llama": [1, 3, 4, 6, 10, 17, 22, 23, 26, 30], "llama_index": 4, "llamaindex": 4, "llm": [1, 3, 7, 9, 17, 24, 26, 29, 30, 31], "llm_hf": 27, "llok": 25, "lm": [0, 2, 4, 5, 14, 17, 23, 24, 25, 26, 28, 29, 30, 31], "lm_head": [23, 31], "lm_scorer": [5, 29], "lmhead": 24, "lmql": 27, "ln_1": [23, 31], "ln_2": [23, 31], "ln_f": [23, 26, 31], "lnaguag": 14, "load": [0, 1, 2, 3, 4, 5, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 31], "load_dataset": [0, 1, 2, 4, 5, 17, 22, 24, 26, 29], "load_dotenv": 27, "load_gpt2": 31, "load_in_4bit": 26, "load_in_8bit": 4, "load_model": 28, "load_tool": 27, "loader": [0, 2], "loc": [19, 20, 25], "local": [0, 2, 18, 21, 22, 23, 25, 26, 27, 28, 31], "locat": [16, 18, 19, 24, 25, 28], "log": [0, 1, 2, 4, 5, 21, 22, 23, 25, 26, 29, 31], "log_histori": 22, "log_p": 25, "log_prob": [19, 21], "log_stat": [1, 4], "logging_step": 22, "logic": 30, "logit": [16, 22, 24, 31, 32], "logits_to_logit_diff": 31, "logsoftmax": [20, 21], "logspac": 21, "long": [1, 2, 4, 8, 17, 22, 24, 25, 28, 29, 30], "longer": [19, 23, 26, 29], "longtensor": 21, "look": [0, 2, 4, 5, 6, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "loop": [0, 1, 2, 4, 20, 21, 22, 24, 27], "lora": 26, "loss": [0, 1, 2, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29], "loss_funct": 20, "lot": [4, 17, 25, 26], "love": 5, "low": [25, 26], "lower": [17, 19, 21, 23, 25, 26], "lowest": 29, "lr": [0, 2, 19, 20, 21], "lr_scheduler_typ": 22, "lstm": [8, 24], "luckili": [20, 22, 24], "lvwerra": 26, "ly": 18, "m": [0, 2, 18, 21, 23, 25, 28], "m1": 17, "m3hrdadfi": 4, "m_1": [0, 2], "m_coef": 31, "m_out": 32, "mac": 17, "machin": [9, 17, 18, 20, 22, 24, 26, 30], "made": [3, 17, 19, 20, 22], "magnitud": [20, 28], "mahowald": 15, "mai": [0, 2, 4, 5, 19, 23, 24, 25, 27, 29], "main": [1, 2, 4, 5, 19, 20, 21, 26, 27, 30], "main_chain": 27, "main_cours": 27, "mainli": [17, 20], "major": 17, "make": [0, 2, 4, 5, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "make_df": 21, "man": 3, "manag": [5, 21], "mani": [0, 2, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "manipul": [5, 18], "manner": [17, 18], "manual": [19, 20, 22, 23], "map": [0, 1, 2, 4, 17, 20, 21, 22, 23, 24, 28, 29, 31], "mari": [29, 31], "markup": 17, "martin": 7, "mask": [2, 17, 22, 25, 28, 29], "masked_label": 25, "massag": [0, 2, 17, 19, 22], "massage_input_text": [0, 2, 29], "massaged_dataset": [0, 2], "massaged_dataset_v": 29, "master": 6, "match": [3, 4, 5, 17, 21, 23, 28, 29], "materi": 17, "math": [20, 21, 23, 29, 30], "mathbb": 26, "mathc": 29, "mathemat": [0, 2, 7, 9, 16, 18, 23, 30], "matmul": [18, 31], "matplotlib": [0, 2, 17, 19, 20, 21, 22], "matric": [0, 2, 18, 20, 22, 23, 26], "matrix": [0, 2, 17, 21, 23, 26, 31, 32], "matrix1": 18, "matrix2": 18, "matrixprod": 18, "max": [1, 3, 23, 24, 25, 28], "max_len": 23, "max_length": [0, 1, 2, 4, 21, 22, 24], "max_new_token": [0, 1, 2, 4, 25, 27], "max_ord": 29, "max_position_embed": 0, "max_prob_idx": 25, "max_seq_length": 26, "max_token": 27, "maxim": [1, 2, 3, 4, 5, 17, 19, 22, 24, 25, 26], "maximum": [19, 26], "mayb": [22, 26, 31], "mccoi": 13, "mcdonnel": 10, "mcyftsxc2n": 17, "mdoel": 31, "mdp": 26, "me": 27, "mean": [4, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32], "meaning": 31, "meant": [17, 19], "measur": [4, 5, 19, 23, 29], "meat": 17, "mechan": [16, 22, 26, 28, 31], "mechanist": 6, "mediat": 16, "medic": 26, "medium": 31, "meet": 30, "mega002": 31, "meinung": 29, "meister": 25, "melt": 20, "memor": 24, "memori": [0, 1, 2, 4, 8, 17, 18, 21], "meng": 16, "mention": [4, 7, 10, 16, 23, 24, 25, 28, 29, 30], "menu": 27, "merg": 23, "merullo": [16, 31], "messag": [19, 27], "meta": [0, 23], "metaphor": 29, "metaphor_results_gpt": 29, "metaphor_results_human": 29, "meteor": 29, "method": [2, 4, 6, 16, 17, 20, 22, 26, 29, 30, 31], "methodolog": [26, 29], "metric": [1, 4, 5, 21, 22, 30, 31], "michael": [6, 18, 19, 20, 21, 25], "microsoft": [4, 26, 27], "mid": [21, 25, 29], "mid_attn_": 31, "middl": [3, 23, 24], "might": [0, 1, 2, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "mikolov": 7, "militari": 3, "milk": 31, "million": [24, 26], "min": [10, 24], "min_length": [1, 4], "mind": [17, 26, 27, 29], "mini": [4, 20, 26], "mini_batch_s": [1, 4], "minicon": [5, 29], "minim": [0, 2, 5, 17, 19, 20, 23, 27, 30], "minimum": [24, 26], "minist": 5, "minut": 21, "mismatch": 5, "misrepresent": 17, "miss": [17, 30], "mistak": 25, "mistral": [1, 27], "mistralai": 27, "mitchel": 15, "mix": [17, 18], "mix2": 18, "mix3": 18, "mix4": 18, "mix5": 18, "mix6": 18, "mix7": 18, "mix8": 18, "mixtur": [2, 17], "ml": [17, 30], "mll": 5, "mlm": [0, 22], "mlm_probabl": 24, "mlp": [23, 31], "mlp_": 31, "mlp_19": 31, "mlp_condens": 20, "mlp_explicit": 20, "mlpcondens": 20, "mlpexplicit": 20, "mmlu": [29, 30], "mode": [0, 2, 4, 26, 29], "model": [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 23, 25, 27, 28, 29, 30, 31], "model_": 29, "model_instruct": 26, "model_kwarg": 4, "model_lm": 26, "model_nam": [1, 2, 4, 28], "model_s": [0, 2], "model_t5": [28, 29], "model_typ": 23, "model_view": 28, "model_xl": 29, "modelout": 22, "modelwrapp": 31, "modern": [1, 3, 27, 29], "modifi": [0, 5, 17, 18, 27], "modul": [21, 23, 28, 31], "module_guid": 4, "modulelist": 23, "moment": [25, 26], "monitor": [0, 2, 17, 21], "monolingu": 5, "moodl": [0, 1, 2, 3, 4, 5], "moral": 30, "more": [1, 3, 4, 5, 6, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "morgan": 17, "morphologi": 5, "most": [5, 17, 21, 22, 23, 25, 26, 29, 30], "mostli": [5, 17, 20, 22, 24, 26, 30], "motiv": [28, 29], "mous": 2, "move": [0, 2, 29, 31], "movi": [1, 4, 22, 26], "mp": [0, 2, 5, 17, 22, 25, 28, 29], "mrr": 31, "mse": 24, "mseloss": 20, "mtx": 32, "much": [17, 18, 20, 22, 23, 25, 26, 28, 29, 31], "multi": [17, 20, 30], "multihead_attn": 23, "multiheadattent": 23, "multilanguag": 17, "multilingu": 5, "multipl": [5, 17, 20, 23, 24, 25, 29, 30], "multipli": [17, 18, 24, 32], "multitask": 9, "must": [17, 19, 20, 23, 25, 30], "my": [17, 25, 27], "m\u00fcll": 21, "m\u00fcller": 21, "n": [4, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 32], "n_categori": 21, "n_hidden": 20, "n_input": 20, "n_item": 21, "n_iter": 21, "n_layer": 31, "n_letter": 21, "n_name": 21, "n_ob": [19, 20], "n_output": 20, "n_train_step": 20, "n_training_step": 19, "naiv": 26, "name": [0, 1, 2, 3, 4, 5, 6, 17, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32], "named_paramet": 26, "names_data": 21, "nanda": 16, "nanswer": [0, 2], "nappet": 27, "nation": 17, "nativ": [22, 31], "natur": [1, 3, 4, 13, 17, 22, 25, 26, 29, 31], "naturalqa": 30, "navig": [0, 1, 2, 3, 4, 5, 17], "nb": [17, 18, 19, 20, 22], "ndessert": 27, "neat": 27, "neatli": 20, "necess": [23, 27], "necessari": [23, 26, 27, 31], "necessarili": [0, 2, 19, 26], "need": [0, 1, 2, 3, 4, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "neg": [19, 21, 24, 26, 29], "negative_sent": 26, "negbackward0": 19, "ner": 24, "net": [8, 20, 21, 22, 23], "network": [0, 2, 6, 8, 9, 20, 22, 23, 24, 27, 28], "neural": [0, 2, 6, 7, 8, 9, 16, 20, 21, 22, 23, 24], "neural_pragmatic_nlg": 21, "neuron": [0, 2, 28], "neutral": [3, 17, 24, 25], "never": [17, 21], "nevertheless": 17, "new": [0, 1, 2, 4, 17, 18, 21, 22, 23, 26, 31], "new_tensor": 18, "newer": 29, "newgeluactiv": 23, "newli": 22, "next": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "nf": 23, "nf4": 26, "nhead": 23, "nhid": 23, "nice": [22, 23], "nightmar": 3, "ninp": 23, "ninth": 15, "nlayer": 23, "nlg": [6, 25, 29], "nll": 29, "nllloss": 21, "nlp": [0, 1, 2, 3, 6, 7, 16, 17, 22, 24, 29], "nmain": 27, "nmean": 21, "nn": [21, 22, 23, 24, 28, 31], "no_grad": [0, 2, 21, 28], "noce": 25, "node": [4, 20, 24], "nois": 20, "nomura": 17, "non": [17, 21, 24, 25, 28], "nondynamicallyquantizablelinear": 23, "none": [2, 19, 20, 22, 23, 24, 31], "nonetheless": [17, 27], "nonlinearregressiondata": 20, "nonliter": 29, "nonsens": [5, 26], "noodl": 4, "norm": [23, 31], "norm1": 23, "norm2": 23, "norm3": 23, "normal": [19, 20, 23, 24, 31], "normalis": 32, "notabl": 20, "notat": [7, 18], "note": [0, 1, 2, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "notebook": [0, 2, 5, 17, 19, 21, 22, 26, 28, 31], "notebook_tqdm": [0, 2, 17, 22], "notic": [18, 19, 21, 25], "notion": [17, 21], "noun": [5, 26], "now": [19, 20, 21, 23, 24, 26, 28, 29, 30], "nowadai": 17, "np": [0, 2, 18, 20, 21, 25, 28, 29, 31, 32], "np_arrai": 18, "np_array_to_tensor": 18, "np_conv": 32, "npi_present_1": 5, "npleas": 27, "npnlg": 21, "ntoken": 23, "nuber": 24, "nudg": 26, "null": 0, "num": [0, 2, 20, 31], "num_attention_head": 0, "num_class": 22, "num_correct": 28, "num_decoder_lay": 23, "num_encoder_lay": 23, "num_epoch": 28, "num_head": 23, "num_hidden_lay": 0, "num_items_in_batch": 22, "num_key_value_head": 0, "num_label": 28, "num_lay": [28, 31], "num_posit": 31, "num_process": [1, 4], "num_test_step": [0, 2], "num_token": 31, "num_tot": 28, "num_train_epoch": 22, "num_word": 28, "number": [0, 2, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29], "number_training_token": 2, "numel": [0, 2, 26], "numer": [17, 18, 19, 23, 26], "numpi": [0, 2, 18, 20, 21, 25, 28, 29, 31, 32], "numpydoc": 17, "nwhich": 27, "nx": 23, "nye": 10, "nyu": 5, "o": [1, 4, 20, 21, 27, 28, 29, 30, 32], "o2o": 21, "o_citi": 31, "object": [2, 4, 5, 16, 17, 18, 19, 20, 21, 22, 24, 26, 31], "obscur": 28, "observ": [4, 5, 20, 24, 25, 27, 28, 31], "obtain": [17, 18, 19, 21, 25, 26, 30], "obvious": 3, "occupi": [17, 18], "occur": [5, 17, 20, 24, 29], "odd": 4, "off": [3, 17], "offer": [6, 26, 27, 28], "often": [0, 2, 4, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31], "oftentim": 27, "old": 18, "older": 3, "ollama": 4, "ollamaembed": 4, "ommit": 17, "onc": [17, 20, 22, 23, 26], "one": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ones": [17, 18, 19, 20, 26, 31], "ones_lik": 25, "onli": [0, 1, 2, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "onlin": [22, 25, 26], "onto": [17, 20, 23, 29, 31], "onward": 20, "open": [1, 2, 4, 5, 10, 17, 21, 22, 25, 26, 27, 28, 29], "openai": [11, 22, 26, 27], "openai_api_kei": 27, "openai_summarize_tldr": 26, "oper": [20, 23, 31], "operation": [5, 31], "opinion": [29, 30], "opportun": [15, 20], "oppos": [17, 21], "opprotun": 30, "opt": [0, 2, 17, 19, 22, 26, 31], "optim": [0, 1, 2, 4, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28], "optima": 24, "optimis": 26, "option": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 27, 28, 29, 30, 31], "orang": 3, "orc": 5, "ord": 18, "order": [1, 4, 17, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30], "ordereddict": 23, "ordin": 26, "org": [2, 18, 26, 28, 29], "orient": 29, "origin": [9, 17, 21, 26, 29, 31], "original_summari": [1, 4], "other": [1, 3, 5, 6, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "otherwis": [0, 2, 4, 17, 19, 22, 25, 26, 29], "our": [0, 1, 2, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31], "ourselv": [17, 22, 23, 27, 28], "out": [0, 1, 2, 4, 5, 6, 9, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "out_contrast": 28, "out_featur": 23, "out_intermediate_residual_": 31, "out_proj": 23, "out_with_gener": 28, "outcom": [26, 30, 31], "outdoor": 3, "outlier": 17, "outlin": 30, "outlook": [17, 25], "output": [0, 1, 2, 4, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32], "output_": 29, "output_attent": [28, 31], "output_combin": 21, "output_dim": 28, "output_dir": 22, "output_hidden_st": [28, 31], "output_max_length": [1, 4], "output_pars": 27, "output_s": 21, "output_text": 26, "output_xl": 29, "outset": 19, "outsid": 3, "ouyang": 11, "over": [0, 2, 3, 4, 5, 15, 17, 19, 20, 23, 24, 25, 26, 27, 29, 31, 32], "overal": [1, 4, 19, 23, 25, 27, 28, 29], "overfit": [22, 24, 25], "overlap": [17, 29], "overoptim": 26, "overrepres": 5, "overris": 22, "overview": [11, 14, 17, 20, 22, 24, 25, 26, 27, 30], "overwhelm": 22, "own": [4, 5, 17, 20, 21, 22, 23, 25, 26, 27], "p": [0, 2, 17, 18, 21, 23, 24, 25, 26], "p_": [21, 25, 29], "p_categori": 21, "p_name": 21, "pack": 20, "pack_padded_sequ": 20, "packag": [0, 1, 2, 3, 4, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "pad": [0, 1, 2, 4, 17, 20, 22, 23, 24, 25], "pad_packed_sequ": 20, "pad_sequ": 20, "pad_token": [0, 1, 2, 4, 22], "pad_token_id": [0, 1, 2, 4, 22, 24, 25], "padding_sid": [0, 1, 2, 4, 22], "page": [17, 27], "pai": 20, "pain": 20, "pair": [0, 2, 5, 17, 20, 21, 23, 26, 29], "panda": [1, 4, 5, 20, 21, 25, 29], "paper": [1, 2, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 23, 24, 25, 26, 29, 30, 31], "paper_url": 2, "paradigm": [10, 29], "parallel": [17, 22, 23, 25, 31], "param": [20, 26], "paramet": [0, 1, 2, 3, 4, 11, 17, 22, 23, 24, 25, 26, 27, 28, 29, 31], "parameter": 22, "paramt": [4, 25], "paraphras": 29, "parenthes": 5, "pari": [28, 31], "park": 12, "parrot": 30, "part": [4, 5, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "partial": [2, 26, 31], "particip": [6, 29], "particular": [0, 1, 2, 3, 4, 5, 6, 17, 21, 22, 23, 26, 27, 28, 30], "particularli": 20, "particulat": 25, "pass": [0, 2, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32], "passag": 24, "passs": 27, "past_key_valu": 31, "past_layer_": 31, "patch": 16, "patched_logit": 31, "patched_logit_diff": 31, "path": [17, 25, 28], "patient": 27, "pattern": [24, 28, 30, 31], "pavlick": [10, 30], "paywal": 27, "pd": [1, 4, 5, 20, 25, 29], "pdf": 26, "pe": 23, "peak": 17, "peft": [11, 22], "penguin": 25, "penn": 29, "peopl": [3, 5, 17, 29], "pep8": 17, "per": [1, 3, 17, 21, 22, 24, 25, 26, 28], "per_device_eval_batch_s": 22, "per_device_train_batch_s": 22, "percentag": 30, "perceptron": 20, "perci": 6, "perez": 5, "perfect": [21, 29], "perform": [0, 2, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "perhap": [24, 26, 29], "permut": 22, "perpetu": 30, "perplex": [21, 29], "perplexity_": 29, "perplexity_xl": 29, "perplxti": 21, "perplxty_dict": 21, "person": [3, 17, 24], "perspect": [6, 29, 30], "perturb": 28, "phenomena": 5, "phenomenon": [5, 29, 30], "phi": [4, 26], "phrase": 5, "physic": 30, "pick": [0, 2, 17, 23, 26, 31], "pictur": [0, 21, 23, 25], "piec": [17, 23, 27, 29], "pile": [17, 22], "pilot": 5, "pinecon": 4, "pip": [0, 1, 2, 4, 17, 22, 24, 26, 27, 28, 31], "pipe_output": 22, "pipelin": [0, 1, 2, 4, 17, 22, 25], "piper": 17, "pizza": 25, "pizzeria": 25, "place": [4, 25], "placement": [1, 4], "plai": [0, 1, 2, 3, 19, 21, 22, 23, 25, 26, 27, 30], "plan": 27, "platform": [17, 22], "plausibl": 30, "pleas": [0, 1, 2, 3, 4, 5, 17, 20, 22, 23, 25, 26, 27, 28, 29], "plot": [0, 1, 2, 4, 5, 17, 18, 19, 20, 21, 22, 24, 30], "plot_everi": 21, "plotli": 31, "plt": [0, 2, 17, 19, 20, 21, 22], "plu": [21, 23, 28], "plural": 5, "png": 2, "po": [23, 24, 28], "point": [17, 20, 23, 24, 25, 26, 27, 29], "pointer": 23, "pointwis": 17, "pol_tok": 31, "poland": 31, "poland_id": 31, "poland_text": 31, "polici": [1, 4], "polina": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "polish": 21, "polit": 30, "poor": 17, "popul": 18, "popular": [4, 22, 24, 27, 30], "pork": 4, "portugues": 21, "pos_encod": 23, "posencod": 23, "posit": [9, 18, 23, 24, 25, 26, 29, 31], "positionalencod": 23, "positive_sent": 26, "possess": 30, "possibl": [5, 17, 18, 23, 24, 25, 26, 27, 29, 30, 31], "possibli": [17, 23, 26], "post": [1, 3, 4, 25, 26, 28], "potenit": 29, "potenti": [17, 24, 25, 26, 27, 28, 29], "power": [12, 20, 29], "pp": 5, "ppl": 29, "ppl_": 29, "ppo": [1, 4], "ppo_epoch": [1, 4], "ppo_train": [1, 4], "ppoconfig": [1, 4], "ppotrain": [1, 4], "practic": [0, 2, 6, 20, 22, 23, 24, 25, 29], "practition": [1, 3], "pragmat": [6, 29], "prder": 18, "pre": [0, 1, 3, 9, 11, 17, 20, 21, 22, 23, 24, 28, 31], "pre_wo_attn": 31, "preced": [17, 23, 24, 25], "precis": [18, 29], "pred": [25, 28], "predict": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "predicted_answ": 29, "predicted_d": 29, "predicted_decoded_d": 29, "predicted_label": 29, "prediction_instruct": 26, "prediction_lm": 26, "prefer": [4, 5, 11, 17, 26], "prefix": [23, 29], "preliminari": 6, "prep": [0, 2], "prepair": 17, "prepar": [0, 2, 4, 17, 19, 22], "prepend": 23, "preposit": 5, "preprocess": [0, 2, 17, 23], "preprocessed_train_dataset": 17, "present": [3, 20, 21, 30], "presid": 3, "press": 17, "presuppos": 29, "pretrain": [0, 1, 2, 4, 17, 18, 22, 26, 27, 31], "pretrainedtokenizerbas": 22, "pretraining_data_s": 2, "prevent": [3, 22, 24, 25], "previou": [20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "price": 17, "primarili": 30, "primit": 20, "principl": [0, 22, 23], "principle_a_case_1": 5, "print": [0, 1, 2, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "print_everi": 21, "print_funct": 21, "print_top": 31, "prior": [6, 30], "priori": 23, "pro": 25, "prob": [21, 32], "prob_of_answ": 31, "probabl": [0, 1, 2, 4, 5, 17, 19, 20, 21, 23, 24, 25, 26, 29, 31], "probe": [6, 13, 21], "probing_dir": 28, "problem": [4, 6, 10, 17, 29], "problemat": [1, 4, 30], "probs_t": 32, "procedur": [1, 4, 19, 25, 29], "proces": [0, 2], "process": [0, 2, 5, 7, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "prodcut": 18, "produc": [17, 20, 21, 22, 31], "product": [18, 26, 28], "program": [6, 10, 24], "progress": [1, 3, 24], "project": [6, 17, 31, 32], "promin": [1, 17, 23], "promot": 31, "prompt": [4, 5, 6, 17, 21, 23, 26, 27, 28, 29, 30, 31], "prompt_input_id": 25, "prompt_template_appet": 27, "prompt_template_dessert": 27, "prompt_template_main": 27, "prompt_template_summari": 27, "prompttempl": 27, "propag": 8, "propens": 30, "proper": 21, "properli": 27, "properti": [2, 18], "proport": [5, 17, 21, 29], "proprietari": 4, "propto": 25, "provd": 30, "proven": 26, "provid": [0, 1, 2, 3, 4, 5, 7, 14, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "proxim": [1, 4, 26], "pseudo": [5, 22, 29], "psuchologi": 29, "pt": [0, 1, 2, 4, 17, 22, 24, 25, 26, 28, 29, 31], "publicli": 27, "publish": 17, "pull": 27, "punctuat": [0, 2, 17, 23], "pure": [22, 25], "purpos": [4, 17, 18, 20, 22, 26, 27, 28], "push": [17, 22], "push_to_hub": 22, "put": [0, 2, 4, 22, 28, 29, 31], "puzzl": 30, "px": 31, "py": [0, 2, 17, 22, 23, 26, 31], "pyplot": [0, 2, 17, 19, 20, 21, 22], "pythia": [3, 5, 25], "python": [6, 17, 20, 28, 29], "python3": [0, 2, 17, 22, 23, 31], "pytorch": [17, 19, 21, 22, 24, 28, 31], "q": [1, 4, 23, 25, 31, 32], "q_2": 0, "q_proj_weight": 23, "q_x": 32, "qa": [0, 24, 26], "qlora": 26, "qquestion": [0, 2], "qualiti": [17, 24, 29], "quantifi": 24, "quantit": 5, "queri": [1, 4, 17, 23, 25, 27, 28, 32], "query_engin": 4, "query_tensor": [1, 4], "question": [1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "quick": [21, 23, 24], "quickstart": 28, "quiet": 21, "quit": [17, 22, 26, 27, 29, 30, 31], "quot": 30, "qwen": 1, "r": [0, 1, 2, 4, 17, 26, 29, 32], "r_": 26, "radford": 9, "rafailov": 26, "rag": 4, "rag_respons": 4, "rahwan": 9, "rais": [28, 29, 31], "ram": 17, "ran": 28, "rand": [17, 18, 20], "randint": 21, "random": [4, 18, 21, 24, 25, 28, 31], "random_choic": 21, "random_training_exampl": 21, "random_training_pair": 21, "random_weight": 28, "randomli": [17, 21, 24], "rang": [0, 2, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "rank": [26, 31], "rare": 30, "rate": [0, 2, 17, 19, 21, 22, 24, 25, 26], "rather": [11, 17, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "raw": [17, 21, 23, 29], "rcl": 17, "rdbu": 31, "rdquo": 26, "re": [23, 24, 27], "reach": [23, 24], "react": 27, "read": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 25, 31], "read_csv": [5, 25, 29], "readabl": [17, 22, 23], "reader": 31, "readi": 19, "readlin": 28, "readm": 17, "readthedoc": [0, 2, 17, 22], "real": [27, 30], "realis": 31, "realiti": 3, "realiz": [21, 30], "realli": 10, "realtoxicityprompt": [29, 30], "reason": [0, 1, 2, 3, 10, 13, 26, 29], "recal": [16, 27, 29, 31], "recap": [26, 29], "receiv": [1, 4, 17, 26, 28], "recent": [1, 3, 5, 17, 23, 25, 29, 30], "recevi": 26, "recip": [4, 26, 27], "recipe_nlg_lit": 4, "recipi": 27, "reciproc": 31, "recognit": 24, "recommend": [6, 17, 21], "record": [4, 17, 29], "recov": 31, "recurr": [8, 21, 22], "recycl": 18, "red": [3, 30], "reduc": [23, 25], "reduct": 21, "reel": 17, "ref_model": [1, 4], "refer": [1, 3, 4, 5, 9, 12, 17, 20, 22, 24, 25, 26, 28, 29, 30, 31], "reflect": [1, 5, 17, 30], "reformat": 17, "regard": [3, 17, 21, 26, 29, 30], "regex": 29, "regim": 21, "register_buff": 23, "register_forward_hook": 31, "regress": 23, "regular": 28, "reimplement": 23, "reinforc": [1, 11, 26], "reject": 26, "rel": [5, 17, 22, 23, 26], "relat": [3, 6, 11, 17, 19, 21, 23, 24, 29, 30], "relev": [1, 4, 6, 17, 19, 22, 24, 26, 27, 29, 30], "reli": [17, 23, 24, 28, 30], "reliabl": [25, 29, 30], "reload": [0, 2, 22], "relu": [0, 2, 20, 21], "remain": [22, 30], "rememb": [20, 21, 25], "remind": [22, 25, 28], "remov": [17, 18, 21, 23, 31], "remove_column": [0, 22, 24], "render": [5, 31], "repeat": [19, 23, 25], "replac": 31, "replic": [18, 25], "repo_id": 27, "report": [3, 17, 19, 21, 26], "report_to": 22, "repositori": [17, 22, 26, 31], "repres": [1, 3, 5, 17, 18, 20, 21, 22, 23, 26, 28, 29, 31], "represen": 28, "represent": [0, 1, 4, 8, 13, 17, 18, 20, 21, 23, 24, 28, 31], "representation_dim": 28, "reproduc": 17, "req_res_oop": 31, "request": [21, 25], "requir": [0, 1, 2, 4, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "requires_grad": [19, 23, 26], "research": [1, 3, 17, 24, 26, 27, 29, 30], "reserach": 29, "reset": 21, "reset_activ": 31, "reshap": [20, 21], "resid_dropout": 23, "resid_pr": 31, "residu": 32, "residual_stream_patching_hook": 31, "resourc": [0, 1, 2, 3, 4, 5, 9, 17, 22, 24, 25, 26, 27, 30], "respect": [1, 4, 5, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "respond": 29, "respons": [1, 2, 4, 5, 23, 29], "response_mod": 4, "response_rag": 4, "response_synthes": 4, "response_tensor": [1, 4], "response_vanilla": 4, "responsinbl": 31, "rest": [5, 17, 22, 24, 26], "restrict": [17, 25], "result": [4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "resum": 31, "resume_download": 31, "rethink": 10, "retreiv": [0, 2, 27, 29], "retriev": [2, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 31], "retrieved_node_scor": 4, "retrieved_node_text": 4, "return": [0, 1, 2, 4, 17, 18, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "return_dict": 28, "return_output": 22, "return_tensor": [0, 1, 2, 4, 17, 22, 24, 25, 26, 28, 29, 31], "reus": [4, 16, 20, 25, 26], "reusabl": 20, "revers": 31, "revert": 19, "review": [1, 4, 22, 26], "reward": [1, 4, 30], "reward_fn": [1, 4], "reward_model": 26, "reward_neg": 26, "reward_po": 26, "reward_token": 26, "reynold": 10, "right": [0, 2, 13, 20, 22, 23, 24, 25, 27, 30], "rigor": 16, "rise": [17, 30], "risk": [15, 30], "rl": 1, "rlaif": 26, "rlhf": [2, 17, 26, 30], "rm_hook": 31, "rms_norm_ep": 0, "rnn": [20, 23, 24], "robot": [11, 12], "robust": [21, 29, 30], "rocm": 17, "role": [10, 23, 31], "rolling_mean": 21, "rome": 16, "root": 29, "rope_sc": 0, "rope_theta": 0, "roug": [1, 4, 26, 29], "rouge1": [1, 4], "rouge_scor": [1, 4], "roughli": 20, "round": [20, 21, 28, 32], "row": [23, 26], "royal": 17, "rr": 31, "rr_per_lay": 31, "rt": 5, "rtain": 22, "ruff": 17, "rule": [0, 2, 20, 21, 23], "rumelhart": 8, "run": [0, 1, 2, 4, 17, 20, 22, 25, 26, 28, 29, 31], "run_with_cach": 31, "run_with_hook": 31, "runtim": [0, 1, 2, 3, 4, 5, 17, 25], "russian": 21, "ryan": 6, "safe": 3, "safer": 17, "safeti": 30, "sai": [1, 4, 5, 12, 17, 25, 30, 31], "said": 25, "sake": 27, "salazar": 29, "salienc": 28, "same": [1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "sampl": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29], "santurkar": 30, "satisfii": 27, "satoshi": 21, "save": [0, 1, 2, 3, 4, 5, 17, 20, 21, 24, 31], "save_step": 22, "saw": 31, "scalabl": [29, 30], "scalar": [1, 4, 18, 20, 26], "scale": [0, 4, 7, 11, 19, 20, 26, 29, 32], "scan": 0, "scari": 3, "scatterplot": 20, "scenario": 29, "scene": [19, 20], "schedul": [22, 24, 26], "scheme": [1, 3, 4, 22], "schmidhub": 8, "schnell": 23, "school": 3, "scienc": [6, 29, 30], "scientif": 26, "scope": 21, "score": [1, 4, 5, 23, 24, 25, 26, 28, 29, 32], "scorer": [5, 29], "scottish": 21, "scratch": [9, 22, 24], "scratchpad": 10, "script": 26, "scrub": 16, "seaborn": [19, 20], "seamlessli": [17, 27], "search": [3, 4, 17, 24, 25, 27], "searchabl": 4, "searhc": 27, "second": [0, 1, 3, 4, 5, 8, 9, 17, 18, 20, 23, 28], "secretli": 26, "section": [1, 3, 5, 17, 26, 29, 30], "see": [0, 1, 2, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "seed": 25, "seek": 19, "seem": [17, 20, 21, 25, 26, 28, 29], "seen": [18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "segmented_token": 28, "select": [5, 17, 20, 22, 24, 25, 26, 28, 29, 30], "self": [0, 1, 2, 10, 20, 21, 22, 23, 26, 28, 31], "self_attn": 23, "sell": 2, "semant": [5, 29], "semest": 17, "seminar": 6, "send": 22, "sens": [0, 2, 4, 21, 22, 23, 25, 26, 30], "sensibl": [17, 22, 26], "sensit": [28, 30], "sentenc": [0, 1, 2, 3, 4, 5, 13, 17, 22, 23, 24, 25, 26, 28, 29, 31, 32], "sentence1": 29, "sentence2": 29, "sentiment": [3, 17, 22, 24, 25, 26, 29], "sep": [24, 25, 28], "separ": [0, 2, 4, 5, 20, 23, 25, 26, 29], "seq2seq": [24, 28], "sequenc": [0, 2, 20, 23, 24, 25, 27, 28, 31], "sequence_length": 28, "sequence_scor": 29, "sequenti": [20, 21], "seri": [9, 19, 22, 24], "serious": 21, "serv": [1, 4, 25, 27], "server": [17, 22], "servic": 17, "session": [9, 17, 22, 25, 26], "set": [0, 1, 2, 4, 5, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "set_format": [1, 4, 17, 22], "settl": 17, "setup": 22, "seventh": 13, "sever": [0, 2, 17, 21, 23, 24, 27, 29], "sft": [1, 4, 26], "sfttrainer": 26, "sgd": 19, "shape": [17, 18, 21, 22, 23, 25, 28, 30, 31, 32], "share": [17, 20, 26, 27], "sharehold": 17, "sharpen": 30, "she": [3, 29], "shed": 29, "sheet": [0, 1, 2, 3, 4, 5, 7], "shift": [1, 3, 18, 22], "shima": 21, "ship": [0, 2, 22, 23], "shirt": 3, "shop": [3, 25], "short": [1, 4, 8, 17, 18, 20, 21, 22, 26, 30], "shorter": [17, 20], "shot": [1, 3, 10, 25], "should": [0, 2, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "shouldn": 3, "show": [1, 2, 4, 5, 10, 19, 20, 21, 22, 23, 24, 26, 28, 31], "shown": [1, 4, 21, 26, 29, 30], "shuffl": [0, 2, 17, 20, 21], "shy": 17, "side": [0, 2, 17, 22, 23, 24], "sidewalk": 3, "sigma": 26, "sign": [17, 23, 27], "signal": [1, 4, 17, 20, 23, 26], "signific": [1, 3, 17], "significantli": 17, "silu": 0, "sim": 26, "similar": [1, 3, 4, 5, 19, 20, 23, 25, 26, 28, 29, 30, 31], "similarity_top_k": 4, "similarli": [18, 22, 29], "simpl": [2, 5, 16, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31], "simplest": 23, "simpli": [23, 26, 28], "simplif": 25, "simplifi": [22, 25], "simulacra": 12, "simultan": [1, 4, 17], "sin": [20, 23], "sinc": [0, 1, 2, 4, 17, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "sine": 23, "sing": [0, 2], "singl": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "singular": 5, "sit": 3, "site": [0, 2, 17, 22, 31], "situat": 17, "sixth": 12, "size": [0, 1, 2, 4, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 31], "skate": 3, "skateboard": 3, "skill": [0, 1, 2, 3, 4, 5, 20, 30], "skim": 30, "skip": 31, "skip_special_token": [0, 2, 25, 26, 29], "sklearn": 29, "sleep": 2, "slide": [1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 26, 28], "slight": 21, "slightli": [17, 18, 20, 24, 28, 29, 31], "slip": 17, "slope": 20, "slot": 17, "slow": 31, "slowdown": 5, "slowli": 19, "small": [2, 3, 4, 6, 16, 17, 19, 22, 23, 26, 28, 29, 31], "smaller": [0, 2, 17, 20, 22, 29], "smart": 3, "smile": 3, "smoothen": 25, "sn": [19, 20], "sneez": 0, "so": [0, 1, 4, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "social": [5, 29], "societi": 6, "sociocultur": 17, "soft": [25, 31], "softmax": [21, 25, 31, 32], "softwar": [17, 30], "sold": 25, "solut": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 24, 26, 30], "solv": [0, 1, 2, 3, 4, 5, 10, 17, 19, 29], "some": [0, 1, 2, 3, 4, 5, 9, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "somehow": 27, "someth": [0, 2, 5, 19, 20, 21, 26, 30, 31], "sometim": [17, 22, 23, 24, 25, 26, 27, 30], "somewhat": [2, 20, 22, 25, 27, 29], "soon": 24, "sophist": [1, 3], "sort": 26, "sorted_prob": 31, "sosindex": 21, "sota": [23, 26, 29, 30], "sound": [21, 25, 26, 30], "soup": 4, "sourc": [4, 5, 6, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "source_nod": 4, "space": [0, 1, 2, 3, 4, 17, 21, 26, 28, 29, 31], "spaci": 28, "span": [24, 26], "spanish": 21, "spars": 2, "speak": [18, 21], "speaker": 21, "spec": 17, "special": [4, 20, 21, 22, 24, 25, 26, 27, 28, 29], "specicif": 31, "specif": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "specifi": [2, 17, 18, 20, 22, 23, 24, 26, 27, 28], "speech": [7, 28, 29], "speed": [0, 1, 2, 3, 4, 5, 17, 20, 26], "spend": 3, "split": [0, 1, 2, 4, 17, 20, 22, 23, 24, 26, 28, 29], "split_percentag": 21, "spoiler": 25, "sponsor": 27, "spot": [0, 2, 22], "sprang": 23, "spuriou": 28, "sqrt": [20, 24, 32], "squeez": [1, 4, 18, 20, 21, 31], "src": 5, "src_mask": 23, "ss": 6, "stabil": [19, 24, 26], "stabl": [0, 2, 4, 17, 18, 20, 22, 24], "stack": [18, 20, 31], "stage": 24, "stai": [10, 11, 12, 13, 14, 15, 16, 31], "stand": [17, 29], "standard": [1, 4, 17, 19, 24, 26, 29], "stanford": 9, "stanfordnlp": [22, 24], "stanlei": 3, "start": [0, 1, 4, 17, 20, 21, 23, 24, 25, 26, 27, 30, 31], "starter": 5, "startofsequ": 23, "startswith": [26, 28], "stat": [1, 4], "state": [0, 2, 3, 6, 17, 19, 21, 22, 23, 26, 28, 31], "stateless": 27, "statement": 25, "static": 23, "statist": [17, 20], "stdv": 20, "step": [0, 1, 2, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "step_scor": 28, "stepwis": 27, "stereotyp": 30, "stick": 17, "still": [17, 19, 21, 22, 23, 25, 29], "stochast": [19, 21, 30], "stock": 17, "stop": [17, 20, 23, 24, 28], "stopword": 17, "storag": [4, 17], "store": [3, 4, 5, 18, 19, 20, 21, 22, 29, 31], "stori": 26, "storycloz": 30, "str": [0, 1, 2, 4, 17, 29, 31, 32], "str_tok": 31, "straightforward": 4, "stranger": 5, "strategi": [10, 17, 29, 30], "stream": 27, "street": [17, 25], "stress": 3, "strictli": 18, "string": [0, 2, 5, 17, 18, 21, 22, 23, 28, 29, 31], "strip": [1, 4, 28], "strong": [17, 26], "strongli": [17, 30], "stroutputpars": 27, "structur": [1, 3, 5, 13, 17, 18, 20, 22, 27, 29], "student": [0, 2, 6, 26], "studi": [17, 19, 21, 26, 27, 29], "studio": 17, "stumbl": 26, "style": [1, 3, 16, 17, 26], "sualli": 17, "sub": [17, 18, 27, 28], "subclass": 22, "subject": [5, 6, 26], "submiss": [0, 1, 2, 3, 4, 5], "submit": [0, 1, 2, 3, 4, 5, 17], "subplot": 24, "subsampled_dataset": [22, 24], "subsect": 21, "subsequ": [19, 20, 21, 26, 30, 31], "subset": [22, 26], "substep": [22, 27], "subtl": 20, "subtract": [18, 20, 31, 32], "subword": 23, "success": [1, 3, 4, 22, 23, 24, 26], "successfulli": [17, 24], "suffici": [0, 22], "sufficintli": 26, "suggest": [5, 9, 17, 21, 27], "suiss": 17, "suit": [5, 26, 29], "suitabl": [17, 26], "sum": [0, 2, 17, 19, 21, 23, 25, 26, 28, 29], "sum_": 29, "summar": [22, 24, 26, 29], "summari": [1, 2, 3, 4, 26, 27, 29], "summaris": 26, "summend": 25, "super": [20, 21, 23, 28, 31], "super_glue_boolq": 29, "superglu": 29, "superlative_quantifiers_1": 5, "supermarket": 5, "supervis": [11, 28, 30], "supplement": [4, 29], "supplementari": [9, 10, 11, 12, 13, 14, 15, 16], "suppli": [4, 17, 20, 21], "support": [17, 18, 28, 30], "supporting_modul": 4, "suppos": [1, 4, 17, 22, 26, 29], "suppress": 19, "sure": [0, 2, 3, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 31], "surnam": [2, 21], "surname_firstname_hw1": [0, 2], "surname_firstname_hw2": [1, 3], "surname_firstname_hw3": 4, "surname_firstname_hw4": 5, "surp_avg": 21, "surp_avg_dict": 21, "surp_dict": 21, "surp_scal": 21, "surpris": [0, 2, 21], "surprisal_test": 21, "surprisal_train": 21, "surprisl": 21, "surprisl_dict": 21, "survei": 7, "sva_data": 5, "swap": 22, "switch": 24, "swoop": 20, "sy": 28, "symbol": [17, 23], "symmetr": 29, "syntact": [5, 13, 14, 28, 29], "syntax": [5, 18], "syntaxgym": 14, "system": [1, 3, 5, 19, 23, 24, 26, 27, 29, 30], "systemat": 6, "t": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "t5": [24, 28, 29], "t5forconditionalgener": 29, "t5token": 29, "tabl": [3, 5, 17], "tag": [17, 24, 28, 29], "tail": 18, "take": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "taken": [5, 22, 28, 29, 30, 31], "talk": [9, 27], "talmor": [0, 2], "tandem": 29, "tap": 5, "target": [17, 19, 20, 21, 22, 26, 28, 29, 30], "target_id": 28, "target_line_tensor": 21, "target_out": 22, "target_tensor": 21, "task": [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "tau": [0, 2, 25, 29], "teach": 26, "teacher": 5, "team": [17, 30], "technic": [6, 29], "techniqu": [1, 3, 4, 20, 25, 26, 28, 30, 31], "tediou": 20, "televis": 3, "tell": [0, 1, 3, 4, 18, 19, 20, 21, 26, 29], "temp_hook_fn": 31, "temperatur": [0, 2, 4, 25, 27], "templat": 27, "tempor": 21, "temporari": 31, "ten": 26, "tend": 26, "tendenc": 21, "tennei": [13, 28], "tenni": 5, "tensor": [0, 1, 2, 4, 17, 19, 20, 21, 22, 23, 24, 25, 28, 31, 32], "tensor1": 18, "tensor2": 18, "tensor3": 18, "tensor4": 18, "tensor5": 18, "tensor_0d": 18, "tensor_1": 18, "tensor_1_transpos": 18, "tensor_2": 18, "tensor_2d": 18, "tensor_from_list": 18, "tenth": 16, "tep": 4, "term": [5, 8, 17, 22, 23, 25, 26, 29], "terminologi": [27, 29], "termn": [0, 2], "terribl": 25, "test": [0, 1, 2, 3, 4, 5, 14, 16, 17, 20, 22, 24, 25, 26, 27, 28, 30, 31], "test_accuraci": 28, "test_data": 21, "test_dataload": 2, "test_dataset": 2, "test_df": 4, "test_indic": 21, "test_label": 28, "test_labels_al": 28, "test_layer_represent": 28, "test_loss": [2, 22, 28], "test_output": [0, 2], "test_queri": 4, "test_represent": 28, "test_representations_al": 28, "test_sampl": [0, 2], "test_sent": 28, "test_sentence_represent": 28, "test_siz": [17, 21], "test_split": 2, "testabl": 5, "testset": 21, "tex": 0, "text": [0, 1, 2, 3, 4, 11, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "text1": 23, "text2": 23, "text3": 23, "text_d": 29, "text_en": 29, "textbook": [7, 8, 9], "textual": [4, 29], "th": [1, 3, 4, 5, 23], "than": [0, 3, 5, 11, 17, 23, 24, 26, 27, 28, 29, 31], "thei": [1, 3, 4, 5, 6, 17, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "thelik": 23, "them": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "themselv": 6, "theorem": 26, "theoret": [27, 29], "theori": 29, "therebi": [23, 29], "therefor": [0, 2, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "theta": 26, "thi": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "thing": [17, 19, 20, 21, 22, 23, 24, 27, 31], "think": [0, 1, 2, 3, 4, 6, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30], "third": [4, 5, 9, 18, 20, 23, 27, 28], "those": [21, 22, 23, 25, 28, 29, 30], "though": [17, 25], "thought": [1, 3, 10, 15, 18, 22, 25, 30], "thousand": [26, 29], "three": [0, 1, 2, 4, 17, 18, 21, 23, 24, 27], "threshold": 25, "through": [0, 2, 17, 18, 19, 21, 22, 23, 25, 26, 28, 31], "throughout": [0, 2, 17, 22, 30, 31], "thu": [6, 20, 29], "tidi": 17, "tie_word_embed": 0, "tightli": 24, "tile": 28, "time": [0, 1, 2, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 27, 29], "time_sinc": 21, "times5": [0, 2], "timestamp": 20, "tiramiu": 27, "titl": 31, "tmobil": 17, "to_numpi": 31, "to_single_token": 31, "to_str_token": 31, "to_token": 31, "todo": 18, "tofu": 26, "togeth": [4, 5, 22, 23, 25, 27, 28, 31], "tok": 23, "tokein": 17, "token": [0, 1, 2, 3, 4, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32], "token_label": 31, "tokenized_dataset": [0, 22, 24], "tokenized_input": [2, 22, 24], "tokenizer_gpt2": 17, "tokenizer_instruct": 26, "tokenizer_lm": 26, "tokenizer_nam": 4, "tokenizer_t5": 29, "tokenizer_typ": 2, "tokenizers_parallel": 31, "told": 19, "tomato": 27, "too": [1, 4, 22, 24, 29], "tooken": 17, "tool": 17, "top": [17, 25, 27, 28, 31], "top_k": [1, 4, 22, 25], "top_p": [1, 4, 25], "topi": 21, "topic": [2, 6, 11, 12, 17, 23, 24, 25, 29, 30], "topk": [21, 31], "topk_per_lay": 31, "topv": 21, "torch": [0, 1, 2, 4, 5, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32], "torch1": 18, "torch2": 18, "torch_dtyp": [0, 4, 25, 31], "torchrl": 17, "torchtext": 29, "total": [1, 4, 21, 26], "total_loss": [21, 28], "total_s": 21, "touvron": [10, 26], "toward": 26, "town": 29, "toxic": [17, 29, 30], "tqdm": [0, 1, 2, 4, 17, 22, 31], "tqdmwarn": [0, 2, 17, 22], "tra": 17, "trace": 28, "track": [0, 2, 19, 21, 22, 29], "tradit": 17, "train": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 18, 22, 23, 25, 29, 30, 31], "train_accuraci": 28, "train_data": [19, 21], "train_dataload": 20, "train_dataset": [0, 2, 22, 26], "train_indic": 21, "train_label": 28, "train_labels_al": 28, "train_layer_represent": 28, "train_loss": [22, 28], "train_represent": 28, "train_representations_al": 28, "train_sent": 28, "train_sentence_represent": 28, "train_siz": [17, 21], "train_split": 2, "train_step": [0, 2], "train_test_split": 17, "trainabl": [0, 2, 19, 20, 26], "trainer": [22, 26], "training_data": 2, "training_data_cutoff": 2, "trainingargu": 22, "tram": 3, "transfer": 30, "transform": [0, 1, 2, 3, 4, 6, 16, 17, 20, 25, 26, 27, 28, 29, 31], "transformer_len": 31, "transformer_model": 23, "transformerdecod": 23, "transformerdecoderlay": 23, "transformerencod": 23, "transformerencoderlay": 23, "transformermodel": 23, "translat": [24, 28, 29], "transpos": [17, 21, 23], "treat": [18, 20, 22, 28], "tree": [1, 3, 10, 25], "treebank": 29, "trend": 7, "tri": [3, 24, 27], "trial": [5, 26, 29], "trian": [0, 2], "trick": [20, 24], "tricki": [24, 30, 31], "trigram": 29, "triplet": 21, "trivial": 26, "triviaqa": 30, "trl": [1, 4, 26], "troubl": 3, "trough": 17, "true": [0, 1, 2, 4, 5, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "true_answ": 29, "true_dist": 19, "true_loc": 19, "true_logit": 31, "true_posit": 29, "truncat": [0, 1, 2, 4, 22, 24], "trust_remote_cod": [4, 25], "truth": [0, 1, 2, 4, 20, 26, 29], "truthfulqa": 30, "try": [0, 1, 2, 5, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "tsvilodub": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "tuck": 17, "tue": 6, "tune": [3, 6, 10, 12, 13, 14, 15, 16, 17, 19, 22, 24, 25, 27, 28, 29, 30], "tupl": [0, 2], "turbo": [27, 29], "turn": [20, 26], "tutor": 26, "tutori": [0, 2, 17, 19, 20, 21, 22, 23, 24], "tweet": 17, "tweet_length": 17, "twice": [1, 4, 31], "twitter": [2, 17], "two": [0, 1, 2, 3, 4, 5, 8, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30], "txt": [17, 28], "type": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 26, 27, 30, 31], "typic": [5, 20, 21, 25, 26], "u": [1, 4, 5, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30], "ud": 28, "ud_en_pref": 28, "ultim": 26, "umbrella": 22, "un": 26, "unanim": 25, "unclear": [20, 26], "uncom": [0, 2, 4, 17, 22, 26], "under": [0, 2, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "underfit": 24, "undergo": [23, 31], "undergon": [1, 3], "underli": [4, 22, 29], "underpin": 26, "understand": [1, 3, 4, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "understanding_llm": [0, 2, 17, 22, 31], "understood": 17, "undesir": [17, 26, 30], "unembed": 31, "unexpect": 25, "unexpectedli": 29, "unfortun": 17, "unfortunatelli": 27, "unfrozen": 26, "ungrammat": 29, "ungrammatical_log_prob": 29, "ungrammatical_sent": 29, "uni": 17, "unicod": 23, "unicode_liter": 21, "uniform": 20, "uniform_": 20, "uniformli": 18, "unigram": [23, 29], "union": 28, "uniqu": [2, 17, 21, 23, 28], "unique_label": 28, "unit": [5, 17, 18, 21, 23], "univers": 11, "unk": 23, "unknown": [17, 23, 26], "unless": [0, 2, 17], "unnecessari": 23, "unpack": 20, "unrecogn": 28, "unsaf": 30, "unseen": 17, "unsolv": 29, "unsqueez": [18, 22, 23, 31], "unsqueeze_": 21, "unstructur": 4, "unsupervis": [9, 26], "unsurpris": 17, "until": [4, 23, 24, 25], "up": [0, 1, 2, 3, 4, 5, 20, 22, 25, 26, 27, 28, 29, 30, 31], "upcom": 17, "updat": [0, 2, 17, 20, 22, 24, 26, 27, 31], "upload": [0, 1, 2, 3, 4, 5, 22, 28], "upon": 26, "urg": 17, "url": 21, "urllib": 21, "urlopen": 21, "us": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "usa": 5, "usabl": [18, 26], "usag": 17, "usage_custom": 4, "use_cach": [0, 31], "use_mps_devic": 22, "use_nested_tensor": 23, "user": [17, 23, 24, 26, 27, 29, 30], "user_instal": [0, 2, 17, 22], "userwarn": 23, "using_llm": 4, "usr": 23, "usual": [0, 2, 5, 17, 18, 21, 22, 23, 24, 26, 27, 29], "util": [0, 1, 2, 4, 17, 22, 25, 28, 31], "v": [0, 2, 5, 20, 22, 23, 29, 31, 32], "v0": 27, "v1": [4, 29], "v2": [1, 4], "v_0": 32, "v_1": 32, "v_2": 0, "v_4": 32, "v_proj_weight": 23, "v_x": 32, "val_loss": 0, "valid": [0, 1, 2, 4, 17, 23, 24, 26, 27, 29], "validation_dataload": 0, "validation_dataset": 0, "validation_loss": 0, "valu": [1, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "valuabl": 17, "value_var": 20, "valueerror": 28, "vanilla": [4, 26], "vanilla_respons": 4, "vanish": 20, "var": 32, "vari": [25, 26], "variabl": [0, 2, 17, 19, 20, 21, 27, 29, 31], "varianc": 21, "variant": 20, "variat": 5, "varieti": [17, 27, 29], "variou": [1, 3, 4, 6, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31], "vast": [20, 27], "vaswani": 9, "vdim": 23, "ve": 24, "vec": 32, "vecor": 28, "vector": [4, 16, 17, 20, 21, 23, 28, 31], "vector_store_index": 4, "vectorstor": 4, "vectorstorageindex": 4, "vectorstoreindex": 4, "vegetarian": 27, "verb": 5, "verbos": [4, 27], "veri": [1, 3, 4, 17, 21, 22, 23, 24, 25, 26, 27, 29], "versa": [23, 26], "version": [2, 3, 17, 20, 23, 26, 27, 31], "vf_coef": [1, 4], "via": [0, 1, 2, 3, 4, 5, 17, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "vice": [23, 26], "vicuna": 3, "video": [6, 9, 17], "vietnames": 21, "view": [27, 28], "vig": 16, "vignett": 5, "vision": [22, 24, 30], "visual": [4, 5, 17, 23, 25, 30], "vivid": 3, "vocab": [23, 32], "vocab_s": [0, 23], "vocabulari": [0, 2, 17, 20, 21, 23, 24, 25, 31], "vocabulary_s": 2, "vram": 17, "w_": 25, "w_f": 32, "w_i": 25, "wa": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "wai": [0, 1, 2, 3, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "wait": 3, "walk": [5, 28], "wall": 17, "walmart": [3, 17], "wandb": 22, "wang": [10, 16], "want": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "waren": 29, "warm": 26, "warn": [19, 20, 21, 23, 26, 31], "warsaw": 31, "wash": 20, "wave": 3, "we": [0, 1, 2, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "weak": 17, "weaker": 29, "wear": 3, "web": 17, "webbbook": 6, "webbook": 25, "webook": 17, "websit": [2, 9, 22, 23, 27], "webson": [10, 30], "week": [17, 22, 24], "weekli": 6, "wei": 10, "weigh": [1, 4], "weight": [0, 2, 17, 18, 20, 22, 23, 24, 26, 28, 29, 31], "weight_decai": 22, "weight_norm": 20, "welcom": 29, "well": [0, 1, 2, 3, 4, 5, 7, 17, 21, 22, 23, 24, 26, 28, 29, 31], "went": 31, "were": [1, 3, 4, 10, 17, 23, 25, 26, 29, 30, 31], "weren": 23, "what": [0, 1, 2, 3, 4, 5, 6, 10, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "when": [0, 2, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "whenev": 17, "where": [0, 1, 2, 3, 4, 5, 6, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "wherein": [4, 29], "whether": [0, 2, 3, 5, 17, 18, 22, 24, 26, 28, 29, 30, 31], "which": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "while": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 25, 26, 29], "white": 3, "whitespac": [17, 23], "who": [6, 17, 23, 24], "whole": [27, 29], "whose": [24, 26, 30], "why": [1, 3, 4, 5, 17, 20, 21, 23, 25, 26, 28, 29, 30, 31], "wide": [26, 29], "widespread": 23, "width": [18, 21], "wiggl": 20, "wikipedia": [17, 27, 29], "wikipediaapiwrapp": 17, "wikipediaqueryrun": 17, "wikitext": 29, "wilcox": 5, "wild": 16, "window": [0, 1, 4, 17, 28, 29], "wing": 25, "winogend": 29, "winogrand": 30, "wise": [18, 24], "within": [4, 17, 22, 23, 25, 29, 31], "without": [0, 2, 17, 18, 22, 25, 27, 29, 31], "witin": 0, "wkipedia": 29, "wo": 31, "woman": 3, "women": 3, "word": [0, 1, 2, 3, 4, 13, 17, 20, 22, 23, 24, 25, 26, 28, 30], "word2vec": [7, 16, 17], "wordpiec": 23, "work": [0, 1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31], "worker": 17, "workflow": 22, "worksheet": 6, "world": [18, 30], "worri": 29, "wors": [24, 26], "worthwhil": 20, "would": [0, 1, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "wouldn": 23, "wpe": 23, "wrangl": [0, 2, 22, 29], "wrap": 22, "wrapper": [17, 22, 23, 31], "write": [0, 1, 2, 3, 5, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "written": [0, 1, 3, 4, 26, 29], "wrong": [13, 30], "wrongfuldeath": 17, "wte": 23, "www": 4, "w\u00fcrttemberg": 17, "x": [0, 2, 5, 6, 17, 18, 20, 21, 23, 25, 26, 28, 31, 32], "x_": 29, "x_0": 29, "x_1": [0, 2], "x_2": [0, 2], "x_i": 29, "x_n": 29, "x_ob": 20, "x_test": [0, 2], "xaxi": 31, "xie": 10, "xl": 29, "xlabel": [0, 2, 17, 22], "xxx": 2, "y": [5, 17, 18, 20, 25, 31, 32], "y_1": [0, 2, 26], "y_2": [0, 2, 26], "y_3": [0, 2], "y_nois": 20, "y_normal": 20, "y_ob": 20, "y_pred": 20, "yao": 10, "yaxi": 31, "ye": [4, 21, 22, 28, 30], "year": [1, 3, 17], "yet": [4, 17, 21, 22, 26, 28], "ygjpt2red3": 17, "yield": 18, "ylabel": [0, 2, 22], "you": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "your": [0, 1, 2, 3, 4, 5, 10, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "your_api_kei": 27, "yourself": [0, 2, 4, 17, 20, 21, 22, 23, 24, 25, 31], "youself": 20, "yu": 16, "z": [17, 20, 32], "z1": 17, "z2": 17, "z37ijmcqzb": 17, "z_0": 32, "zero": [0, 1, 2, 3, 10, 18, 19, 20, 21, 23, 24, 29, 31], "zero_grad": [19, 20, 21, 28], "zeroshot": 17, "zhao": 7, "ziegler": [1, 4], "zip": [0, 1, 2, 4, 5, 28, 29], "zoom": [3, 4, 5, 28, 30], "\u00fcber": 23}, "titles": ["Homework 1: Language models (58 points)", "Homework 2: Fine-tuning &amp; Prompting of LMs (51 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Implications, Understanding &amp; Philosophy", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "titleterms": {"": [5, 20], "1": [0, 1, 2, 3, 4, 5, 17, 18, 19, 23, 25, 26, 27, 28, 29, 31], "10": 5, "12": [0, 2], "13": 5, "14": 3, "15": [0, 1, 2, 4], "16": [1, 3], "2": [0, 1, 2, 3, 4, 5, 9, 18, 19, 20, 21, 22, 24, 25, 27, 30], "20": [1, 3], "22": 5, "23": [0, 2], "3": [0, 1, 2, 3, 4, 5, 19, 20, 23, 24, 25], "30": 4, "4": [0, 5, 19, 21, 26], "5": [4, 5, 19, 22, 27], "50": [2, 3], "51": 1, "58": 0, "6": 28, "7": [29, 30], "8": [0, 31], "activ": 31, "addit": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "advanc": [1, 3, 20, 30], "agent": [4, 12, 27], "ann": 8, "answer": 0, "api": 17, "ar": 5, "arithmet": 18, "aspect": [4, 30], "assess": [14, 18, 29], "assist": 30, "attent": [23, 28], "attribut": [13, 18, 28], "audienc": 6, "augment": 4, "autograd": 20, "background": 7, "backprop": 19, "backpropag": 19, "behavior": [14, 29], "benchmark": [29, 30], "best": 17, "bias": 5, "bpe": 23, "broadcast": 18, "build": 4, "built": 20, "bwjupyt": 17, "capabl": 5, "charact": 21, "choic": 3, "code": 17, "colab": 17, "column": 18, "comput": [19, 20], "concept": 17, "concis": 20, "configur": [0, 24], "consist": 30, "core": 17, "cours": 6, "creat": 18, "current": [10, 19], "data": [17, 18, 19, 20, 21], "dataset": 17, "decod": [25, 31], "defin": [20, 21], "definit": 20, "distribut": 19, "document": 17, "dynam": 24, "earli": 31, "eo": 23, "error": 19, "essenti": 18, "estim": 19, "evalu": [5, 14, 21, 28, 29, 30], "excercis": 27, "exercis": [0, 1, 2, 3, 4, 5, 24, 25], "explicit": 20, "extract": 2, "fine": [0, 1, 2, 4, 11, 26], "fingerprint": 2, "first": [1, 3], "flavour": 26, "formalia": 6, "function": 21, "further": 6, "gener": [3, 4, 21], "global": [20, 21], "gpt": 2, "gradient": 19, "grammat": 5, "graph": 20, "hallucin": 30, "handl": 27, "head": 24, "helper": 21, "homework": [0, 1, 2, 3, 4, 5], "how": 5, "huggingfac": 22, "human": 5, "implic": 15, "index": 18, "infer": 21, "inform": 19, "inspect": 21, "instal": 17, "intend": 6, "interpret": [16, 24, 31], "introduct": 22, "invert": 21, "iter": 6, "join": 18, "just": 18, "knowledg": 30, "langchain": 27, "languag": [0, 2], "layer": 20, "level": 21, "like": 5, "linear": 20, "llama": 5, "llm": [0, 2, 4, 5, 12, 27, 28], "lm": [1, 3, 6, 8, 10, 22], "load": 21, "local": 17, "logist": [0, 1, 2, 3, 4, 5], "loop": 19, "loss": 19, "lstm": 9, "machin": 29, "main": 17, "mask": [23, 24], "materi": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "matrix": 18, "mechanist": [16, 31], "memori": 27, "method": [13, 28], "metric": 29, "ml": [19, 22], "mlm": 24, "mlp": 20, "model": [0, 2, 20, 21, 22, 24, 26], "modul": 20, "more": 20, "multipl": [3, 18], "network": 21, "neural": [1, 3], "nli": 3, "nn": 20, "non": 20, "nvidia": 17, "oper": 18, "optim": 19, "option": [20, 23, 24, 26], "outlook": [20, 22, 23, 24, 26, 29], "output": 27, "overview": 6, "packag": [19, 20, 21], "paramet": [19, 20, 21], "pars": 27, "part": [9, 19], "patch": 31, "peft": 26, "philosophi": 15, "point": [0, 1, 2, 3, 4, 5], "polici": 26, "ppo": 26, "practic": [17, 26], "predict": 19, "prepar": 20, "pretrain": 23, "previou": 6, "probe": 28, "problem": 30, "process": [17, 30], "prompt": [1, 3, 10, 25], "psychologi": 29, "pythia": 0, "pytorch": [8, 18, 20, 23], "qa": [2, 3], "question": 0, "reason": 30, "regress": 20, "requir": 17, "reset": 19, "reshap": 18, "residu": 31, "retriev": 4, "reward": 26, "rl": [4, 26], "rlhf": [1, 4, 11], "rnn": 21, "row": 18, "schedul": 6, "scheme": 25, "sequenc": 21, "set": 17, "sheet": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "signal": 19, "slice": 18, "social": 30, "societ": 5, "solv": 30, "special": 23, "split": 21, "step": 17, "strategi": [1, 3, 25], "stream": 31, "summar": [1, 4], "supervis": 26, "surpris": 5, "system": [4, 12], "tensor": 18, "test": [21, 29], "token": 23, "tool": 27, "train": [17, 19, 20, 21, 24, 26, 28], "transform": [9, 22, 23, 24], "transpos": 18, "true": [19, 20], "tune": [0, 1, 2, 4, 11, 26], "type": 18, "understand": [0, 2, 5, 6, 15, 17], "up": 17, "updat": 19, "us": 20, "util": [20, 24], "valu": [18, 19], "vector": 18, "verifi": 17, "via": 22, "visual": 28, "w": [20, 21], "work": 22, "write": 17}})