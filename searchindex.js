Search.setIndex({"docnames": ["homework/01-language-modeling", "homework/01_language_modeling_solutions", "homework/02-prompting", "homework/02-prompting_solution", "homework/03-agents-RL", "homework/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/09-philosophy", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "filenames": ["homework/01-language-modeling.ipynb", "homework/01_language_modeling_solutions.ipynb", "homework/02-prompting.ipynb", "homework/02-prompting_solution.ipynb", "homework/03-agents-RL.ipynb", "homework/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/09-philosophy.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "titles": ["Homework 1: Language models (50 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LLMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Implications, Understanding &amp; Philosophy", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "terms": {"The": [0, 1, 2, 3, 4, 5, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "first": [0, 4, 7, 8, 9, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "focus": [0, 1, 6, 22, 26, 27, 29], "follow": [0, 1, 2, 3, 4, 5, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "skill": [0, 1, 2, 3, 4, 5, 20, 30], "being": [0, 1, 3, 4, 19, 22, 24, 25, 26, 30, 31], "abl": [0, 1, 3, 17, 18, 21, 22, 23, 24, 26, 30, 31], "work": [0, 1, 2, 4, 5, 6, 10, 13, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31], "simpl": [0, 1, 5, 16, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31], "formal": [0, 1, 8, 23, 26, 30], "properti": [0, 1, 18], "configur": [0, 1, 2, 3, 4, 22, 23, 25, 26], "state": [0, 1, 2, 3, 6, 17, 19, 21, 22, 23, 26, 28, 31], "art": [0, 1, 2, 3, 6, 17, 22, 23, 25, 26], "final": [0, 1, 3, 6, 17, 19, 21, 22, 25, 26, 28, 29, 30], "train": [0, 1, 2, 4, 5, 6, 8, 9, 11, 18, 22, 23, 25, 29, 30, 31], "yourself": [0, 1, 4, 17, 20, 21, 22, 23, 24, 25, 31], "submiss": [0, 1, 2, 3, 4, 5], "deadlin": [0, 1, 2, 3, 4, 5], "mai": [0, 1, 3, 4, 5, 19, 23, 25, 27, 29], "15th": 0, "59": [0, 1, 2, 3, 4, 5], "german": [0, 1, 2, 3, 4, 5, 21, 23, 29], "time": [0, 1, 2, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 27, 29], "via": [0, 1, 2, 3, 4, 5, 17, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "moodl": [0, 1, 2, 3, 4, 5], "pleas": [0, 1, 2, 3, 4, 5, 17, 20, 22, 23, 25, 26, 27, 28, 29], "upload": [0, 1, 2, 3, 4, 5, 22, 28], "singl": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "zip": [0, 1, 4, 5, 28, 29], "file": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 27, 28, 29], "name": [0, 1, 2, 3, 4, 5, 6, 17, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32], "surname_firstname_hw1": 0, "contain": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30], "ipynb": [0, 1, 2, 3, 4, 5], "notebook": [0, 1, 5, 17, 19, 21, 22, 26, 28, 31], "you": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "solv": [0, 1, 2, 3, 4, 5, 10, 17, 19, 29], "colab": [0, 1, 2, 3, 4, 5, 22, 25, 26, 28], "can": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "go": [0, 1, 3, 4, 17, 18, 19, 22, 23, 25, 26, 29, 30], "download": [0, 1, 4, 5, 17, 22, 23, 24, 27, 28, 31], "json": [0, 1, 21, 31], "ex": [0, 2, 3, 4, 24], "png": 0, "jpg": 0, "your": [0, 1, 2, 3, 4, 5, 10, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "loss": [0, 1, 3, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29], "plot": [0, 1, 4, 5, 17, 18, 19, 20, 21, 22, 24, 30], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "submit": [0, 1, 2, 3, 4, 5, 17], "individu": [0, 1, 2, 3, 4, 5, 28], "us": [0, 1, 2, 4, 5, 12, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "speed": [0, 1, 2, 3, 4, 5, 17, 20, 26], "up": [0, 1, 2, 3, 4, 5, 20, 22, 25, 26, 27, 28, 29, 30, 31], "execut": [0, 1, 2, 3, 4, 5, 17, 26, 27, 31], "code": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "especi": [0, 1, 3, 17, 21, 26, 29, 30], "avail": [0, 1, 2, 3, 4, 5, 17, 18, 22, 25, 26, 27, 28, 29], "gpu": [0, 1, 2, 3, 4, 5, 17, 18, 22, 25, 31], "resourc": [0, 1, 2, 3, 4, 5, 17, 22, 24, 25, 26, 27, 30], "allow": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31], "For": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "befor": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 26, 27, 29, 31], "navig": [0, 1, 2, 3, 4, 5, 17], "runtim": [0, 1, 2, 3, 4, 5, 17, 25], "chang": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 22, 24, 25, 26, 28, 29, 30], "type": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 26, 27, 30, 31], "save": [0, 1, 2, 3, 4, 5, 17, 20, 21, 24, 31], "answer": [0, 2, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "importantli": [0, 1, 26, 29], "reason": [0, 1, 2, 3, 10, 13, 26, 29], "step": [0, 1, 4, 5, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31], "i": [0, 1, 2, 3, 4, 5, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "e": [0, 1, 2, 3, 4, 5, 6, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "where": [0, 1, 2, 3, 4, 5, 6, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "calcul": [0, 1, 3, 4, 5, 20, 21, 23, 26, 29, 31, 32], "ar": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "requir": [0, 1, 3, 4, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "provid": [0, 1, 2, 3, 4, 5, 14, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "intermedi": [0, 1, 10, 29, 30, 31], "how": [0, 1, 2, 4, 6, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "arriv": [0, 1, 28, 31], "solut": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 24, 26, 30], "do": [0, 1, 2, 3, 4, 5, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "need": [0, 1, 2, 3, 4, 9, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "write": [0, 1, 2, 3, 5, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "ani": [0, 1, 2, 5, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31], "just": [0, 1, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 31], "mathemat": [0, 1, 7, 16, 18, 23, 30], "6pt": [0, 1], "consid": [0, 1, 2, 3, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "corpu": [0, 1, 3, 17, 22, 23, 30], "c": [0, 1, 3, 4, 5, 18, 20, 21, 23, 26, 29], "sentenc": [0, 1, 2, 3, 4, 5, 13, 17, 22, 23, 24, 25, 26, 28, 29, 31, 32], "cat": [0, 1, 3, 18, 21, 22], "sleep": [0, 1, 3], "mous": [0, 1], "sing": [0, 1, 3], "A": [0, 1, 2, 4, 5, 7, 12, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32], "dog": [0, 1, 23, 24, 28], "defin": [0, 1, 3, 4, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31], "vocabulari": [0, 1, 3, 17, 20, 21, 23, 24, 25, 31], "v": [0, 1, 20, 23, 32], "thi": [0, 1, 2, 3, 4, 5, 6, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "assum": [0, 1, 22, 23, 24, 25], "word": [0, 1, 2, 4, 13, 17, 20, 22, 23, 24, 25, 26, 28, 30], "token": [0, 1, 2, 4, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32], "b": [0, 1, 3, 4, 5, 17, 18, 20, 23, 26, 28, 29], "pick": [0, 1, 17, 23, 26, 31], "one": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "four": [0, 1, 3, 25], "formul": [0, 1, 2, 3, 5], "probabl": [0, 1, 3, 4, 5, 17, 19, 20, 21, 23, 24, 25, 26, 29, 31], "form": [0, 1, 2, 3, 4, 17, 18, 26, 29, 30], "chain": [0, 1, 10, 20, 25, 27, 30], "rule": [0, 1, 20, 21, 23], "each": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "termn": [0, 1], "given": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "4pt": [0, 1], "we": [0, 1, 3, 4, 5, 6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "want": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "neural": [0, 1, 6, 7, 8, 9, 16, 20, 21, 22, 23, 24], "network": [0, 1, 3, 6, 8, 9, 20, 22, 23, 24, 27, 28], "take": [0, 1, 2, 3, 4, 5, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "input": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "two": [0, 1, 2, 3, 4, 5, 8, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30], "number": [0, 1, 3, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29], "x_1": [0, 1], "x_2": [0, 1], "pass": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32], "them": [0, 1, 2, 3, 4, 5, 6, 13, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "through": [0, 1, 3, 17, 18, 19, 21, 22, 23, 25, 26, 28, 31], "three": [0, 1, 3, 4, 17, 18, 21, 23, 24, 27], "hidden": [0, 1, 20, 21, 24, 31], "linear": [0, 1, 21, 23, 24, 28, 31], "layer": [0, 1, 21, 22, 23, 24, 26, 28, 31, 32], "13": [0, 1, 3, 20, 21, 25, 32], "neuron": [0, 1, 28], "relu": [0, 1, 20, 21], "activ": [0, 1, 3, 16, 19, 20, 21, 22, 26], "function": [0, 1, 3, 4, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31], "output": [0, 1, 3, 4, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32], "y_1": [0, 1, 26], "y_2": [0, 1, 26], "y_3": [0, 1], "down": [0, 1, 2, 3, 17, 20, 23, 26, 28], "all": [0, 1, 3, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "weight": [0, 1, 18, 20, 22, 23, 24, 26, 28, 29, 31], "matric": [0, 1, 18, 20, 22, 23, 26], "dimens": [0, 1, 17, 18, 20, 22, 23, 24, 26], "exampl": [0, 1, 2, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "matrix": [0, 1, 17, 21, 23, 26, 31, 32], "ha": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "3x5": [0, 1], "m_1": [0, 1], "r": [0, 1, 4, 17, 26, 29, 32], "times5": [0, 1], "2pt": [0, 1, 4], "sequenc": [0, 1, 3, 20, 23, 24, 25, 27, 28, 31], "some": [0, 1, 2, 3, 4, 5, 10, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "student": [0, 1, 3, 6, 26], "space": [0, 1, 2, 3, 4, 17, 21, 26, 28, 29, 31], "punctuat": [0, 1, 17, 23], "correspond": [0, 1, 5, 20, 22, 23, 24, 26, 28, 29], "under": [0, 1, 3, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "p": [0, 1, 3, 17, 18, 21, 23, 24, 25, 26], "0": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "67": [0, 1, 5, 20, 21], "91": [0, 1, 32], "83": [0, 1, 20], "40": [0, 1, 18, 21], "29": [0, 1, 23, 26, 32], "58": [0, 1, 21], "75": [0, 1, 21, 28, 32], "comput": [0, 1, 3, 4, 6, 10, 16, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "averag": [0, 1, 3, 5, 17, 21, 25, 29], "surpris": [0, 1, 21], "note": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "class": [0, 1, 2, 3, 4, 7, 10, 11, 12, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "alwai": [0, 1, 17, 21, 25, 27, 29, 31], "base": [0, 1, 2, 3, 4, 5, 10, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "log": [0, 1, 3, 4, 5, 21, 22, 23, 25, 26, 29, 31], "unless": [0, 1], "indic": [0, 1, 3, 5, 21, 22, 23, 25, 26, 28, 29, 30], "otherwis": [0, 1, 4, 17, 19, 22, 25, 26, 29], "also": [0, 1, 2, 3, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "usual": [0, 1, 3, 5, 17, 18, 21, 22, 23, 24, 26, 27, 29], "case": [0, 1, 3, 4, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31], "throughout": [0, 1, 17, 22, 30, 31], "nlp": [0, 1, 2, 3, 6, 7, 16, 17, 22, 24, 29], "task": [0, 1, 2, 3, 4, 5, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "job": [0, 1, 3, 4, 17, 20, 25, 29], "larg": [0, 1, 3, 6, 10, 11, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 31], "paper": [0, 1, 2, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 23, 24, 25, 26, 29, 30, 31], "specif": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "find": [0, 1, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30], "assign": [0, 1, 5, 6, 17, 19, 21, 23, 24, 25, 26, 29, 30, 31], "surnam": [0, 1, 21], "list": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "hw1_model2group_assign": [0, 1], "csv": [0, 1, 5, 25, 29], "found": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29], "topic": [0, 1, 6, 11, 12, 14, 16, 17, 23, 24, 25, 29, 30], "02": [0, 1, 18, 23, 25], "investig": [0, 1, 5, 21, 29], "latest": [0, 1, 28], "version": [0, 1, 2, 3, 17, 20, 23, 26, 27, 31], "specifi": [0, 1, 17, 18, 20, 22, 23, 24, 26, 27, 28], "out": [0, 1, 3, 4, 5, 6, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "charactersitc": 0, "respons": [0, 1, 3, 4, 5, 23, 29], "format": [0, 1, 3, 4, 5, 17, 19, 20, 21, 25, 26, 27, 28, 29], "below": [0, 1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "partial": [0, 1, 3, 26, 31], "cours": [0, 1, 3, 17, 22, 25, 26, 27, 31], "might": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "inform": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "categori": [0, 1, 5, 21, 24, 26, 29], "applic": [0, 1, 4, 20, 21, 22, 23, 24, 28, 29, 30], "idea": [0, 1, 3, 5, 17, 20, 21, 24, 25, 26, 27, 28, 29, 31], "creat": [0, 1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31], "fun": [0, 1, 2, 3], "websit": [0, 1, 22, 23, 27], "which": [0, 1, 2, 4, 5, 6, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "show": [0, 1, 3, 4, 5, 10, 19, 20, 21, 22, 23, 24, 26, 28, 31], "somewhat": [0, 1, 20, 25, 27, 29], "comprehens": [0, 1], "graphic": [0, 1], "comparison": [0, 1, 2, 3, 26, 29, 30, 31], "current": [0, 1, 20, 21, 23, 26, 28, 31], "collect": [0, 1, 3, 17, 21, 22, 26], "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "set": [0, 1, 3, 4, 5, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "front": [0, 1, 3], "end": [0, 1, 3, 4, 18, 21, 23, 24, 25, 26, 29, 30, 31, 32], "dure": [0, 1, 2, 3, 4, 5, 17, 19, 21, 23, 24, 26, 29, 31], "import": [0, 1, 3, 4, 5, 6, 14, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "email": [0, 1], "NOT": [0, 1, 4, 17, 22, 26, 27, 30], "consent": [0, 1], "model_nam": [0, 1, 4, 28], "35": [0, 1, 21, 29], "huggingface_model_id": [0, 1], "gpt35": [0, 1], "paper_url": [0, 1], "http": [0, 1, 3, 4, 17, 18, 21, 22, 26, 28, 29, 31], "arxiv": [0, 1, 3, 26, 29], "org": [0, 1, 3, 18, 26, 28, 29], "ab": [0, 1, 19, 20, 29], "xxx": [0, 1], "tokenizer_typ": [0, 1], "bpe": [0, 1], "vocabulary_s": [0, 1], "architectur": [0, 1, 2, 3, 6, 9, 16, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31], "mixtur": [0, 1, 17], "transform": [0, 1, 2, 3, 4, 6, 13, 16, 17, 20, 25, 26, 27, 28, 29, 31], "agent": [0, 1, 6, 26], "architecture_typ": [0, 1], "decod": [0, 1, 2, 3, 4, 21, 22, 23, 26, 28, 29], "onli": [0, 1, 2, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "architecture_quirk": [0, 1], "spars": [0, 1], "attent": [0, 1, 3, 9, 13, 17, 20, 25, 26, 31, 32], "paramet": [0, 1, 2, 3, 4, 11, 17, 22, 23, 24, 25, 26, 27, 28, 29, 31], "finetuning_typ": [0, 1], "rlhf": [0, 1, 17, 26, 30], "training_data_cutoff": [0, 1], "2050": [0, 1], "number_training_token": [0, 1], "pretraining_data_s": [0, 1], "1gb": [0, 1], "finetuning_data_s": [0, 1], "training_data": [0, 1], "book": [0, 1, 3, 6, 17], "twitter": [0, 1, 17], "finetuning_data": [0, 1], "access": [0, 1, 3, 4, 17, 20, 22, 23, 25, 26, 28, 31], "open": [0, 1, 3, 4, 5, 10, 17, 21, 22, 25, 26, 27, 28, 29], "summari": [0, 1, 2, 3, 4, 26, 27, 29], "few": [0, 1, 2, 6, 7, 10, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29], "what": [0, 1, 2, 4, 5, 6, 10, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "claim": [0, 1], "uniqu": [0, 1, 17, 21, 23, 28], "sell": [0, 1], "main": [0, 1, 3, 4, 5, 19, 20, 21, 26, 27, 30], "contribut": [0, 1, 17, 23, 28, 31], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "goal": [0, 1, 4, 14, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "practic": [0, 1, 6, 20, 22, 23, 24, 25, 29], "pretrain": [0, 1, 4, 17, 18, 22, 26, 27, 31], "lm": [0, 1, 4, 5, 6, 11, 14, 17, 23, 24, 25, 26, 28, 29, 30, 31], "small": [0, 1, 2, 3, 4, 6, 16, 17, 19, 22, 23, 26, 28, 29, 31], "particular": [0, 1, 2, 3, 4, 5, 11, 17, 21, 22, 23, 26, 27, 28, 30], "commonsens": [0, 1, 3, 10], "question": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "dataset": [0, 1, 4, 5, 20, 21, 22, 24, 26, 29, 30], "commonsenseqa": [0, 1, 25, 29, 30], "wa": [0, 1, 2, 4, 5, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31], "introduc": [0, 1, 2, 3, 6, 8, 9, 10, 17, 18, 19, 21, 23, 24, 25, 26, 29, 30], "talmor": [0, 1], "et": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "al": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "2018": [0, 1, 11], "evalu": [0, 3, 4, 6, 22, 24, 26], "perform": [0, 1, 3, 4, 5, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "our": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31], "test": [0, 1, 2, 3, 4, 5, 14, 16, 17, 20, 22, 24, 25, 26, 27, 28, 30, 31], "split": [0, 1, 4, 17, 20, 22, 23, 24, 26, 28, 29], "over": [0, 1, 2, 3, 4, 5, 15, 17, 19, 20, 23, 24, 25, 26, 27, 29, 31, 32], "monitor": [0, 1, 17, 21], "whether": [0, 1, 2, 3, 5, 15, 17, 22, 24, 26, 28, 29, 30, 31], "s": [0, 1, 3, 4, 6, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "improv": [0, 1, 3, 4, 10, 17, 20, 21, 22, 25], "compar": [0, 1, 2, 3, 4, 5, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31], "prepar": [0, 1, 3, 4, 17, 19, 22], "data": [0, 1, 2, 4, 5, 22, 23, 24, 26, 28, 29, 30], "accord": [0, 1, 17, 23, 30], "describ": [0, 1, 3, 4, 5, 17, 21, 22, 25, 26, 29, 30], "sheet": [0, 1, 2, 3, 4, 5, 7], "addition": [0, 1, 4, 17, 21, 26, 28, 30], "custom": [0, 1, 4, 20, 22, 26, 28], "like": [0, 1, 2, 3, 4, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "massag": [0, 1, 17, 19, 22], "ship": [0, 1, 22, 23], "huggingfac": [0, 1, 4, 11, 17, 23, 26, 27, 28, 31], "string": [0, 1, 5, 17, 18, 21, 22, 23, 28, 29, 31], "proces": [0, 1], "happen": [0, 1, 3, 21, 22, 27, 29], "load": [0, 1, 2, 3, 4, 5, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 31], "pipelin": [0, 1, 4, 17, 22, 25], "5": [0, 1, 3, 17, 18, 20, 21, 23, 25, 26, 29, 30, 32], "run": [0, 1, 3, 4, 17, 20, 22, 25, 26, 28, 29, 31], "while": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 25, 26, 29], "track": [0, 1, 19, 21, 29], "19pt": [0, 1], "complet": [0, 1, 3, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31], "spot": [0, 1, 22], "comment": [0, 1, 4, 5, 17, 22, 23], "here": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "There": [0, 1, 2, 3, 6, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "instruct": [0, 1, 2, 3, 4, 11, 17, 18, 26, 27, 28, 29], "should": [0, 1, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "implement": [0, 1, 2, 4, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "With": [0, 1, 18, 22, 25], "let": [0, 1, 2, 3, 4, 17, 18, 19, 21, 23, 24, 26, 27, 29], "without": [0, 1, 3, 17, 18, 22, 25, 27, 29, 31], "error": [0, 1, 8, 17, 22, 26, 31], "necessarili": [0, 1, 19, 26], "expect": [0, 1, 3, 4, 17, 21, 22, 25, 26, 27, 28, 29], "great": [0, 1, 3, 17, 20, 29], "actual": [0, 1, 2, 3, 4, 15, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "grade": [0, 1], "often": [0, 1, 3, 4, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31], "sever": [0, 1, 3, 17, 21, 23, 24, 27, 29], "correct": [0, 1, 2, 3, 23, 24, 25, 26, 27, 29, 30, 31], "wai": [0, 1, 2, 3, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "someth": [0, 1, 5, 15, 19, 20, 21, 26, 30, 31], "anyth": [0, 1, 3, 17, 20, 23, 26], "accept": [0, 1, 3, 5, 27], "execis": [0, 1], "instal": [0, 1, 4, 18, 20, 22, 26, 27, 28, 29, 31], "did": [0, 1, 4, 17, 20, 22, 24, 25, 26, 31], "don": [0, 1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 29, 31], "t": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "forget": [0, 1, 20, 22, 26], "local": [0, 1, 18, 21, 22, 25, 26, 27, 28, 31], "environ": [0, 1, 4, 17, 22, 26, 31], "load_dataset": [0, 1, 4, 5, 17, 22, 24, 26, 29], "autotoken": [0, 1, 3, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "automodelforcausallm": [0, 1, 3, 22, 24, 25, 26, 29, 31], "gpt2token": [0, 22], "gpt2lmheadmodel": [0, 22, 23, 24], "torch": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32], "util": [0, 1, 3, 4, 17, 22, 25, 28, 31], "dataload": [0, 1, 4, 17, 20, 22], "numpi": [0, 1, 3, 18, 20, 21, 25, 28, 29, 31, 32], "np": [0, 1, 3, 18, 20, 21, 25, 28, 29, 31, 32], "matplotlib": [0, 1, 17, 19, 20, 21, 22], "pyplot": [0, 1, 17, 19, 20, 21, 22], "plt": [0, 1, 17, 19, 20, 21, 22], "tqdm": [0, 1, 3, 4, 17, 22, 31], "opt": [0, 17, 19, 22, 23, 26, 31], "anaconda3": [0, 17, 22, 23, 31], "env": [0, 3, 17, 22, 23, 27, 31], "understanding_llm": [0, 17, 22, 23, 31], "lib": [0, 3, 17, 22, 23, 31], "python3": [0, 17, 22, 23, 31], "10": [0, 1, 3, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "site": [0, 3, 17, 22, 23, 31], "packag": [0, 1, 2, 3, 4, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "auto": [0, 3, 4, 17, 22, 23, 26], "py": [0, 3, 17, 22, 23, 26, 31], "21": [0, 3, 17, 18, 20, 22, 32], "tqdmwarn": [0, 3, 17, 22], "iprogress": [0, 3, 17, 22], "updat": [0, 1, 3, 17, 20, 22, 24, 26, 27, 31], "jupyt": [0, 3, 17, 22], "ipywidget": [0, 3, 17, 22, 28], "see": [0, 1, 2, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "readthedoc": [0, 3, 17, 22], "io": [0, 3, 4, 17, 22], "en": [0, 3, 4, 17, 22, 28], "stabl": [0, 3, 4, 17, 18, 20, 22, 24], "user_instal": [0, 3, 17, 22], "html": [0, 3, 17, 18, 22, 28], "autonotebook": [0, 3, 17, 22], "notebook_tqdm": [0, 3, 17, 22], "additioanlli": [0, 1], "acceler": [0, 1, 2, 3, 4, 22, 26], "uncom": [0, 1, 4, 17, 22, 26], "line": [0, 1, 4, 17, 20, 21, 22, 23, 24, 28], "pip": [0, 1, 4, 17, 22, 26, 27, 28, 31], "reload": [0, 1, 22], "kernel": [0, 1, 22], "after": [0, 1, 3, 17, 19, 20, 22, 23, 24, 25, 26, 31], "get": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "depend": [0, 1, 3, 17, 18, 21, 22, 23, 24, 26, 27, 28, 30], "prep": [0, 1], "acquir": [0, 1, 17], "minim": [0, 1, 5, 17, 19, 20, 23, 27, 30], "explor": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28], "clean": [0, 1, 2, 3, 17, 20, 31], "wrangl": [0, 1, 22, 29], "combin": [0, 1, 3, 17, 21, 23, 24, 25, 29], "4": [0, 1, 2, 3, 4, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "abov": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "d": [0, 1, 3, 4, 18, 20, 21, 22, 24, 26, 29], "hyperparam": [0, 1], "further": [0, 1, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 31], "make": [0, 1, 3, 4, 5, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "sure": [0, 1, 2, 3, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 31], "batch": [0, 1, 4, 17, 20, 22, 23, 24, 26, 28, 31], "converst": [0, 1], "2d": [0, 1], "tensor": [0, 1, 4, 17, 19, 20, 21, 22, 23, 25, 28, 31, 32], "common": [0, 1, 4, 17, 20, 22, 23, 24, 25, 26, 29, 30], "when": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "text": [0, 1, 2, 3, 4, 11, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "downaload": [0, 1], "hf": [0, 1, 2, 3, 4, 20, 22, 23, 24, 25, 27, 28], "tau": [0, 1, 25, 29], "commonsense_qa": [0, 1, 29], "inspect": [0, 1, 3, 4, 5, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "print": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "kei": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32], "sampl": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29], "dict_kei": 0, "valid": [0, 1, 4, 17, 23, 24, 26, 27, 29], "doe": [0, 1, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "have": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ground": [0, 1, 2, 3, 4, 12, 20, 26, 29], "truth": [0, 1, 4, 20, 26, 29], "label": [0, 1, 2, 3, 4, 17, 20, 21, 22, 24, 25, 26, 28, 29, 31], "therefor": [0, 1, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "from_pretrain": [0, 1, 3, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "gpt2": [0, 1, 4, 5, 17, 22, 23, 24, 26, 28, 29, 31], "pad_token": [0, 1, 4, 22], "eos_token": [0, 1, 4, 22], "pad": [0, 1, 3, 4, 17, 20, 22, 23, 24, 25], "side": [0, 1, 3, 17, 22, 23], "left": [0, 1, 3, 4, 22, 23, 27], "becaus": [0, 1, 3, 4, 17, 19, 20, 21, 22, 23, 24, 26, 29, 31], "causal": [0, 1, 16, 22, 23, 24, 25, 28, 29, 31], "padding_sid": [0, 1, 4, 22], "def": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "massage_input_text": [0, 1, 29], "helper": [0, 1, 22, 24, 29, 31], "convert": [0, 1, 4, 17, 18, 22, 23, 28, 29], "separ": [0, 1, 4, 5, 20, 23, 25, 26, 29], "qquestion": [0, 1], "option": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 27, 28, 29, 30, 31], "argument": [0, 1, 18, 22, 23, 24, 26, 28, 29, 30], "dict": [0, 1, 4, 17, 21, 28, 29], "g": [0, 1, 3, 4, 5, 6, 12, 13, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "return": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "input_text": [0, 1, 3, 22, 24, 25, 28], "str": [0, 1, 4, 17, 29, 31, 32], "forwat": [0, 1], "etc": [0, 1, 4, 12, 17, 20, 22, 23, 24, 28, 29, 30], "its": [0, 1, 2, 3, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "answer_options_list": [0, 1, 29], "choic": [0, 1, 4, 5, 17, 22, 24, 25, 26, 27, 29, 30], "join": [0, 1, 3, 17, 25, 28, 29], "answer_opt": [0, 1, 3, 5, 29], "answer_options_str": [0, 1], "append": [0, 1, 3, 4, 21, 22, 23, 25, 26, 29, 31], "true": [0, 1, 3, 4, 5, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "new": [0, 1, 3, 4, 17, 18, 21, 22, 23, 26, 31], "nanswer": [0, 1], "answerkei": [0, 1, 29], "process": [0, 1, 3, 5, 7, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "massaged_dataset": [0, 1], "map": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 28, 29, 31], "lambda": [0, 1, 17, 29], "preprocess": [0, 1, 17, 23], "commonsenseqadataset": [0, 1], "__init__": [0, 1, 20, 21, 23, 28, 31], "self": [0, 1, 3, 10, 20, 21, 22, 23, 26, 28, 31], "train_split": [0, 1], "test_split": [0, 1], "max_length": [0, 1, 4, 21, 22, 24], "64": [0, 1, 19, 22, 23, 24], "dataset_split": [0, 1], "none": [0, 1, 3, 19, 20, 23, 24, 31], "initi": [0, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29], "object": [0, 4, 5, 16, 17, 18, 19, 20, 21, 22, 24, 26, 31], "dictionari": [0, 1, 21, 23], "differ": [0, 1, 2, 4, 5, 6, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "column": [0, 1, 3, 17, 21, 29], "int": [0, 1, 17, 18], "maxim": [0, 2, 3, 4, 5, 17, 19, 22, 24, 25, 26], "length": [0, 1, 5, 17, 18, 20, 21, 23, 25, 26, 29], "truncat": [0, 1, 4, 22, 24], "default": [0, 18, 19, 21, 22, 23, 26, 27, 28, 29, 31], "__len__": [0, 1, 20], "method": [0, 1, 3, 4, 6, 14, 16, 17, 20, 22, 26, 29, 30, 31], "__getitem__": [0, 1, 20], "idx": [0, 1, 3, 20, 23], "mask": [0, 1, 3, 17, 22, 25, 28, 29], "index": [0, 1, 3, 4, 17, 20, 21, 23, 24, 29, 31], "retriev": [0, 1, 3, 18, 21, 22, 23, 25, 26, 28, 29, 31], "tokenized_input": [0, 1, 22, 24], "input_id": [0, 1, 3, 4, 17, 22, 23, 24, 25, 28, 29, 31], "an": [0, 1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "attention_mask": [0, 1, 3, 17, 22, 23, 24, 25], "hint": [0, 1, 4, 5, 17, 20, 22, 23, 24, 25, 29, 30], "return_tensor": [0, 1, 3, 4, 17, 22, 24, 25, 26, 28, 29, 31], "pt": [0, 1, 3, 4, 17, 22, 24, 25, 26, 28, 29, 31], "pad_token_id": [0, 1, 3, 4, 22, 24, 25], "long": [0, 1, 3, 4, 9, 17, 22, 24, 25, 28, 29, 30], "move": [0, 1, 29, 31], "devic": [0, 1, 3, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "cuda": [0, 1, 3, 4, 5, 17, 22, 25, 26, 28, 29, 31], "is_avail": [0, 1, 3, 4, 5, 17, 22, 25, 26, 28, 29, 31], "f": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32], "elif": [0, 1, 3, 5, 17, 22, 25, 28, 29, 31, 32], "backend": [0, 1, 3, 5, 17, 22, 25, 28, 29], "mp": [0, 1, 3, 5, 17, 22, 25, 28, 29], "els": [0, 1, 3, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32], "cpu": [0, 1, 3, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "init": [0, 1, 23], "num": [0, 1, 20, 31], "trainabl": [0, 1, 19, 20, 26], "model_s": [0, 1], "sum": [0, 1, 3, 17, 19, 21, 23, 25, 26, 28, 29], "numel": [0, 1, 26], "size": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 31], "1000": [0, 1, 19, 20, 25], "1f": [0, 1], "m": [0, 1, 3, 18, 21, 23, 25, 28], "If": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 28, 29, 30, 31], "memori": [0, 4, 9, 17, 18, 21], "try": [0, 5, 13, 14, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "decreas": [0, 20, 22, 24, 26], "loop": [0, 1, 4, 20, 21, 22, 24, 27], "instanti": [0, 1, 19, 20, 21, 22, 23, 24, 27], "train_dataset": [0, 1, 22, 26], "test_dataset": [0, 1], "loader": [0, 1], "automat": [0, 1, 4, 12, 20, 22, 23, 24, 27, 29], "iter": [0, 1, 3, 5, 17, 19, 20, 21, 25, 26, 29], "pair": [0, 1, 5, 17, 20, 21, 23, 26, 29], "batch_siz": [0, 1, 4, 20, 22, 28], "32": [0, 1, 17, 18, 20, 21, 23, 28, 32], "shuffl": [0, 1, 17, 20, 21], "retreiv": [0, 1, 27, 29], "test_dataload": [0, 1], "forward": [0, 1, 20, 21, 22, 23, 28, 31, 32], "carefulli": [0, 1, 2, 3, 23, 28], "look": [0, 1, 3, 4, 5, 6, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "link": [0, 1, 4, 5, 27], "tutori": [0, 1, 17, 19, 20, 21, 22, 23, 24], "put": [0, 1, 4, 22, 28, 29, 31], "mode": [0, 1, 4, 26, 29], "trian": [0, 1], "configut": [0, 1], "feel": [0, 1, 2, 3, 5, 19, 22, 23, 25, 26], "free": [0, 1, 2, 3, 5, 17, 22, 23, 25, 26, 29], "plai": [0, 1, 2, 3, 19, 21, 22, 23, 25, 26, 27, 30], "around": [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 25, 26, 27], "epoch": [0, 1, 4, 17, 20, 22, 24, 26, 28], "train_step": [0, 1], "len": [0, 1, 3, 16, 17, 20, 21, 25, 26, 28, 29, 31], "everi": [0, 1, 3, 17, 20, 21, 22, 23, 24, 25, 26, 28], "smaller": [0, 1, 3, 17, 20, 22, 29], "entor": [0, 1], "comp": [0, 1], "num_test_step": [0, 1], "optim": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28], "rate": [0, 1, 3, 17, 19, 21, 22, 24, 25, 26], "adamw": [0, 1], "lr": [0, 1, 19, 20, 21], "5e": [0, 1, 22], "variabl": [0, 1, 3, 17, 19, 20, 21, 27, 29, 31], "accumul": [0, 1, 19], "test_loss": [0, 1, 22, 28], "rang": [0, 1, 3, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "x": [0, 1, 5, 6, 17, 18, 20, 21, 23, 25, 26, 28, 31, 32], "next": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "backward": [0, 1, 19, 20, 21, 22, 28], "item": [0, 1, 3, 5, 18, 19, 20, 21, 23, 25, 28, 29, 31], "zero": [0, 1, 2, 3, 10, 18, 19, 20, 21, 23, 24, 29, 31], "gradient": [0, 1, 20, 21, 24, 26, 28], "j": [0, 1, 17, 29], "x_test": [0, 1], "no_grad": [0, 1, 21, 28], "test_output": [0, 1], "TO": 0, "IT": [0, 27], "AND": [0, 5], "axi": [0, 32], "xlabel": [0, 1, 17, 22], "ylabel": [0, 1, 22], "predict": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "eval": [0, 1, 31], "construct": [0, 1, 3, 4, 5, 18, 20, 21, 22, 25, 26, 27, 29, 30], "construct_test_sampl": [0, 1], "tupl": [0, 1], "sinc": [0, 1, 4, 17, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "test_sampl": [0, 1], "gener": [0, 1, 5, 6, 7, 8, 9, 10, 12, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "max_new_token": [0, 1, 3, 4, 25, 27], "do_sampl": [0, 1, 3, 4, 22, 25], "temperatur": [0, 1, 3, 4, 25, 27], "skip_special_token": [0, 1, 3, 25, 26, 29], "brief": [0, 1, 2, 3, 5, 25], "descript": [0, 1, 3, 4, 5, 27], "kind": [0, 1, 2, 3, 4, 17, 20, 22, 23, 24, 25, 26, 28], "develop": [0, 1, 7, 19, 21, 22, 23, 24, 26, 27, 28, 30], "conceptu": [0, 2, 3, 4, 5, 6, 22, 23, 24, 26, 29, 30, 31], "curv": [0, 1], "think": [0, 1, 2, 3, 4, 6, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30], "well": [0, 1, 2, 3, 4, 5, 7, 10, 14, 17, 21, 22, 23, 24, 26, 28, 29, 31], "sens": [0, 1, 4, 15, 21, 22, 23, 25, 26, 30], "right": [0, 1, 13, 20, 22, 23, 25, 27, 30], "interpret": [0, 1, 4, 5, 6, 21, 28, 29, 30], "On": [0, 1, 15, 17, 22, 25], "mani": [0, 1, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "accuraci": [0, 1, 2, 3, 5, 24, 28, 29, 30], "eabl": 1, "conduct": [1, 6], "12th": 1, "surname_firtname_hw1": 1, "usag": [1, 17], "bo": [1, 23, 25, 32], "eo": [1, 21, 22, 25, 32], "typic": [1, 3, 5, 20, 21, 25, 26], "theses": 1, "nonetheless": [1, 3, 17, 27], "both": [1, 3, 4, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 29, 30], "begin": [1, 17, 22, 23, 25, 26, 32], "align": [1, 6, 26], "p_": [1, 21, 25, 29], "prod": 1, "n_": 1, "n": [1, 3, 4, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 32], "w_i": [1, 25], "w_": [1, 25], "frac": [1, 24, 25, 26, 28, 29], "6": [1, 3, 6, 18, 20, 21, 22, 23, 25, 26, 30, 31, 32], "167": 1, "24": [1, 18, 19, 20, 21, 31, 32], "125": [1, 20, 21], "083": 1, "25": [1, 17, 20, 21, 25], "incorrect": [1, 28, 29, 31], "formula": [1, 23], "deduct": 1, "minor": 1, "mistak": [1, 25], "cacul": 1, "altern": [1, 3, 18, 21, 22, 24, 26, 28, 29], "other": [1, 2, 3, 5, 6, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "alter": [1, 21], "multipli": [1, 17, 18, 24, 32], "w": 1, "cdot": [1, 29], "unlik": 1, "scalar": [1, 4, 18, 20, 26], "multipl": [1, 5, 17, 20, 23, 24, 25, 29, 30], "commut": 1, "pytorch": [1, 17, 19, 21, 22, 24, 28, 31], "would": [1, 3, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "input_neuron": 1, "hidden_neuron": 1, "output_neuron": 1, "\u03f5": 1, "13x2": 1, "hidden1": 1, "b_1": 1, "\u03f5r": 1, "13x1": 1, "bia": [1, 5, 16, 20, 23, 26, 29, 30, 32], "weights1": 1, "m_2": 1, "13x13": 1, "hidden2": 1, "b_2": 1, "weights2": 1, "m_3": 1, "hidden3": 1, "b_3": 1, "weights3": 1, "m_4": 1, "3x13": 1, "b_4": 1, "3x1": 1, "weights4": 1, "In": [1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "transpos": [1, 17, 21, 23], "2x1": 1, "mupltipli": 1, "It": [1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "inner": [1, 17], "match": [1, 2, 3, 4, 5, 17, 21, 23, 28, 29], "result": [1, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "row": [1, 3, 23, 26], "howev": [1, 3, 4, 17, 19, 20, 22, 23, 24, 26, 29, 30], "previou": [1, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "revers": [1, 31], "order": [1, 4, 17, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30], "factor": 1, "orini": 1, "again": [1, 17, 19, 20, 23, 24, 25, 26, 27, 31], "shape": [1, 3, 17, 18, 21, 22, 23, 25, 28, 30, 31, 32], "1x13": 1, "2x13": 1, "13x3": 1, "1x3": 1, "matriz": 1, "m_i": 1, "definit": [1, 17, 21, 22, 23, 25], "b_i": 1, "amount": [1, 17, 21], "0255": 1, "avg": 1, "_": [1, 4, 26, 31], "logp_": 1, "7": [1, 3, 4, 5, 17, 18, 20, 21, 25, 26, 27, 31, 32], "2553533346": 1, "523": 1, "calucl": 1, "mayb": [1, 22, 26, 31], "could": [1, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "even": [1, 3, 15, 17, 18, 20, 22, 24, 26, 27, 28, 29], "own": [1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27], "tbd": 1, "phi": [1, 4, 26], "mixtral": 1, "mistral": [1, 27], "v2": [1, 4], "mamba": 1, "jamba": 1, "ye": [1, 4, 21, 22, 28, 30], "joke": 1, "llama": [1, 2, 3, 4, 6, 10, 17, 22, 23, 26, 30], "suit": [1, 5, 26, 29], "8b": 1, "70b": [1, 26], "gemini": 1, "whole": [1, 27, 29], "multimod": 1, "though": [1, 3, 17, 25], "claud": 1, "seem": [1, 3, 20, 21, 25, 26, 28, 29], "technic": [1, 6, 29], "report": [1, 2, 3, 17, 19, 21, 26], "detail": [1, 3, 4, 17, 22, 23, 24, 25, 26, 27, 29, 30], "palm": 1, "bloom": [1, 5], "interest": [1, 4, 6, 19, 27, 28, 29, 30], "multilingu": [1, 5], "grok": 1, "vicuna": [1, 2, 3], "blog": [1, 4, 25, 26], "falcon": 1, "40b": 1, "gemma": 1, "dbrx": 1, "cmd": 1, "rag": [1, 4], "integr": [1, 17, 20, 25, 26, 27, 28], "coher": 1, "h2o": 1, "danub": 1, "bitnet": 1, "jetmo": 1, "qwen": 1, "moe": 1, "wizardlm": 1, "modulenotfounderror": 1, "traceback": 1, "most": [1, 3, 5, 17, 21, 22, 23, 25, 26, 29, 30], "recent": [1, 2, 3, 5, 17, 23, 25, 29, 30], "call": [1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "last": [1, 5, 17, 19, 20, 21, 22, 24, 26, 28, 29, 30, 31], "ipython": [1, 4], "66d1a2d3ccf0": 1, "modul": [1, 21, 23, 28, 31], "No": 1, "unfortun": [1, 17], "docstr": [1, 17, 23], "were": [1, 2, 4, 10, 17, 23, 25, 26, 29, 30, 31], "wrong": [1, 13, 30], "respect": [1, 4, 5, 14, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "suggest": [1, 3, 5, 17, 21, 27], "fill": [1, 3, 5, 18, 27], "me": [1, 27], "zero_grad": [1, 19, 20, 21, 28], "todo": [1, 18], "arang": [1, 23], "y": [1, 5, 17, 18, 20, 25, 31, 32], "legend": [1, 22], "involv": [1, 3, 17, 23], "basic": [1, 7, 17, 18, 19, 20, 21, 22, 27], "world": [1, 18, 30], "knowledg": [1, 5, 6, 10, 25, 26, 28, 29], "These": [1, 4, 17, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31], "present": [1, 2, 3, 20, 21, 30], "concept": [1, 4, 6, 18, 20, 22, 23, 24, 25, 26, 30, 31], "neg": [1, 19, 21, 24, 26, 29], "likelihood": [1, 19, 21, 29], "grad_fn": [1, 19], "oon": 1, "total": [1, 4, 21, 26], "second": [2, 3, 4, 5, 8, 17, 18, 20, 23, 28], "zoom": [2, 3, 4, 5, 28, 30], "gain": [2, 3, 17, 24, 26, 28], "deeper": [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 23, 30], "understand": [2, 3, 4, 9, 10, 13, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "techniqu": [2, 3, 4, 13, 20, 25, 26, 28, 30, 31], "critic": [2, 3, 4, 6, 17, 20, 22, 28, 29, 30, 31], "regard": [2, 3, 17, 21, 26, 29, 30], "research": [2, 3, 17, 24, 26, 27, 29, 30], "june": [2, 3, 4], "2nd": [2, 3], "th": [2, 3, 4, 5, 23], "23": [2, 3, 4, 5, 20, 21, 31, 32], "surname_firstname_hw2": [2, 3], "discuss": [2, 3, 5, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "variou": [2, 3, 4, 6, 12, 14, 16, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31], "sophist": [2, 3], "languag": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30], "model": [2, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 19, 23, 25, 27, 28, 29, 30, 31], "about": [2, 3, 4, 5, 6, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "context": [2, 4, 5, 6, 10, 11, 13, 17, 18, 20, 22, 23, 24, 25, 26, 29, 30, 31], "briefli": [2, 3, 4, 5, 23, 24, 26], "explain": [2, 3, 4, 5, 20, 21, 26], "max": [2, 3, 23, 24, 25, 28], "build": [2, 3, 5, 17, 18, 20, 22, 23, 25, 26, 27, 28, 29], "intuit": [2, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30], "gpt": [2, 3, 4, 5, 6, 9, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "tune": [2, 3, 6, 10, 17, 19, 22, 24, 25, 27, 28, 29, 30], "7b": [2, 3, 23, 27], "beam": [2, 3, 25], "search": [2, 3, 4, 17, 24, 25, 27], "tree": [2, 3, 10, 25], "thought": [2, 3, 10, 15, 22, 25, 30], "shot": [2, 10, 25], "cot": [2, 3], "why": [2, 3, 4, 5, 17, 20, 21, 23, 25, 26, 28, 29, 30, 31], "thei": [2, 3, 4, 5, 6, 17, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31], "better": [2, 3, 6, 17, 19, 21, 23, 27, 29], "than": [2, 3, 5, 11, 17, 23, 24, 26, 27, 28, 29, 31], "creativ": [2, 3, 25], "flow": [2, 3, 20, 31], "come": [2, 3, 5, 17, 21, 22, 23, 25, 26, 27, 29, 30], "achiev": [2, 3, 25, 26], "inspir": [2, 3, 5, 21, 22, 23, 25, 26, 27, 29], "sentiment": [2, 3, 17, 22, 24, 25, 26, 29], "classif": [2, 3, 11, 17, 20, 22, 24, 26, 29], "scheme": [2, 4, 22], "interact": [2, 3, 12, 28], "intro": [2, 3, 4], "best": [2, 3, 4, 19, 24, 25, 26, 29], "tri": [2, 3, 24, 27], "pythia": [2, 3, 5, 25], "410m": [2, 3], "4b": [2, 3, 25], "natur": [2, 4, 13, 17, 22, 25, 26, 29, 31], "infer": [2, 4, 10, 13, 19, 22, 23, 25, 27, 29], "classifi": [2, 3, 21, 22, 28], "contradict": [2, 3], "entail": [2, 3, 24], "relat": [2, 3, 6, 11, 17, 19, 21, 23, 29, 30], "neutral": [2, 3, 17, 24, 25], "gold": [2, 3, 4, 17, 20, 21, 29], "refer": [2, 3, 4, 5, 12, 17, 20, 22, 24, 25, 26, 28, 29, 30, 31], "obvious": [2, 3], "shouldn": [2, 3], "person": [2, 3, 17, 24], "hors": [2, 3, 20], "jump": [2, 3, 23, 24, 32], "broken": [2, 3], "airplan": [2, 3], "hi": [2, 3, 23, 25], "competit": [2, 3], "outdoor": [2, 3], "children": [2, 3, 30], "smile": [2, 3], "wave": [2, 3], "camera": [2, 3], "boi": [2, 3], "skateboard": [2, 3], "middl": [2, 3, 23, 24], "red": [2, 3, 30], "bridg": [2, 3], "skate": [2, 3], "sidewalk": [2, 3], "older": [2, 3], "man": [2, 3], "sit": [2, 3], "orang": [2, 3], "juic": [2, 3], "tabl": [2, 3, 5, 17], "coffe": [2, 3], "shop": [2, 3, 25], "employe": [2, 3], "bright": [2, 3], "color": [2, 3, 20, 26, 28], "shirt": [2, 3], "background": [2, 3, 4, 5, 11, 22], "drink": [2, 3], "he": [2, 3, 24], "wait": [2, 3], "daughter": [2, 3], "off": [2, 3, 17], "high": [2, 3, 4, 17, 18, 22, 24, 25, 26, 28, 29, 30], "fashion": [2, 3], "ladi": [2, 3], "outsid": [2, 3], "tram": [2, 3], "besid": [2, 3], "crowd": [2, 3], "peopl": [2, 3, 5, 17, 29], "citi": [2, 3, 24, 25], "women": [2, 3], "care": [2, 3, 4, 17, 18, 22, 27, 29, 31], "cloth": [2, 3], "wear": [2, 3], "baggag": [2, 3], "woman": [2, 3], "check": [2, 3, 4, 5, 17, 18, 20, 23, 24, 25, 26, 28, 29, 30, 31], "drawstr": [2, 3], "bag": [2, 3], "she": [2, 3, 29], "head": [2, 3, 4, 5, 18, 22, 26, 28, 29], "garbag": [2, 3, 26], "militari": [2, 3], "jewelri": [2, 3], "store": [2, 3, 4, 5, 18, 19, 20, 21, 22, 29, 31], "safe": [2, 3], "airport": [2, 3], "To": [2, 3, 4, 6, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 31], "prevent": [2, 3, 22, 25], "glare": [2, 3], "big": [2, 3, 29, 30], "footbal": [2, 3], "game": [2, 3], "made": [2, 3, 17, 19, 20, 22], "dust": [2, 3], "televis": [2, 3], "attic": [2, 3], "corner": [2, 3], "cannot": [2, 3, 17, 22, 23, 28, 29], "librari": [2, 3, 4, 18, 23, 26, 31], "presid": [2, 3], "leader": [2, 3], "institut": [2, 3], "walmart": [2, 3, 17], "white": [2, 3], "hous": [2, 3, 29], "countri": [2, 3, 21], "corpor": [2, 3], "govern": [2, 3], "drive": [2, 3], "lead": [2, 3, 21, 25, 26, 29, 31], "accid": [2, 3], "stress": [2, 3], "danger": [2, 3], "illeg": [2, 3], "deadli": [2, 3], "good": [2, 3, 4, 5, 17, 19, 21, 22, 25, 26, 27, 29, 30], "attend": [2, 3, 22, 23, 24], "school": [2, 3], "smart": [2, 3], "boredom": [2, 3], "cold": [2, 3], "flu": [2, 3], "spend": [2, 3], "stanlei": [2, 3], "had": [2, 3, 26], "dream": [2, 3], "veri": [2, 3, 4, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29], "vivid": [2, 3], "scari": [2, 3], "troubl": [2, 3], "tell": [2, 3, 4, 18, 19, 20, 21, 26, 29], "imagin": [2, 3], "realiti": [2, 3], "dreamwork": [2, 3], "nightmar": [2, 3], "awak": [2, 3], "read": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 25, 31], "document": [2, 3, 4, 18, 20, 21, 22, 23, 24, 25, 27, 29], "practition": [2, 3], "assess": [2, 3, 5, 17, 28, 30, 31], "literatur": [2, 3, 17], "densiti": [2, 3, 19], "style": [2, 3, 16, 17, 26], "undergon": [2, 3], "signific": [2, 3, 17], "shift": [2, 3, 18, 22], "year": [2, 3, 17], "increas": [2, 3, 19, 21, 23, 24, 29], "progress": [2, 3, 24], "success": [2, 3, 4, 22, 23, 24, 26], "langaug": [2, 3], "compon": [2, 4, 16, 20, 23, 26, 27], "evolv": [2, 3], "modern": [2, 9, 27, 29], "system": [2, 3, 5, 19, 23, 24, 26, 27, 29, 30], "bengio": [2, 8], "2003": 2, "repres": [2, 5, 17, 18, 20, 21, 22, 23, 26, 28, 29, 31], "similar": [2, 4, 5, 19, 20, 23, 25, 26, 28, 29, 30, 31], "llm": [2, 7, 9, 13, 14, 15, 17, 24, 26, 29, 30, 31], "curs": 2, "dimension": [2, 18, 23], "give": [2, 4, 17, 18, 25, 26, 27, 28, 31], "concret": [2, 19, 22, 23, 26, 27], "same": [2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "post": [2, 3, 4, 25, 26, 28], "dedic": [2, 3, 22], "forum": [2, 3], "furthermor": [2, 3, 5, 17, 20, 21, 28, 29, 30, 31], "dissect": [2, 3], "analys": [2, 3], "structur": [2, 3, 5, 13, 17, 18, 20, 22, 27, 29], "anoth": [2, 3, 5, 20, 21, 22, 23, 24, 28, 29, 30, 31], "more": [2, 3, 4, 5, 6, 9, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "devlin": [2, 3, 9], "2019": [2, 3, 9, 13, 28, 29, 30], "bert": [2, 3, 9, 20, 22, 23, 24, 28], "pre": [2, 3, 9, 11, 17, 20, 21, 23, 28, 31], "deep": [2, 3, 6, 8, 9, 17, 24], "bidirect": [2, 3, 9, 24], "section": [2, 5, 17, 26, 29, 30], "between": [2, 3, 4, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 31], "written": [2, 3, 4, 26, 29], "includ": [2, 3, 4, 12, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "content": [2, 3, 17, 22, 23, 26, 30], "per": [2, 21, 22, 24, 25, 26, 28], "4p": 3, "aspect": [3, 5, 17, 23, 25, 26, 28, 29, 31], "mention": [3, 4, 7, 10, 16, 23, 24, 25, 28, 29, 30], "been": [3, 4, 5, 17, 22, 23, 24, 25, 26, 28, 29, 30, 31], "shown": [3, 4, 21, 26, 29, 30], "standard": [3, 4, 17, 19, 24, 26, 29], "liek": 3, "too": [3, 4, 22, 24, 29], "fanci": 3, "except": [3, 21, 29, 31], "costli": [3, 22, 26], "tot": 3, "wasn": 3, "rl": 3, "matter": 3, "much": [3, 17, 18, 20, 22, 23, 25, 26, 28, 29, 31], "sensibl": [3, 17, 22, 26], "reflect": [3, 5, 17, 30], "upon": [3, 26], "ask": [3, 4, 5, 17, 20, 22, 26, 29, 30, 31], "possibl": [3, 5, 17, 18, 23, 24, 25, 26, 27, 29, 30, 31], "manual": [3, 19, 20, 22, 23], "fine": [3, 6, 10, 17, 22, 25, 27, 28, 29, 30], "continu": [3, 5, 21, 22, 24, 28, 29], "rather": [3, 11, 17, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "larger": [3, 5, 12, 17, 18, 27, 28, 29], "thing": [3, 17, 19, 20, 21, 22, 23, 24, 27, 31], "karahan": 3, "sar\u0131ta\u015f": 3, "systemat": [3, 6], "approach": [3, 4, 5, 6, 17, 23, 24, 25, 26, 27, 28, 29, 30], "ivestig": 3, "panda": [3, 4, 5, 20, 21, 25, 29], "pd": [3, 4, 5, 20, 25, 29], "eleutherai": [3, 25], "user": [3, 17, 23, 24, 26, 27, 29, 30], "karab": 3, "desktop": 3, "special": [3, 4, 20, 21, 22, 24, 25, 26, 27, 28, 29], "ad": [3, 17, 19, 22, 23, 24, 25, 27], "associ": [3, 16, 19, 25], "embed": [3, 4, 17, 20, 21, 23, 25, 28, 29, 30, 31, 32], "set_se": 3, "reproduc": [3, 17], "manual_se": 3, "42": [3, 20, 32], "test_set": 3, "pretty_print": 3, "replac": [3, 31], "100": [3, 17, 18, 19, 20, 21, 25, 27, 29, 31], "greedi": [3, 21, 22, 25], "greedy_decod": 3, "eos_token_id": [3, 4, 22, 25], "beam_search_decod": 3, "num_beam": 3, "early_stop": 3, "impli": 3, "stop": [3, 17, 20, 23, 24, 28], "reach": [3, 23, 24], "pure_sampling_decod": 3, "deactiv": [3, 21], "top_k": [3, 4, 22, 25], "softmax_sampling_decod": 3, "higher": [3, 5, 17, 18, 19, 21, 23, 24, 26, 30, 31], "mean": [3, 4, 10, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32], "random": [3, 4, 18, 21, 24, 25, 28, 31], "top_k_sampling_decod": 3, "k": [3, 18, 21, 23, 25, 31, 32], "exce": [3, 17, 24, 25], "threshold": [3, 25], "nucleu": 3, "top_p_sampling_decod": 3, "9": [3, 17, 18, 21, 25, 32], "top_p": [3, 4, 25], "contrastive_decod": 3, "penalty_alpha": 3, "intent": 3, "prefix": [3, 23, 29], "engin": [3, 4, 17, 20, 23, 24, 27, 29, 31], "One": [3, 17, 21, 24, 26, 27, 28, 29, 30, 31], "consist": [3, 4, 5, 6, 10, 17, 19, 20, 21, 22, 23, 26, 29, 31], "softmax": [3, 21, 25, 31, 32], "major": [3, 17], "vote": 3, "scenario": [3, 29], "pure": [3, 22, 25], "top": [3, 17, 25, 27, 28, 31], "contrast": [3, 5, 22, 23, 28, 29, 30], "penalti": 3, "appli": [3, 17, 18, 20, 21, 22, 23, 24, 28, 29, 31, 32], "disclaim": [3, 27, 30], "As": [3, 12, 20, 22, 23, 25, 26, 27, 28, 29, 30], "hyperparamet": [3, 17, 24, 26, 27], "fair": [3, 30], "believ": [3, 30], "stanford": 3, "snli": 3, "pdf": [3, 26], "1508": 3, "05326": 3, "entir": [3, 5, 17, 20, 22, 23, 24, 27], "independ": 3, "hypothesi": [3, 5], "premis": 3, "reli": [3, 23, 24, 28, 30], "sole": 3, "select": [3, 5, 17, 20, 22, 24, 25, 26, 28, 29, 30], "highest": [3, 5, 25, 29], "disregard": 3, "determin": [3, 17, 18, 20, 21, 23, 24, 29], "decid": [3, 26], "observ": [3, 4, 5, 20, 24, 25, 27, 28, 31], "doesn": [3, 22, 24, 25, 26, 29, 31], "although": [3, 17, 25, 26, 29, 30], "explicitli": [3, 17, 18, 22, 31], "attempt": [3, 28, 30], "irrelev": 3, "appear": 3, "hierarchi": 3, "among": [3, 6], "vari": [3, 25, 26], "outperform": 3, "draw": [3, 20, 25, 29, 30], "solid": 3, "few_shot_examples_v1": 3, "uniform": [3, 20], "figur": [3, 4, 20, 21, 24, 26, 27], "east": 3, "asian": 3, "younger": 3, "men": 3, "laugh": 3, "floor": [3, 21], "church": 3, "choir": 3, "mass": 3, "joyou": 3, "song": 3, "black": [3, 17], "race": 3, "car": 3, "start": [3, 4, 17, 20, 21, 23, 24, 25, 26, 27, 30, 31], "lone": 3, "road": 3, "costum": 3, "hold": [3, 5], "umbrella": [3, 22], "happi": 3, "fairi": 3, "soccer": 3, "male": 3, "sport": 3, "dirti": 3, "barefoot": 3, "kid": 3, "won": 3, "award": 3, "cleanest": [3, 29], "feet": 3, "green": 3, "headscarf": 3, "blue": 3, "grin": 3, "young": 3, "few_shot_examples_v2": 3, "frown": 3, "parent": 3, "basebal": 3, "crack": 3, "ceil": 3, "few_shot_exampl": 3, "__name__": 3, "enumer": [3, 4, 20, 21, 31, 32], "suffix": 3, "few_shot": 3, "encod": [3, 4, 17, 21, 22, 23, 26, 28, 29, 31], "majority_vot": 3, "gt": 3, "gc": 3, "empty_cach": 3, "self_consist": 3, "12": [3, 17, 18, 21, 23, 31, 32], "102": [3, 20], "distractor": [3, 29], "numer": [3, 17, 18, 19, 23, 26], "probe": [3, 6, 13, 21], "diagnost": 3, "145": 3, "primarili": [3, 30], "statement": [3, 25], "pertain": 3, "subsequ": [3, 19, 20, 21, 26, 30, 31], "methodolog": [3, 26, 29], "enabl": [3, 20, 23, 27], "either": [3, 5, 17, 24, 27, 31], "support": [3, 16, 17, 18, 28, 30], "oppos": [3, 17, 21], "emploi": [3, 29, 30], "extract": [3, 17, 23, 24, 28], "score": [3, 4, 5, 23, 24, 25, 26, 28, 29, 32], "classic": 3, "henc": 3, "former": [3, 24], "constrain": 3, "therebi": [3, 23, 29], "limit": [3, 17, 21, 23, 25, 27, 29, 30], "five": [3, 23], "\ud835\udc4e": 3, "identifi": [3, 16, 23, 24, 26, 28, 29, 30, 31], "augment": 3, "maximum": [3, 19, 26], "ultim": [3, 26], "overal": [3, 4, 19, 23, 25, 27, 28, 29], "vanilla": [3, 4, 26], "wing": [3, 25], "penguin": [3, 25], "parallelogram": 3, "limb": [3, 25], "human": [3, 4, 11, 12, 17, 22, 23, 25, 26, 27, 28, 29, 30], "yard": 3, "bird": [3, 25], "rectangular": 3, "squar": 3, "beings": [3, 25], "datafram": [3, 4, 20, 21, 22], "df": [3, 5], "few_shot_templ": [3, 25], "q": [3, 4, 23, 25, 31, 32], "know": [3, 5, 17, 19, 20, 22, 23, 25, 26, 27, 28, 30, 31], "few_shot_prompt": [3, 25], "loc": [3, 19, 20, 25], "lower": [3, 17, 19, 21, 23, 25, 26], "googl": [3, 17, 28, 29], "highwai": 3, "street": [3, 17, 25], "gp": 3, "servic": 3, "fox": [3, 23, 24, 32], "walk": [3, 5, 28], "forest": 3, "share": [3, 17, 20, 26, 27], "someon": 3, "connect": [3, 17, 20, 30, 31, 32], "exot": 3, "snake": 3, "demand": 3, "carri": [3, 17, 23], "bodyguard": 3, "duti": 3, "who": [3, 6, 17, 23, 24], "hire": 3, "him": 3, "electron": [3, 17], "atla": 3, "habitat": 3, "awai": [3, 17, 23], "internet": [3, 17, 29], "rais": [3, 28, 29, 31], "pet": 3, "ensur": [3, 17, 23], "safeti": [3, 30], "secur": 3, "employ": 3, "visual": [3, 4, 5, 13, 17, 23, 25, 30], "prompt_input_id": [3, 25], "knowledge_stat": [3, 25], "15": [3, 17, 19, 20, 21, 24, 25, 32], "id": [3, 17, 22, 23, 24, 25, 28, 29, 31], "consequ": [3, 25], "unexpect": [3, 25], "behavior": [3, 4, 5, 12, 13, 20, 25, 26, 30], "obtain": [3, 17, 18, 19, 21, 25, 26, 30], "reliabl": [3, 25, 29, 30], "so": [3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "no_knowledge_stat": 3, "answer_log_prob": [3, 25], "now": [3, 19, 20, 21, 23, 24, 26, 28, 29, 30], "hand": [3, 4, 6, 17, 21, 25, 27, 28], "maximizing_answ": 3, "maximizing_log_prob": 3, "float": [3, 18, 19, 23, 31], "inf": [3, 32], "log_probs_for_a": 3, "full": [3, 4, 17, 18, 20, 23, 24, 25, 28, 31], "context_prompt": [3, 25], "context_input_id": [3, 25], "ignor": [3, 19, 20, 21, 25], "masked_label": [3, 25], "ones_lik": [3, 25], "pred": [3, 25, 28], "log_p": [3, 25], "max_prob": 3, "her": 3, "luggag": 3, "didn": 3, "re": [3, 23, 24, 27], "carrier": 3, "briefcas": 3, "8": [3, 17, 18, 21, 25, 26, 32], "651183128356934": 3, "358133316040039": 3, "2638578414917": 3, "854644775390625": 3, "918338775634766": 3, "746541976928711": 3, "27782917022705": 3, "510452270507812": 3, "339978218078613": 3, "297685623168945": 3, "776968002319336": 3, "095916748046875": 3, "659232139587402": 3, "95555591583252": 3, "486684799194336": 3, "11": [3, 18, 20, 21, 23, 26, 32], "570777893066406": 3, "832415580749512": 3, "639629364013672": 3, "748946189880371": 3, "790425300598145": 3, "538839340209961": 3, "888652801513672": 3, "38808536529541": 3, "434816360473633": 3, "631083488464355": 3, "umpir": 3, "field": [3, 5, 17, 26, 30], "polic": 3, "offic": 3, "ic": 3, "softwar": [3, 17, 30], "worker": [3, 17], "goe": [3, 21, 26, 29], "235928535461426": 3, "407893180847168": 3, "890667915344238": 3, "370429039001465": 3, "198206901550293": 3, "596774101257324": 3, "11440658569336": 3, "61604118347168": 3, "67751693725586": 3, "281587600708008": 3, "031961441040039": 3, "703117370605469": 3, "687712669372559": 3, "021014213562012": 3, "909016609191895": 3, "271496772766113": 3, "655148983001709": 3, "51792049407959": 3, "4584479331970215": 3, "452688217163086": 3, "554006576538086": 3, "23339557647705": 3, "114116668701172": 3, "754240989685059": 3, "520474433898926": 3, "decis": 3, "elect": 3, "lot": [3, 4, 17, 25, 26], "power": [3, 12, 20, 29], "offici": 3, "142420768737793": 3, "972271919250488": 3, "90455436706543": 3, "03041934967041": 3, "8204474449157715": 3, "612419128417969": 3, "63491153717041": 3, "091569900512695": 3, "645547866821289": 3, "576825141906738": 3, "13504695892334": 3, "369648933410645": 3, "64605712890625": 3, "518067359924316": 3, "83149242401123": 3, "276028633117676": 3, "06977367401123": 3, "650859832763672": 3, "893194198608398": 3, "85256576538086": 3, "173294067382812": 3, "73061466217041": 3, "749650001525879": 3, "258166313171387": 3, "929475784301758": 3, "faulti": 3, "brake": 3, "driver": 3, "influenc": [3, 5, 19], "drug": 3, "708761215209961": 3, "258934020996094": 3, "46780014038086": 3, "419212341308594": 3, "7927885055542": 3, "114299774169922": 3, "092577934265137": 3, "165120124816895": 3, "094646453857422": 3, "583547592163086": 3, "501969337463379": 3, "986560821533203": 3, "233652114868164": 3, "622293472290039": 3, "889074325561523": 3, "216497421264648": 3, "336479187011719": 3, "792975425720215": 3, "515718460083008": 3, "635777473449707": 3, "690098762512207": 3, "63901424407959": 3, "035849571228027": 3, "710489273071289": 3, "199512481689453": 3, "expens": 3, "meant": [3, 17, 19], "educ": 3, "teach": [3, 26], "place": [3, 4, 25], "ith": [3, 29], "589640617370605": 3, "743338584899902": 3, "013982772827148": 3, "673873901367188": 3, "343545913696289": 3, "858763694763184": 3, "82045841217041": 3, "263005256652832": 3, "9718918800354": 3, "668207168579102": 3, "3271989822387695": 3, "516082286834717": 3, "24860143661499": 3, "370843410491943": 3, "465941429138184": 3, "29901123046875": 3, "830539703369141": 3, "338224411010742": 3, "12620735168457": 3, "884116172790527": 3, "690305233001709": 3, "893522262573242": 3, "179699897766113": 3, "780394554138184": 3, "239646911621094": 3, "avers": 3, "height": 3, "medicin": 3, "treat": [3, 20, 22, 28], "pain": [3, 20], "361309051513672": 3, "466972351074219": 3, "520139694213867": 3, "94018840789795": 3, "04466724395752": 3, "76948356628418": 3, "612512588500977": 3, "671875": 3, "55483865737915": 3, "412652015686035": 3, "165630340576172": 3, "419055938720703": 3, "055522918701172": 3, "118217468261719": 3, "015838623046875": 3, "019416809082031": 3, "555357933044434": 3, "577406883239746": 3, "60135555267334": 3, "841059684753418": 3, "815916061401367": 3, "528425216674805": 3, "598419189453125": 3, "201595306396484": 3, "424176216125488": 3, "revolv": 3, "door": 3, "conveni": [3, 20, 22], "direct": [3, 19, 20, 26], "travel": 3, "serv": [3, 4, 25, 27], "measur": [3, 4, 5, 19, 23, 29], "bank": [3, 17], "depart": 3, "mall": 3, "york": 3, "aim": [3, 29, 30], "kill": 3, "anim": 3, "hat": 3, "talk": [3, 27], "magazin": 3, "alongsid": 3, "doctor": 3, "bookstor": 3, "market": 3, "station": 3, "mortuari": 3, "hamburg": 3, "fast": [3, 25], "food": [3, 25, 27], "restaur": 3, "pizza": [3, 25], "dead": 3, "cow": 3, "mouth": 3, "carcass": [3, 22], "jame": 3, "bui": [3, 17], "farmland": 3, "midwest": 3, "countrysid": 3, "estat": [3, 17], "farm": 3, "area": [3, 17, 26, 30], "illinoi": 3, "island": 3, "ferret": 3, "popular": [3, 4, 22, 24, 27, 30], "home": 3, "north": 3, "carolina": 3, "britain": 3, "hutch": 3, "correct_answ": [3, 31], "task_prompt": 3, "instructions_prompt": 3, "review": [3, 4, 22, 26], "iterrow": [3, 4, 29], "noption": 3, "displai": [3, 4], "nquestion": 3, "chr": 3, "ord": [3, 18], "nselect": 3, "moment": [3, 25, 26], "max_prob_idx": [3, 25], "argmax": [3, 25, 29], "149327039718628": 3, "8839691281318665": 3, "7674624919891357": 3, "4614875316619873": 3, "297186851501465": 3, "6051456928253174": 3, "3155701160430908": 3, "452256441116333": 3, "5575783252716064": 3, "7076313495635986": 3, "0540814399719238": 3, "9338192343711853": 3, "921186923980713": 3, "363598346710205": 3, "736490726470947": 3, "7589095234870911": 3, "0533545017242432": 3, "1971399784088135": 3, "8056986331939697": 3, "040278911590576": 3, "03721284866333": 3, "8900933861732483": 3, "955305576324463": 3, "6002087593078613": 3, "708530902862549": 3, "9054934978485107": 3, "1341121196746826": 3, "681248426437378": 3, "6236846446990967": 3, "031479835510254": 3, "real": [3, 27, 30], "vector": [3, 4, 16, 17, 20, 21, 23, 28, 31], "instead": [3, 17, 20, 22, 24, 26, 27, 28, 29, 31], "discret": 3, "determinist": [3, 21], "That": [3, 17, 20, 22, 23, 26, 30], "featur": [3, 13, 17, 21, 27, 28], "remind": [3, 22, 25, 28], "distribut": [3, 20, 21, 24, 25, 29], "represent": [3, 4, 8, 13, 17, 18, 20, 21, 23, 24, 28, 31], "sensit": [3, 28, 30], "divid": [3, 29, 32], "sub": [3, 17, 18, 27, 28], "learnt": 3, "preced": [3, 17, 23, 24, 25], "occur": [3, 5, 17, 20, 24, 29], "wider": 3, "window": [3, 4, 17, 28, 29], "decrib": 3, "rise": [3, 17, 30], "volum": 3, "exponenti": 3, "problem": [3, 4, 6, 10, 17, 29], "still": [3, 17, 19, 21, 22, 23, 25, 29], "dimensi": 3, "rel": [3, 5, 22, 23, 26], "simialar": 3, "joint": 3, "consecut": [3, 21], "000": [3, 5, 17], "smooth": 3, "valu": [3, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "crucial": [3, 17, 28, 29], "finit": [3, 23], "brown": [3, 17, 23, 24, 28], "800": 3, "press": [3, 17], "stream": [3, 27], "million": [3, 24, 26], "divers": [3, 17, 29], "unseen": [3, 17], "contextualis": 3, "challeng": [3, 30], "statist": [3, 17, 20], "offer": [3, 6, 26, 27, 28], "focu": [3, 15, 23, 26, 29, 30], "exist": [3, 17, 20], "theoret": [3, 27, 29], "framework": [3, 12, 16, 25, 26, 27], "wherea": 3, "denvio": 3, "earlier": [3, 26, 28], "elmo": 3, "giant": [3, 14], "finetun": [3, 4, 26], "pictur": [3, 21, 23, 25], "But": [3, 18, 25, 27], "presuppos": [3, 29], "emphas": 3, "diffenrenc": 3, "hardwar": 3, "longer": [3, 19, 23, 26, 29], "comapr": 3, "perplex": [3, 21, 29], "reduct": [3, 21], "ap": 3, "corpora": [3, 17, 29, 30], "sota": [3, 23, 26, 29, 30], "benchmark": [3, 5, 14, 17, 25], "keep": [3, 17, 19, 21, 22, 25, 26], "part": [3, 4, 5, 12, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "short": [3, 4, 9, 17, 18, 20, 21, 22, 26, 30], "summar": [3, 22, 24, 26, 29], "break": [3, 27], "shorter": [3, 17, 20], "third": [4, 5, 9, 18, 20, 23, 27, 28], "advanc": [4, 6, 9, 17, 22, 25], "dive": [4, 11, 22, 23, 30], "28th": 4, "surname_firstname_hw3": 4, "issu": [4, 17, 24, 27, 29, 30], "increasingli": [4, 30], "wherein": [4, 29], "suppli": [4, 17, 20, 21], "addit": [4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29], "textual": [4, 29], "storag": [4, 17], "queri": [4, 17, 23, 25, 27, 28, 32], "proprietari": 4, "databas": [4, 12, 26], "db": 4, "searchabl": 4, "relev": [4, 6, 17, 19, 22, 24, 26, 27, 29, 30], "www": 4, "pinecon": 4, "chosen": [4, 25, 26, 29], "ins": 4, "tep": 4, "depnd": 4, "extend": [4, 17, 18, 20, 30], "imag": [4, 17, 22, 23, 24], "sourc": [4, 5, 6, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "until": [4, 23, 24, 25], "within": [4, 16, 17, 22, 23, 25, 29, 31], "recip": [4, 26, 27], "directli": [4, 17, 18, 23, 24], "llamaindex": 4, "mini": [4, 20, 26], "4k": [4, 26], "backbon": [4, 24, 26, 27], "baai": 4, "bge": 4, "v1": [4, 29], "unstructur": 4, "m3hrdadfi": 4, "recipe_nlg_lit": 4, "supplement": [4, 29], "familiar": [4, 17, 18, 21, 22, 27, 28, 29, 30], "alreadi": [4, 17, 18, 22, 23, 25, 26, 27, 29, 30, 31], "haven": [4, 26], "yet": [4, 17, 21, 22, 26, 28], "huggingface_hub": [4, 31], "bitsandbyt": 4, "clear_output": 4, "os": [4, 27, 28], "llama_index": 4, "core": [4, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "vectorstoreindex": 4, "ollama": 4, "ollamaembed": 4, "huggingfaceembed": 4, "huggingfacellm": 4, "dataset_df": 4, "vectorstorageindex": 4, "ingredi": [4, 27], "accur": 4, "correctli": [4, 20, 21, 22, 23, 24, 26, 29], "prompt": [4, 5, 6, 21, 23, 26, 27, 28, 29, 30, 31], "co": [4, 17, 23], "microsoft": [4, 26, 27], "heck": 4, "completion_to_prompt": 4, "cell": [4, 5, 17, 22, 24, 31], "block": [4, 17, 20, 23, 26, 27, 28, 31], "togeth": [4, 5, 22, 23, 25, 27, 28, 31], "reus": [4, 16, 20, 25, 26], "across": [4, 5, 16, 28, 29], "doc": [4, 18, 21, 22, 26, 27, 29], "ai": [4, 6, 15, 26], "module_guid": 4, "supporting_modul": 4, "embed_model": 4, "info": 4, "using_llm": 4, "usage_custom": 4, "tokenizer_nam": 4, "context_window": 4, "1024": [4, 23, 26, 28], "128": [4, 21, 23, 27], "generate_kwarg": 4, "device_map": [4, 26], "model_kwarg": 4, "torch_dtyp": [4, 25, 31], "float16": [4, 18, 25, 26, 31], "load_in_8bit": 4, "trust_remote_cod": [4, 25], "vector_store_index": 4, "vectorstor": 4, "node": [4, 20, 24], "from_docu": 4, "help": [4, 11, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31], "explan": [4, 5, 10, 13, 22, 26, 28, 29], "paramt": [4, 25], "deploi": 4, "query_engin": 4, "interfac": [4, 20, 22, 27], "as_query_engin": 4, "response_mod": 4, "compact": 4, "similarity_top_k": 4, "verbos": [4, 27], "response_synthes": 4, "pork": 4, "chop": 4, "noodl": 4, "soup": 4, "source_nod": 4, "get_cont": 4, "rag_respons": 4, "vanilla_respons": 4, "retrieved_node_text": 4, "retrieved_node_scor": 4, "20": [4, 17, 18, 20, 21, 23, 29, 32], "dish": 4, "test_df": 4, "test_queri": 4, "against": [4, 21, 24, 29], "response_rag": 4, "record": [4, 17, 29], "straightforward": 4, "response_vanilla": 4, "prefer": [4, 5, 11, 17, 26], "inpsect": 4, "advantag": [4, 17, 24, 26, 27, 29], "disadvantag": 4, "underli": [4, 22, 29], "Is": [4, 5, 21, 27, 30], "procedur": [4, 19, 25, 29], "movi": [4, 22, 26], "ziegler": 4, "2020": [4, 7, 16, 17], "polici": 4, "sft": [4, 26], "reward": [4, 30], "signal": [4, 17, 20, 23, 26], "roug": [4, 26, 29], "cnn": 4, "datset": 4, "4gb": 4, "ppo": 4, "trl": [4, 26], "insert": [4, 5, 27], "sai": [4, 5, 12, 17, 25, 30, 31], "dig": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20], "bit": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21], "proxim": [4, 26], "algorithm": [4, 5, 23, 24, 25, 26, 30, 31], "27": [4, 20, 21, 26, 32], "rouge_scor": 4, "ppotrain": 4, "ppoconfig": 4, "automodelforcausallmwithvaluehead": 4, "config": [4, 22, 24], "gavin124": 4, "learning_r": [4, 19, 21, 22], "41e": 4, "250": 4, "mini_batch_s": 4, "ppo_epoch": 4, "500": [4, 19, 21, 22], "heavi": [4, 22, 27, 30], "Then": [4, 23, 24], "build_dataset": 4, "dataset_nam": 4, "abise": 4, "cnn_dailymail": 4, "arg": [4, 17, 22, 23], "ds": [4, 21], "512": [4, 18, 26], "fals": [4, 18, 20, 21, 22, 23, 25, 26, 28, 29, 31], "set_format": [4, 17], "collat": [4, 22], "twice": [4, 31], "kl": 4, "diverg": [4, 24], "ref_model": 4, "baselin": 4, "slide": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 26, 28], "76": [4, 20, 29], "78": [4, 32], "05": [4, 21, 23], "simultan": [4, 17], "action": [4, 26], "placement": 4, "later": [4, 20, 21, 31], "ppo_train": 4, "data_col": [4, 22, 24], "num_process": 4, "avoid": [4, 23, 24, 25, 26, 27, 31], "bug": 4, "reward_fn": 4, "original_summari": 4, "o": [4, 20, 21, 29, 30, 32], "strip": [4, 28], "rouge1": 4, "output_max_length": 4, "generation_kwarg": 4, "min_length": 4, "query_tensor": 4, "squeez": [4, 18, 20, 21, 31], "response_tensor": 4, "stat": 4, "log_stat": 4, "cite": 4, "suppos": [4, 17, 22, 26, 29], "metric": [4, 5, 21, 22, 30, 31], "Be": 4, "concis": 4, "articl": [4, 17], "problemat": [4, 30], "bonu": 4, "receiv": [4, 17, 26, 28], "weigh": 4, "coeffici": [4, 5], "vf_coef": 4, "affect": [4, 25, 26, 31], "assist": [4, 11, 23, 26], "harmless": [4, 11, 26, 30], "odd": 4, "evas": 4, "commonli": [4, 17, 20, 22, 23, 24, 26, 29, 30], "chat": [4, 10, 23, 26, 27], "purpos": [4, 17, 18, 20, 22, 26, 27, 28], "effici": [4, 10, 11, 20, 22, 26], "scale": [4, 7, 11, 19, 20, 26, 29, 32], "aspet": 5, "juli": 5, "13th": 5, "surname_firstname_hw4": 5, "render": [5, 31], "blimp": 5, "linguist": [5, 6, 17, 28, 29, 30], "known": [5, 17, 19, 22, 23, 26, 28, 29], "isol": [5, 29], "phenomenon": [5, 29, 30], "syntax": [5, 18], "morpholog": 5, "semant": [5, 29], "author": [5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "160m": 5, "anaphor_gender_agr": 5, "determiner_noun_agreement_with_adjective_1": 5, "animate_subject_pass": 5, "complex_np_island": 5, "npi_present_1": 5, "superlative_quantifiers_1": 5, "existential_there_object_rais": 5, "principle_a_case_1": 5, "phenomena": 5, "confid": [5, 25, 29], "interv": [5, 18], "difficult": [5, 17, 20, 26, 29], "easiest": 5, "gramamt": [5, 17], "captur": [5, 21, 24, 26], "minicon": [5, 29], "scorer": [5, 29], "nyu": 5, "mll": 5, "lm_scorer": [5, 29], "incrementallmscor": [5, 29], "bar": [5, 30], "ci": 5, "social": [5, 29], "implic": 5, "deepli": 5, "interconnect": 5, "overrepres": 5, "certain": [5, 17, 19, 20, 23, 24, 25, 28, 29, 31], "cultur": 5, "due": [5, 17, 31], "imbal": 5, "appropri": [5, 24, 29], "exhibit": [5, 24, 29, 30], "instanc": [5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "lens": 5, "mostli": [5, 17, 20, 22, 24, 26, 30], "monolingu": 5, "bigscienc": 5, "560m": 5, "compelt": 5, "parenthes": 5, "analog": 5, "supermarket": 5, "cashier": 5, "greet": 5, "american": 5, "hello": [5, 18], "intuititv": 5, "appropi": [5, 17], "germani": 5, "condit": [5, 19, 21, 29], "bye": 5, "inappropri": 5, "stranger": 5, "ethic": [5, 30], "fig": 5, "came": 5, "tap": 5, "variat": 5, "usa": 5, "evid": [5, 29], "caus": 5, "justif": 5, "starter": 5, "gpt2_scorer": 5, "bloom_scor": 5, "gpt2_predict": 5, "bloom_predict": 5, "answer_kei": 5, "ger": 5, "nonsens": [5, 26], "vignett": 5, "answer_scores_gpt2": 5, "conditional_scor": [5, 29], "answer_scores_bloom": 5, "perez": 5, "2022": [5, 10, 11, 12, 15, 16, 23, 25, 26, 29, 30], "pseudo": [5, 22, 29], "elicit": [5, 10, 25, 26, 30], "concern": 5, "guid": [5, 17, 22, 31], "subject": [5, 6, 26], "verb": 5, "agreement": 5, "taken": [5, 22, 28, 29, 30, 31], "wilcox": 5, "2021": [5, 10, 13, 16, 30], "rest": [5, 17, 22, 24, 26], "rt": 5, "agre": [5, 21], "mismatch": 5, "term": [5, 9, 17, 22, 23, 25, 26, 29], "manipul": [5, 18], "syntact": [5, 13, 14, 28, 29], "plural": 5, "singular": 5, "noun": [5, 26], "src": 5, "claus": 5, "modifi": [5, 17, 18, 27], "pilot": 5, "injur": 5, "teacher": 5, "bring": 5, "love": 5, "orc": 5, "minist": 5, "manag": [5, 21], "tenni": 5, "pp": 5, "preposit": 5, "phrase": 5, "difficulti": [5, 17, 25], "quantit": 5, "testabl": 5, "operation": [5, 31], "unit": [5, 17, 18, 21, 23], "trial": [5, 26, 29], "proport": [5, 17, 21, 29], "born": 5, "barplot": 5, "correl": [5, 28, 29], "slowdown": 5, "read_csv": [5, 25, 29], "sva_data": 5, "FOR": 5, "vs": [5, 22, 29, 31], "analysi": [5, 16, 24, 31], "taught": 6, "uni": 6, "t\u00fcbingen": 6, "cover": [6, 10, 11, 12, 14, 16, 17, 22, 24, 25, 29], "equip": [6, 17, 23, 24], "particip": [6, 29], "mechanist": 6, "perspect": [6, 15, 29, 30], "encourag": [6, 17], "cognit": [6, 29], "scienc": [6, 29, 30], "societi": 6, "master": 6, "bachelor": 6, "interdisciplinari": 6, "prior": [6, 30], "experi": [6, 17, 25, 26, 27, 28], "program": [6, 10, 24], "python": [6, 17, 20, 28, 29], "highli": [6, 26], "ss": 6, "2024": [6, 7, 12, 16, 31], "weekli": 6, "tue": 6, "seminar": 6, "fri": 6, "worksheet": 6, "themselv": 6, "webbbook": 6, "host": [6, 22], "ect": 6, "compulsori": 6, "homework": [6, 17, 26, 29], "exam": [6, 30], "9ect": 6, "group": 6, "project": [6, 17, 31, 32], "preliminari": 6, "introduct": [6, 17, 23, 25], "attribut": [6, 23, 29, 31], "excel": [6, 17, 31], "ryan": 6, "cotterel": 6, "lab": 6, "perci": 6, "liang": 6, "pragmat": [6, 29], "nlg": [6, 25, 29], "michael": [6, 18, 19, 20, 21, 25], "frank": [6, 18, 19, 20, 21, 25], "andrej": 6, "karpathi": 6, "1h": 6, "video": [6, 17], "recommend": [6, 17, 21], "brian": 6, "christian": 6, "cogsci": 6, "cheat": 7, "notat": [7, 18], "trend": 7, "textbook": [7, 8, 9], "jurafski": 7, "martin": 7, "speech": [7, 28, 29], "zhao": 7, "2023": [7, 10, 11, 12, 15, 16, 26, 30], "survei": 7, "kaplan": 7, "law": [7, 21, 26, 30], "mikolov": 7, "2013": 7, "word2vec": [7, 16, 17], "artifici": 8, "recurr": [8, 21, 22], "backpropag": [8, 9, 28], "goodfellow": 8, "courvil": 8, "2016": 8, "rumelhart": 8, "1986": 8, "back": [8, 18, 22, 23, 25, 31], "propag": 8, "rnn": [9, 20, 23, 24], "behind": [9, 17, 19, 20, 23, 26, 27, 28, 29, 31], "supplementari": [9, 10, 11, 12, 13, 14, 15, 16], "hochreit": 9, "schmidhub": 9, "1997": 9, "vaswani": 9, "2017": 9, "radford": 9, "unsupervis": [9, 26], "multitask": 9, "learner": 9, "2": [9, 10, 16, 17, 23, 26, 28, 29, 31, 32], "fourth": 10, "strategi": [10, 17, 29, 30], "foundat": [10, 15, 17, 30], "wei": 10, "kojima": 10, "webson": [10, 30], "pavlick": [10, 30], "realli": [10, 15], "Their": [10, 31], "nye": 10, "scratchpad": 10, "reynold": 10, "mcdonnel": 10, "beyond": [10, 17, 23, 29, 30], "paradigm": [10, 29], "wang": [10, 16], "liu": [10, 25], "yao": 10, "deliber": 10, "xie": 10, "implicit": [10, 22], "bayesian": [10, 24], "min": [10, 24], "rethink": 10, "role": [10, 23, 31], "demonstr": [10, 17, 26, 28], "lampinen": 10, "touvron": [10, 26], "session": [11, 12, 13, 14, 15, 16, 17, 22, 25, 26], "reinforc": [11, 26], "feedback": [11, 26], "supervis": [11, 28, 30], "ding": 11, "howard": 11, "univers": 11, "peft": [11, 22], "blogpost": [11, 12, 16, 20, 26, 29, 30], "robot": [11, 12], "openai": [11, 22, 26, 27], "ouyang": 11, "overview": [11, 14, 17, 20, 22, 24, 25, 26, 27, 30], "chatgpt": 11, "bai": [11, 26], "tool": [12, 17], "autonom": 12, "park": 12, "simulacra": 12, "chen": 12, "autoag": 12, "ahn": 12, "Not": [12, 21, 27], "afford": 12, "intern": [13, 17], "mccoi": 13, "diagnos": 13, "heurist": 13, "tennei": [13, 28], "contextu": [13, 23], "elazar": 13, "amnes": 13, "counterfactu": 13, "qualiti": [14, 17, 24, 29], "syntaxgym": 14, "holist": [14, 19, 20], "lnaguag": 14, "helm": 14, "depth": [15, 22], "philosoph": 15, "said": [15, 25], "bommasani": 15, "opportun": [15, 20], "risk": [15, 30], "mahowald": 15, "dissoci": 15, "mitchel": 15, "krakauer": 15, "debat": [15, 17, 29], "cut": [16, 17], "edg": [16, 20], "towatd": 16, "mechan": [16, 22, 26, 28, 31], "logit": [16, 22, 24, 31, 32], "merullo": [16, 31], "arithmet": 16, "elhag": 16, "circuit": 16, "meng": 16, "locat": [16, 18, 19, 24, 25, 28], "edit": 16, "factual": [16, 29, 30], "aka": 16, "rome": 16, "vig": 16, "mediat": 16, "gender": [16, 30], "heimersheim": 16, "nanda": 16, "patch": 16, "wild": 16, "indirect": [16, 31], "identif": [16, 31], "scrub": 16, "rigor": 16, "hypothes": [16, 29], "yu": 16, "character": 16, "recal": [16, 27, 29, 31], "polina": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "tsvilodub": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "page": [17, 27], "materi": 17, "april": 17, "19th": 17, "exercis": [17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31], "upcom": 17, "ahead": 17, "ideal": [17, 20, 22, 23, 24, 26, 29], "fridai": 17, "semest": 17, "machin": [17, 18, 20, 22, 24, 26, 30], "easili": [17, 22, 29, 31], "latter": [17, 22, 24, 27, 28, 30], "icon": 17, "webook": 17, "safer": 17, "comfort": 17, "platform": [17, 22], "account": [17, 22, 27], "mind": [17, 26, 27, 29], "frequent": [17, 18, 22, 23], "choos": [17, 19, 21, 24, 25, 26, 29, 31], "langchain": [17, 25], "torchrl": 17, "bertviz": [17, 28], "wikipedia": [17, 27, 29], "strongli": [17, 30], "conda": [17, 20], "suitabl": [17, 26], "significantli": 17, "spec": 17, "rocm": 17, "occupi": [17, 18], "3": [17, 18, 21, 22, 26, 27, 28, 29, 30, 31, 32], "txt": [17, 28], "onc": [17, 20, 23, 26], "adjust": [17, 22, 23, 25, 30], "path": [17, 25, 28], "successfulli": [17, 24], "shy": 17, "wikipediaqueryrun": 17, "langchain_commun": [17, 27], "wikipediaapiwrapp": 17, "mac": 17, "m1": 17, "chip": 17, "randomli": [17, 21, 24], "rand": [17, 18, 20], "ones": [17, 18, 19, 20, 26, 31], "pointwis": 17, "manner": 17, "z": [17, 20, 32], "must": [17, 19, 20, 23, 25, 30], "z1": 17, "z2": 17, "nb": [17, 18, 19, 20, 22], "api_wrapp": 17, "infrastructur": [17, 22], "tokenizer_gpt2": 17, "daili": 17, "commit": 17, "produc": [17, 20, 21, 22, 31], "readm": 17, "immedi": 17, "de": [17, 20], "facto": 17, "crisp": 17, "adher": 17, "pep8": 17, "convent": 17, "indent": 17, "handi": 17, "reformat": 17, "Such": [17, 29], "seamlessli": [17, 27], "ruff": 17, "formatt": 17, "extens": [17, 27], "studio": 17, "fct": 17, "slightli": [17, 18, 20, 24, 28, 29, 31], "numpydoc": 17, "bad": [17, 19, 26], "add": [17, 18, 20, 21, 23, 27, 31], "github": [17, 26, 31], "repositori": [17, 26, 31], "fyi": 17, "tidi": 17, "collabor": 17, "git": 17, "studi": [17, 19, 21, 26, 27, 29], "team": [17, 30], "stick": 17, "guidelin": 17, "ourselv": [17, 22, 23, 27, 28], "kindli": 17, "urg": 17, "gram": 17, "potenti": [17, 24, 25, 26, 27, 28, 29], "bias": [17, 20, 26, 29, 30], "inherit": [17, 20], "heard": [17, 29], "target": [17, 19, 20, 21, 22, 26, 28, 29, 30], "fluent": [17, 22, 29], "interchang": [17, 25, 26], "ling": 17, "piec": [17, 23, 27, 29], "extern": 17, "criteria": [17, 30], "far": [17, 22, 24, 26, 30], "varieti": [17, 27, 29], "literari": 17, "british": 17, "nation": 17, "bnc": 17, "ml": [17, 30], "sualli": 17, "held": [17, 24], "drop": [17, 23, 25, 28], "sometim": [17, 22, 23, 24, 25, 26, 27, 30], "ommit": 17, "done": [17, 22, 23, 24, 25, 29, 30, 31], "approxim": [17, 25, 29], "my": [17, 25, 27], "raw": [17, 21, 23, 29], "web": 17, "accomplish": [17, 22, 27], "remov": [17, 18, 21, 23, 31], "markup": 17, "tag": [17, 24, 28, 29], "annot": [17, 26, 28, 30, 31], "enrich": 17, "judgement": 17, "promin": [17, 23], "onto": [17, 20, 23, 29, 31], "readabl": [17, 22, 23], "charact": [17, 18, 23, 24], "multi": [17, 20, 30], "chunk": [17, 29], "whenev": 17, "notion": [17, 21], "equival": [17, 25], "lingusit": 17, "hide": [17, 23], "week": [17, 22, 24], "tooken": 17, "understood": 17, "parallel": [17, 22, 23, 25, 31], "effect": [17, 20, 22, 26, 29, 31], "inter": 17, "nowadai": 17, "fulli": [17, 22, 28], "anticip": 17, "toxic": [17, 29, 30], "desir": [17, 18, 23, 24, 26, 30], "mix": [17, 18], "filter": [17, 26], "non": [17, 21, 24, 25, 28], "undesir": [17, 26, 30], "digit": 17, "arguabl": [17, 29], "stopword": 17, "symbol": [17, 23], "emoji": [17, 23], "valuabl": 17, "prepair": 17, "overlap": [17, 29], "fed": [17, 21], "restrict": [17, 25], "insight": [17, 28, 29], "tradit": 17, "tweet": 17, "financi": 17, "origin": [17, 21, 26, 29, 31], "intend": [17, 19, 24, 26, 27, 30], "slot": 17, "adequ": 17, "bot": 17, "zeroshot": 17, "column_nam": [17, 22, 24], "dataset_s": 17, "whitespac": [17, 23], "tweet_length": 17, "average_tweet_length": 17, "histogram": 17, "click": [17, 18, 19, 20, 21, 22, 24, 26, 28], "hist": 17, "bin": 17, "bynd": 17, "jpmorgan": 17, "reel": 17, "meat": 17, "bd0xbfgjkt": 17, "ccl": 17, "rcl": 17, "nomura": 17, "point": [17, 20, 23, 24, 25, 26, 27, 29], "weak": 17, "carniv": 17, "royal": 17, "caribbean": 17, "ygjpt2red3": 17, "cx": 17, "cemex": 17, "credit": 17, "suiss": 17, "morgan": 17, "outlook": [17, 25], "kn1g4awfib": 17, "ess": 17, "btig": 17, "mcyftsxc2n": 17, "fnko": 17, "funko": 17, "piper": 17, "jaffrai": 17, "z37ijmcqzb": 17, "9543": 17, "17835062349366": 17, "lenght": 17, "peak": 17, "almost": [17, 25, 27], "never": [17, 21], "quit": [17, 22, 26, 27, 29, 30, 31], "alphabet": [17, 23], "clean_tweet": 17, "cleaned_tweet": 17, "cleaned_dataset": 17, "char": [17, 18, 32], "isalpha": 17, "isspac": 17, "httpstcobdxbfgjkt": 17, "80": [17, 18, 21], "train_siz": [17, 21], "test_siz": [17, 21], "cleaned_dataset_split": 17, "train_test_split": 17, "7634": 17, "1909": 17, "aimia": 17, "settl": 17, "dissid": 17, "sharehold": 17, "hit": 17, "wrongfuldeath": 17, "lawsuit": 17, "di": [17, 27], "coronaviru": 17, "httpstcozzaplmfa": 17, "lharri": 17, "stock": 17, "price": 17, "intang": 17, "push": 17, "central": 17, "boe": 17, "haskel": 17, "httpstcogymzyzi": 17, "httpstcoyfehvc": 17, "bullish": 17, "tmobil": 17, "unsurpris": 17, "ceo": 17, "wall": 17, "slip": 17, "wrapper": [17, 22, 23, 31], "tokein": 17, "hood": [17, 22, 23, 24, 28], "preprocessed_train_dataset": 17, "00": [17, 31], "32869": 17, "18": [17, 20, 21], "customiz": 17, "essenti": [17, 21, 22, 23, 24, 31], "tuck": 17, "pile": [17, 22], "gao": [17, 26], "trough": 17, "abstract": [17, 22, 26, 30], "glimps": 17, "stand": [17, 29], "foster": 17, "mainli": [17, 20], "hungarian": 17, "crawl": [17, 29], "miss": [17, 30], "english": [17, 21, 28, 29], "14": [17, 18, 20, 21, 32], "multilanguag": 17, "poor": 17, "favour": 17, "cc": 17, "justext": 17, "archiv": 17, "constitu": 17, "diviat": 17, "infor": 17, "strong": [17, 26], "outlier": 17, "impress": [17, 26, 29], "establish": 17, "tra": 17, "publish": 17, "unknown": [17, 23, 26], "misrepresent": 17, "situat": 17, "jo": 17, "gebru": 17, "lesson": 17, "sociocultur": 17, "usabl": [18, 26], "algebra": 18, "arrai": [18, 20, 28, 31, 32], "And": [18, 27], "documet": 18, "width": [18, 21], "300px": 18, "tensor1": 18, "tensor2": 18, "tensor3": 18, "tensor4": 18, "tensor5": 18, "prder": 18, "initialis": 18, "a_list": 18, "tensor_from_list": 18, "Or": 18, "new_tensor": 18, "replic": [18, 25], "tensor_0d": 18, "tensor_2d": 18, "np_arrai": 18, "np_array_to_tensor": 18, "dtype": [18, 19, 23], "float64": [18, 19], "popul": 18, "drawn": 18, "uniformli": 18, "6004": 18, "1671": 18, "2114": 18, "4924": 18, "5919": 18, "0054": 18, "30": [18, 20, 21, 32], "50": [18, 21, 29], "60": [18, 21, 23], "ly": 18, "exercise1a": 18, "exercise1b": 18, "exercise2": 18, "exercise3": 18, "9025e": 18, "01": 18, "4543e": 18, "3338e": 18, "04": 18, "5581e": 18, "8884e": 18, "4922e": 18, "row_vector": 18, "strictli": 18, "speak": [18, 21], "col_vector": 18, "boolean": 18, "complex": [18, 25, 27], "float32": [18, 19], "integ": [18, 23], "int64": 18, "declar": 18, "bool": 18, "implicitli": [18, 20, 26], "cast": 18, "hello_tensor": 18, "72": [18, 20, 21, 32], "101": 18, "108": 18, "111": [18, 32], "87": [18, 20], "114": 18, "33": [18, 21, 32], "less": [18, 20, 23, 25], "datatyp": 18, "seen": [18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "equal": [18, 21, 29], "mix2": 18, "mix3": 18, "mix4": 18, "mix5": 18, "mix6": 18, "mix7": 18, "mix8": 18, "0000": 18, "2000": [18, 19, 21], "datas": 18, "element": [18, 21], "concaten": [18, 25, 28], "tail": 18, "head_and_tail": 18, "stack": [18, 20, 31], "Its": [18, 26], "old": 18, "tensor_1": 18, "tensor_2": 18, "col": 18, "unsqueez": [18, 22, 23, 31], "posit": [18, 23, 24, 25, 26, 29, 31], "flatten": [18, 20], "least": [18, 22, 25, 26, 27], "dimes": 18, "70": [18, 21], "90": [18, 20, 21], "tensor_1_transpos": 18, "infix": 18, "wise": [18, 24], "5000": [18, 19, 20, 21, 23], "3750": 18, "16": [18, 20, 21, 22, 32], "similarli": [18, 29], "recycl": 18, "obviou": 18, "divis": [18, 21], "4000": [18, 19], "subtract": [18, 20, 31, 32], "precis": [18, 29], "matmul": [18, 31], "200": [18, 21, 29], "34": [18, 32], "400": 18, "56": [18, 23, 32], "600": 18, "notic": [18, 19, 21, 25], "flexibl": [18, 20, 23, 24], "yield": 18, "product": [18, 26, 28], "dot": [18, 24, 28], "prodcut": 18, "43": [18, 20, 21, 32], "65": [18, 20, 21], "another_tensor": 18, "detach": [18, 20, 21, 31], "ex1": 18, "ex1_row": 18, "ex1_col": 18, "ex1_col_tran": 18, "torch1": 18, "torch2": 18, "matrix1": 18, "matrix2": 18, "matrixprod": 18, "531": [18, 32], "300": 18, "fit": [19, 20, 22, 24, 26, 29], "normal": [19, 20, 23, 24, 31], "gaussian": [19, 20], "candid": 19, "By": [19, 23, 26], "stochast": [19, 21, 30], "descent": 19, "seek": 19, "seaborn": [19, 20], "warn": [19, 20, 21, 23, 26, 31], "suppress": 19, "messag": [19, 27], "sn": [19, 20], "filterwarn": [19, 20, 21], "true_loc": 19, "deviat": 19, "fix": [19, 21, 22, 26, 29, 31], "readi": 19, "n_ob": [19, 20], "10000": [19, 20, 21, 23], "true_dist": 19, "train_data": [19, 21], "empir": 19, "ident": 19, "empirical_mean": 19, "5f": 19, "00150": 19, "kdeplot": 19, "seri": [19, 22, 24], "becom": [19, 20, 29], "Being": 19, "deriv": [19, 20], "stabil": [19, 24, 26], "requires_grad": [19, 23, 26], "scene": [19, 20], "sgd": 19, "aggress": 19, "0000001": 19, "degre": 19, "log_prob": [19, 21], "19274": 19, "0312": 19, "negbackward0": 19, "outset": 19, "grad": [19, 26], "10015": 19, "0458984375": 19, "told": 19, "itself": [19, 21, 26, 27], "9989984954101563": 19, "repeat": [19, 23, 25], "eras": 19, "ing": [19, 23], "gone": 19, "cycl": 19, "n_training_step": 19, "5s": 19, "diff": 19, "5d": [19, 20], "3f": [19, 20, 31], "16102": 19, "988": 19, "60579": 19, "60729": 19, "14937": 19, "011": 19, "36674": 19, "36825": 19, "1500": 19, "14508": 19, "284": 19, "22179": 19, "22330": 19, "14350": 19, "645": 19, "13390": 19, "13540": 19, "2500": [19, 20], "14292": 19, "682": 19, "08060": 19, "08211": 19, "3000": 19, "14271": 19, "368": 19, "04828": 19, "04979": 19, "3500": 19, "14263": 19, "533": 19, "02869": 19, "03019": 19, "14260": 19, "650": 19, "01680": 19, "01831": 19, "4500": [19, 20], "14259": 19, "591": 19, "00960": 19, "01110": 19, "201": [19, 32], "00523": 19, "00673": 19, "5500": [19, 20], "059": 19, "00258": 19, "00408": 19, "6000": 19, "006": 19, "00097": 19, "00248": 19, "6500": 19, "14258": 19, "986": 19, "00000": 19, "7000": 19, "979": 19, "00059": 19, "00091": 19, "7500": [19, 20], "977": 19, "00095": 19, "00055": 19, "8000": 19, "00117": 19, "00033": 19, "8500": 19, "00130": 19, "00020": 19, "9000": 19, "975": 19, "00138": 19, "00012": 19, "9500": 19, "976": 19, "00143": 19, "00007": 19, "00146": 19, "00005": 19, "revert": 19, "apart": 19, "slowli": 19, "perceptron": 20, "feed": [20, 23, 25], "goal_fun": 20, "sin": [20, 23], "linspac": 20, "lineplot": 20, "nois": 20, "y_normal": 20, "y_nois": 20, "x_ob": 20, "y_ob": 20, "scatterplot": 20, "n_input": 20, "1": [20, 21, 22, 24, 30, 32], "n_hidden": 20, "n_output": 20, "exclus": [20, 21], "instati": [20, 22], "design": [20, 29], "constitut": [20, 22, 26], "variant": 20, "exact": 20, "eventu": 20, "mlpexplicit": 20, "super": [20, 21, 23, 28, 31], "linear1": [20, 23], "linear2": [20, 23], "linear3": 20, "linear4": 20, "h1": 20, "h2": 20, "h3": 20, "mlp_explicit": 20, "param": [20, 26], "round": [20, 21, 28, 32], "0076": 20, "8415": 20, "9536": 20, "6464": 20, "9964": 20, "7288": 20, "1196": 20, "462": 20, "8668": 20, "9444": 20, "5211": 20, "0849": 20, "2557": 20, "9653": 20, "4786": 20, "5713": 20, "6843": 20, "2133": 20, "342": 20, "0769": 20, "2313": 20, "0227": 20, "2852": 20, "0166": 20, "2986": 20, "0292": 20, "1179": 20, "2564": 20, "2944": 20, "1009": 20, "0552": 20, "0447": 20, "2081": 20, "2009": 20, "033": 20, "1969": 20, "1945": 20, "1427": 20, "0546": 20, "2106": 20, "1128": 20, "0149": 20, "237": 20, "095": [20, 32], "2698": 20, "0059": 20, "1793": 20, "2842": 20, "2865": 20, "1744": [20, 23], "0109": 20, "1259": 20, "1426": 20, "0955": 20, "3025": 20, "2543": 20, "2068": 20, "0964": 20, "0934": 20, "0013": 20, "2462": 20, "2037": 20, "0994": 20, "2537": 20, "1462": 20, "2201": 20, "1222": 20, "2095": 20, "107": 20, "253": [20, 32], "1784": 20, "1452": 20, "0968": 20, "1959": 20, "0706": [20, 23], "0282": 20, "2097": 20, "1417": 20, "0523": 20, "2028": 20, "2256": 20, "1229": 20, "1682": 20, "0451": 20, "0309": 20, "1407": [20, 23], "1962": 20, "0854": 20, "2872": 20, "0421": 20, "3001": 20, "0915": [20, 23], "0519": 20, "2862": 20, "1163": 20, "2389": 20, "0924": 20, "2941": 20, "2323": 20, "0592": 20, "212": 20, "071": 20, "0909": 20, "1527": 20, "0588": 20, "2353": 20, "0547": 20, "0211": 20, "1491": 20, "2182": 20, "2239": 20, "2984": 20, "1006": 20, "1116": 20, "0044": 20, "251": 20, "2208": 20, "039": 20, "0528": 20, "3162": 20, "0257": 20, "0663": 20, "2846": 20, "0646": 20, "1269": 20, "2371": 20, "3099": 20, "2536": 20, "0446": 20, "1587": [20, 23], "255": 20, "074": 20, "1321": 20, "2919": 20, "1839": 20, "1293": 20, "0429": [20, 23], "2682": 20, "2615": 20, "0671": 20, "2576": 20, "1129": 20, "0199": 20, "0655": 20, "043": 20, "1449": 20, "1796": 20, "0972": 20, "1241": 20, "2595": 20, "151": 20, "1908": 20, "286": [20, 23], "2029": 20, "2647": 20, "1574": 20, "2976": 20, "1041": 20, "0947": 20, "0225": 20, "0479": 20, "0493": 20, "2154": 20, "2965": 20, "2934": 20, "0936": 20, "3114": 20, "2956": 20, "2425": 20, "1305": 20, "046": 20, "1408": 20, "023": 20, "0155": 20, "1967": 20, "2333": 20, "179": 20, "0348": 20, "2954": 20, "2073": 20, "2232": 20, "1136": 20, "0556": 20, "0454": 20, "315": 20, "2971": 20, "0509": 20, "1394": 20, "2337": 20, "0912": 20, "256": [20, 26], "1774": 20, "2738": 20, "0386": 20, "034": 20, "2706": 20, "0666": 20, "2664": 20, "0419": 20, "1732": 20, "0622": 20, "2011": 20, "276": [20, 31], "0453": 20, "1481": 20, "0383": 20, "2165": 20, "1897": 20, "1638": 20, "1007": 20, "2027": 20, "3049": 20, "0017": 20, "2579": 20, "0675": 20, "1464": 20, "1149": [20, 32], "195": 20, "1961": 20, "2143": 20, "2373": 20, "0853": 20, "016": 20, "1031": 20, "1161": 20, "1396": 20, "0505": 20, "2276": 20, "2393": 20, "1518": 20, "2711": 20, "1264": 20, "2712": 20, "2633": 20, "1861": 20, "2758": 20, "2591": 20, "3013": 20, "2468": 20, "2455": 20, "guess": [20, 21, 22, 24], "slope": 20, "roughli": 20, "intercept": 20, "10x1": 20, "10x10": 20, "1x10": 20, "1x1": 20, "stdv": 20, "math": [20, 21, 23, 29, 30], "sqrt": [20, 24, 32], "uniform_": 20, "condens": 20, "sequenti": [20, 21], "neatli": 20, "thu": [20, 29], "swoop": 20, "mlpcondens": 20, "mlp_condens": 20, "onward": 20, "tediou": 20, "primit": 20, "reusabl": 20, "easi": [20, 22, 29], "nonlinearregressiondata": 20, "reshap": [20, 21], "train_dataload": 20, "deliv": 20, "4495": 20, "5819": 20, "7650": 20, "1632": 20, "3451": 20, "6135": 20, "6223": 20, "1976": 20, "7169": 20, "3746": 20, "5931": 20, "8005": 20, "0434": 20, "8540": 20, "0562": 20, "4078": 20, "9046": 20, "4005": 20, "7086": 20, "1871": 20, "0338": 20, "3793": 20, "7298": [20, 25], "7743": 20, "4155": 20, "121": 20, "0789": 20, "133": 20, "6013": 20, "2198": 20, "6659": 20, "4612": 20, "7734": 20, "6199": 20, "61": 20, "5975": 20, "4716": 20, "3842": 20, "3931": 20, "2188": 20, "4141": 20, "6194": 20, "131": 20, "9025": 20, "4001": 20, "46": [20, 28], "9520": 20, "0037": 20, "1146": 20, "4007": 20, "94": [20, 21], "9994": 20, "147": 20, "9163": 20, "52": [20, 21, 32], "8589": 20, "2630": 20, "0369": 20, "3773": 20, "2532": 20, "5453": 20, "2955": 20, "3915": 20, "7552": 20, "6925": 20, "3938": 20, "6076": 20, "6834": [20, 32], "8546": 20, "2283": 20, "8123": 20, "3403": 20, "9574": 20, "0644": 20, "9521": 20, "0436": 20, "2180": 20, "3797": 20, "7454": 20, "7530": 20, "8264": 20, "3442": 20, "122": 20, "4230": 20, "2478": 20, "3011": 20, "104": 20, "4167": 20, "6514": 20, "1359": 20, "3875": 20, "5973": 20, "5617": 20, "8176": 20, "5437": 20, "1630": 20, "9920": 20, "55": [20, 21], "6051": 20, "41": [20, 21, 23, 32], "1025": [20, 23], "38": [20, 32], "8970": 20, "9164": 20, "8666": 20, "2518": 20, "0591": 20, "5863": 20, "6087": 20, "5321": 20, "3973": 20, "9640": 20, "6017": 20, "6880": 20, "9468": 20, "4264": 20, "0024": 20, "7179": 20, "5653": 20, "5318": 20, "0374": 20, "7767": 20, "7110": 20, "6955": 20, "7494": 20, "0279": 20, "5396": 20, "4075": 20, "9538": 20, "6411": 20, "8022": 20, "9450": 20, "4118": 20, "7496": 20, "6096": 20, "6654": 20, "77": 20, "7501": 20, "7172": 20, "36": [20, 21, 32], "9245": 20, "8191": 20, "6196": 20, "5388": 20, "88": [20, 32], "0235": 20, "45": [20, 21, 24], "1277": 20, "0365": 20, "0066": 20, "0195": 20, "6423": 20, "5127": 20, "7764": 20, "69": 20, "8224": 20, "5756": 20, "9476": 20, "37": [20, 23], "1051": 20, "119": 20, "4592": 20, "4126": 20, "1727": 20, "47": [20, 32], "0679": 20, "6114": 20, "0246": 20, "5510": 20, "9079": 20, "1315": 20, "0575": 20, "4921": 20, "7523": 20, "3927": 20, "9023": 20, "3946": 20, "3009": 20, "0370": 20, "2317": 20, "1652": [20, 25], "1014": 20, "9101": 20, "1524": 20, "2815": 20, "0928": 20, "2689": 20, "6177": 20, "7121": 20, "7293": 20, "4614": 20, "3488": 20, "1371": 20, "82": 20, "1433": 20, "2099": 20, "7502": 20, "5580": 20, "6555": 20, "113": 20, "4812": 20, "6265": 20, "7873": 20, "2406": 20, "8441": 20, "0513": [20, 23], "140": 20, "1428": 20, "4315": 20, "9185": 20, "66": [20, 21], "8981": 20, "1600": 20, "2063": 20, "89": [20, 23, 32], "8697": 20, "129": 20, "4619": 20, "118": 20, "5045": 20, "51": 20, "6166": 20, "1447": 20, "2186": 20, "loss_funct": 20, "mseloss": 20, "adam": [20, 21, 28], "1e": [20, 23], "n_train_step": 20, "50000": [20, 21], "current_loss": 20, "finish": [20, 23], "y_pred": 20, "d_wide": 20, "melt": 20, "id_var": 20, "value_var": 20, "hue": 20, "alpha": 20, "298": [20, 21, 32], "1596": [20, 23], "497": 20, "740": 20, "628": 20, "522": 20, "447": 20, "12500": 20, "473": 20, "209": [20, 21], "15000": [20, 21], "450": 20, "191": 20, "17500": 20, "441": 20, "309": 20, "20000": [20, 21], "436": 20, "642": 20, "22500": 20, "433": 20, "959": 20, "25000": [20, 21], "432": 20, "27500": 20, "430": 20, "475": 20, "30000": [20, 21], "428": 20, "987": [20, 32], "32500": 20, "427": 20, "638": [20, 21], "35000": [20, 21], "425": 20, "664": [20, 32], "37500": 20, "424": [20, 32], "004": [20, 32], "40000": [20, 21], "422": 20, "595": 20, "42500": 20, "419": 20, "45000": [20, 21], "417": 20, "816": 20, "47500": 20, "416": 20, "479": 20, "415": 20, "unclear": [20, 26], "notabl": 20, "pai": 20, "closer": [20, 23, 25, 27, 30], "subtl": 20, "wiggl": 20, "wash": 20, "vast": [20, 27], "trick": [20, 24], "net": [20, 21, 22, 23], "particularli": 20, "clear": 20, "youself": 20, "gelu": 20, "logsoftmax": [20, 21], "gru": 20, "grucel": 20, "cosinesimilar": 20, "crossentropyloss": [20, 22, 28], "clip_grad_value_": 20, "weight_norm": 20, "pad_sequ": 20, "pad_packed_sequ": 20, "deal": [20, 23, 29], "vanish": 20, "rememb": [20, 21, 25], "timestamp": 20, "cosin": [20, 22, 23, 24, 26], "clip": [20, 24], "bigger": 20, "cap": 20, "magnitud": [20, 28], "unpack": 20, "pack": 20, "invers": 20, "pack_padded_sequ": 20, "differenti": 20, "calculu": 20, "complic": [20, 23], "turn": [20, 26], "luckili": [20, 22, 24], "handl": [20, 21, 22], "acycl": 20, "oper": [20, 23, 31], "worthwhil": 20, "graphviz": 20, "digraph": 20, "ac": 20, "bd": 20, "ce": 20, "ef": 20, "fg": 20, "dz": 20, "dy": 20, "dv": 20, "dw": 20, "dx": 20, "h": [20, 23, 26, 31], "bc": 20, "cg": 20, "dh": 20, "ge": 20, "quick": [21, 23, 24], "__future__": 21, "unicode_liter": 21, "print_funct": 21, "urllib": 21, "request": [21, 25], "nn": [21, 22, 23, 24, 28, 31], "urlopen": 21, "githubusercont": 21, "com": [21, 26, 31], "npnlg": 21, "neural_pragmatic_nlg": 21, "url": 21, "names_data": 21, "datafil": 21, "n_categori": 21, "ascii": [21, 23], "letter": [21, 23], "plu": [21, 23, 28], "all_lett": 21, "ascii_lett": 21, "n_letter": 21, "sosindex": 21, "eosindex": 21, "sound": [21, 25, 26, 30], "ear": 21, "bruckner": 21, "duplic": [21, 31], "czech": 21, "519": 21, "724": 21, "arab": 21, "japanes": 21, "991": 21, "chines": 21, "268": 21, "vietnames": 21, "73": [21, 32], "russian": 21, "9408": 21, "french": [21, 28], "277": 21, "irish": 21, "232": 21, "3668": [21, 23], "spanish": 21, "greek": 21, "203": 21, "italian": [21, 25, 27], "709": 21, "portugues": 21, "74": [21, 32], "scottish": 21, "dutch": 21, "297": 21, "korean": 21, "polish": 21, "139": 21, "realiz": [21, 30], "test_data": 21, "split_percentag": 21, "total_s": 21, "train_indic": 21, "test_indic": 21, "467": 21, "652": 21, "1800": 21, "892": 21, "99": 21, "241": 21, "8467": 21, "941": 21, "249": [21, 32], "28": 21, "3301": 21, "367": 21, "183": 21, "71": 21, "267": 21, "85": 21, "alloc": 21, "exhaust": [21, 24, 25, 30], "testset": 21, "datapoint": [21, 24], "craft": 21, "borrow": 21, "550px": 21, "hot": [21, 23, 32], "blank": 21, "dropout": [21, 23], "inclus": 21, "input_s": 21, "hidden_s": [21, 28], "output_s": 21, "i2h": 21, "i2o": 21, "o2o": 21, "dim": [21, 22, 23, 31, 32], "input_combin": 21, "output_combin": 21, "init_hidden": 21, "graph": 21, "slight": 21, "quiet": 21, "random_training_pair": 21, "random_choic": 21, "l": [21, 26, 28, 31, 32], "randint": 21, "distinguish": [21, 24, 29, 30], "those": [21, 22, 23, 25, 28, 29, 30], "input_tensor": 21, "target_tensor": 21, "category_tensor": 21, "li": [21, 29], "letter_index": 21, "longtensor": 21, "proper": 21, "random_training_exampl": 21, "category_tensor_": 21, "input_line_tensor": 21, "target_line_tensor": 21, "explanatori": 21, "1x18": 21, "elsewher": 21, "time_sinc": 21, "dm": 21, "triplet": 21, "fresh": 21, "unsqueeze_": 21, "reset": 21, "cumul": 21, "criterion": [21, 28], "minut": 21, "nllloss": 21, "0005": 21, "n_iter": 21, "100000": 21, "print_everi": 21, "plot_everi": 21, "all_loss": 21, "total_loss": [21, 28], "rolling_mean": 21, "4f": 21, "0m": 21, "19": [21, 31], "8029": 21, "7308": 21, "54": 21, "1777": 21, "1m": 21, "17": [21, 27, 32], "7180": 21, "3607": 21, "49": 21, "0758": 21, "2m": 21, "7s": 21, "8325": 21, "6393": 21, "4591": 21, "3m": 21, "0s": 21, "2746": 21, "55000": 21, "1081": 21, "60000": 21, "9675": 21, "65000": 21, "8344": 21, "4m": 21, "70000": 21, "7046": 21, "75000": 21, "5894": 21, "80000": 21, "4826": 21, "85000": 21, "3850": 21, "5m": 21, "90000": 21, "2958": 21, "95000": 21, "95": 21, "2122": 21, "1304": 21, "tempor": 21, "regim": 21, "exactli": [21, 22, 23, 25, 26, 27, 31], "auxiliari": [21, 28], "get_surprisal_item": 21, "get_surprisal_dataset": 21, "surprisl_dict": 21, "surp_avg_dict": 21, "perplxty_dict": 21, "surprisl": 21, "surp_avg": 21, "perplxti": 21, "item_surpr": 21, "n_item": 21, "make_df": 21, "surp_dict": 21, "from_dict": 21, "surp_scal": 21, "surprisal_test": 21, "surprisal_train": 21, "nmean": 21, "743693795963553": 21, "90373899401307": 21, "anymor": 21, "effienc": 21, "initial_sequ": 21, "topv": 21, "topi": 21, "topk": [21, 31], "m\u00fcll": 21, "m\u00fcller": 21, "empti": [21, 27], "shima": 21, "robust": [21, 29, 30], "favor": 21, "perfect": [21, 29], "serious": 21, "flaw": 21, "subsect": 21, "varianc": 21, "leav": 21, "speaker": 21, "scope": 21, "mid": [21, 25, 29], "857054710388184": 21, "908905029296875": 21, "bay": 21, "doveski": 21, "jackson": 21, "satoshi": 21, "n_name": 21, "get_prob": 21, "exp": [21, 23, 25, 29, 32], "p_categori": 21, "cond_prob_nam": 21, "country2idx": 21, "prob": [21, 32], "p_name": 21, "logspac": 21, "329154273345582": 21, "049187345280759": 21, "044040465112291": 21, "5707610099012776": 21, "9830674364599212": 21, "176395016805715": 21, "557712239995114": 21, "26594367422115": 21, "1344274634863063": 21, "089089898243062": 21, "989767319373302": 21, "4374993423367664": 21, "746094297468178": 21, "2719710113848373": 21, "503078942968957": 21, "7748951742793246": 21, "33744430690024": 21, "9166837202752751": 21, "6531856900705275": 21, "6175335252350447": 21, "8089478089254367": 21, "3889435308678326": 21, "6692703950843093": 21, "384112744200534": 21, "6612294775126752": 21, "262053290805339": 21, "21096220730527": 21, "1701001434279856": 21, "137311827640074": 21, "9253905269010243": 21, "8398610504968342": 21, "879318062464732": 21, "4070479577071051": 21, "943814170795518": 21, "79754031778924": 21, "0787130945986387": 21, "9999999999999994": 21, "582685867418279": 21, "205616125930776": 21, "151007538987999": 21, "819255000074138": 21, "5181813091977734": 21, "454367770907213": 21, "9190526549711127": 21, "945132093597879": 21, "83683439539813": 21, "1927830372943777": 21, "975641382951965": 21, "726918229927053": 21, "1676781420602698": 21, "0917557944550413": 21, "076368400920858": 21, "444657022227277": 21, "716580436309544": 21, "033587316144933": 21, "tendenc": 21, "nativ": [22, 31], "workflow": 22, "futur": [22, 25, 26], "principl": [22, 23], "suffici": 22, "autom": [22, 29], "hungri": 22, "parameter": 22, "domain": [22, 23, 29, 30], "vision": [22, 24, 30], "cv": 22, "level": [22, 23, 24, 28, 30], "imagenet": 22, "curat": [22, 29], "scratch": [22, 24], "absolut": [22, 23, 26, 28], "doubt": 22, "imdb": [22, 24, 26], "highlevel": 22, "freeli": 22, "close": [22, 24, 25, 26, 29], "insid": [22, 23], "send": 22, "server": 22, "api": [22, 27, 28], "commun": [22, 26, 27, 30], "heavili": 22, "audio": 22, "abbrevi": 22, "nice": [22, 23], "onlin": [22, 25, 26], "hub": [22, 27], "checkpoint": [22, 29], "brows": 22, "incld": 22, "overwhelm": 22, "highlight": [22, 30], "remain": [22, 30], "trainer": [22, 26], "setup": 22, "blackbox": [22, 29, 31], "newli": 22, "datacollatorforlanguagemodel": [22, 24], "trainingargu": 22, "additioanli": 22, "belong": 22, "easier": [22, 26, 31], "pipe_output": 22, "explicit": [22, 23, 30], "frozen": [22, 26, 29], "simplifi": [22, 25], "substep": [22, 27], "truthful_qa": 22, "stanfordnlp": [22, 24], "mlm": 22, "tokenized_dataset": [22, 24], "remove_column": [22, 24], "subset": [22, 26], "subsampled_dataset": [22, 24], "output_dir": 22, "imdb_gpt2": 22, "per_device_train_batch_s": 22, "per_device_eval_batch_s": 22, "evaluation_strategi": 22, "eval_step": 22, "logging_step": 22, "gradient_accumulation_step": 22, "num_train_epoch": 22, "weight_decai": 22, "lr_scheduler_typ": 22, "save_step": 22, "5_000": 22, "fp16": 22, "push_to_hub": 22, "use_mps_devic": 22, "eval_dataset": 22, "directori": [22, 28], "decai": 22, "overfit": [22, 24, 25], "schedul": [22, 24, 26], "overris": 22, "compute_loss": 22, "imdbtrain": 22, "return_output": 22, "celoss": 22, "modelout": 22, "num_class": 22, "additional_dim": 22, "swap": 22, "permut": 22, "eos_tensor": 22, "exclud": 22, "target_out": 22, "explicit_train": 22, "dynam": 22, "histori": [22, 30], "log_histori": 22, "train_loss": [22, 28], "eval_loss": 22, "autoclass": [22, 24], "subclass": 22, "friendli": 23, "convers": [23, 26], "subword": 23, "simplest": 23, "priori": 23, "wouldn": 23, "byte": 23, "undergo": [23, 31], "unnecessari": 23, "unicod": 23, "frequenc": 23, "merg": 23, "freuqenc": 23, "wordpiec": 23, "simpli": [23, 26, 28], "prepend": 23, "act": [23, 31], "startofsequ": 23, "thelik": 23, "At": [23, 27], "endofsequ": 23, "fact": [23, 30], "necess": [23, 27], "regress": 23, "unk": 23, "aren": 23, "delin": 23, "necessari": [23, 26, 27, 31], "du": 23, "vocab_s": 23, "vocab": [23, 32], "vice": [23, 26], "versa": [23, 26], "text1": 23, "lazi": [23, 24], "enc1": 23, "chek": 23, "tok": 23, "text2": 23, "enc2": 23, "text3": 23, "der": 23, "schnell": 23, "braun": 23, "fuch": 23, "sprang": 23, "\u00fcber": 23, "den": 23, "faul": 23, "hund": 23, "enc3": 23, "meta": 23, "freq_of_pair": 23, "freq_of_first_el": 23, "freq_of_second_el": 23, "unigram": [23, 29], "reduc": [23, 25], "static": 23, "parallelis": 23, "widespread": 23, "weren": 23, "curiou": [23, 25, 31], "sign": [23, 27], "bmatrix": [23, 32], "62": 23, "03": 23, "positionalencod": 23, "inject": [23, 31], "sine": 23, "posencod": 23, "po": [23, 24, 28], "2i": 23, "d_model": 23, "emb": 23, "max_len": 23, "incom": 23, "pos_encod": 23, "pe": 23, "div_term": 23, "register_buff": 23, "transformermodel": 23, "ntoken": 23, "ninp": 23, "nhead": 23, "nhid": 23, "nlayer": 23, "dim_feedforward": 23, "num_encoder_lay": 23, "num_decoder_lay": 23, "model_typ": 23, "src_mask": 23, "input_emb": 23, "transformer_model": 23, "userwarn": 23, "enable_nested_tensor": 23, "use_nested_tensor": 23, "encoder_lay": 23, "self_attn": 23, "batch_first": 23, "why_not_sparsity_fast_path": 23, "transformerencod": 23, "modulelist": 23, "transformerencoderlay": 23, "multiheadattent": 23, "out_proj": 23, "nondynamicallyquantizablelinear": 23, "in_featur": 23, "out_featur": 23, "inplac": 23, "norm1": 23, "layernorm": 23, "ep": 23, "elementwise_affin": 23, "norm2": 23, "dropout1": 23, "dropout2": 23, "norm": [23, 31], "transformerdecod": 23, "transformerdecoderlay": 23, "multihead_attn": 23, "norm3": 23, "dropout3": 23, "__dict__": 23, "_paramet": 23, "ordereddict": 23, "in_proj_weight": 23, "1548": 23, "1673": 23, "2034": [23, 32], "0239": 23, "0457": 23, "0236": 23, "1674": 23, "1002": 23, "2152": 23, "1966": 23, "0204": 23, "0941": 23, "1385": 23, "1005": 23, "0104": 23, "0569": 23, "0696": 23, "1157": 23, "0846": 23, "1056": 23, "0601": 23, "1913": 23, "1003": 23, "0028": 23, "1869": 23, "1173": 23, "0612": 23, "0919": 23, "q_proj_weight": 23, "k_proj_weight": 23, "v_proj_weight": 23, "in_proj_bia": 23, "_buffer": 23, "_non_persistent_buffers_set": 23, "_backward_pre_hook": 23, "_backward_hook": 23, "_is_full_backward_hook": 23, "_forward_hook": 23, "_forward_hooks_with_kwarg": 23, "_forward_hooks_always_cal": 23, "_forward_pre_hook": 23, "_forward_pre_hooks_with_kwarg": 23, "_state_dict_hook": 23, "_state_dict_pre_hook": 23, "_load_state_dict_pre_hook": 23, "_load_state_dict_post_hook": 23, "_modul": 23, "embed_dim": 23, "kdim": 23, "vdim": 23, "_qkv_same_embed_dim": 23, "num_head": 23, "head_dim": 23, "bias_k": 23, "bias_v": 23, "add_zero_attn": 23, "96": 23, "reimplement": 23, "gpt2_lm": 23, "gpt2model": 23, "wte": 23, "50257": 23, "768": [23, 26, 28], "wpe": 23, "gpt2block": 23, "ln_1": [23, 31], "attn": [23, 31], "gpt2attent": 23, "c_attn": 23, "conv1d": 23, "c_proj": 23, "attn_dropout": 23, "resid_dropout": 23, "ln_2": [23, 31], "mlp": [23, 31], "gpt2mlp": 23, "c_fc": 23, "newgeluactiv": 23, "ln_f": [23, 26, 31], "lm_head": [23, 31], "4738": 23, "2614": 23, "0978": 23, "0584": 23, "0250": 23, "0874": 23, "1473": 23, "2387": 23, "0525": 23, "0113": 23, "0156": 23, "0039": 23, "0695": 23, "1143": 23, "0363": 23, "0318": 23, "2592": 23, "0164": 23, "1991": 23, "0095": 23, "0516": 23, "0319": 23, "1517": 23, "2170": [23, 32], "1043": 23, "0293": 23, "0475": 23, "4100": 23, "1924": 23, "2400": 23, "0046": 23, "0070": 23, "0198": 23, "4803": 23, "5254": 23, "4293": 23, "0126": 23, "0499": 23, "0032": 23, "nf": 23, "2304": [23, 26], "_is_hf_initi": 23, "acccess": 23, "pointer": 23, "caption": 23, "whose": [24, 26, 30], "ve": 24, "initialize": 24, "causallm": 24, "lmhead": 24, "gpt2forsequenceclassif": 24, "gpt2fortokenclassif": 24, "entiti": 24, "recognit": 24, "ner": 24, "crossentropi": 24, "forsequenceclassif": 24, "passag": 24, "perhap": [24, 26, 29], "qa": [24, 26], "translat": [24, 28, 29], "nuber": 24, "mse": 24, "cross": [24, 28], "entropi": 24, "binari": [24, 26, 29], "span": [24, 26], "gpt2doubleheadsmodel": 24, "tricki": [24, 30, 31], "decad": 24, "bytest": 24, "encount": 24, "optima": 24, "grid": 24, "balanc": 24, "converg": [24, 26], "minimum": [24, 26], "benefit": 24, "lastli": 24, "quantifi": 24, "hw1": [24, 29], "aris": 24, "memor": 24, "cost": 24, "illustr": 24, "subplot": 24, "stage": 24, "underfit": 24, "fail": 24, "pattern": [24, 28, 30, 31], "tightli": 24, "wors": [24, 26], "earli": [24, 26, 28], "soon": 24, "mlm_probabl": 24, "switch": 24, "bert_tok": 24, "exemplifi": [24, 29], "seq2seq": [24, 28], "t5": [24, 28, 29], "lstm": 24, "address": [25, 28, 29], "determinisit": 25, "forc": [25, 28, 31], "seed": 25, "soft": [25, 31], "propto": 25, "famili": 25, "along": 25, "unanim": 25, "endpoint": [25, 27, 28], "noce": 25, "detial": 25, "awesom": 25, "terribl": 25, "favourit": 25, "full_prompt": 25, "few_shot_predict": 25, "aw": 25, "pizzeria": 25, "chicago": 25, "littl": [25, 27], "itali": 25, "court": 25, "capit": [25, 28, 31], "k_q": 25, "a_i": 25, "simplif": 25, "examples_df": 25, "knowledge_exampl": 25, "sep": [25, 28], "center": 25, "448": [25, 32], "765625": 25, "6406": 25, "4921875": 25, "352": 25, "5242": 25, "4765625": 25, "2739": 25, "1302": 25, "484375": 25, "5347": 25, "8238": 25, "1640625": 25, "diagram": 25, "pro": 25, "con": 25, "low": [25, 26], "smoothen": 25, "exceed": 25, "summend": 25, "accordingli": 25, "comparis": [25, 27], "meister": 25, "complementari": 25, "particulat": 25, "Of": [25, 26, 27], "experienc": 25, "inoffici": 25, "dai": 25, "hour": 25, "debug": [25, 31], "inconsist": [25, 30], "eat": 25, "203125": 25, "5625": 25, "84765625": 25, "85546875": 25, "84375": 25, "knowledge_examples_chain": 25, "sold": 25, "39453125": 25, "3515625": 25, "625": 25, "1796875": 25, "453125": 25, "knowledge_examples_chain_incorrect": 25, "leg": 25, "01171875": 25, "859375": 25, "06640625": 25, "7734375": 25, "984375": 25, "llok": 25, "webbook": 25, "spoiler": 25, "creation": 26, "brush": 26, "distinct": 26, "recap": [26, 29], "ten": 26, "tofu": 26, "bullet": 26, "scientif": 26, "tutor": 26, "medic": 26, "awar": [26, 30], "broad": 26, "stori": 26, "cook": 26, "dialogu": [26, 30], "everyth": 26, "optimis": 26, "summaris": 26, "alic": 26, "admir": 26, "fulfil": 26, "tokenizer_instruct": 26, "model_instruct": 26, "load_in_4bit": 26, "bnb_4bit_use_double_qu": 26, "bnb_4bit_quant_typ": 26, "nf4": 26, "bnb_4bit_compute_dtyp": 26, "tokenizer_lm": 26, "model_lm": 26, "instruction_text": 26, "input_ids_instruct": 26, "input_ids_lm": 26, "prediction_instruct": 26, "prediction_lm": 26, "naiv": 26, "un": 26, "freez": [26, 31], "gpt2_model": 26, "named_paramet": 26, "layers_to_unfreez": 26, "unfrozen": 26, "startswith": [26, 28], "rank": [26, 31], "lora": 26, "124": 26, "fewer": 26, "catastroph": 26, "qlora": 26, "broadli": 26, "discov": 26, "underpin": 26, "mdp": 26, "outcom": [26, 30, 31], "trivial": 26, "innov": 26, "led": 26, "toward": 26, "commerici": 26, "lend": 26, "recevi": 26, "honest": [26, 30], "sufficintli": 26, "1b": 26, "capac": 26, "wide": [26, 29], "tend": 26, "imposs": 26, "fold": 26, "nudg": 26, "giagant": 26, "stumbl": 26, "clone": 26, "apect": 26, "sort": 26, "sfttrainer": 26, "kept": 26, "harm": [26, 30], "alien": 26, "eniron": 26, "carperai": 26, "openai_summarize_tldr": 26, "facebook": 26, "350m": 26, "extrem": 26, "deploy": [26, 29], "formatting_prompts_func": 26, "output_text": 26, "formatting_func": 26, "max_seq_length": 26, "dataset_batch_s": 26, "blob": [26, 31], "script": 26, "thousand": [26, 29], "cumbersom": 26, "reject": 26, "theta": 26, "mathbb": 26, "sim": 26, "sigma": 26, "r_": 26, "proven": 26, "anthrop": 26, "rlaif": 26, "2212": 26, "08073": 26, "ldquo": 26, "d83d2b": 26, "rdquo": 26, "ordin": 26, "automodelforsequenceclassif": 26, "reward_token": 26, "lvwerra": 26, "distilbert": 26, "reward_model": 26, "positive_sent": 26, "negative_sent": 26, "input_po": 26, "input_neg": 26, "reward_po": 26, "reward_neg": 26, "depedn": 26, "theorem": 26, "warm": 26, "rafailov": 26, "secretli": 26, "overoptim": 26, "patient": 27, "demo": [27, 31], "view": [27, 28], "passs": 27, "somehow": 27, "terminolog": [27, 29], "oftentim": 27, "templat": 27, "invok": 27, "neat": 27, "sponsor": 27, "haystack": 27, "dinner": 27, "menu": 27, "turbo": [27, 29], "langchainhub": 27, "langchain_openai": 27, "chatopenai": 27, "langchain_cor": 27, "output_pars": 27, "stroutputpars": 27, "prompttempl": 27, "kwarg": [27, 31], "max_token": 27, "cauliflow": 27, "tomato": 27, "instructions_text_appet": 27, "fridg": 27, "nwhich": 27, "appet": 27, "instructions_text_main": 27, "am": 27, "plan": 27, "instructions_menu_summari": 27, "nappet": 27, "nmain": 27, "main_cours": 27, "npleas": 27, "0125": 27, "openai_api_kei": 27, "prompt_template_appet": 27, "input_vari": 27, "prompt_template_main": 27, "prompt_template_summari": 27, "appetizer_chain": 27, "main_chain": 27, "composed_chain": 27, "composed_result": 27, "instructions_text_dessert": 27, "dessert": 27, "ndessert": 27, "load_dotenv": 27, "your_api_kei": 27, "prompt_template_dessert": 27, "dessert_chain": 27, "decompos": [27, 30], "bite": 27, "react": 27, "agentexecutor": 27, "create_react_ag": 27, "pull": 27, "hwchase17": 27, "agent_executor": 27, "vegetarian": 27, "unfortunatelli": 27, "cage": 27, "allrecip": 27, "satisfii": 27, "dinnerplan": 27, "tiramiu": 27, "load_tool": 27, "agent_with_tool": 27, "searhc": 27, "stepwis": 27, "firt": 27, "italien": 27, "recipi": 27, "concentr": 27, "sake": 27, "paywal": 27, "billion": 27, "getpass": 27, "huggingfacehub_api_token": 27, "huggingfaceendpoint": 27, "publicli": 27, "repo_id": 27, "mistralai": 27, "v0": 27, "llm_hf": 27, "agent_hf": 27, "agent_hf_executor": 27, "bottleneck": 27, "properli": 27, "lmql": 27, "control": 27, "stateless": 27, "agnet": 27, "trace": 28, "vecor": 28, "ran": 28, "le": 28, "chien": 28, "brun": 28, "couru": 28, "flan": [28, 29], "automodelforseq2seqlm": 28, "model_view": 28, "head_view": 28, "model_t5": [28, 29], "target_id": 28, "output_attent": [28, 31], "return_dict": 28, "attiont": 28, "encoder_attent": 28, "cross_attent": 28, "decoder_attent": 28, "eas": 28, "input_token": [28, 29], "convert_ids_to_token": 28, "decoder_token": 28, "facet": 28, "encoder_token": 28, "doubl": 28, "tile": 28, "franc": [28, 31], "pari": [28, 31], "hoc": 28, "spuriou": 28, "inseq": 28, "perturb": 28, "obscur": 28, "load_model": 28, "salienc": 28, "hook": [28, 31], "integrated_gradi": 28, "justifi": 28, "light": [28, 29], "out_with_gener": 28, "generated_text": 28, "quickstart": 28, "regular": 28, "berlin": 28, "attribution_model": 28, "out_contrast": 28, "attributed_fn": 28, "contrast_prob_diff": 28, "contrast_target": 28, "attribute_target": 28, "step_scor": 28, "ahv": 28, "deem": 28, "motiv": [28, 29], "ud": 28, "spaci": 28, "ftfy": 28, "berttoken": 28, "bertmodel": 28, "sy": 28, "data_dir": 28, "ud_en_pref": 28, "get_model_and_token": 28, "random_weight": 28, "output_hidden_st": [28, 31], "emb_dim": 28, "valueerror": 28, "unrecogn": 28, "init_weight": 28, "get_sentence_repr": 28, "hug": 28, "face": [28, 29, 30], "floattensor": 28, "sequence_length": 28, "hidden_st": [28, 31], "all_hidden_st": 28, "contextev": 28, "num_lay": [28, 31], "representation_dim": 28, "segmented_token": 28, "assert": 28, "incompat": 28, "cl": 28, "get_pos_data": 28, "probing_dir": 28, "get_data": 28, "data_typ": 28, "data_pref": 28, "train_sent": 28, "readlin": 28, "test_sent": 28, "train_label": 28, "test_label": 28, "fraction": 28, "unique_label": 28, "union": 28, "label2index": 28, "num_label": 28, "input_dim": 28, "output_dim": 28, "build_classifi": 28, "ll": 28, "num_epoch": 28, "train_represent": 28, "num_tot": 28, "num_correct": 28, "batch_repr": 28, "batch_label": 28, "eq": 28, "test_represent": 28, "num_word": 28, "train_sentence_represent": 28, "test_sentence_represent": 28, "represen": 28, "train_representations_al": 28, "train_layer_represent": 28, "test_representations_al": 28, "test_layer_represent": 28, "train_labels_al": 28, "test_labels_al": 28, "train_accuraci": 28, "test_accuraci": 28, "experiment": 29, "fuller": 29, "ppl": 29, "f1": 29, "orient": 29, "grammat": 29, "penn": 29, "treebank": 29, "glue": 29, "paraphras": 29, "unexpectedli": 29, "fluenci": 29, "incorpor": 29, "capabl": [29, 30], "mmlu": [29, 30], "bench": [29, 30], "assisst": 29, "becam": [29, 30], "potenit": 29, "impact": 29, "realtoxicityprompt": [29, 30], "winogend": 29, "assumpt": [29, 31], "count": [29, 30], "coverag": 29, "newer": 29, "worri": 29, "contamin": 29, "inflat": 29, "scalabl": [29, 30], "unsolv": 29, "root": 29, "ppl_": 29, "x_0": 29, "x_n": 29, "sum_": 29, "x_i": 29, "x_": 29, "exerpt": 29, "wkipedia": 29, "nll": 29, "wikitext": 29, "model_": 29, "model_xl": 29, "xl": 29, "output_": 29, "output_xl": 29, "perplexity_": 29, "perplexity_xl": 29, "constraint": 29, "weaker": 29, "regex": 29, "hw2": 29, "chanc": 29, "massaged_dataset_v": 29, "answer_scor": 29, "predicted_label": 29, "is_correct": 29, "harmon": 29, "symmetr": 29, "f_": 29, "beta": [29, 32], "lowest": 29, "boolq": 29, "superglu": 29, "sklearn": 29, "df_boolq": 29, "super_glue_boolq": 29, "is_tru": 29, "predicted_answ": 29, "true_answ": 29, "sentence1": 29, "sentence2": 29, "true_posit": 29, "false_posit": 29, "false_neg": 29, "f1_score": 29, "bleu": 29, "meteor": 29, "hw": 29, "bigram": 29, "trigram": 29, "max_ord": 29, "torchtext": 29, "bleu_scor": 29, "t5token": 29, "t5forconditionalgener": 29, "tokenizer_t5": 29, "text_en": 29, "opinion": [29, 30], "text_d": 29, "anderen": 29, "waren": 29, "ander": 29, "meinung": 29, "encoding_en": 29, "encoding_d": 29, "predicted_d": 29, "predicted_decoded_d": 29, "THE": 29, "salazar": 29, "hu": 29, "levi": 29, "2032": 29, "calibr": 29, "influenti": 29, "kadavath": 29, "2207": 29, "05221": 29, "evalut": 29, "tandem": 29, "emerg": 29, "psucholog": 29, "latg": 29, "extent": 29, "shed": 29, "learnabl": 29, "grammar": 29, "innat": 29, "layout": 29, "comaprison": 29, "ungrammat": 29, "grammaticality_df": 29, "grammaticality_test": 29, "grammaticality_predict": 29, "grammatical_sent": 29, "ungrammatical_sent": 29, "grammatical_log_prob": 29, "sequence_scor": 29, "ungrammatical_log_prob": 29, "is_grammat": 29, "reserach": 29, "intersect": 29, "theori": 29, "mathc": 29, "metaphor": 29, "mari": [29, 31], "town": 29, "respond": 29, "chimnei": 29, "nonliter": 29, "live": 29, "welcom": 29, "liter": 29, "compani": 29, "metaphor_results_gpt": 29, "gpt_metaphor_result": 29, "metaphor_results_human": 29, "human_metaphor": 29, "correcti": 29, "itemnum": 29, "item_id": 29, "intric": 30, "sharpen": 30, "possess": 30, "elementari": 30, "childhood": 30, "biologi": 30, "physic": 30, "interestingli": 30, "composit": 30, "driven": 30, "puzzl": 30, "logic": 30, "intens": 30, "iron": 30, "humanev": 30, "appar": 30, "abil": 30, "hellaswag": 30, "lambada": 30, "triviaqa": 30, "storycloz": 30, "naturalqa": 30, "gsm8k": 30, "intellig": 30, "conclud": 30, "conclus": 30, "quot": 30, "absenc": 30, "heart": 30, "grow": 30, "fonder": 30, "plausibl": 30, "faith": 30, "propens": 30, "detect": 30, "truthfulqa": 30, "skim": 30, "factscor": 30, "atom": 30, "percentag": 30, "provd": 30, "behvaior": 30, "got": [30, 31], "benefici": 30, "rare": 30, "transfer": 30, "distinctli": 30, "arc": 30, "chollet": 30, "bear": 30, "outlin": 30, "hallmark": 30, "parrot": 30, "bender": 30, "perpetu": 30, "stereotyp": 30, "winogrand": 30, "bbq": 30, "polit": 30, "endors": 30, "santurkar": 30, "moral": 30, "opprotun": 30, "hasn": 30, "assit": 30, "inde": 30, "meet": 30, "unsaf": 30, "expert": 30, "honesti": 30, "inscrut": 31, "behav": 31, "mdoel": 31, "unembed": 31, "accompani": 31, "bloomtokenizerfast": 31, "get_devic": 31, "load_gpt2": 31, "lambdalay": 31, "lambd": 31, "modelwrapp": 31, "activations_": 31, "layer_past": 31, "list_decod": 31, "inpid": 31, "layer_decod": 31, "get_lay": 31, "true_logit": 31, "get_layers_w_attn": 31, "rr_per_lay": 31, "reciproc": 31, "answer_id": 31, "rr": 31, "sorted_prob": 31, "argsort": 31, "descend": 31, "prob_of_answ": 31, "answer_prob": 31, "first_top": 31, "mrr": 31, "is_top_at_end": 31, "print_top": 31, "topk_per_lay": 31, "get_activ": 31, "mega002": 31, "debugg": 31, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 31, "flask_serv": 31, "req_res_oop": 31, "l57": 31, "in_sln": 31, "num_token": 31, "m_coef": 31, "in_": 31, "3072": 31, "layer_residual_": 31, "intermediate_residual_": 31, "final_lay": 31, "mlp_": 31, "reset_activ": 31, "gpt2wrapper": 31, "add_hook": 31, "register_forward_hook": 31, "in_sln_": 31, "attn_": 31, "out_intermediate_residual_": 31, "get_pre_wo_activ": 31, "wo": 31, "use_cach": 31, "past_key_valu": 31, "attn_weight": 31, "pre_wo_attn": 31, "get_past_lay": 31, "add_mid_attn_hook": 31, "mid_attn_": 31, "past_layer_": 31, "rm_hook": 31, "last_past": 31, "medium": 31, "inp_id": 31, "str_tok": 31, "poland_text": 31, "poland": 31, "poland_id": 31, "pol_tok": 31, "skip": 31, "realis": 31, "ffnn": 31, "specicif": 31, "promot": 31, "warsaw": 31, "responsinbl": 31, "saw": 31, "adapt": 31, "ffn": [31, 32], "stai": 31, "o_citi": 31, "mlp_19": 31, "layer_logit": 31, "intervent": 31, "meaning": 31, "corrupt": 31, "downstream": 31, "transformer_len": 31, "john": 31, "went": 31, "gave": 31, "bottl": 31, "milk": 31, "interven": 31, "recov": 31, "plotli": 31, "hookedtransform": 31, "express": 31, "px": 31, "functool": 31, "file_download": 31, "1132": 31, "futurewarn": 31, "resume_download": 31, "deprec": 31, "resum": 31, "force_download": 31, "clean_prompt": 31, "corrupted_prompt": 31, "clean_token": 31, "to_token": 31, "corrupted_token": 31, "logits_to_logit_diff": 31, "incorrect_answ": 31, "to_single_token": 31, "correct_index": 31, "incorrect_index": 31, "cach": 31, "clean_logit": 31, "clean_cach": 31, "run_with_cach": 31, "clean_logit_diff": 31, "corrupted_logit": 31, "corrupted_logit_diff": 31, "738": [31, 32], "imshow": 31, "xaxi": 31, "yaxi": 31, "to_numpi": 31, "color_continuous_midpoint": 31, "color_continuous_scal": 31, "rdbu": 31, "resid_pr": 31, "reader": 31, "residual_stream_patching_hook": 31, "hookpoint": 31, "clean_resid_pr": 31, "slow": 31, "num_posit": 31, "ioi_patching_result": 31, "cfg": 31, "n_layer": 31, "temporari": 31, "temp_hook_fn": 31, "patched_logit": 31, "run_with_hook": 31, "fwd_hook": 31, "get_act_nam": 31, "patched_logit_diff": 31, "ish": 31, "fork": 31, "disabl": 31, "deadlock": 31, "tokenizers_parallel": 31, "97": 31, "token_label": 31, "to_str_token": 31, "titl": 31, "ioi": 31, "np_conv": 32, "mtx": 32, "isdigit": 32, "w_f": 32, "b_f": 32, "m_out": 32, "vec": 32, "q_x": 32, "k_x": 32, "v_x": 32, "44": 32, "31": 32, "68": 32, "612": 32, "2411": 32, "2064": 32, "570": 32, "501": 32, "2263": 32, "1071": 32, "1926": 32, "2482": 32, "2174": 32, "9820": 32, "4622": 32, "8362": 32, "1050": 32, "921": 32, "4123": 32, "1851": 32, "3486": 32, "1773": 32, "8015": 32, "3759": 32, "d_h": 32, "normalis": 32, "decim": 32, "520": 32, "z_0": 32, "0_0": 32, "v_0": 32, "0_1": 32, "v_1": 32, "0_4": 32, "v_4": 32, "residu": 32, "353": 32, "33836474": 32, "329": 32, "08965344": 32, "289": 32, "25248486": 32, "1432": 32, "98336813": 32, "1255": 32, "15948522": 32, "5669": 32, "57964344": 32, "606": 32, "21778265": 32, "73959792": 32, "2380": 32, "41515987": 32, "1068": 32, "67534827": 32, "1174": 32, "33044753": 32, "1023": 32, "64202727": 32, "4627": 32, "46240755": 32, "25966188": 32, "3945": 32, "61173964": 32, "8063146353260925e": 32, "57": 32, "53": 32, "epsilon": 32, "00001": 32, "gamma": 32, "var": 32, "probs_t": 32, "313": 32, "402": 32, "247": 32, "269": 32, "202": 32, "539": 32, "22": 32, "045": 32, "863": 32, "175": 32, "798": 32, "461": 32, "955": 32, "905": 32, "909": 32, "394": 32, "192": 32, "323": 32, "666": 32, "383": 32, "607": 32, "843": 32, "264": 32, "279": 32, "156": 32, "695": 32, "864": 32, "819": 32, "08": 32, "713": 32, "716": 32, "077": 32, "621": 32, "444": 32, "305": 32, "094": 32, "001": 32, "009": 32, "002": 32, "149": 32, "184": 32, "042": 32, "445": 32, "349": 32, "081": 32, "013": 32, "295": 32, "338": 32, "086": 32, "012": 32, "337": 32, "214": 32}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 1, 2, 3, 4, 5], "1": [0, 1, 2, 3, 4, 5, 17, 18, 19, 23, 25, 26, 27, 28, 29, 31], "languag": [0, 1, 3], "model": [0, 1, 3, 20, 21, 22, 24, 26], "50": [0, 1, 2, 3], "point": [0, 1, 2, 3, 4, 5], "logist": [0, 1, 2, 3, 4, 5], "exercis": [0, 1, 2, 3, 4, 5, 24, 25], "understand": [0, 1, 5, 6, 15, 17], "12": [0, 1], "2": [0, 1, 2, 3, 4, 5, 18, 19, 20, 21, 22, 24, 25, 27, 30], "extract": [0, 1], "llm": [0, 1, 3, 4, 5, 6, 12, 27, 28], "fingerprint": [0, 1], "15": [0, 1, 4], "3": [0, 1, 2, 3, 4, 5, 19, 20, 23, 24, 25], "fine": [0, 1, 4, 11, 26], "tune": [0, 1, 4, 11, 26], "gpt": [0, 1], "qa": [0, 1, 2, 3], "23": [0, 1], "answer": [1, 3], "first": [1, 2, 3], "possibl": 1, "second": 1, "evalu": [1, 5, 14, 21, 28, 29, 30], "prompt": [2, 3, 10, 25], "gener": [2, 3, 4, 21], "lm": [2, 3, 8, 10, 22], "advanc": [2, 3, 20, 30], "strategi": [2, 3, 25], "16": [2, 3], "nli": [2, 3], "multipl": [2, 3, 18], "choic": [2, 3], "14": [2, 3], "neural": [2, 3], "20": [2, 3], "experi": 3, "scheme": [3, 25], "natur": 3, "infer": [3, 21], "knowledg": [3, 30], "numersens": 3, "dataset": [3, 17], "few": 3, "shot": 3, "commonsenseqa": 3, "how": [3, 5], "were": 3, "word": 3, "token": [3, 23], "repres": 3, "what": 3, "differ": 3, "similar": 3, "modern": 3, "wa": 3, "context": 3, "curs": 3, "dimension": 3, "give": 3, "concret": 3, "exampl": 3, "which": 3, "train": [3, 17, 19, 20, 21, 24, 26, 28], "data": [3, 17, 18, 19, 20, 21], "us": [3, 20], "compon": 3, "bengio": 3, "et": 3, "al": 3, "2003": 3, "ani": 3, "can": 3, "found": 3, "per": 3, "section": 3, "abstract": 3, "introduct": [3, 22], "A": 3, "parallel": 3, "implement": 3, "experiment": 3, "result": 3, "extens": 3, "futur": 3, "work": [3, 22], "conclus": 3, "agent": [4, 12, 27], "rl": [4, 26], "build": 4, "retriev": 4, "augment": 4, "system": [4, 12], "30": 4, "rlhf": [4, 11], "summar": 4, "aspect": [4, 30], "5": [4, 5, 19, 22, 27], "4": [5, 19, 21, 26], "grammat": 5, "capabl": 5, "10": 5, "societ": 5, "bias": 5, "13": 5, "human": 5, "like": 5, "ar": 5, "llama": 5, "s": [5, 20], "surpris": 5, "22": 5, "cours": 6, "overview": 6, "intend": 6, "audienc": 6, "formalia": 6, "schedul": 6, "further": 6, "materi": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "background": 7, "addit": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "pytorch": [8, 18, 20, 23], "ann": 8, "lstm": 9, "transform": [9, 22, 23, 24], "current": [10, 19], "attribut": [13, 18, 28], "method": [13, 28], "behavior": [14, 29], "assess": [14, 18, 29], "implic": 15, "philosophi": 15, "mechanist": [16, 31], "interpret": [16, 24, 31], "sheet": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "practic": [17, 26], "set": 17, "up": 17, "instal": 17, "requir": 17, "colab": 17, "local": 17, "verifi": 17, "best": 17, "write": 17, "code": 17, "core": 17, "concept": 17, "main": 17, "process": [17, 30], "step": 17, "document": 17, "essenti": 18, "tensor": 18, "creat": 18, "row": 18, "column": 18, "vector": 18, "type": 18, "oper": 18, "index": 18, "slice": 18, "join": 18, "reshap": 18, "transpos": 18, "arithmet": 18, "broadcast": 18, "matrix": 18, "just": 18, "valu": [18, 19], "ml": [19, 22], "estim": 19, "packag": [19, 20, 21], "true": [19, 20], "distribut": 19, "optim": 19, "paramet": [19, 20, 21], "gradient": 19, "loss": 19, "backprop": 19, "part": 19, "comput": [19, 20], "predict": 19, "backpropag": 19, "error": 19, "signal": 19, "updat": 19, "reset": 19, "inform": 19, "loop": 19, "non": 20, "linear": 20, "regress": 20, "mlp": 20, "w": [20, 21], "modul": 20, "global": [20, 21], "defin": [20, 21], "built": 20, "more": 20, "explicit": 20, "definit": 20, "nn": 20, "concis": 20, "prepar": 20, "outlook": [20, 22, 23, 24, 26, 29], "layer": 20, "util": [20, 24], "option": [20, 23, 24, 26], "autograd": 20, "graph": 20, "charact": 21, "level": 21, "sequenc": 21, "rnn": 21, "load": 21, "inspect": 21, "test": [21, 29], "split": 21, "helper": 21, "function": 21, "network": 21, "invert": 21, "huggingfac": 22, "via": 22, "bpe": 23, "special": 23, "eo": 23, "pretrain": 23, "attent": [23, 28], "mask": [23, 24], "configur": 24, "head": 24, "dynam": 24, "mlm": 24, "decod": [25, 31], "supervis": 26, "flavour": 26, "peft": 26, "polici": 26, "reward": 26, "ppo": 26, "langchain": 27, "excercis": 27, "tool": 27, "output": 27, "pars": 27, "memori": 27, "handl": 27, "6": 28, "probe": 28, "visual": 28, "7": [29, 30], "benchmark": [29, 30], "metric": 29, "machin": 29, "psycholog": 29, "problem": 30, "solv": 30, "hallucin": 30, "consist": 30, "reason": 30, "social": 30, "assist": 30, "8": 31, "earli": 31, "residu": 31, "stream": 31, "activ": 31, "patch": 31}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})