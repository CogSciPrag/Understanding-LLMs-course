Search.setIndex({"alltitles": {"1. Second Possibility": [[1, "second-possibility"]], "1.1 evaluation": [[1, "evaluation"]], "1.2 evaluation": [[1, "id1"]], "1.3 evaluation": [[1, "id2"]], "Activation patching": [[31, "activation-patching"]], "Additional materials": [[7, "additional-materials"], [8, "additional-materials"], [9, "additional-materials"], [10, "additional-materials"], [11, "additional-materials"], [12, "additional-materials"], [13, "additional-materials"], [14, "additional-materials"], [15, "additional-materials"], [16, "additional-materials"]], "Advanced outlook: PyTorch Autograd and computational graph [optional]": [[20, "advanced-outlook-pytorch-autograd-and-computational-graph-optional"]], "Agents": [[27, "agents"]], "Answer Exercise 1: Understanding language modeling (12 points)": [[1, "answer-exercise-1-understanding-language-modeling-12-points"]], "Assessing just the values of a tensor": [[18, "assessing-just-the-values-of-a-tensor"]], "Assistant evaluation": [[30, "assistant-evaluation"]], "Attention masks": [[23, "attention-masks"]], "Attention visualization": [[28, "attention-visualization"]], "Attributes of a tensor": [[18, "attributes-of-a-tensor"]], "Attribution methods": [[13, null], [28, "attribution-methods"]], "BPE tokenization": [[23, "bpe-tokenization"]], "Background": [[7, null]], "Benchmark testing": [[29, "benchmark-testing"]], "Best practices for writing code": [[17, "best-practices-for-writing-code"]], "Broadcasting": [[18, "broadcasting"]], "Colab": [[17, "colab"]], "Core concepts": [[17, "core-concepts"]], "Course formalia": [[6, "course-formalia"]], "Course overview: Understanding LLMs": [[6, null]], "Creating a tensor": [[18, "creating-a-tensor"]], "Dataset documentation": [[17, "dataset-documentation"]], "Decoding schemes": [[25, "decoding-schemes"]], "Defining the MLP using PyTorch\u2019s built-in modules": [[20, "defining-the-mlp-using-pytorchs-built-in-modules"]], "Defining the model": [[21, "defining-the-model"]], "Early decoding": [[31, "early-decoding"]], "Evaluation": [[28, "evaluation"]], "Evaluation & behavioral assessment": [[14, null]], "Evaluation & inference": [[21, "evaluation-inference"]], "Excercise 5.1.1.2": [[27, "excercise-5-1-1-2"]], "Exercise 1: Advanced prompting strategies (16 points)": [[2, "exercise-1-advanced-prompting-strategies-16-points"], [3, "exercise-1-advanced-prompting-strategies-16-points"]], "Exercise 1: Building a retrieval-augmented generation system (30 points)": [[4, "exercise-1-building-a-retrieval-augmented-generation-system-30-points"]], "Exercise 1: Understanding grammatical capabilities of LLMs (10 points)": [[5, "exercise-1-understanding-grammatical-capabilities-of-llms-10-points"]], "Exercise 1: Understanding language modeling (12 points)": [[0, "exercise-1-understanding-language-modeling-12-points"], [1, "exercise-1-understanding-language-modeling-12-points"]], "Exercise 2": [[3, "exercise-2"]], "Exercise 2: Evaluating societal biases (13 points)": [[5, "exercise-2-evaluating-societal-biases-13-points"]], "Exercise 2: Extracting LLM fingerprints (15 points)": [[0, "exercise-2-extracting-llm-fingerprints-15-points"], [1, "exercise-2-extracting-llm-fingerprints-15-points"]], "Exercise 2: Prompting for NLI & Multiple-choice QA (14 points)": [[2, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"], [3, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"]], "Exercise 2: RLHF for summarization (15 points)": [[4, "exercise-2-rlhf-for-summarization-15-points"]], "Exercise 3.3.3.1.": [[25, "exercise-3-3-3-1"]], "Exercise 3.3.3.2.": [[25, "exercise-3-3-3-2"]], "Exercise 3.3.3.3": [[25, "exercise-3-3-3-3"]], "Exercise 3: Aspects of fine-tuning (5 points)": [[4, "exercise-3-aspects-of-fine-tuning-5-points"]], "Exercise 3: Fine-tuning GPT-2 for QA (23 points)": [[0, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"], [1, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"]], "Exercise 3: First neural LM (20 points)": [[2, "exercise-3-first-neural-lm-20-points"], [3, "exercise-3-first-neural-lm-20-points"]], "Exercise 3: LLM evaluations with LLMs (5 points)": [[5, "exercise-3-llm-evaluations-with-llms-5-points"]], "Exercise 4: How human-like are Llama\u2019s surprisals? (22 points)": [[5, "exercise-4-how-human-like-are-llama-s-surprisals-22-points"]], "Experiment Scheme": [[3, "experiment-scheme"], [3, "id2"]], "Few-Shot Prompting with CommonSenseQA": [[3, "few-shot-prompting-with-commonsenseqa"]], "Fine-tuning and RLHF": [[11, null]], "Flavours of fine-tuning": [[26, "flavours-of-fine-tuning"]], "Further materials": [[6, "further-materials"]], "Generated Knowledge Prompting with NumerSense Dataset": [[3, "generated-knowledge-prompting-with-numersense-dataset"]], "Hallucinations": [[30, "hallucinations"]], "Helper functions for training": [[21, "helper-functions-for-training"]], "Homework 1: Language models (50 points)": [[0, null], [1, null]], "Homework 2: Prompting & Generation with LMs (50 points)": [[2, null], [3, null]], "Homework 3: LLM agents & RL fine-tuning": [[4, null]], "Homework 4: LLM evaluation": [[5, null]], "HuggingFace \ud83e\udd17": [[22, "huggingface"]], "Implications, Understanding & Philosophy": [[15, null]], "Indexing and slicing": [[18, "indexing-and-slicing"]], "Inference": [[21, "inference"]], "Installing requirements": [[17, "installing-requirements"]], "Intended audience": [[6, "intended-audience"]], "Interpreting training dynamics": [[24, "interpreting-training-dynamics"]], "Introduction: ML models": [[22, "introduction-ml-models"]], "Inverting the generation model": [[21, "inverting-the-generation-model"]], "Joining tensors": [[18, "joining-tensors"]], "Knowledge & Problem solving benchmarks": [[30, "knowledge-problem-solving-benchmarks"]], "LLM systems & agents": [[12, null]], "LSTMs & Transformers": [[9, null]], "LangChain": [[27, "langchain"]], "LangChain agent with tools": [[27, "langchain-agent-with-tools"]], "Loading & inspecting the data": [[21, "loading-inspecting-the-data"]], "Local installation": [[17, "local-installation"]], "Logistics": [[0, "logistics"], [1, "logistics"], [2, "logistics"], [3, "logistics"], [4, "logistics"], [5, "logistics"]], "MLM masking": [[24, "mlm-masking"]], "Machine psychology": [[29, "machine-psychology"]], "Main training data processing steps": [[17, "main-training-data-processing-steps"]], "Matrix Multiplication": [[18, "matrix-multiplication"]], "Mechanistic Interpretability": [[16, null]], "Memory handling": [[27, "memory-handling"]], "Metrics": [[29, "metrics"]], "Model heads": [[24, "model-heads"]], "More concise definition of NN module": [[20, "more-concise-definition-of-nn-module"]], "More explicit definition NN module": [[20, "more-explicit-definition-nn-module"]], "Multiple-choice QA": [[3, "multiple-choice-qa"]], "Natural Language Inference": [[3, "natural-language-inference"], [3, "id1"]], "Operations on tensors": [[18, "operations-on-tensors"]], "Optimizing a parameter: gradients, optimizers, loss & backprop": [[19, "optimizing-a-parameter-gradients-optimizers-loss-backprop"]], "Optional outlook": [[26, "optional-outlook"]], "Outlook": [[22, "outlook"], [29, "outlook"]], "Outlook (optional)": [[23, "outlook-optional"]], "Outlook (optional): EOS tokens": [[23, "outlook-optional-eos-tokens"]], "Outlook and optional exercises": [[24, "outlook-and-optional-exercises"]], "Outlook: PEFT in practice": [[26, "outlook-peft-in-practice"]], "Outlook: PyTorch layers and utils [optional]": [[20, "outlook-pytorch-layers-and-utils-optional"]], "Output parsing": [[27, "output-parsing"]], "PPO training": [[26, "ppo-training"]], "Packages": [[19, "packages"]], "Packages & global parameters": [[20, "packages-global-parameters"], [21, "packages-global-parameters"]], "Part 1: Compute the predictions for current parameter value": [[19, "part-1-compute-the-predictions-for-current-parameter-value"]], "Part 2: Computing the loss for the current prediction": [[19, "part-2-computing-the-loss-for-the-current-prediction"]], "Part 3: Backpropagate the error signal": [[19, "part-3-backpropagate-the-error-signal"]], "Part 4: Update the parameter values": [[19, "part-4-update-the-parameter-values"]], "Part 5: Reset the gradient information": [[19, "part-5-reset-the-gradient-information"]], "Policy": [[26, "policy"]], "Preparing the training data": [[20, "preparing-the-training-data"]], "Pretrained tokenizers": [[23, "pretrained-tokenizers"]], "Pretrained transformers": [[23, "pretrained-transformers"]], "Previous iterations of the course": [[6, "previous-iterations-of-the-course"]], "Probing": [[28, "probing"]], "Process consistency": [[30, "process-consistency"]], "Prompting & Current LMs": [[10, null]], "Prompting strategies": [[25, "prompting-strategies"]], "PyTorch": [[23, "pytorch"]], "PyTorch, ANNs & LMs": [[8, null]], "RL fine-tuning": [[26, "rl-fine-tuning"]], "Reasoning benchmarks": [[30, "reasoning-benchmarks"]], "Reshaping": [[18, "reshaping"]], "Residual stream": [[31, "residual-stream"]], "Reward modeling": [[26, "reward-modeling"]], "Row & column vectors": [[18, "row-column-vectors"]], "Schedule": [[6, "schedule"]], "Sheet 1.1: Practical set-up & Training data": [[17, null]], "Sheet 2.1: PyTorch essentials": [[18, null]], "Sheet 2.2: ML-estimation": [[19, null]], "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)": [[20, null]], "Sheet 2.4: Character-level sequence modeling w/ RNNs": [[21, null]], "Sheet 2.5: Introduction to HuggingFace & LMs": [[22, null]], "Sheet 3.1: Tokenization & Transformers": [[23, null]], "Sheet 3.2: Transformer configurations & Training utilities": [[24, null]], "Sheet 3.3: Prompting & Decoding": [[25, null]], "Sheet 4.1 Supervised fine-tuning and RL fine-tuning": [[26, null]], "Sheet 5.1 LLM agents": [[27, null]], "Sheet 6.1 LLM probing & attribution": [[28, null]], "Sheet 7.1: Behavioral assessment & Evaluation": [[29, null]], "Sheet 7.2: Advanced evaluation": [[30, null]], "Sheet 8.1: Mechanistic interpretability": [[31, null]], "Social aspects": [[30, "social-aspects"]], "Special tokens": [[23, "special-tokens"]], "Supervised fine-tuning": [[26, "supervised-fine-tuning"]], "Tensor arithmetic": [[18, "tensor-arithmetic"]], "Tensor data types": [[18, "tensor-data-types"]], "Tensors": [[18, "tensors"]], "Tokenization": [[23, "tokenization"]], "Train-test split": [[21, "train-test-split"]], "Training": [[28, "training"]], "Training loop": [[19, "training-loop"]], "Training the model": [[20, "training-the-model"]], "Training the network": [[21, "training-the-network"]], "Training utilities": [[24, "training-utilities"]], "Transformers": [[23, "transformers"]], "Transposing": [[18, "transposing"]], "True distribution & training data": [[19, "true-distribution-training-data"]], "True model & training data": [[20, "true-model-training-data"]], "Understanding training data": [[17, "understanding-training-data"]], "Verifying requirement installation": [[17, "verifying-requirement-installation"]], "Working with LMs via \ud83e\udd17 Transformers": [[22, "working-with-lms-via-transformers"]]}, "docnames": ["homework/archive_2024/01-language-modeling", "homework/archive_2024/01_language_modeling_solutions", "homework/archive_2024/02-prompting", "homework/archive_2024/02-prompting_solution", "homework/archive_2024/03-agents-RL", "homework/archive_2024/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/09-philosophy", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["homework/archive_2024/01-language-modeling.ipynb", "homework/archive_2024/01_language_modeling_solutions.ipynb", "homework/archive_2024/02-prompting.ipynb", "homework/archive_2024/02-prompting_solution.ipynb", "homework/archive_2024/03-agents-RL.ipynb", "homework/archive_2024/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/09-philosophy.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 4, 6, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "0": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "00": [17, 31], "000": [3, 5, 17], "0000": 18, "00000": 19, "0000001": 19, "00001": 32, "00005": 19, "00007": 19, "00012": 19, "00020": 19, "00033": 19, "0005": 21, "00055": 19, "00059": 19, "00091": 19, "00095": 19, "00097": 19, "001": 32, "00117": 19, "0013": 20, "00130": 19, "00138": 19, "00143": 19, "00146": 19, "00150": 19, "0017": 20, "002": 32, "0024": 20, "00248": 19, "00258": 19, "0028": 23, "0032": 23, "0037": 20, "0039": 23, "004": [20, 32], "00408": 19, "0044": 20, "0046": 23, "00523": 19, "0054": 18, "0059": 20, "006": 19, "0066": 20, "00673": 19, "0070": 23, "0076": 20, "009": 32, "0095": 23, "00960": 19, "01": 18, "0104": 23, "0109": 20, "011": 19, "01110": 19, "0113": 23, "01171875": 25, "012": 32, "0125": 27, "0126": 23, "013": 32, "013982772827148": 3, "0149": 20, "0155": 20, "0156": 23, "015838623046875": 3, "016": 20, "0164": 23, "0166": 20, "01680": 19, "01831": 19, "019416809082031": 3, "0195": 20, "0198": 23, "0199": 20, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 31, "02": [0, 1, 18, 23, 25], "0204": 23, "021014213562012": 3, "0211": 20, "0225": 20, "0227": 20, "023": 20, "0235": 20, "0236": 23, "0239": 23, "0246": 20, "0250": 23, "0255": 1, "0257": 20, "0279": 20, "0282": 20, "02869": 19, "0292": 20, "0293": 23, "03": 23, "03019": 19, "03041934967041": 3, "0309": 20, "0312": 19, "031479835510254": 3, "0318": 23, "0319": 23, "031961441040039": 3, "033": 20, "033587316144933": 21, "0338": 20, "034": 20, "0348": 20, "035849571228027": 3, "0363": 23, "0365": 20, "0369": 20, "0370": 20, "03721284866333": 3, "0374": 20, "0383": 20, "0386": 20, "039": 20, "04": 18, "040278911590576": 3, "0419": 20, "042": 32, "0421": 20, "0429": [20, 23], "043": 20, "0434": 20, "0436": 20, "044040465112291": 21, "0446": 20, "04466724395752": 3, "0447": 20, "045": 32, "0451": 20, "0453": 20, "0454": 20, "0457": 23, "0458984375": 19, "046": 20, "0475": 23, "0479": 20, "04828": 19, "049187345280759": 21, "0493": 20, "04979": 19, "0499": 23, "05": [4, 21, 23], "0505": 20, "0509": 20, "0513": [20, 23], "0516": 23, "0519": 20, "05221": 29, "0523": 20, "0525": 23, "0528": 20, "05326": 3, "0533545017242432": 3, "0540814399719238": 3, "0546": 20, "0547": 20, "0552": 20, "055522918701172": 3, "0556": 20, "0562": 20, "0569": 23, "0575": 20, "0584": 23, "0588": 20, "059": 19, "0591": 20, "0592": 20, "0601": 23, "0612": 23, "0622": 20, "0644": 20, "0646": 20, "0655": 20, "0663": 20, "06640625": 25, "0666": 20, "0671": 20, "0675": 20, "0679": 20, "0695": 23, "0696": 23, "06977367401123": 3, "0706": [20, 23], "071": 20, "074": 20, "0758": 21, "076368400920858": 21, "0769": 20, "077": 32, "0787130945986387": 21, "0789": 20, "08": 32, "08060": 19, "08073": 26, "081": 32, "08211": 19, "083": 1, "0846": 23, "0849": 20, "0853": 20, "0854": 20, "086": 32, "0874": 23, "089089898243062": 21, "08965344": 32, "0909": 20, "0912": 20, "0915": [20, 23], "091569900512695": 3, "0917557944550413": 21, "0919": 23, "0924": 20, "092577934265137": 3, "0928": 20, "0934": 20, "0936": 20, "094": 32, "0941": 23, "094646453857422": 3, "0947": 20, "095": [20, 32], "0955": 20, "095916748046875": 3, "0964": 20, "0968": 20, "0972": 20, "0978": 23, "0994": 20, "0_0": 32, "0_1": 32, "0_4": 32, "0m": 21, "1": [20, 21, 22, 24, 30, 32], "10": [0, 1, 3, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "100": [3, 17, 18, 19, 20, 21, 25, 27, 29, 31], "1000": [0, 1, 19, 20, 25], "10000": [19, 20, 21, 23], "100000": 21, "10015": 19, "1002": 23, "1003": 23, "1005": 23, "1006": 20, "1007": 20, "1009": 20, "101": 18, "1014": 20, "102": [3, 20], "1023": 32, "1024": [4, 23, 26, 28], "1025": [20, 23], "1031": 20, "104": 20, "1041": 20, "1043": 23, "1050": 32, "1051": 20, "1056": 23, "1068": 32, "107": 20, "1071": 32, "108": 18, "1081": 21, "10x1": 20, "10x10": 20, "11": [3, 18, 20, 21, 23, 26, 32], "111": [18, 32], "1116": 20, "1128": 20, "1129": 20, "113": 20, "1132": 31, "1136": 20, "114": 18, "114116668701172": 3, "114299774169922": 3, "1143": 23, "11440658569336": 3, "1146": 20, "1149": [20, 32], "1157": 23, "1161": 20, "1163": 20, "1173": 23, "1174": 32, "1179": 20, "118": 20, "118217468261719": 3, "119": 20, "1196": 20, "12": [3, 17, 18, 21, 23, 31, 32], "121": 20, "122": 20, "1222": 20, "1229": 20, "124": 26, "1241": 20, "125": [1, 20, 21], "12500": 20, "1255": 32, "1259": 20, "12620735168457": 3, "1264": 20, "1269": 20, "1277": 20, "128": [4, 21, 23, 27], "129": 20, "1293": 20, "12th": 1, "13": [0, 1, 3, 20, 21, 25, 32], "1302": 25, "1304": 21, "1305": 20, "131": 20, "1315": 20, "1321": 20, "133": 20, "13390": 19, "1341121196746826": 3, "1344274634863063": 21, "13504695892334": 3, "13540": 19, "1359": 20, "1371": 20, "137311827640074": 21, "1385": 23, "139": 21, "1394": 20, "1396": 20, "13th": 5, "13x1": 1, "13x13": 1, "13x2": 1, "13x3": 1, "14": [17, 18, 20, 21, 32], "140": 20, "1407": [20, 23], "1408": 20, "1417": 20, "142420768737793": 3, "14258": 19, "14259": 19, "1426": 20, "14260": 19, "14263": 19, "1427": 20, "14271": 19, "1428": 20, "14292": 19, "1432": 32, "1433": 20, "14350": 19, "1447": 20, "1449": 20, "145": 3, "14508": 19, "1452": 20, "1462": 20, "1464": 20, "147": 20, "1473": 23, "1481": 20, "149": 32, "1491": 20, "149327039718628": 3, "14937": 19, "15": [3, 17, 19, 20, 21, 24, 25, 32], "1500": 19, "15000": [20, 21], "1508": 3, "151": 20, "151007538987999": 21, "1517": 23, "1518": 20, "1524": 20, "1527": 20, "1548": 23, "156": 32, "1574": 20, "1587": [20, 23], "15948522": 32, "1596": [20, 23], "15th": 0, "16": [18, 20, 21, 22, 32], "1600": 20, "160m": 5, "16102": 19, "1630": 20, "1632": 20, "1638": 20, "1640625": 25, "165120124816895": 3, "1652": [20, 25], "165630340576172": 3, "167": 1, "1671": 18, "1673": 23, "1674": 23, "1676781420602698": 21, "1682": 20, "17": [21, 27, 32], "1701001434279856": 21, "1727": 20, "1732": 20, "173294067382812": 3, "1744": [20, 23], "175": 32, "17500": 20, "176395016805715": 21, "1773": 32, "1774": 20, "1777": 21, "17835062349366": 17, "1784": 20, "179": 20, "1793": 20, "1796": 20, "1796875": 25, "179699897766113": 3, "18": [17, 20, 21], "1800": 21, "183": 21, "1839": 20, "184": 32, "1851": 32, "1861": 20, "1869": 23, "1871": 20, "1897": 20, "19": [21, 31], "1908": 20, "1909": 17, "191": 20, "1913": 23, "192": 32, "1924": 23, "1926": 32, "19274": 19, "1927830372943777": 21, "1945": 20, "195": 20, "1959": 20, "1961": 20, "1962": 20, "1966": 23, "1967": 20, "1969": 20, "1971399784088135": 3, "1976": 20, "198206901550293": 3, "1986": 8, "1991": 23, "199512481689453": 3, "1997": 9, "19pt": [0, 1], "19th": 17, "1b": 26, "1e": [20, 23], "1f": [0, 1], "1gb": [0, 1], "1h": 6, "1m": 21, "1x1": 20, "1x10": 20, "1x13": 1, "1x18": 21, "1x3": 1, "2": [9, 10, 16, 17, 23, 26, 28, 29, 31, 32], "20": [4, 17, 18, 20, 21, 23, 29, 32], "200": [18, 21, 29], "2000": [18, 19, 21], "20000": [20, 21], "2003": [2, 3], "2009": 20, "201": [19, 32], "2011": 20, "2013": 7, "201595306396484": 3, "2016": 8, "2017": 9, "2018": [0, 1, 11], "2019": [2, 3, 9, 13, 28, 29, 30], "202": 32, "2020": [4, 7, 16, 17], "2021": [5, 10, 13, 16, 30], "2022": [5, 10, 11, 12, 15, 16, 23, 25, 26, 29, 30], "2023": [7, 10, 11, 12, 15, 16, 26, 30], "2024": [6, 7, 12, 16, 31], "2027": 20, "2028": 20, "2029": 20, "203": 21, "203125": 25, "2032": 29, "2034": [23, 32], "2037": 20, "2050": [0, 1], "205616125930776": 21, "2063": 20, "2064": 32, "2068": 20, "2073": 20, "2081": 20, "209": [20, 21], "2095": 20, "2097": 20, "2099": 20, "21": [0, 3, 17, 18, 20, 22, 32], "2106": 20, "21096220730527": 21, "2114": 18, "212": 20, "2122": 21, "2133": 20, "214": 32, "2143": 20, "2152": 23, "2154": 20, "216497421264648": 3, "2165": 20, "2170": [23, 32], "2174": 32, "21778265": 32, "2180": 20, "2182": 20, "2186": 20, "2188": 20, "2198": 20, "22": 32, "2201": 20, "2207": 29, "2208": 20, "2212": 26, "22179": 19, "2232": 20, "22330": 19, "2239": 20, "22500": 20, "2256": 20, "2263": 32, "2276": 20, "2283": 20, "23": [2, 3, 4, 5, 20, 21, 31, 32], "2304": [23, 26], "2313": 20, "2317": 20, "232": 21, "2323": 20, "2333": 20, "23339557647705": 3, "233652114868164": 3, "2337": 20, "2353": 20, "235928535461426": 3, "237": 20, "2371": 20, "2373": 20, "2380": 32, "2387": 23, "2389": 20, "2393": 20, "239646911621094": 3, "24": [1, 18, 19, 20, 21, 31, 32], "2400": 23, "2406": 20, "241": 21, "2411": 32, "2425": 20, "2455": 20, "2462": 20, "2468": 20, "247": 32, "2478": 20, "2482": 32, "24860143661499": 3, "249": [21, 32], "25": [1, 17, 20, 21, 25], "250": 4, "2500": [19, 20], "25000": [20, 21], "251": 20, "2518": 20, "25248486": 32, "253": [20, 32], "2532": 20, "2536": 20, "2537": 20, "2543": 20, "255": 20, "2553533346": 1, "2557": 20, "256": [20, 26], "2564": 20, "2576": 20, "2579": 20, "258166313171387": 3, "258934020996094": 3, "2591": 20, "2592": 23, "2595": 20, "25966188": 32, "2614": 23, "2615": 20, "262053290805339": 21, "2630": 20, "263005256652832": 3, "2633": 20, "2638578414917": 3, "264": 32, "2647": 20, "26594367422115": 21, "2664": 20, "267": 21, "268": 21, "2682": 20, "2689": 20, "269": 32, "2698": 20, "27": [4, 20, 21, 26, 32], "2706": 20, "2711": 20, "2712": 20, "271496772766113": 3, "2719710113848373": 21, "2738": 20, "2739": 25, "2746": 21, "27500": 20, "2758": 20, "276": [20, 31], "276028633117676": 3, "277": 21, "27782917022705": 3, "279": 32, "28": 21, "2815": 20, "281587600708008": 3, "284": 19, "2842": 20, "2846": 20, "2852": 20, "286": [20, 23], "2862": 20, "2865": 20, "2872": 20, "289": 32, "28th": 4, "29": [0, 1, 23, 26, 32], "2919": 20, "2934": 20, "2941": 20, "2944": 20, "295": 32, "2954": 20, "2955": 20, "2956": 20, "2958": 21, "2965": 20, "297": 21, "2971": 20, "297186851501465": 3, "2976": 20, "297685623168945": 3, "298": [20, 21, 32], "2984": 20, "2986": 20, "29901123046875": 3, "2d": [0, 1], "2i": 23, "2m": 21, "2nd": [2, 3], "2pt": [0, 1, 4], "2x1": 1, "2x13": 1, "3": [17, 18, 21, 22, 26, 27, 28, 29, 30, 31, 32], "30": [18, 20, 21, 32], "300": 18, "3000": 19, "30000": [20, 21], "3001": 20, "3009": 20, "300px": 18, "3011": 20, "3013": 20, "3025": 20, "3049": 20, "305": 32, "3072": 31, "309": 20, "3099": 20, "31": 32, "3114": 20, "313": 32, "315": 20, "3155701160430908": 3, "3162": 20, "32": [0, 1, 17, 18, 20, 21, 23, 28, 32], "323": 32, "32500": 20, "3271989822387695": 3, "32869": 17, "329": 32, "329154273345582": 21, "33": [18, 21, 32], "3301": 21, "33044753": 32, "3338e": 18, "336479187011719": 3, "337": 32, "33744430690024": 21, "338": 32, "338224411010742": 3, "33836474": 32, "339978218078613": 3, "34": [18, 32], "3403": 20, "342": 20, "343545913696289": 3, "3442": 20, "3451": 20, "3486": 32, "3488": 20, "349": 32, "35": [0, 1, 21, 29], "3500": 19, "35000": [20, 21], "350m": 26, "3515625": 25, "352": 25, "353": 32, "358133316040039": 3, "36": [20, 21, 32], "3607": 21, "361309051513672": 3, "363598346710205": 3, "36674": 19, "3668": [21, 23], "367": 21, "368": 19, "36825": 19, "369648933410645": 3, "37": [20, 23], "370429039001465": 3, "370843410491943": 3, "3746": 20, "3750": 18, "37500": 20, "3759": 32, "3773": 20, "3793": 20, "3797": 20, "38": [20, 32], "383": 32, "384112744200534": 21, "3842": 20, "3850": 21, "3875": 20, "38808536529541": 3, "3889435308678326": 21, "3915": 20, "3927": 20, "3931": 20, "3938": 20, "394": 32, "3945": 32, "39453125": 25, "3946": 20, "3973": 20, "3f": [19, 20, 31], "3m": 21, "3x1": 1, "3x13": 1, "3x5": [0, 1], "4": [0, 1, 2, 3, 4, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "40": [0, 1, 18, 21], "400": 18, "4000": [18, 19], "40000": [20, 21], "4001": 20, "4005": 20, "4007": 20, "402": 32, "4070479577071051": 21, "4075": 20, "4078": 20, "407893180847168": 3, "40b": 1, "41": [20, 21, 23, 32], "4100": 23, "410m": [2, 3], "4118": 20, "4123": 32, "4126": 20, "412652015686035": 3, "4141": 20, "415": 20, "41515987": 32, "4155": 20, "416": 20, "4167": 20, "417": 20, "419": 20, "419055938720703": 3, "419212341308594": 3, "41e": 4, "42": [3, 20, 32], "422": 20, "4230": 20, "424": [20, 32], "424176216125488": 3, "425": 20, "42500": 20, "4264": 20, "427": 20, "428": 20, "4293": 23, "43": [18, 20, 21, 32], "430": 20, "4315": 20, "432": 20, "433": 20, "434816360473633": 3, "436": 20, "4374993423367664": 21, "44": 32, "441": 20, "444": 32, "444657022227277": 21, "445": 32, "447": 20, "448": [25, 32], "4495": 20, "45": [20, 21, 24], "450": 20, "4500": [19, 20], "45000": [20, 21], "452256441116333": 3, "452688217163086": 3, "453125": 25, "454367770907213": 21, "4543e": 18, "4584479331970215": 3, "4591": 21, "4592": 20, "46": [20, 28], "461": 32, "4612": 20, "4614": 20, "4614875316619873": 3, "4619": 20, "462": 20, "4622": 32, "46240755": 32, "4627": 32, "465941429138184": 3, "466972351074219": 3, "467": 21, "46780014038086": 3, "47": [20, 32], "4716": 20, "473": 20, "4738": 23, "475": 20, "47500": 20, "4765625": 25, "4786": 20, "479": 20, "4803": 23, "4812": 20, "4826": 21, "484375": 25, "486684799194336": 3, "49": 21, "4921": 20, "4921875": 25, "4922e": 18, "4924": 18, "497": 20, "4b": [2, 3, 25], "4f": 21, "4gb": 4, "4k": [4, 26], "4m": 21, "4p": 3, "4pt": [0, 1], "5": [0, 1, 3, 17, 18, 20, 21, 23, 25, 26, 29, 30, 32], "50": [18, 21, 29], "500": [4, 19, 21, 22], "5000": [18, 19, 20, 21, 23], "50000": [20, 21], "501": 32, "501969337463379": 3, "50257": 23, "503078942968957": 21, "5045": 20, "51": 20, "510452270507812": 3, "512": [4, 18, 26], "5127": 20, "515718460083008": 3, "516082286834717": 3, "51792049407959": 3, "518067359924316": 3, "5181813091977734": 21, "519": 21, "52": [20, 21, 32], "520": 32, "520139694213867": 3, "520474433898926": 3, "5211": 20, "522": 20, "523": 1, "5242": 25, "5254": 23, "528425216674805": 3, "53": 32, "531": [18, 32], "5318": 20, "5321": 20, "533": 19, "5347": 25, "5388": 20, "538839340209961": 3, "539": 32, "5396": 20, "54": 21, "5437": 20, "5453": 20, "55": [20, 21], "5500": [19, 20], "55000": 21, "550px": 21, "5510": 20, "554006576538086": 3, "55483865737915": 3, "555357933044434": 3, "5575783252716064": 3, "557712239995114": 21, "5580": 20, "5581e": 18, "56": [18, 23, 32], "560m": 5, "5617": 20, "5625": 25, "5653": 20, "5669": 32, "57": 32, "570": 32, "5707610099012776": 21, "570777893066406": 3, "5713": 20, "5756": 20, "576825141906738": 3, "577406883239746": 3, "57964344": 32, "58": [0, 1, 21], "5819": 20, "582685867418279": 21, "583547592163086": 3, "5863": 20, "5894": 21, "589640617370605": 3, "59": [0, 1, 2, 3, 4, 5], "591": 19, "5919": 18, "5931": 20, "595": 20, "596774101257324": 3, "5973": 20, "5975": 20, "598419189453125": 3, "5_000": 22, "5d": [19, 20], "5e": [0, 1, 22], "5f": 19, "5m": 21, "6": [1, 3, 6, 18, 20, 21, 22, 23, 25, 26, 30, 31, 32], "60": [18, 21, 23], "600": 18, "6000": 19, "60000": 21, "6002087593078613": 3, "6004": 18, "6013": 20, "60135555267334": 3, "6017": 20, "6051": 20, "6051456928253174": 3, "60579": 19, "606": 32, "607": 32, "60729": 19, "6076": 20, "6087": 20, "6096": 20, "61": 20, "6114": 20, "61173964": 32, "612": 32, "612419128417969": 3, "612512588500977": 3, "6135": 20, "61604118347168": 3, "6166": 20, "6175335252350447": 21, "6177": 20, "6194": 20, "6196": 20, "6199": 20, "62": 23, "621": 32, "622293472290039": 3, "6223": 20, "6236846446990967": 3, "625": 25, "6265": 20, "628": 20, "631083488464355": 3, "63491153717041": 3, "635777473449707": 3, "638": [20, 21], "63901424407959": 3, "6393": 21, "639629364013672": 3, "64": [0, 1, 19, 22, 23, 24], "6406": 25, "6411": 20, "642": 20, "64202727": 32, "6423": 20, "645": 19, "645547866821289": 3, "64605712890625": 3, "6464": 20, "65": [18, 20, 21], "650": 19, "6500": 19, "65000": 21, "650859832763672": 3, "651183128356934": 3, "6514": 20, "652": 21, "6531856900705275": 21, "655148983001709": 3, "6555": 20, "659232139587402": 3, "66": [20, 21], "6612294775126752": 21, "664": [20, 32], "6654": 20, "6659": 20, "666": 32, "668207168579102": 3, "6692703950843093": 21, "66d1a2d3ccf0": 1, "67": [0, 1, 5, 20, 21], "671875": 3, "673873901367188": 3, "67534827": 32, "67751693725586": 3, "68": 32, "681248426437378": 3, "682": 19, "6834": [20, 32], "6843": 20, "687712669372559": 3, "6880": 20, "69": 20, "690098762512207": 3, "690305233001709": 3, "6925": 20, "695": 32, "6955": 20, "6pt": [0, 1], "7": [1, 3, 4, 5, 17, 18, 20, 21, 25, 26, 27, 31, 32], "70": [18, 21], "7000": 19, "70000": 21, "703117370605469": 3, "7046": 21, "7076313495635986": 3, "708530902862549": 3, "7086": 20, "708761215209961": 3, "709": 21, "70b": [1, 26], "71": 21, "710489273071289": 3, "7110": 20, "7121": 20, "713": 32, "716": 32, "716580436309544": 21, "7169": 20, "7172": 20, "7179": 20, "7180": 21, "72": [18, 20, 21, 32], "724": 21, "726918229927053": 21, "7288": 20, "7293": 20, "7298": [20, 25], "73": [21, 32], "73061466217041": 3, "7308": 21, "736490726470947": 3, "738": [31, 32], "73959792": 32, "74": [21, 32], "740": 20, "743338584899902": 3, "743693795963553": 21, "7454": 20, "746094297468178": 21, "746541976928711": 3, "748946189880371": 3, "7494": 20, "7496": 20, "749650001525879": 3, "75": [0, 1, 21, 28, 32], "7500": [19, 20], "75000": 21, "7501": 20, "7502": 20, "7523": 20, "7530": 20, "754240989685059": 3, "7552": 20, "7589095234870911": 3, "76": [4, 20, 29], "7634": 17, "7650": 20, "765625": 25, "7674624919891357": 3, "768": [23, 26, 28], "76948356628418": 3, "77": 20, "7734": 20, "7734375": 25, "7743": 20, "7748951742793246": 21, "7764": 20, "7767": 20, "776968002319336": 3, "78": [4, 32], "780394554138184": 3, "7873": 20, "790425300598145": 3, "7927885055542": 3, "792975425720215": 3, "79754031778924": 21, "798": 32, "7b": [2, 3, 23, 27], "8": [3, 17, 18, 21, 25, 26, 32], "80": [17, 18, 21], "800": 3, "8000": 19, "80000": 21, "8005": 20, "8015": 32, "8022": 20, "8029": 21, "8056986331939697": 3, "8063146353260925e": 32, "8089478089254367": 21, "8123": 20, "815916061401367": 3, "816": 20, "8176": 20, "819": 32, "8191": 20, "819255000074138": 21, "82": 20, "8204474449157715": 3, "82045841217041": 3, "8224": 20, "8238": 25, "8264": 20, "83": [0, 1, 20], "830539703369141": 3, "83149242401123": 3, "832415580749512": 3, "8325": 21, "8344": 21, "8362": 32, "83683439539813": 21, "8398610504968342": 21, "841059684753418": 3, "8415": 20, "843": 32, "84375": 25, "8441": 20, "8467": 21, "84765625": 25, "85": 21, "8500": 19, "85000": 21, "85256576538086": 3, "8540": 20, "8546": 20, "854644775390625": 3, "85546875": 25, "857054710388184": 21, "858763694763184": 3, "8589": 20, "859375": 25, "863": 32, "864": 32, "8666": 20, "8668": 20, "8697": 20, "87": [18, 20], "879318062464732": 21, "88": [20, 32], "8839691281318665": 3, "884116172790527": 3, "8884e": 18, "888652801513672": 3, "889074325561523": 3, "89": [20, 23, 32], "8900933861732483": 3, "890667915344238": 3, "892": 21, "893194198608398": 3, "893522262573242": 3, "8970": 20, "8981": 20, "8b": 1, "9": [3, 17, 18, 21, 25, 32], "90": [18, 20, 21], "9000": 19, "90000": 21, "9023": 20, "9025": 20, "9025e": 18, "90373899401307": 21, "90455436706543": 3, "9046": 20, "905": 32, "9054934978485107": 3, "9079": 20, "908905029296875": 21, "909": 32, "909016609191895": 3, "91": [0, 1, 32], "9101": 20, "9163": 20, "9164": 20, "9166837202752751": 21, "918338775634766": 3, "9185": 20, "9190526549711127": 21, "921": 32, "921186923980713": 3, "9245": 20, "9253905269010243": 21, "929475784301758": 3, "9338192343711853": 3, "94": [20, 21], "94018840789795": 3, "9408": 21, "941": 21, "943814170795518": 21, "9444": 20, "9450": 20, "945132093597879": 21, "9468": 20, "9476": 20, "95": 21, "9500": 19, "95000": 21, "9520": 20, "9521": 20, "9536": 20, "9538": 20, "9543": 17, "955": 32, "955305576324463": 3, "95555591583252": 3, "9574": 20, "959": 20, "96": 23, "9640": 20, "9653": 20, "9675": 21, "97": 31, "9718918800354": 3, "972271919250488": 3, "975": 19, "975641382951965": 21, "976": 19, "977": 19, "979": 19, "9820": 32, "9830674364599212": 21, "98336813": 32, "984375": 25, "986": 19, "986560821533203": 3, "987": [20, 32], "988": 19, "989767319373302": 21, "99": 21, "991": 21, "9920": 20, "9964": 20, "9989984954101563": 19, "9994": 20, "9999999999999994": 21, "9ect": 6, "A": [0, 1, 2, 3, 4, 5, 7, 12, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32], "AND": [0, 5], "And": [18, 27], "As": [3, 12, 20, 22, 23, 25, 26, 27, 28, 29, 30], "At": [23, 27], "Be": 4, "Being": 19, "But": [3, 18, 25, 27], "By": [19, 23, 26], "FOR": 5, "For": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "IT": [0, 27], "If": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 28, 29, 30, 31], "In": [1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "It": [1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "Its": [18, 26], "NOT": [0, 1, 4, 17, 22, 26, 27, 30], "No": 1, "Not": [12, 21, 27], "Of": [25, 26, 27], "On": [0, 1, 15, 17, 22, 25], "One": [3, 17, 21, 24, 26, 27, 28, 29, 30, 31], "Or": 18, "Such": [17, 29], "THE": 29, "TO": 0, "That": [3, 17, 20, 22, 23, 26, 30], "The": [0, 1, 2, 3, 4, 5, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "Their": [10, 31], "Then": [4, 23, 24], "There": [0, 1, 2, 3, 6, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31], "These": [1, 4, 17, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31], "To": [2, 3, 4, 6, 17, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 31], "With": [0, 1, 18, 22, 25], "_": [1, 4, 26, 31], "__dict__": 23, "__future__": 21, "__getitem__": [0, 1, 20], "__init__": [0, 1, 20, 21, 23, 28, 31], "__len__": [0, 1, 20], "__name__": 3, "_backward_hook": 23, "_backward_pre_hook": 23, "_buffer": 23, "_forward_hook": 23, "_forward_hooks_always_cal": 23, "_forward_hooks_with_kwarg": 23, "_forward_pre_hook": 23, "_forward_pre_hooks_with_kwarg": 23, "_is_full_backward_hook": 23, "_is_hf_initi": 23, "_load_state_dict_post_hook": 23, "_load_state_dict_pre_hook": 23, "_modul": 23, "_non_persistent_buffers_set": 23, "_paramet": 23, "_qkv_same_embed_dim": 23, "_state_dict_hook": 23, "_state_dict_pre_hook": 23, "a_i": 25, "a_list": 18, "ab": [0, 1, 19, 20, 29], "abbrevi": 22, "abil": 30, "abise": 4, "abl": [0, 1, 3, 17, 18, 21, 22, 23, 24, 26, 30, 31], "about": [2, 3, 4, 5, 6, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "abov": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "absenc": 30, "absolut": [22, 23, 26, 28], "abstract": [3, 17, 22, 26, 30], "ac": 20, "acccess": 23, "acceler": [0, 1, 2, 3, 4, 22, 26], "accept": [0, 1, 3, 5, 27], "access": [0, 1, 3, 4, 17, 20, 22, 23, 25, 26, 28, 31], "accid": [2, 3], "accompani": 31, "accomplish": [17, 22, 27], "accord": [0, 1, 17, 23, 30], "accordingli": 25, "account": [17, 22, 27], "accumul": [0, 1, 19], "accur": 4, "accuraci": [0, 1, 2, 3, 5, 24, 28, 29, 30], "achiev": [2, 3, 25, 26], "acquir": [0, 1, 17], "across": [4, 5, 16, 28, 29], "act": [23, 31], "action": [4, 26], "activ": [0, 1, 3, 16, 19, 20, 21, 22, 26], "activations_": 31, "actual": [0, 1, 2, 3, 4, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "acycl": 20, "ad": [3, 17, 19, 22, 23, 24, 25, 27], "adam": [20, 21, 28], "adamw": [0, 1], "adapt": 31, "add": [17, 18, 20, 21, 23, 27, 31], "add_hook": 31, "add_mid_attn_hook": 31, "add_zero_attn": 23, "addit": [4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29], "additioanli": 22, "additioanlli": [0, 1], "addition": [0, 1, 4, 17, 21, 26, 28, 30], "additional_dim": 22, "address": [25, 28, 29], "adequ": 17, "adher": 17, "adjust": [17, 22, 23, 25, 30], "admir": 26, "advanc": [4, 6, 17, 22, 25], "advantag": [4, 17, 24, 26, 27, 29], "affect": [4, 25, 26, 31], "afford": 12, "after": [0, 1, 3, 17, 19, 20, 22, 23, 24, 25, 26, 31], "again": [1, 17, 19, 20, 23, 24, 25, 26, 27, 31], "against": [4, 21, 24, 29], "agent": [0, 1, 6, 26], "agent_executor": 27, "agent_hf": 27, "agent_hf_executor": 27, "agent_with_tool": 27, "agentexecutor": 27, "aggress": 19, "agnet": 27, "agre": [5, 21], "agreement": 5, "ahead": 17, "ahn": 12, "ahv": 28, "ai": [4, 6, 15, 26], "aim": [3, 29, 30], "aimia": 17, "airplan": [2, 3], "airport": [2, 3], "aka": 16, "al": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "algebra": 18, "algorithm": [4, 5, 23, 24, 25, 26, 30, 31], "alic": 26, "alien": 26, "align": [1, 6, 26], "all": [0, 1, 3, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "all_hidden_st": 28, "all_lett": 21, "all_loss": 21, "alloc": 21, "allow": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31], "allrecip": 27, "almost": [17, 25, 27], "along": 25, "alongsid": 3, "alpha": 20, "alphabet": [17, 23], "alreadi": [4, 17, 18, 22, 23, 25, 26, 27, 29, 30, 31], "also": [0, 1, 2, 3, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "alter": [1, 21], "altern": [1, 3, 18, 21, 22, 24, 26, 28, 29], "although": [3, 17, 25, 26, 29, 30], "alwai": [0, 1, 17, 21, 25, 27, 29, 31], "am": 27, "american": 5, "amnes": 13, "among": [3, 6], "amount": [1, 17, 21], "an": [0, 1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "anaconda3": [0, 17, 22, 23, 31], "analog": 5, "analys": [2, 3], "analysi": [5, 16, 24, 31], "anaphor_gender_agr": 5, "ander": 29, "anderen": 29, "andrej": 6, "ani": [0, 1, 2, 3, 5, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31], "anim": 3, "animate_subject_pass": 5, "annot": [17, 26, 28, 30, 31], "anoth": [2, 3, 5, 20, 21, 22, 23, 24, 28, 29, 30, 31], "another_tensor": 18, "answer": [0, 2, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "answer_id": 31, "answer_kei": 5, "answer_log_prob": [3, 25], "answer_opt": [0, 1, 3, 5, 29], "answer_options_list": [0, 1, 29], "answer_options_str": [0, 1], "answer_prob": 31, "answer_scor": 29, "answer_scores_bloom": 5, "answer_scores_gpt2": 5, "answerkei": [0, 1, 29], "anthrop": 26, "anticip": 17, "anymor": 21, "anyth": [0, 1, 3, 17, 20, 23, 26], "ap": 3, "apart": 19, "apect": 26, "api": [22, 27, 28], "api_wrapp": 17, "appar": 30, "appear": 3, "append": [0, 1, 3, 4, 21, 22, 23, 25, 26, 29, 31], "appet": 27, "appetizer_chain": 27, "appli": [3, 17, 18, 20, 21, 22, 23, 24, 28, 29, 31, 32], "applic": [0, 1, 4, 20, 21, 22, 23, 24, 28, 29, 30], "approach": [3, 4, 5, 6, 17, 23, 24, 25, 26, 27, 28, 29, 30], "appropi": [5, 17], "appropri": [5, 24, 29], "approxim": [17, 25, 29], "april": 17, "ar": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "arab": 21, "arang": [1, 23], "arc": 30, "architectur": [0, 1, 2, 3, 6, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31], "architecture_quirk": [0, 1], "architecture_typ": [0, 1], "archiv": 17, "area": [3, 17, 26, 30], "aren": 23, "arg": [4, 17, 22, 23], "argmax": [3, 25, 29], "argsort": 31, "arguabl": [17, 29], "argument": [0, 1, 18, 22, 23, 24, 26, 28, 29, 30], "aris": 24, "arithmet": 16, "around": [0, 1, 2, 3, 17, 19, 20, 21, 22, 23, 25, 26, 27], "arrai": [18, 20, 28, 31, 32], "arriv": [0, 1, 28, 31], "art": [0, 1, 2, 3, 6, 17, 22, 23, 25, 26], "articl": [4, 17], "arxiv": [0, 1, 3, 26, 29], "as_query_engin": 4, "ascii": [21, 23], "ascii_lett": 21, "asian": 3, "ask": [3, 4, 5, 17, 20, 22, 26, 29, 30, 31], "aspect": [3, 5, 17, 23, 25, 26, 28, 29, 31], "aspet": 5, "assert": 28, "assess": [2, 3, 5, 17, 28, 30, 31], "assign": [0, 1, 5, 6, 17, 19, 21, 23, 24, 25, 26, 29, 30, 31], "assisst": 29, "assist": [4, 11, 23, 26], "assit": 30, "associ": [3, 16, 19, 25], "assum": [0, 1, 22, 23, 24, 25], "assumpt": [29, 31], "atla": 3, "atom": 30, "attempt": [3, 28, 30], "attend": [2, 3, 22, 23, 24], "attent": [0, 1, 3, 9, 17, 20, 25, 26, 31, 32], "attention_mask": [0, 1, 3, 17, 22, 23, 24, 25], "attic": [2, 3], "attiont": 28, "attn": [23, 31], "attn_": 31, "attn_dropout": 23, "attn_weight": 31, "attribut": [6, 23, 29, 31], "attribute_target": 28, "attributed_fn": 28, "attribution_model": 28, "audio": 22, "augment": 3, "author": [5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "auto": [0, 3, 4, 17, 22, 23, 26], "autoag": 12, "autoclass": [22, 24], "autom": [22, 29], "automat": [0, 1, 4, 12, 20, 22, 23, 24, 27, 29], "automodelforcausallm": [0, 1, 3, 22, 24, 25, 26, 29, 31], "automodelforcausallmwithvaluehead": 4, "automodelforseq2seqlm": 28, "automodelforsequenceclassif": 26, "autonom": 12, "autonotebook": [0, 3, 17, 22], "autotoken": [0, 1, 3, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "auxiliari": [21, 28], "avail": [0, 1, 2, 3, 4, 5, 17, 18, 22, 25, 26, 27, 28, 29], "averag": [0, 1, 3, 5, 17, 21, 25, 29], "average_tweet_length": 17, "avers": 3, "avg": 1, "avoid": [4, 23, 24, 25, 26, 27, 31], "aw": 25, "awai": [3, 17, 23], "awak": [2, 3], "awar": [26, 30], "award": 3, "awesom": 25, "axi": [0, 32], "b": [0, 1, 3, 4, 5, 17, 18, 20, 23, 26, 28, 29], "b_1": 1, "b_2": 1, "b_3": 1, "b_4": 1, "b_f": 32, "b_i": 1, "baai": 4, "bachelor": 6, "back": [8, 18, 22, 23, 25, 31], "backbon": [4, 24, 26, 27], "backend": [0, 1, 3, 5, 17, 22, 25, 28, 29], "background": [2, 3, 4, 5, 11, 22], "backpropag": [8, 9, 28], "backward": [0, 1, 19, 20, 21, 22, 28], "bad": [17, 19, 26], "bag": [2, 3], "baggag": [2, 3], "bai": [11, 26], "balanc": 24, "bank": [3, 17], "bar": [5, 30], "barefoot": 3, "barplot": 5, "base": [0, 1, 2, 3, 4, 5, 10, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "basebal": 3, "baselin": 4, "basic": [1, 7, 17, 18, 19, 20, 21, 22, 27], "batch": [0, 1, 4, 17, 20, 22, 23, 24, 26, 28, 31], "batch_first": 23, "batch_label": 28, "batch_repr": 28, "batch_siz": [0, 1, 4, 20, 22, 28], "bay": 21, "bayesian": [10, 24], "bbq": 30, "bc": 20, "bd": 20, "bd0xbfgjkt": 17, "beam": [2, 3, 25], "beam_search_decod": 3, "bear": 30, "becam": [29, 30], "becaus": [0, 1, 3, 4, 17, 19, 20, 21, 22, 23, 24, 26, 29, 31], "becom": [19, 20, 29], "been": [3, 4, 5, 17, 22, 23, 24, 25, 26, 28, 29, 30, 31], "befor": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 26, 27, 29, 31], "begin": [1, 17, 22, 23, 25, 26, 32], "behav": 31, "behavior": [3, 4, 5, 12, 13, 20, 25, 26, 30], "behind": [17, 19, 20, 23, 26, 27, 28, 29, 31], "behvaior": 30, "being": [0, 1, 3, 4, 19, 22, 24, 25, 26, 30, 31], "beings": [3, 25], "believ": [3, 30], "belong": 22, "below": [0, 1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "bench": [29, 30], "benchmark": [3, 5, 14, 17, 25], "bender": 30, "benefici": 30, "benefit": 24, "bengio": [2, 3, 8], "berlin": 28, "bert": [2, 3, 9, 20, 22, 23, 24, 28], "bert_tok": 24, "bertmodel": 28, "berttoken": 28, "bertviz": [17, 28], "besid": [2, 3], "best": [2, 3, 4, 19, 24, 25, 26, 29], "beta": [29, 32], "better": [2, 3, 6, 17, 19, 21, 23, 27, 29], "between": [2, 3, 4, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 31], "beyond": [10, 17, 23, 29, 30], "bge": 4, "bia": [1, 5, 16, 20, 23, 26, 29, 30, 32], "bias": [17, 20, 26, 29, 30], "bias_k": 23, "bias_v": 23, "bidirect": [2, 3, 9, 24], "big": [2, 3, 29, 30], "bigger": 20, "bigram": 29, "bigscienc": 5, "billion": 27, "bin": 17, "binari": [24, 26, 29], "biologi": 30, "bird": [3, 25], "bit": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 21], "bite": 27, "bitnet": 1, "bitsandbyt": 4, "black": [3, 17], "blackbox": [22, 29, 31], "blank": 21, "bleu": 29, "bleu_scor": 29, "blimp": 5, "blob": [26, 31], "block": [4, 17, 20, 23, 26, 27, 28, 31], "blog": [1, 4, 25, 26], "blogpost": [11, 12, 16, 20, 26, 29, 30], "bloom": [1, 5], "bloom_predict": 5, "bloom_scor": 5, "bloomtokenizerfast": 31, "blue": 3, "bmatrix": [23, 32], "bnb_4bit_compute_dtyp": 26, "bnb_4bit_quant_typ": 26, "bnb_4bit_use_double_qu": 26, "bnc": 17, "bo": [1, 23, 25, 32], "bodyguard": 3, "boe": 17, "boi": [2, 3], "bommasani": 15, "bonu": 4, "book": [0, 1, 3, 6, 17], "bookstor": 3, "bool": 18, "boolean": 18, "boolq": 29, "boredom": [2, 3], "born": 5, "borrow": 21, "bot": 17, "both": [1, 3, 4, 5, 6, 17, 18, 19, 21, 22, 23, 24, 26, 29, 30], "bottl": 31, "bottleneck": 27, "bpe": [0, 1], "brake": 3, "braun": 23, "break": [3, 27], "brian": 6, "bridg": [2, 3], "brief": [0, 1, 2, 3, 5, 25], "briefcas": 3, "briefli": [2, 3, 4, 5, 23, 24, 26], "bright": [2, 3], "bring": 5, "britain": 3, "british": 17, "broad": 26, "broadli": 26, "broken": [2, 3], "brown": [3, 17, 23, 24, 28], "brows": 22, "bruckner": 21, "brun": 28, "brush": 26, "btig": 17, "bug": 4, "bui": [3, 17], "build": [2, 3, 5, 17, 18, 20, 22, 23, 25, 26, 27, 28, 29], "build_classifi": 28, "build_dataset": 4, "bullet": 26, "bullish": 17, "bye": 5, "bynd": 17, "byte": 23, "bytest": 24, "c": [0, 1, 3, 4, 5, 18, 20, 21, 23, 26, 29], "c_attn": 23, "c_fc": 23, "c_proj": 23, "cach": 31, "cacul": 1, "cage": 27, "calcul": [0, 1, 3, 4, 5, 20, 21, 23, 26, 29, 31, 32], "calculu": 20, "calibr": 29, "call": [1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "calucl": 1, "came": 5, "camera": [2, 3], "can": [0, 1, 2, 3, 4, 5, 6, 7, 10, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "candid": 19, "cannot": [2, 3, 17, 22, 23, 28, 29], "cap": 20, "capabl": [29, 30], "capac": 26, "capit": [25, 28, 31], "caption": 23, "captur": [5, 21, 24, 26], "car": 3, "carcass": [3, 22], "care": [2, 3, 4, 17, 18, 22, 27, 29, 31], "carefulli": [0, 1, 2, 3, 23, 28], "caribbean": 17, "carniv": 17, "carolina": 3, "carperai": 26, "carri": [3, 17, 23], "carrier": 3, "case": [0, 1, 3, 4, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 31], "cashier": 5, "cast": 18, "cat": [0, 1, 3, 18, 21, 22], "catastroph": 26, "categori": [0, 1, 5, 21, 24, 26, 29], "category_tensor": 21, "category_tensor_": 21, "cauliflow": 27, "caus": 5, "causal": [0, 1, 16, 22, 23, 24, 25, 28, 29, 31], "causallm": 24, "cc": 17, "ccl": 17, "cdot": [1, 29], "ce": 20, "ceil": 3, "cell": [4, 5, 17, 22, 24, 31], "celoss": 22, "cemex": 17, "center": 25, "central": 17, "ceo": 17, "certain": [5, 17, 19, 20, 23, 24, 25, 28, 29, 31], "cfg": 31, "cg": 20, "chain": [0, 1, 10, 20, 25, 27, 30], "challeng": [3, 30], "chanc": 29, "chang": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 22, 24, 25, 26, 28, 29, 30], "char": [17, 18, 32], "charact": [17, 18, 23, 24], "character": 16, "charactersitc": 0, "chat": [4, 10, 23, 26, 27], "chatgpt": 11, "chatopenai": 27, "cheat": 7, "check": [2, 3, 4, 5, 17, 18, 20, 23, 24, 25, 26, 28, 29, 30, 31], "checkpoint": [22, 29], "chek": 23, "chen": 12, "chicago": 25, "chien": 28, "childhood": 30, "children": [2, 3, 30], "chimnei": 29, "chines": 21, "chip": 17, "choic": [0, 1, 4, 5, 17, 22, 24, 25, 26, 27, 29, 30], "choir": 3, "chollet": 30, "choos": [17, 19, 21, 24, 25, 26, 29, 31], "chop": 4, "chosen": [4, 25, 26, 29], "chr": 3, "christian": 6, "chunk": [17, 29], "church": 3, "ci": 5, "circuit": 16, "cite": 4, "citi": [2, 3, 24, 25], "cl": 28, "claim": [0, 1], "class": [0, 1, 2, 3, 4, 7, 10, 11, 12, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "classic": 3, "classif": [2, 3, 11, 17, 20, 22, 24, 26, 29], "classifi": [2, 3, 21, 22, 28], "claud": 1, "claus": 5, "clean": [0, 1, 2, 3, 17, 20, 31], "clean_cach": 31, "clean_logit": 31, "clean_logit_diff": 31, "clean_prompt": 31, "clean_resid_pr": 31, "clean_token": 31, "clean_tweet": 17, "cleaned_dataset": 17, "cleaned_dataset_split": 17, "cleaned_tweet": 17, "cleanest": [3, 29], "clear": 20, "clear_output": 4, "click": [17, 18, 19, 20, 21, 22, 24, 26, 28], "clip": [20, 24], "clip_grad_value_": 20, "clone": 26, "close": [22, 24, 25, 26, 29], "closer": [20, 23, 25, 27, 30], "cloth": [2, 3], "cmd": 1, "cnn": 4, "cnn_dailymail": 4, "co": [4, 17, 23], "code": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "coeffici": [4, 5], "coffe": [2, 3], "cognit": [6, 29], "cogsci": 6, "coher": 1, "col": 18, "col_vector": 18, "colab": [0, 1, 2, 3, 4, 5, 22, 25, 26, 28], "cold": [2, 3], "collabor": 17, "collat": [4, 22], "collect": [0, 1, 3, 17, 21, 22, 26], "color": [2, 3, 20, 26, 28], "color_continuous_midpoint": 31, "color_continuous_scal": 31, "column": [0, 1, 3, 17, 21, 29], "column_nam": [17, 22, 24], "com": [21, 26, 31], "comapr": 3, "comaprison": 29, "combin": [0, 1, 3, 17, 21, 23, 24, 25, 29], "come": [2, 3, 5, 17, 21, 22, 23, 25, 26, 27, 29, 30], "comfort": 17, "comment": [0, 1, 4, 5, 17, 22, 23], "commerici": 26, "commit": 17, "common": [0, 1, 4, 17, 20, 22, 23, 24, 25, 26, 29, 30], "commonli": [4, 17, 20, 22, 23, 24, 26, 29, 30], "commonsens": [0, 1, 3, 10], "commonsense_qa": [0, 1, 29], "commonsenseqa": [0, 1, 25, 29, 30], "commonsenseqadataset": [0, 1], "commun": [22, 26, 27, 30], "commut": 1, "comp": [0, 1], "compact": 4, "compani": 29, "compar": [0, 1, 2, 3, 4, 5, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31], "comparis": [25, 27], "comparison": [0, 1, 2, 3, 26, 29, 30, 31], "compelt": 5, "competit": [2, 3], "complementari": 25, "complet": [0, 1, 3, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31], "completion_to_prompt": 4, "complex": [18, 25, 27], "complex_np_island": 5, "complic": [20, 23], "compon": [2, 3, 4, 16, 20, 23, 26, 27], "composed_chain": 27, "composed_result": 27, "composit": 30, "comprehens": [0, 1], "compulsori": 6, "comput": [0, 1, 3, 4, 6, 10, 17, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32], "compute_loss": 22, "con": 25, "concaten": [18, 25, 28], "concentr": 27, "concept": [1, 4, 6, 18, 20, 22, 23, 24, 25, 26, 30, 31], "conceptu": [0, 2, 3, 4, 5, 6, 22, 23, 24, 26, 29, 30, 31], "concern": 5, "concis": 4, "conclud": 30, "conclus": [3, 30], "concret": [2, 3, 19, 22, 23, 26, 27], "cond_prob_nam": 21, "conda": [17, 20], "condens": 20, "condit": [5, 19, 21, 29], "conditional_scor": [5, 29], "conduct": [1, 6], "confid": [5, 25, 29], "config": [4, 22, 24], "configur": [0, 1, 2, 3, 4, 22, 23, 25, 26], "configut": [0, 1], "connect": [3, 17, 20, 30, 31, 32], "consecut": [3, 21], "consent": [0, 1], "consequ": [3, 25], "consid": [0, 1, 2, 3, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "consist": [3, 4, 5, 6, 10, 17, 19, 20, 21, 22, 23, 26, 29, 31], "constitu": 17, "constitut": [20, 22, 26], "constrain": 3, "constraint": 29, "construct": [0, 1, 3, 4, 5, 18, 20, 21, 22, 25, 26, 27, 29, 30], "construct_test_sampl": [0, 1], "contain": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30], "contamin": 29, "content": [2, 3, 17, 22, 23, 26, 30], "context": [2, 3, 4, 5, 6, 10, 11, 13, 17, 18, 20, 22, 23, 24, 25, 26, 29, 30, 31], "context_input_id": [3, 25], "context_prompt": [3, 25], "context_window": 4, "contextev": 28, "contextu": [13, 23], "contextualis": 3, "continu": [3, 5, 21, 22, 24, 28, 29], "contradict": [2, 3], "contrast": [3, 5, 22, 23, 28, 29, 30], "contrast_prob_diff": 28, "contrast_target": 28, "contrastive_decod": 3, "contribut": [0, 1, 17, 23, 28, 31], "control": 27, "conv1d": 23, "conveni": [3, 20, 22], "convent": 17, "converg": [24, 26], "convers": [23, 26], "converst": [0, 1], "convert": [0, 1, 4, 17, 18, 22, 23, 28, 29], "convert_ids_to_token": 28, "cook": 26, "core": [4, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "corner": [2, 3], "coronaviru": 17, "corpor": [2, 3], "corpora": [3, 17, 29, 30], "corpu": [0, 1, 3, 17, 22, 23, 30], "correct": [0, 1, 2, 3, 23, 24, 25, 26, 27, 29, 30, 31], "correct_answ": [3, 31], "correct_index": 31, "correcti": 29, "correctli": [4, 20, 21, 22, 23, 24, 26, 29], "correl": [5, 28, 29], "correspond": [0, 1, 5, 20, 22, 23, 24, 26, 28, 29], "corrupt": 31, "corrupted_logit": 31, "corrupted_logit_diff": 31, "corrupted_prompt": 31, "corrupted_token": 31, "cosin": [20, 22, 23, 24, 26], "cosinesimilar": 20, "cost": 24, "costli": [3, 22, 26], "costum": 3, "cot": [2, 3], "cotterel": 6, "could": [1, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31], "count": [29, 30], "counterfactu": 13, "countri": [2, 3, 21], "country2idx": 21, "countrysid": 3, "cours": [0, 1, 3, 17, 22, 25, 26, 27, 31], "court": 25, "couru": 28, "courvil": 8, "cover": [6, 10, 11, 12, 17, 22, 24, 25, 29], "coverag": 29, "cow": 3, "cpu": [0, 1, 3, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "crack": 3, "craft": 21, "crawl": [17, 29], "creat": [0, 1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31], "create_react_ag": 27, "creation": 26, "creativ": [2, 3, 25], "credit": 17, "crisp": 17, "criteria": [17, 30], "criterion": [21, 28], "critic": [2, 3, 4, 6, 17, 20, 22, 28, 29, 30, 31], "cross": [24, 28], "cross_attent": 28, "crossentropi": 24, "crossentropyloss": [20, 22, 28], "crowd": [2, 3], "crucial": [3, 17, 28, 29], "csv": [0, 1, 5, 25, 29], "cuda": [0, 1, 3, 4, 5, 17, 22, 25, 26, 28, 29, 31], "cultur": 5, "cumbersom": 26, "cumul": 21, "curat": [22, 29], "curiou": [23, 25, 31], "current": [0, 1, 20, 21, 23, 26, 28, 31], "current_loss": 20, "curs": [2, 3], "curv": [0, 1], "custom": [0, 1, 4, 20, 22, 26, 28], "customiz": 17, "cut": 17, "cv": 22, "cx": 17, "cycl": 19, "czech": 21, "d": [0, 1, 3, 4, 18, 20, 21, 22, 24, 26, 29], "d83d2b": 26, "d_h": 32, "d_model": 23, "d_wide": 20, "dai": 25, "daili": 17, "danger": [2, 3], "danub": 1, "data": [0, 1, 2, 3, 4, 5, 22, 23, 24, 26, 28, 29, 30], "data_col": [4, 22, 24], "data_dir": 28, "data_pref": 28, "data_typ": 28, "databas": [4, 26], "datacollatorforlanguagemodel": [22, 24], "datafil": 21, "datafram": [3, 4, 20, 21, 22], "dataload": [0, 1, 4, 17, 20, 22], "datapoint": [21, 24], "datas": 18, "dataset": [0, 1, 4, 5, 20, 21, 22, 24, 26, 29, 30], "dataset_batch_s": 26, "dataset_df": 4, "dataset_nam": 4, "dataset_s": 17, "dataset_split": [0, 1], "datatyp": 18, "datset": 4, "daughter": [2, 3], "db": 4, "dbrx": 1, "de": [17, 20], "deactiv": [3, 21], "dead": 3, "deadli": [2, 3], "deadlin": [0, 1, 2, 3, 4, 5], "deadlock": 31, "deal": [20, 23, 29], "debat": [15, 17, 29], "debug": [25, 31], "debugg": 31, "decad": 24, "decai": 22, "decid": [3, 26], "decim": 32, "decis": 3, "declar": 18, "decod": [0, 1, 2, 3, 4, 21, 22, 23, 26, 28, 29], "decoder_attent": 28, "decoder_token": 28, "decompos": [27, 30], "decreas": [0, 20, 22, 24, 26], "decrib": 3, "dedic": [2, 3, 22], "deduct": 1, "deem": 28, "deep": [2, 3, 6, 8, 9, 17, 24], "deeper": [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20, 23, 30], "deepli": 5, "def": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "default": [0, 18, 19, 21, 22, 23, 26, 27, 28, 29, 31], "defin": [0, 1, 3, 4, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 31], "definit": [1, 17, 21, 22, 23, 25], "degre": 19, "deliber": 10, "delin": 23, "deliv": 20, "demand": 3, "demo": [27, 31], "demonstr": [10, 17, 26, 28], "den": 23, "densiti": [2, 3, 19], "denvio": 3, "depart": 3, "depedn": 26, "depend": [0, 1, 3, 17, 18, 21, 22, 23, 24, 26, 27, 28, 30], "deploi": 4, "deploy": [26, 29], "depnd": 4, "deprec": 31, "depth": 22, "der": 23, "deriv": [19, 20], "descend": 31, "descent": 19, "describ": [0, 1, 3, 4, 5, 17, 21, 22, 25, 26, 29, 30], "descript": [0, 1, 3, 4, 5, 27], "design": [20, 29], "desir": [17, 18, 23, 24, 26, 30], "desktop": 3, "dessert": 27, "dessert_chain": 27, "detach": [18, 20, 21, 31], "detail": [1, 3, 4, 17, 22, 23, 24, 25, 26, 27, 29, 30], "detect": 30, "determin": [3, 17, 18, 20, 21, 23, 24, 29], "determiner_noun_agreement_with_adjective_1": 5, "determinisit": 25, "determinist": [3, 21], "detial": 25, "develop": [0, 1, 7, 19, 21, 22, 23, 24, 26, 27, 28, 30], "deviat": 19, "devic": [0, 1, 3, 4, 5, 17, 18, 22, 25, 26, 28, 29, 31], "device_map": [4, 26], "devlin": [2, 3, 9], "df": [3, 5], "df_boolq": 29, "dh": 20, "di": [17, 27], "diagnos": 13, "diagnost": 3, "diagram": 25, "dialogu": [26, 30], "dict": [0, 1, 4, 17, 21, 28, 29], "dict_kei": 0, "dictionari": [0, 1, 21, 23], "did": [0, 1, 4, 17, 20, 22, 24, 25, 26, 31], "didn": 3, "diff": 19, "diffenrenc": 3, "differ": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "differenti": 20, "difficult": [5, 17, 20, 26, 29], "difficulti": [5, 17, 25], "dig": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 20], "digit": 17, "digraph": 20, "dim": [21, 22, 23, 31, 32], "dim_feedforward": 23, "dimens": [0, 1, 17, 18, 20, 22, 23, 24, 26], "dimensi": 3, "dimension": [2, 3, 18, 23], "dimes": 18, "ding": 11, "dinner": 27, "dinnerplan": 27, "direct": [3, 19, 20, 26], "directli": [4, 17, 18, 23, 24], "directori": [22, 28], "dirti": 3, "disabl": 31, "disadvantag": 4, "disclaim": [3, 27, 30], "discov": 26, "discret": 3, "discuss": [2, 3, 5, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "dish": 4, "displai": [3, 4], "disregard": 3, "dissect": [2, 3], "dissid": 17, "dissoci": 15, "distilbert": 26, "distinct": 26, "distinctli": 30, "distinguish": [21, 24, 29, 30], "distractor": [3, 29], "distribut": [3, 20, 21, 24, 25, 29], "div_term": 23, "dive": [4, 22, 23, 30], "diverg": [4, 24], "divers": [3, 17, 29], "diviat": 17, "divid": [3, 29, 32], "divis": [18, 21], "dm": 21, "do": [0, 1, 2, 3, 4, 5, 10, 12, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "do_sampl": [0, 1, 3, 4, 22, 25], "doc": [4, 18, 21, 22, 26, 27, 29], "docstr": [1, 17, 23], "doctor": 3, "document": [2, 3, 4, 18, 20, 21, 22, 23, 24, 25, 27, 29], "documet": 18, "doe": [0, 1, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "doesn": [3, 22, 24, 25, 26, 29, 31], "dog": [0, 1, 23, 24, 28], "domain": [22, 23, 29, 30], "don": [0, 1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27, 29, 31], "done": [17, 22, 23, 24, 25, 29, 30, 31], "door": 3, "dot": [18, 24, 28], "doubl": 28, "doubt": 22, "doveski": 21, "down": [0, 1, 2, 3, 17, 20, 23, 26, 28], "downaload": [0, 1], "download": [0, 1, 4, 5, 17, 22, 23, 24, 27, 28, 31], "downstream": 31, "draw": [3, 20, 25, 29, 30], "drawn": 18, "drawstr": [2, 3], "dream": [2, 3], "dreamwork": [2, 3], "drink": [2, 3], "drive": [2, 3], "driven": 30, "driver": 3, "drop": [17, 23, 25, 28], "dropout": [21, 23], "dropout1": 23, "dropout2": 23, "dropout3": 23, "drug": 3, "dtype": [18, 19, 23], "du": 23, "due": [5, 17, 31], "duplic": [21, 31], "dure": [0, 1, 2, 3, 4, 5, 17, 19, 21, 23, 24, 26, 29, 31], "dust": [2, 3], "dutch": 21, "duti": 3, "dv": 20, "dw": 20, "dx": 20, "dy": 20, "dynam": 22, "dz": 20, "e": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "eabl": 1, "each": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32], "ear": 21, "earli": [24, 26, 28], "earlier": [3, 26, 28], "early_stop": 3, "eas": 28, "easi": [20, 22, 29], "easier": [22, 26, 31], "easiest": 5, "easili": [17, 22, 29, 31], "east": 3, "eat": 25, "ect": 6, "edg": 20, "edit": 16, "educ": 3, "ef": 20, "effect": [17, 20, 22, 26, 29, 31], "effici": [4, 10, 11, 20, 22, 26], "effienc": 21, "eighth": 14, "either": [3, 5, 17, 24, 27, 31], "elazar": 13, "elect": 3, "electron": [3, 17], "element": [18, 21], "elementari": 30, "elementwise_affin": 23, "eleutherai": [3, 25], "elhag": 16, "elicit": [5, 10, 25, 26, 30], "elif": [0, 1, 3, 5, 17, 22, 25, 28, 29, 31, 32], "elmo": 3, "els": [0, 1, 3, 4, 5, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32], "elsewher": 21, "email": [0, 1], "emb": 23, "emb_dim": 28, "embed": [3, 4, 17, 20, 21, 23, 25, 28, 29, 30, 31, 32], "embed_dim": 23, "embed_model": 4, "emerg": 29, "emoji": [17, 23], "emphas": 3, "empir": 19, "empirical_mean": 19, "emploi": [3, 29, 30], "employ": 3, "employe": [2, 3], "empti": [21, 27], "empty_cach": 3, "en": [0, 3, 4, 17, 22, 28], "enabl": [3, 20, 23, 27], "enable_nested_tensor": 23, "enc1": 23, "enc2": 23, "enc3": 23, "encod": [3, 4, 17, 21, 22, 23, 26, 28, 29, 31], "encoder_attent": 28, "encoder_lay": 23, "encoder_token": 28, "encoding_d": 29, "encoding_en": 29, "encount": 24, "encourag": [6, 17], "end": [0, 1, 3, 4, 18, 21, 23, 24, 25, 26, 29, 30, 31, 32], "endofsequ": 23, "endors": 30, "endpoint": [25, 27, 28], "engin": [3, 4, 17, 20, 23, 24, 27, 29, 31], "english": [17, 21, 28, 29], "eniron": 26, "enrich": 17, "ensur": [3, 17, 23], "entail": [2, 3, 24], "entir": [3, 5, 17, 20, 22, 23, 24, 27], "entiti": 24, "entor": [0, 1], "entropi": 24, "enumer": [3, 4, 20, 21, 31, 32], "env": [0, 3, 17, 22, 23, 27, 31], "environ": [0, 1, 4, 17, 22, 26, 31], "eo": [1, 21, 22, 25, 32], "eos_tensor": 22, "eos_token": [0, 1, 4, 22], "eos_token_id": [3, 4, 22, 25], "eosindex": 21, "ep": 23, "epoch": [0, 1, 4, 17, 20, 22, 24, 26, 28], "epsilon": 32, "eq": 28, "equal": [18, 21, 29], "equip": [6, 17, 23, 24], "equival": [17, 25], "eras": 19, "error": [0, 1, 8, 17, 22, 26, 31], "especi": [0, 1, 3, 17, 21, 26, 29, 30], "ess": 17, "essenti": [17, 21, 22, 23, 24, 31], "establish": 17, "estat": [3, 17], "et": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 25, 26, 28, 29, 30, 31], "etc": [0, 1, 4, 17, 20, 22, 23, 24, 28, 29, 30], "ethic": [5, 30], "eval": [0, 1, 31], "eval_dataset": 22, "eval_loss": 22, "eval_step": 22, "evalu": [0, 3, 4, 6, 22, 24, 26], "evaluation_strategi": 22, "evalut": 29, "evas": 4, "even": [1, 3, 17, 18, 20, 22, 24, 26, 27, 28, 29], "eventu": 20, "everi": [0, 1, 3, 17, 20, 21, 22, 23, 24, 25, 26, 28], "everyth": 26, "evid": [5, 29], "evolv": [2, 3], "ex": [0, 2, 3, 4, 24], "ex1": 18, "ex1_col": 18, "ex1_col_tran": 18, "ex1_row": 18, "exact": 20, "exactli": [21, 22, 23, 25, 26, 27, 31], "exam": [6, 30], "exampl": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "examples_df": 25, "exce": [3, 17, 24, 25], "exceed": 25, "excel": [6, 17, 31], "except": [3, 21, 29, 31], "exclud": 22, "exclus": [20, 21], "execis": [0, 1], "execut": [0, 1, 2, 3, 4, 5, 17, 26, 27, 31], "exemplifi": [24, 29], "exercis": [17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31], "exercise1a": 18, "exercise1b": 18, "exercise2": 18, "exercise3": 18, "exerpt": 29, "exhaust": [21, 24, 25, 30], "exhibit": [5, 24, 29, 30], "exist": [3, 17, 20], "existential_there_object_rais": 5, "exot": 3, "exp": [21, 23, 25, 29, 32], "expect": [0, 1, 3, 4, 17, 21, 22, 25, 26, 27, 28, 29], "expens": 3, "experi": [6, 17, 25, 26, 27, 28], "experienc": 25, "experiment": [3, 29], "expert": 30, "explain": [2, 3, 4, 5, 20, 21, 26], "explan": [4, 5, 10, 13, 22, 26, 28, 29], "explanatori": 21, "explicit": [22, 23, 30], "explicit_train": 22, "explicitli": [3, 17, 18, 22, 31], "explor": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28], "exponenti": 3, "express": 31, "extend": [4, 17, 18, 20, 30], "extens": [3, 17, 27], "extent": 29, "extern": 17, "extract": [3, 17, 23, 24, 28], "extrem": 26, "f": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32], "f1": 29, "f1_score": 29, "f_": 29, "face": [28, 29, 30], "facebook": 26, "facet": 28, "fact": [23, 30], "facto": 17, "factor": 1, "factscor": 30, "factual": [16, 29, 30], "fail": 24, "fair": [3, 30], "fairi": 3, "faith": 30, "falcon": 1, "fals": [4, 18, 20, 21, 22, 23, 25, 26, 28, 29, 31], "false_neg": 29, "false_posit": 29, "famili": 25, "familiar": [4, 17, 18, 21, 22, 27, 28, 29, 30], "fanci": 3, "far": [17, 22, 24, 26, 30], "farm": 3, "farmland": 3, "fashion": [2, 3], "fast": [3, 25], "faul": 23, "faulti": 3, "favor": 21, "favour": 17, "favourit": 25, "fct": 17, "featur": [3, 17, 21, 27, 28], "fed": [17, 21], "feed": [20, 23, 25], "feedback": [11, 26], "feel": [0, 1, 2, 3, 5, 19, 22, 23, 25, 26], "feet": 3, "ferret": 3, "few": [0, 1, 2, 6, 7, 10, 17, 18, 21, 22, 24, 25, 26, 27, 28, 29], "few_shot": 3, "few_shot_exampl": 3, "few_shot_examples_v1": 3, "few_shot_examples_v2": 3, "few_shot_predict": 25, "few_shot_prompt": [3, 25], "few_shot_templ": [3, 25], "fewer": 26, "ffn": [31, 32], "ffnn": 31, "fg": 20, "field": [3, 5, 17, 26, 30], "fifth": 11, "fig": 5, "figur": [3, 4, 20, 21, 24, 26, 27], "file": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 27, 28, 29], "file_download": 31, "fill": [1, 3, 5, 18, 27], "filter": [17, 26], "filterwarn": [19, 20, 21], "final": [0, 1, 3, 6, 17, 19, 21, 22, 25, 26, 28, 29, 30], "final_lay": 31, "financi": 17, "find": [0, 1, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30], "fine": [3, 6, 10, 17, 22, 25, 27, 28, 29, 30], "finetun": [3, 4, 26], "finetuning_data": [0, 1], "finetuning_data_s": [0, 1], "finetuning_typ": [0, 1], "finish": [20, 23], "finit": [3, 23], "first": [0, 1, 4, 7, 8, 9, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "first_top": 31, "firt": 27, "fit": [19, 20, 22, 24, 26, 29], "five": [3, 23], "fix": [19, 21, 22, 26, 29, 31], "flan": [28, 29], "flask_serv": 31, "flatten": [18, 20], "flaw": 21, "flexibl": [20, 23], "flexibli": [18, 24], "float": [3, 18, 19, 23, 31], "float16": [4, 18, 25, 26, 31], "float32": [18, 19], "float64": [18, 19], "floattensor": 28, "floor": [3, 21], "flow": [2, 3, 20, 31], "flu": [2, 3], "fluenci": 29, "fluent": [17, 22, 29], "fnko": 17, "focu": [3, 23, 26, 29, 30], "focus": [0, 1, 6, 22, 26, 27, 29], "fold": 26, "follow": [0, 1, 2, 3, 4, 5, 11, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "fonder": 30, "food": [3, 25, 27], "footbal": [2, 3], "forc": [25, 28, 31], "force_download": 31, "forest": 3, "forget": [0, 1, 20, 22, 26], "fork": 31, "form": [0, 1, 2, 3, 4, 17, 18, 26, 29, 30], "formal": [0, 1, 23, 26, 30], "format": [0, 1, 3, 4, 5, 17, 19, 20, 21, 25, 26, 27, 28, 29], "formatt": 17, "formatting_func": 26, "formatting_prompts_func": 26, "former": [3, 24], "formul": [0, 1, 2, 3, 5], "formula": [1, 23], "forsequenceclassif": 24, "forum": [2, 3], "forward": [0, 1, 20, 21, 22, 23, 28, 31, 32], "forwat": [0, 1], "foster": 17, "found": [0, 1, 2, 3, 4, 5, 6, 7, 12, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29], "foundat": [10, 15, 17, 30], "four": [0, 1, 3, 25], "fourth": 10, "fox": [3, 23, 24, 32], "fp16": 22, "frac": [1, 24, 25, 26, 28, 29], "fraction": 28, "framework": [3, 12, 16, 25, 26, 27], "franc": [28, 31], "frank": [6, 18, 19, 20, 21, 25], "free": [0, 1, 2, 3, 5, 17, 22, 23, 25, 26, 29], "freeli": 22, "freez": [26, 31], "french": [21, 28], "freq_of_first_el": 23, "freq_of_pair": 23, "freq_of_second_el": 23, "frequenc": 23, "frequent": [17, 18, 22, 23], "fresh": 21, "freuqenc": 23, "fri": 6, "fridai": 17, "fridg": 27, "friendli": 23, "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "from_dict": 21, "from_docu": 4, "from_pretrain": [0, 1, 3, 4, 17, 22, 23, 24, 25, 26, 28, 29, 31], "front": [0, 1, 3], "frown": 3, "frozen": [22, 26, 29], "ftfy": 28, "fuch": 23, "fulfil": 26, "full": [3, 4, 17, 18, 20, 23, 24, 25, 28, 31], "full_prompt": 25, "fuller": 29, "fulli": [17, 22, 28], "fun": [0, 1, 2, 3], "function": [0, 1, 3, 4, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31], "functool": 31, "funko": 17, "further": [0, 1, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 31], "furthermor": [2, 3, 5, 17, 20, 21, 28, 29, 30, 31], "futur": [3, 22, 25, 26], "futurewarn": 31, "fwd_hook": 31, "fyi": 17, "g": [0, 1, 3, 4, 5, 6, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "gain": [2, 3, 17, 24, 26, 28], "game": [2, 3], "gamma": 32, "gao": [17, 26], "garbag": [2, 3, 26], "gaussian": [19, 20], "gave": 31, "gavin124": 4, "gc": 3, "ge": 20, "gebru": 17, "gelu": 20, "gemini": 1, "gemma": 1, "gender": [16, 30], "gener": [0, 1, 5, 6, 7, 8, 9, 10, 12, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "generate_kwarg": 4, "generated_text": 28, "generation_kwarg": 4, "ger": 5, "german": [0, 1, 2, 3, 4, 5, 21, 23, 29], "germani": 5, "get": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "get_act_nam": 31, "get_activ": 31, "get_cont": 4, "get_data": 28, "get_devic": 31, "get_lay": 31, "get_layers_w_attn": 31, "get_model_and_token": 28, "get_past_lay": 31, "get_pos_data": 28, "get_pre_wo_activ": 31, "get_prob": 21, "get_sentence_repr": 28, "get_surprisal_dataset": 21, "get_surprisal_item": 21, "getpass": 27, "giagant": 26, "giant": [3, 14], "git": 17, "github": [17, 26, 31], "githubusercont": 21, "give": [2, 3, 4, 17, 18, 25, 26, 27, 28, 31], "given": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "glare": [2, 3], "glimps": 17, "glue": 29, "go": [0, 1, 3, 4, 17, 18, 19, 22, 23, 25, 26, 29, 30], "goal": [0, 1, 4, 17, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "goal_fun": 20, "goe": [3, 21, 26, 29], "gold": [2, 3, 4, 17, 20, 21, 29], "gone": 19, "good": [2, 3, 4, 5, 17, 19, 21, 22, 25, 26, 27, 29, 30], "goodfellow": 8, "googl": [3, 17, 28, 29], "got": [30, 31], "govern": [2, 3], "gp": 3, "gpt": [2, 3, 4, 5, 6, 9, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "gpt2": [0, 1, 4, 5, 17, 22, 23, 24, 26, 28, 29, 31], "gpt2_lm": 23, "gpt2_model": 26, "gpt2_predict": 5, "gpt2_scorer": 5, "gpt2attent": 23, "gpt2block": 23, "gpt2doubleheadsmodel": 24, "gpt2forsequenceclassif": 24, "gpt2fortokenclassif": 24, "gpt2lmheadmodel": [0, 22, 23, 24], "gpt2mlp": 23, "gpt2model": 23, "gpt2token": [0, 22], "gpt2wrapper": 31, "gpt35": [0, 1], "gpt_metaphor_result": 29, "gpu": [0, 1, 2, 3, 4, 5, 17, 18, 22, 25, 31], "grad": [19, 26], "grad_fn": [1, 19], "grade": [0, 1], "gradient": [0, 1, 20, 21, 24, 26, 28], "gradient_accumulation_step": 22, "gram": 17, "gramamt": [5, 17], "grammar": 29, "grammat": 29, "grammatical_log_prob": 29, "grammatical_sent": 29, "grammaticality_df": 29, "grammaticality_predict": 29, "grammaticality_test": 29, "graph": 21, "graphic": [0, 1], "graphviz": 20, "great": [0, 1, 3, 17, 20, 29], "greedi": [3, 21, 22, 25], "greedy_decod": 3, "greek": 21, "green": 3, "greet": 5, "grid": 24, "grin": 3, "grok": 1, "ground": [0, 1, 2, 3, 4, 12, 20, 26, 29], "group": 6, "grow": 30, "gru": 20, "grucel": 20, "gsm8k": 30, "gt": 3, "guess": [20, 21, 22, 24], "guid": [5, 17, 22, 31], "guidelin": 17, "h": [20, 23, 26, 31], "h1": 20, "h2": 20, "h2o": 1, "h3": 20, "ha": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "habitat": 3, "had": [2, 3, 26], "hallmark": 30, "hamburg": 3, "hand": [3, 4, 6, 17, 21, 25, 27, 28], "handi": 17, "handl": [20, 21, 22], "happen": [0, 1, 3, 21, 22, 27, 29], "happi": 3, "hardwar": 3, "harm": [26, 30], "harmless": [4, 11, 26, 30], "harmon": 29, "haskel": 17, "hasn": 30, "hat": 3, "have": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "haven": [4, 26], "haystack": 27, "he": [2, 3, 24], "head": [2, 3, 4, 5, 18, 22, 26, 28, 29], "head_and_tail": 18, "head_dim": 23, "head_view": 28, "headscarf": 3, "heard": [17, 29], "heart": 30, "heavi": [4, 22, 27, 30], "heavili": 22, "heck": 4, "height": 3, "heimersheim": 16, "held": [17, 24], "hellaswag": 30, "hello": [5, 18], "hello_tensor": 18, "helm": 14, "help": [4, 11, 17, 20, 24, 25, 26, 27, 28, 29, 30, 31], "helper": [0, 1, 22, 24, 29, 31], "henc": 3, "her": 3, "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "heurist": 13, "hf": [0, 1, 2, 3, 4, 20, 22, 23, 24, 25, 27, 28], "hi": [2, 3, 23, 25], "hidden": [0, 1, 20, 21, 24, 31], "hidden1": 1, "hidden2": 1, "hidden3": 1, "hidden_neuron": 1, "hidden_s": [21, 28], "hidden_st": [28, 31], "hide": [17, 23], "hierarchi": 3, "high": [2, 3, 4, 17, 18, 22, 24, 25, 26, 28, 29, 30], "higher": [3, 5, 17, 18, 19, 21, 23, 24, 26, 30, 31], "highest": [3, 5, 25, 29], "highlevel": 22, "highli": [6, 26], "highlight": [22, 30], "highwai": 3, "him": 3, "hint": [0, 1, 4, 5, 17, 20, 22, 23, 24, 25, 29, 30], "hire": 3, "hist": 17, "histogram": 17, "histori": [22, 30], "hit": 17, "hoc": 28, "hochreit": 9, "hold": [3, 5], "holist": [14, 19, 20], "home": 3, "homework": [6, 17, 26, 29], "honest": [26, 30], "honesti": 30, "hood": [17, 22, 23, 24, 28], "hook": [28, 31], "hookedtransform": 31, "hookpoint": 31, "hors": [2, 3, 20], "host": [6, 22], "hot": [21, 23, 32], "hour": 25, "hous": [2, 3, 29], "how": [0, 1, 2, 3, 4, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "howard": 11, "howev": [1, 3, 4, 17, 19, 20, 22, 23, 24, 26, 29, 30], "html": [0, 3, 17, 18, 22, 28], "http": [0, 1, 3, 4, 17, 18, 21, 22, 26, 28, 29, 31], "httpstcobdxbfgjkt": 17, "httpstcogymzyzi": 17, "httpstcoyfehvc": 17, "httpstcozzaplmfa": 17, "hu": 29, "hub": [22, 27], "hue": 20, "hug": 28, "huggingfac": [0, 1, 4, 11, 17, 23, 26, 27, 28, 31], "huggingface_hub": [4, 31], "huggingface_model_id": [0, 1], "huggingfaceembed": 4, "huggingfaceendpoint": 27, "huggingfacehub_api_token": 27, "huggingfacellm": 4, "human": [3, 4, 11, 12, 17, 22, 23, 25, 26, 27, 28, 29, 30], "human_metaphor": 29, "humanev": 30, "hund": 23, "hungarian": 17, "hungri": 22, "hutch": 3, "hw": 29, "hw1": [24, 29], "hw1_model2group_assign": [0, 1], "hw2": 29, "hwchase17": 27, "hyperparam": [0, 1], "hyperparamet": [3, 17, 24, 26, 27], "hypothes": [16, 29], "hypothesi": [3, 5], "i": [0, 1, 2, 3, 4, 5, 6, 9, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "i2h": 21, "i2o": 21, "ic": 3, "icon": 17, "id": [3, 17, 22, 23, 24, 25, 28, 29, 31], "id_var": 20, "idea": [0, 1, 3, 5, 17, 20, 21, 24, 25, 26, 27, 28, 29, 31], "ideal": [17, 20, 22, 23, 24, 26, 29], "ident": 19, "identif": [16, 31], "identifi": [3, 23, 24, 26, 28, 29, 30, 31], "idx": [0, 1, 3, 20, 23], "ignor": [3, 19, 20, 21, 25], "illeg": [2, 3], "illinoi": 3, "illustr": 24, "imag": [4, 17, 22, 23, 24], "imagenet": 22, "imagin": [2, 3], "imbal": 5, "imdb": [22, 24, 26], "imdb_gpt2": 22, "imdbtrain": 22, "immedi": 17, "impact": 29, "implement": [0, 1, 2, 3, 4, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "impli": 3, "implic": 5, "implicit": [10, 22], "implicitli": [18, 20, 26], "import": [0, 1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "importantli": [0, 1, 26, 29], "imposs": 26, "impress": [17, 26, 29], "improv": [0, 1, 3, 4, 10, 17, 20, 21, 22, 25], "imshow": 31, "in_": 31, "in_featur": 23, "in_proj_bia": 23, "in_proj_weight": 23, "in_sln": 31, "in_sln_": 31, "inappropri": 5, "incld": 22, "includ": [2, 3, 4, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "inclus": 21, "incom": 23, "incompat": 28, "inconsist": [25, 30], "incorpor": 29, "incorrect": [1, 28, 29, 31], "incorrect_answ": 31, "incorrect_index": 31, "increas": [2, 3, 19, 21, 23, 24, 29], "increasingli": [4, 30], "incrementallmscor": [5, 29], "inde": 30, "indent": 17, "independ": 3, "index": [0, 1, 3, 4, 17, 20, 21, 23, 24, 29, 31], "indic": [0, 1, 3, 5, 21, 22, 23, 25, 26, 28, 29, 30], "indirect": [16, 31], "individu": [0, 1, 2, 3, 4, 5, 28], "inf": [3, 32], "infer": [2, 4, 10, 13, 19, 22, 23, 25, 27, 29], "infix": 18, "inflat": 29, "influenc": [3, 5, 19], "influenti": 29, "info": 4, "infor": 17, "inform": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "infrastructur": [17, 22], "ing": [19, 23], "ingredi": [4, 27], "inherit": [17, 20], "init": [0, 1, 23], "init_hidden": 21, "init_weight": 28, "initi": [0, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29], "initial_sequ": 21, "initialis": 18, "initialize": 24, "inject": [23, 31], "injur": 5, "innat": 29, "inner": [1, 17], "innov": 26, "inoffici": 25, "inp_id": 31, "inpid": 31, "inplac": 23, "inpsect": 4, "input": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "input_combin": 21, "input_dim": 28, "input_emb": 23, "input_id": [0, 1, 3, 4, 17, 22, 23, 24, 25, 28, 29, 31], "input_ids_instruct": 26, "input_ids_lm": 26, "input_line_tensor": 21, "input_neg": 26, "input_neuron": 1, "input_po": 26, "input_s": 21, "input_tensor": 21, "input_text": [0, 1, 3, 22, 24, 25, 28], "input_token": [28, 29], "input_vari": 27, "ins": 4, "inscrut": 31, "inseq": 28, "insert": [4, 5, 27], "insid": [22, 23], "insight": [17, 28, 29], "inspect": [0, 1, 3, 4, 5, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31], "inspir": [2, 3, 5, 21, 22, 23, 25, 26, 27, 29], "instal": [0, 1, 4, 18, 20, 22, 26, 27, 28, 29, 31], "instanc": [5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "instanti": [0, 1, 19, 20, 21, 22, 23, 24, 27], "instati": [20, 22], "instead": [3, 17, 20, 22, 24, 26, 27, 28, 29, 31], "institut": [2, 3], "instruct": [0, 1, 2, 3, 4, 11, 17, 18, 26, 27, 28, 29], "instruction_text": 26, "instructions_menu_summari": 27, "instructions_prompt": 3, "instructions_text_appet": 27, "instructions_text_dessert": 27, "instructions_text_main": 27, "int": [0, 1, 17, 18], "int64": 18, "intang": 17, "integ": [18, 23], "integr": [1, 17, 20, 25, 26, 27, 28], "integrated_gradi": 28, "intellig": 30, "intend": [17, 19, 24, 26, 27, 30], "intens": 30, "intent": 3, "inter": 17, "interact": [2, 3, 12, 28], "intercept": 20, "interchang": [17, 25, 26], "interconnect": 5, "interdisciplinari": 6, "interest": [1, 4, 6, 19, 27, 28, 29, 30], "interestingli": 30, "interfac": [4, 20, 22, 27], "intermedi": [0, 1, 10, 29, 30, 31], "intermediate_residual_": 31, "intern": 17, "internet": [3, 17, 29], "interpret": [0, 1, 4, 5, 6, 21, 28, 29, 30], "intersect": 29, "interv": [5, 18], "interven": 31, "intervent": 31, "intric": 30, "intro": [2, 3, 4], "introduc": [0, 1, 2, 3, 6, 8, 9, 10, 17, 18, 19, 21, 23, 24, 25, 26, 29, 30], "introduct": [3, 6, 17, 23, 25], "intuit": [2, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 30], "intuititv": 5, "invers": 20, "investig": [0, 1, 5, 21, 29], "invok": 27, "involv": [1, 3, 17, 23], "io": [0, 3, 4, 17, 22], "ioi": 31, "ioi_patching_result": 31, "iprogress": [0, 3, 17, 22], "ipynb": [0, 1, 2, 3, 4, 5], "ipython": [1, 4], "ipywidget": [0, 3, 17, 22, 28], "irish": 21, "iron": 30, "irrelev": 3, "is_avail": [0, 1, 3, 4, 5, 17, 22, 25, 26, 28, 29, 31], "is_correct": 29, "is_grammat": 29, "is_top_at_end": 31, "is_tru": 29, "isalpha": 17, "isdigit": 32, "ish": 31, "island": 3, "isol": [5, 29], "isspac": 17, "issu": [4, 17, 24, 27, 29, 30], "itali": 25, "italian": [21, 25, 27], "italien": 27, "item": [0, 1, 3, 5, 18, 19, 20, 21, 23, 25, 28, 29, 31], "item_id": 29, "item_surpr": 21, "itemnum": 29, "iter": [0, 1, 3, 5, 17, 19, 20, 21, 25, 26, 29], "iterrow": [3, 4, 29], "ith": [3, 29], "its": [0, 1, 2, 3, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "itself": [19, 21, 26, 27], "ivestig": 3, "j": [0, 1, 17, 29], "jackson": 21, "jaffrai": 17, "jamba": 1, "jame": 3, "japanes": 21, "jetmo": 1, "jewelri": [2, 3], "jo": 17, "job": [0, 1, 3, 4, 17, 20, 25, 29], "john": 31, "join": [0, 1, 3, 17, 25, 28, 29], "joint": 3, "joke": 1, "joyou": 3, "jpg": 0, "jpmorgan": 17, "json": [0, 1, 21, 31], "judgement": 17, "juic": [2, 3], "juli": 5, "jump": [2, 3, 23, 24, 32], "june": [2, 3, 4], "jupyt": [0, 3, 17, 22], "jurafski": 7, "just": [0, 1, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 31], "justext": 17, "justif": 5, "justifi": 28, "k": [3, 18, 21, 23, 25, 31, 32], "k_proj_weight": 23, "k_q": 25, "k_x": 32, "kadavath": 29, "kaplan": 7, "karab": 3, "karahan": 3, "karpathi": 6, "kdeplot": 19, "kdim": 23, "keep": [3, 17, 19, 21, 22, 25, 26], "kei": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 26, 27, 28, 31, 32], "kept": 26, "kernel": [0, 1, 22], "kid": 3, "kill": 3, "kind": [0, 1, 2, 3, 4, 17, 20, 22, 23, 24, 25, 26, 28], "kindli": 17, "kl": 4, "kn1g4awfib": 17, "know": [3, 5, 17, 19, 20, 22, 23, 25, 26, 27, 28, 30, 31], "knowledg": [1, 5, 6, 10, 25, 26, 28, 29], "knowledge_exampl": 25, "knowledge_examples_chain": 25, "knowledge_examples_chain_incorrect": 25, "knowledge_stat": [3, 25], "known": [5, 17, 19, 22, 23, 26, 28, 29], "kojima": 10, "korean": 21, "krakauer": 15, "kwarg": [27, 31], "l": [21, 26, 28, 31, 32], "l57": 31, "lab": 6, "label": [0, 1, 2, 3, 4, 17, 20, 21, 22, 24, 25, 26, 28, 29, 31], "label2index": 28, "ladi": [2, 3], "lambada": 30, "lambd": 31, "lambda": [0, 1, 17, 29], "lambdalay": 31, "lampinen": 10, "langaug": [2, 3], "langchain": [17, 25], "langchain_commun": [17, 27], "langchain_cor": 27, "langchain_openai": 27, "langchainhub": 27, "languag": [2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30], "larg": [0, 1, 3, 6, 10, 11, 15, 17, 22, 23, 24, 26, 27, 28, 29, 30, 31], "larger": [3, 5, 17, 18, 27, 28, 29], "last": [1, 5, 17, 19, 20, 21, 22, 24, 26, 28, 29, 30, 31], "last_past": 31, "lastli": 24, "later": [4, 20, 21, 31], "latest": [0, 1, 28], "latg": 29, "latter": [17, 22, 24, 27, 28, 30], "laugh": 3, "law": [7, 21, 26, 30], "lawsuit": 17, "layer": [0, 1, 21, 22, 23, 24, 26, 28, 31, 32], "layer_decod": 31, "layer_logit": 31, "layer_past": 31, "layer_residual_": 31, "layernorm": 23, "layers_to_unfreez": 26, "layout": 29, "lazi": [23, 24], "ldquo": 26, "le": 28, "lead": [2, 3, 21, 25, 26, 29, 31], "leader": [2, 3], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "learnabl": 29, "learner": 9, "learning_r": [4, 19, 21, 22], "learnt": 3, "least": [18, 22, 25, 26, 27], "leav": 21, "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "led": 26, "left": [0, 1, 3, 4, 22, 23, 27], "leg": 25, "legend": [1, 22], "len": [0, 1, 3, 16, 17, 20, 21, 25, 26, 28, 29, 31], "lend": 26, "lenght": 17, "length": [0, 1, 5, 17, 18, 20, 21, 23, 25, 26, 29], "lens": 5, "less": [18, 20, 23, 25], "lesson": 17, "let": [0, 1, 2, 3, 4, 17, 18, 19, 21, 23, 24, 26, 27, 29], "letter": [21, 23], "letter_index": 21, "level": [22, 23, 24, 28, 30], "levi": 29, "lharri": 17, "li": [21, 29], "liang": 6, "lib": [0, 3, 17, 22, 23, 31], "librari": [2, 3, 4, 18, 23, 26, 31], "liek": 3, "light": [28, 29], "like": [0, 1, 2, 3, 4, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "likelihood": [1, 19, 21, 29], "limb": [3, 25], "limit": [3, 17, 21, 23, 25, 27, 29, 30], "line": [0, 1, 4, 17, 20, 21, 22, 23, 24, 28], "linear": [0, 1, 21, 23, 24, 28, 31], "linear1": [20, 23], "linear2": [20, 23], "linear3": 20, "linear4": 20, "lineplot": 20, "ling": 17, "linguist": [5, 6, 17, 28, 29, 30], "lingusit": 17, "link": [0, 1, 4, 5, 27], "linspac": 20, "list": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31], "list_decod": 31, "liter": 29, "literari": 17, "literatur": [2, 3, 17], "littl": [25, 27], "liu": [10, 25], "live": 29, "ll": 28, "llama": [1, 2, 3, 4, 6, 10, 17, 22, 23, 26, 30], "llama_index": 4, "llamaindex": 4, "llm": [2, 3, 7, 17, 24, 26, 29, 30, 31], "llm_hf": 27, "llok": 25, "lm": [0, 1, 4, 5, 6, 14, 17, 23, 24, 25, 26, 28, 29, 30, 31], "lm_head": [23, 31], "lm_scorer": [5, 29], "lmhead": 24, "lmql": 27, "ln_1": [23, 31], "ln_2": [23, 31], "ln_f": [23, 26, 31], "lnaguag": 14, "load": [0, 1, 2, 3, 4, 5, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 31], "load_dataset": [0, 1, 4, 5, 17, 22, 24, 26, 29], "load_dotenv": 27, "load_gpt2": 31, "load_in_4bit": 26, "load_in_8bit": 4, "load_model": 28, "load_tool": 27, "loader": [0, 1], "loc": [3, 19, 20, 25], "local": [0, 1, 18, 21, 22, 25, 26, 27, 28, 31], "locat": [16, 18, 19, 24, 25, 28], "log": [0, 1, 3, 4, 5, 21, 22, 23, 25, 26, 29, 31], "log_histori": 22, "log_p": [3, 25], "log_prob": [19, 21], "log_probs_for_a": 3, "log_stat": 4, "logging_step": 22, "logic": 30, "logit": [16, 22, 24, 31, 32], "logits_to_logit_diff": 31, "logp_": 1, "logsoftmax": [20, 21], "logspac": 21, "lone": 3, "long": [0, 1, 3, 4, 9, 17, 22, 24, 25, 28, 29, 30], "longer": [3, 19, 23, 26, 29], "longtensor": 21, "look": [0, 1, 3, 4, 5, 6, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "loop": [0, 1, 4, 20, 21, 22, 24, 27], "lora": 26, "loss": [0, 1, 3, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29], "loss_funct": 20, "lot": [3, 4, 17, 25, 26], "love": 5, "low": [25, 26], "lower": [3, 17, 19, 21, 23, 25, 26], "lowest": 29, "lr": [0, 1, 19, 20, 21], "lr_scheduler_typ": 22, "lstm": 24, "luckili": [20, 22, 24], "luggag": 3, "lvwerra": 26, "ly": 18, "m": [0, 1, 3, 18, 21, 23, 25, 28], "m1": 17, "m3hrdadfi": 4, "m_1": [0, 1], "m_2": 1, "m_3": 1, "m_4": 1, "m_coef": 31, "m_i": 1, "m_out": 32, "mac": 17, "machin": [17, 18, 20, 22, 24, 26, 30], "made": [2, 3, 17, 19, 20, 22], "magazin": 3, "magnitud": [20, 28], "mahowald": 15, "mai": [0, 1, 3, 4, 5, 19, 23, 25, 27, 29], "main": [0, 1, 3, 4, 5, 19, 20, 21, 26, 27, 30], "main_chain": 27, "main_cours": 27, "mainli": [17, 20], "major": [3, 17], "majority_vot": 3, "make": [0, 1, 3, 4, 5, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "make_df": 21, "male": 3, "mall": 3, "mamba": 1, "man": [2, 3], "manag": [5, 21], "mani": [0, 1, 3, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "manipul": [5, 18], "manner": 17, "manual": [3, 19, 20, 22, 23], "manual_se": 3, "map": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 28, 29, 31], "mari": [29, 31], "market": 3, "markup": 17, "martin": 7, "mask": [0, 1, 3, 17, 22, 25, 28, 29], "masked_label": [3, 25], "mass": 3, "massag": [0, 1, 17, 19, 22], "massage_input_text": [0, 1, 29], "massaged_dataset": [0, 1], "massaged_dataset_v": 29, "master": 6, "match": [1, 2, 3, 4, 5, 17, 21, 23, 28, 29], "materi": 17, "math": [20, 21, 23, 29, 30], "mathbb": 26, "mathc": 29, "mathemat": [0, 1, 7, 16, 18, 23, 30], "matmul": [18, 31], "matplotlib": [0, 1, 17, 19, 20, 21, 22], "matric": [0, 1, 18, 20, 22, 23, 26], "matrix": [0, 1, 17, 21, 23, 26, 31, 32], "matrix1": 18, "matrix2": 18, "matrixprod": 18, "matriz": 1, "matter": 3, "max": [2, 3, 23, 24, 25, 28], "max_len": 23, "max_length": [0, 1, 4, 21, 22, 24], "max_new_token": [0, 1, 3, 4, 25, 27], "max_ord": 29, "max_prob": 3, "max_prob_idx": [3, 25], "max_seq_length": 26, "max_token": 27, "maxim": [0, 2, 3, 4, 5, 17, 19, 22, 24, 25, 26], "maximizing_answ": 3, "maximizing_log_prob": 3, "maximum": [3, 19, 26], "mayb": [1, 22, 26, 31], "mccoi": 13, "mcdonnel": 10, "mcyftsxc2n": 17, "mdoel": 31, "mdp": 26, "me": [1, 27], "mean": [3, 4, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 32], "meaning": 31, "meant": [3, 17, 19], "measur": [3, 4, 5, 19, 23, 29], "meat": 17, "mechan": [16, 22, 26, 28, 31], "mechanist": 6, "mediat": 16, "medic": 26, "medicin": 3, "medium": 31, "meet": 30, "mega002": 31, "meinung": 29, "meister": 25, "melt": 20, "memor": 24, "memori": [0, 4, 9, 17, 18, 21], "men": 3, "meng": 16, "mention": [3, 4, 7, 10, 16, 23, 24, 25, 28, 29, 30], "menu": 27, "merg": 23, "merullo": [16, 31], "messag": [19, 27], "meta": 23, "metaphor": 29, "metaphor_results_gpt": 29, "metaphor_results_human": 29, "meteor": 29, "method": [0, 1, 3, 4, 6, 16, 17, 20, 22, 26, 29, 30, 31], "methodolog": [26, 29], "methodologi": 3, "metric": [4, 5, 21, 22, 30, 31], "michael": [6, 18, 19, 20, 21, 25], "microsoft": [4, 26, 27], "mid": [21, 25, 29], "mid_attn_": 31, "middl": [2, 3, 23, 24], "midwest": 3, "might": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "mikolov": 7, "militari": [2, 3], "milk": 31, "million": [3, 24, 26], "min": [10, 24], "min_length": 4, "mind": [17, 26, 27, 29], "mini": [4, 20, 26], "mini_batch_s": 4, "minicon": [5, 29], "minim": [0, 1, 5, 17, 19, 20, 23, 27, 30], "minimum": [24, 26], "minist": 5, "minor": 1, "minut": 21, "mismatch": 5, "misrepresent": 17, "miss": [17, 30], "mistak": [1, 25], "mistral": [1, 27], "mistralai": 27, "mitchel": 15, "mix": [17, 18], "mix2": 18, "mix3": 18, "mix4": 18, "mix5": 18, "mix6": 18, "mix7": 18, "mix8": 18, "mixtral": 1, "mixtur": [0, 1, 17], "ml": [17, 30], "mll": 5, "mlm": 22, "mlm_probabl": 24, "mlp": [23, 31], "mlp_": 31, "mlp_19": 31, "mlp_condens": 20, "mlp_explicit": 20, "mlpcondens": 20, "mlpexplicit": 20, "mmlu": [29, 30], "mode": [0, 1, 4, 26, 29], "model": [2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 23, 25, 27, 28, 29, 30, 31], "model_": 29, "model_instruct": 26, "model_kwarg": 4, "model_lm": 26, "model_nam": [0, 1, 4, 28], "model_s": [0, 1], "model_t5": [28, 29], "model_typ": 23, "model_view": 28, "model_xl": 29, "modelout": 22, "modelwrapp": 31, "modern": [2, 3, 27, 29], "modifi": [5, 17, 18, 27], "modul": [1, 21, 23, 28, 31], "module_guid": 4, "modulelist": 23, "modulenotfounderror": 1, "moe": 1, "moment": [3, 25, 26], "monitor": [0, 1, 17, 21], "monolingu": 5, "moodl": [0, 1, 2, 3, 4, 5], "moral": 30, "more": [2, 3, 4, 5, 6, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "morgan": 17, "morphologi": 5, "mortuari": 3, "most": [1, 3, 5, 17, 21, 22, 23, 25, 26, 29, 30], "mostli": [5, 17, 20, 22, 24, 26, 30], "motiv": [28, 29], "mous": [0, 1], "mouth": 3, "move": [0, 1, 29, 31], "movi": [4, 22, 26], "mp": [0, 1, 3, 5, 17, 22, 25, 28, 29], "mrr": 31, "mse": 24, "mseloss": 20, "mtx": 32, "much": [3, 17, 18, 20, 22, 23, 25, 26, 28, 29, 31], "multi": [17, 20, 30], "multihead_attn": 23, "multiheadattent": 23, "multilanguag": 17, "multilingu": [1, 5], "multimod": 1, "multipl": [1, 5, 17, 20, 23, 24, 25, 29, 30], "multipli": [1, 17, 18, 24, 32], "multitask": 9, "mupltipli": 1, "must": [17, 19, 20, 23, 25, 30], "my": [17, 25, 27], "m\u00fcll": 21, "m\u00fcller": 21, "n": [1, 3, 4, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 32], "n_": 1, "n_categori": 21, "n_hidden": 20, "n_input": 20, "n_item": 21, "n_iter": 21, "n_layer": 31, "n_letter": 21, "n_name": 21, "n_ob": [19, 20], "n_output": 20, "n_train_step": 20, "n_training_step": 19, "naiv": 26, "name": [0, 1, 2, 3, 4, 5, 6, 17, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32], "named_paramet": 26, "names_data": 21, "nanda": 16, "nanswer": [0, 1], "nappet": 27, "nation": 17, "nativ": [22, 31], "natur": [2, 4, 13, 17, 22, 25, 26, 29, 31], "naturalqa": 30, "navig": [0, 1, 2, 3, 4, 5, 17], "nb": [17, 18, 19, 20, 22], "ndessert": 27, "neat": 27, "neatli": 20, "necess": [23, 27], "necessari": [23, 26, 27, 31], "necessarili": [0, 1, 19, 26], "need": [0, 1, 2, 3, 4, 9, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "neg": [1, 19, 21, 24, 26, 29], "negative_sent": 26, "negbackward0": 19, "ner": 24, "net": [20, 21, 22, 23], "network": [0, 1, 3, 6, 8, 9, 20, 22, 23, 24, 27, 28], "neural": [0, 1, 6, 7, 8, 9, 16, 20, 21, 22, 23, 24], "neural_pragmatic_nlg": 21, "neuron": [0, 1, 28], "neutral": [2, 3, 17, 24, 25], "never": [17, 21], "new": [0, 1, 3, 4, 17, 18, 21, 22, 23, 26, 31], "new_tensor": 18, "newer": 29, "newgeluactiv": 23, "newli": 22, "next": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "nf": 23, "nf4": 26, "nhead": 23, "nhid": 23, "nice": [22, 23], "nightmar": [2, 3], "ninp": 23, "ninth": 15, "nlayer": 23, "nlg": [6, 25, 29], "nll": 29, "nllloss": 21, "nlp": [0, 1, 2, 3, 6, 7, 16, 17, 22, 24, 29], "nmain": 27, "nmean": 21, "nn": [21, 22, 23, 24, 28, 31], "no_grad": [0, 1, 21, 28], "no_knowledge_stat": 3, "noce": 25, "node": [4, 20, 24], "nois": 20, "nomura": 17, "non": [17, 21, 24, 25, 28], "nondynamicallyquantizablelinear": 23, "none": [0, 1, 3, 19, 20, 23, 24, 31], "nonetheless": [1, 3, 17, 27], "nonlinearregressiondata": 20, "nonliter": 29, "nonsens": [5, 26], "noodl": 4, "noption": 3, "norm": [23, 31], "norm1": 23, "norm2": 23, "norm3": 23, "normal": [19, 20, 23, 24, 31], "normalis": 32, "north": 3, "notabl": 20, "notat": [7, 18], "note": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "notebook": [0, 1, 5, 17, 19, 21, 22, 26, 28, 31], "notebook_tqdm": [0, 3, 17, 22], "notic": [18, 19, 21, 25], "notion": [17, 21], "noun": [5, 26], "now": [3, 19, 20, 21, 23, 24, 26, 28, 29, 30], "nowadai": 17, "np": [0, 1, 3, 18, 20, 21, 25, 28, 29, 31, 32], "np_arrai": 18, "np_array_to_tensor": 18, "np_conv": 32, "npi_present_1": 5, "npleas": 27, "npnlg": 21, "nquestion": 3, "nselect": 3, "ntoken": 23, "nuber": 24, "nucleu": 3, "nudg": 26, "num": [0, 1, 20, 31], "num_beam": 3, "num_class": 22, "num_correct": 28, "num_decoder_lay": 23, "num_encoder_lay": 23, "num_epoch": 28, "num_head": 23, "num_label": 28, "num_lay": [28, 31], "num_posit": 31, "num_process": 4, "num_test_step": [0, 1], "num_token": 31, "num_tot": 28, "num_train_epoch": 22, "num_word": 28, "number": [0, 1, 3, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29], "number_training_token": [0, 1], "numel": [0, 1, 26], "numer": [3, 17, 18, 19, 23, 26], "numpi": [0, 1, 3, 18, 20, 21, 25, 28, 29, 31, 32], "numpydoc": 17, "nwhich": 27, "nye": 10, "nyu": 5, "o": [4, 20, 21, 27, 28, 29, 30, 32], "o2o": 21, "o_citi": 31, "object": [0, 4, 5, 16, 17, 18, 19, 20, 21, 22, 24, 26, 31], "obscur": 28, "observ": [3, 4, 5, 20, 24, 25, 27, 28, 31], "obtain": [3, 17, 18, 19, 21, 25, 26, 30], "obviou": 18, "obvious": [2, 3], "occupi": [17, 18], "occur": [3, 5, 17, 20, 24, 29], "odd": 4, "off": [2, 3, 17], "offer": [3, 6, 26, 27, 28], "offic": 3, "offici": 3, "often": [0, 1, 3, 4, 17, 18, 22, 23, 24, 25, 26, 29, 30, 31], "oftentim": 27, "old": 18, "older": [2, 3], "ollama": 4, "ollamaembed": 4, "ommit": 17, "onc": [17, 20, 23, 26], "one": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "ones": [17, 18, 19, 20, 26, 31], "ones_lik": [3, 25], "onli": [0, 1, 2, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "onlin": [22, 25, 26], "onto": [17, 20, 23, 29, 31], "onward": 20, "oon": 1, "open": [0, 1, 3, 4, 5, 10, 17, 21, 22, 25, 26, 27, 28, 29], "openai": [11, 22, 26, 27], "openai_api_kei": 27, "openai_summarize_tldr": 26, "oper": [20, 23, 31], "operation": [5, 31], "opinion": [29, 30], "opportun": [15, 20], "oppos": [3, 17, 21], "opprotun": 30, "opt": [0, 17, 19, 22, 23, 26, 31], "optim": [0, 1, 3, 4, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28], "optima": 24, "optimis": 26, "option": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 27, 28, 29, 30, 31], "orang": [2, 3], "orc": 5, "ord": [3, 18], "order": [1, 4, 17, 18, 20, 22, 23, 24, 26, 27, 28, 29, 30], "ordereddict": 23, "ordin": 26, "org": [0, 1, 3, 18, 26, 28, 29], "orient": 29, "origin": [17, 21, 26, 29, 31], "original_summari": 4, "orini": 1, "other": [1, 2, 3, 5, 6, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "otherwis": [0, 1, 4, 17, 19, 22, 25, 26, 29], "our": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 31], "ourselv": [17, 22, 23, 27, 28], "out": [0, 1, 3, 4, 5, 6, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "out_contrast": 28, "out_featur": 23, "out_intermediate_residual_": 31, "out_proj": 23, "out_with_gener": 28, "outcom": [26, 30, 31], "outdoor": [2, 3], "outlier": 17, "outlin": 30, "outlook": [17, 25], "outperform": 3, "output": [0, 1, 3, 4, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 30, 31, 32], "output_": 29, "output_attent": [28, 31], "output_combin": 21, "output_dim": 28, "output_dir": 22, "output_hidden_st": [28, 31], "output_max_length": 4, "output_neuron": 1, "output_pars": 27, "output_s": 21, "output_text": 26, "output_xl": 29, "outset": 19, "outsid": [2, 3], "ouyang": 11, "over": [0, 1, 2, 3, 4, 5, 15, 17, 19, 20, 23, 24, 25, 26, 27, 29, 31, 32], "overal": [3, 4, 19, 23, 25, 27, 28, 29], "overfit": [22, 24, 25], "overlap": [17, 29], "overoptim": 26, "overrepres": 5, "overris": 22, "overview": [11, 14, 17, 20, 22, 24, 25, 26, 27, 30], "overwhelm": 22, "own": [1, 3, 4, 5, 17, 20, 21, 22, 23, 25, 26, 27], "p": [0, 1, 3, 17, 18, 21, 23, 24, 25, 26], "p_": [1, 21, 25, 29], "p_categori": 21, "p_name": 21, "pack": 20, "pack_padded_sequ": 20, "packag": [0, 1, 2, 3, 4, 17, 22, 23, 25, 26, 27, 28, 29, 30, 31], "pad": [0, 1, 3, 4, 17, 20, 22, 23, 24, 25], "pad_packed_sequ": 20, "pad_sequ": 20, "pad_token": [0, 1, 4, 22], "pad_token_id": [0, 1, 3, 4, 22, 24, 25], "padding_sid": [0, 1, 4, 22], "page": [17, 27], "pai": 20, "pain": [3, 20], "pair": [0, 1, 5, 17, 20, 21, 23, 26, 29], "palm": 1, "panda": [3, 4, 5, 20, 21, 25, 29], "paper": [0, 1, 2, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 23, 24, 25, 26, 29, 30, 31], "paper_url": [0, 1], "paradigm": [10, 29], "parallel": [3, 17, 22, 23, 25, 31], "parallelis": 23, "parallelogram": 3, "param": [20, 26], "paramet": [0, 1, 2, 3, 4, 11, 17, 22, 23, 24, 25, 26, 27, 28, 29, 31], "parameter": 22, "paramt": [4, 25], "paraphras": 29, "parent": 3, "parenthes": 5, "pari": [28, 31], "park": 12, "parrot": 30, "part": [3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "partial": [0, 1, 3, 26, 31], "particip": [6, 29], "particular": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 26, 27, 28, 30], "particularli": 20, "particulat": 25, "pass": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32], "passag": 24, "passs": 27, "past_key_valu": 31, "past_layer_": 31, "patch": 16, "patched_logit": 31, "patched_logit_diff": 31, "path": [17, 25, 28], "patient": 27, "pattern": [24, 28, 30, 31], "pavlick": [10, 30], "paywal": 27, "pd": [3, 4, 5, 20, 25, 29], "pdf": [3, 26], "pe": 23, "peak": 17, "peft": [11, 22], "penalti": 3, "penalty_alpha": 3, "penguin": [3, 25], "penn": 29, "peopl": [2, 3, 5, 17, 29], "pep8": 17, "per": [2, 3, 21, 22, 24, 25, 26, 28], "per_device_eval_batch_s": 22, "per_device_train_batch_s": 22, "percentag": 30, "perceptron": 20, "perci": 6, "perez": 5, "perfect": [21, 29], "perform": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "perhap": [24, 26, 29], "permut": 22, "perpetu": 30, "perplex": [3, 21, 29], "perplexity_": 29, "perplexity_xl": 29, "perplxti": 21, "perplxty_dict": 21, "person": [2, 3, 17, 24], "perspect": [6, 29, 30], "pertain": 3, "perturb": 28, "pet": 3, "phenomena": 5, "phenomenon": [5, 29, 30], "phi": [1, 4, 26], "phrase": 5, "physic": 30, "pick": [0, 1, 17, 23, 26, 31], "pictur": [3, 21, 23, 25], "piec": [17, 23, 27, 29], "pile": [17, 22], "pilot": 5, "pinecon": 4, "pip": [0, 1, 4, 17, 22, 26, 27, 28, 31], "pipe_output": 22, "pipelin": [0, 1, 4, 17, 22, 25], "piper": 17, "pizza": [3, 25], "pizzeria": 25, "place": [3, 4, 25], "placement": 4, "plai": [0, 1, 2, 3, 19, 21, 22, 23, 25, 26, 27, 30], "plan": 27, "platform": [17, 22], "plausibl": 30, "pleas": [0, 1, 2, 3, 4, 5, 17, 20, 22, 23, 25, 26, 27, 28, 29], "plot": [0, 1, 4, 5, 17, 18, 19, 20, 21, 22, 24, 30], "plot_everi": 21, "plotli": 31, "plt": [0, 1, 17, 19, 20, 21, 22], "plu": [21, 23, 28], "plural": 5, "png": 0, "po": [23, 24, 28], "point": [17, 20, 23, 24, 25, 26, 27, 29], "pointer": 23, "pointwis": 17, "pol_tok": 31, "poland": 31, "poland_id": 31, "poland_text": 31, "polic": 3, "polici": 4, "polina": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "polish": 21, "polit": 30, "poor": 17, "popul": 18, "popular": [3, 4, 22, 24, 27, 30], "pork": 4, "portugues": 21, "pos_encod": 23, "posencod": 23, "posit": [18, 23, 24, 25, 26, 29, 31], "positionalencod": 23, "positive_sent": 26, "possess": 30, "possibl": [3, 5, 17, 18, 23, 24, 25, 26, 27, 29, 30, 31], "possibli": [17, 23, 26], "post": [2, 3, 4, 25, 26, 28], "potenit": 29, "potenti": [17, 24, 25, 26, 27, 28, 29], "power": [3, 12, 20, 29], "pp": 5, "ppl": 29, "ppl_": 29, "ppo": 4, "ppo_epoch": 4, "ppo_train": 4, "ppoconfig": 4, "ppotrain": 4, "practic": [0, 1, 6, 20, 22, 23, 24, 25, 29], "practition": [2, 3], "pragmat": [6, 29], "prder": 18, "pre": [2, 3, 9, 11, 17, 20, 21, 23, 28, 31], "pre_wo_attn": 31, "preced": [3, 17, 23, 24, 25], "precis": [18, 29], "pred": [3, 25, 28], "predict": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "predicted_answ": 29, "predicted_d": 29, "predicted_decoded_d": 29, "predicted_label": 29, "prediction_instruct": 26, "prediction_lm": 26, "prefer": [4, 5, 11, 17, 26], "prefix": [3, 23, 29], "preliminari": 6, "premis": 3, "prep": [0, 1], "prepair": 17, "prepar": [0, 1, 3, 4, 17, 19, 22], "prepend": 23, "preposit": 5, "preprocess": [0, 1, 17, 23], "preprocessed_train_dataset": 17, "present": [1, 2, 3, 20, 21, 30], "presid": [2, 3], "press": [3, 17], "presuppos": [3, 29], "pretrain": [0, 1, 4, 17, 18, 22, 26, 27, 31], "pretraining_data_s": [0, 1], "pretty_print": 3, "prevent": [2, 3, 22, 25], "previou": [1, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "price": 17, "primarili": [3, 30], "primit": 20, "principl": [22, 23], "principle_a_case_1": 5, "print": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "print_everi": 21, "print_funct": 21, "print_top": 31, "prior": [6, 30], "priori": 23, "pro": 25, "prob": [21, 32], "prob_of_answ": 31, "probabl": [0, 1, 3, 4, 5, 17, 19, 20, 21, 23, 24, 25, 26, 29, 31], "probe": [3, 6, 13, 21], "probing_dir": 28, "problem": [3, 4, 6, 10, 17, 29], "problemat": [4, 30], "probs_t": 32, "procedur": [4, 19, 25, 29], "proces": [0, 1], "process": [0, 1, 3, 5, 7, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "prod": 1, "prodcut": 18, "produc": [17, 20, 21, 22, 31], "product": [18, 26, 28], "program": [6, 10, 24], "progress": [2, 3, 24], "project": [6, 17, 31, 32], "promin": [17, 23], "promot": 31, "prompt": [4, 5, 6, 21, 23, 26, 27, 28, 29, 30, 31], "prompt_input_id": [3, 25], "prompt_template_appet": 27, "prompt_template_dessert": 27, "prompt_template_main": 27, "prompt_template_summari": 27, "prompttempl": 27, "propag": 8, "propens": 30, "proper": 21, "properli": 27, "properti": [0, 1, 18], "proport": [5, 17, 21, 29], "proprietari": 4, "propto": 25, "provd": 30, "proven": 26, "provid": [0, 1, 2, 3, 4, 5, 14, 15, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "proxim": [4, 26], "pseudo": [5, 22, 29], "psuchologi": 29, "pt": [0, 1, 3, 4, 17, 22, 24, 25, 26, 28, 29, 31], "publicli": 27, "publish": 17, "pull": 27, "punctuat": [0, 1, 17, 23], "pure": [3, 22, 25], "pure_sampling_decod": 3, "purpos": [4, 17, 18, 20, 22, 26, 27, 28], "push": 17, "push_to_hub": 22, "put": [0, 1, 4, 22, 28, 29, 31], "puzzl": 30, "px": 31, "py": [0, 3, 17, 22, 23, 26, 31], "pyplot": [0, 1, 17, 19, 20, 21, 22], "pythia": [2, 3, 5, 25], "python": [6, 17, 20, 28, 29], "python3": [0, 17, 22, 23, 31], "pytorch": [1, 17, 19, 21, 22, 24, 28, 31], "q": [3, 4, 23, 25, 31, 32], "q_proj_weight": 23, "q_x": 32, "qa": [24, 26], "qlora": 26, "qquestion": [0, 1], "qualiti": [17, 24, 29], "quantifi": 24, "quantit": 5, "queri": [4, 17, 23, 25, 27, 28, 32], "query_engin": 4, "query_tensor": 4, "question": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "quick": [21, 23, 24], "quickstart": 28, "quiet": 21, "quit": [17, 22, 26, 27, 29, 30, 31], "quot": 30, "qwen": 1, "r": [0, 1, 4, 17, 26, 29, 32], "r_": 26, "race": 3, "radford": 9, "rafailov": 26, "rag": [1, 4], "rag_respons": 4, "rais": [3, 28, 29, 31], "ran": 28, "rand": [17, 18, 20], "randint": 21, "random": [3, 4, 18, 21, 24, 25, 28, 31], "random_choic": 21, "random_training_exampl": 21, "random_training_pair": 21, "random_weight": 28, "randomli": [17, 21, 24], "rang": [0, 1, 3, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31], "rank": [26, 31], "rare": 30, "rate": [0, 1, 3, 17, 19, 21, 22, 24, 25, 26], "rather": [3, 11, 17, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "raw": [17, 21, 23, 29], "rcl": 17, "rdbu": 31, "rdquo": 26, "re": [3, 23, 24, 27], "reach": [3, 23, 24], "react": 27, "read": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 25, 31], "read_csv": [5, 25, 29], "readabl": [17, 22, 23], "reader": 31, "readi": 19, "readlin": 28, "readm": 17, "readthedoc": [0, 3, 17, 22], "real": [3, 27, 30], "realis": 31, "realiti": [2, 3], "realiz": [21, 30], "realli": 10, "realtoxicityprompt": [29, 30], "reason": [0, 1, 2, 3, 10, 13, 26, 29], "recal": [16, 27, 29, 31], "recap": [26, 29], "receiv": [4, 17, 26, 28], "recent": [1, 2, 3, 5, 17, 23, 25, 29, 30], "recevi": 26, "recip": [4, 26, 27], "recipe_nlg_lit": 4, "recipi": 27, "reciproc": 31, "recognit": 24, "recommend": [6, 17, 21], "record": [4, 17, 29], "recov": 31, "rectangular": 3, "recurr": [21, 22], "recycl": 18, "red": [2, 3, 30], "reduc": [23, 25], "reduct": [3, 21], "reel": 17, "ref_model": 4, "refer": [2, 3, 4, 5, 12, 17, 20, 22, 24, 25, 26, 28, 29, 30, 31], "reflect": [3, 5, 17, 30], "reformat": 17, "regard": [2, 3, 17, 21, 26, 29, 30], "regex": 29, "regim": 21, "register_buff": 23, "register_forward_hook": 31, "regress": 23, "regular": 28, "reimplement": 23, "reinforc": [11, 26], "reject": 26, "rel": [3, 5, 22, 23, 26], "relat": [2, 3, 6, 11, 17, 19, 21, 23, 29, 30], "relev": [4, 6, 17, 19, 22, 24, 26, 27, 29, 30], "reli": [3, 23, 24, 28, 30], "reliabl": [3, 25, 29, 30], "reload": [0, 1, 22], "relu": [0, 1, 20, 21], "remain": [22, 30], "rememb": [20, 21, 25], "remind": [3, 22, 25, 28], "remov": [17, 18, 21, 23, 31], "remove_column": [22, 24], "render": [5, 31], "repeat": [19, 23, 25], "replac": [3, 31], "replic": [18, 25], "repo_id": 27, "report": [1, 2, 3, 17, 19, 21, 26], "repositori": [17, 26, 31], "repres": [2, 3, 5, 17, 18, 20, 21, 22, 23, 26, 28, 29, 31], "represen": 28, "represent": [3, 4, 8, 13, 17, 18, 20, 21, 23, 24, 28, 31], "representation_dim": 28, "reproduc": [3, 17], "req_res_oop": 31, "request": [21, 25], "requir": [0, 1, 3, 4, 6, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "requires_grad": [19, 23, 26], "research": [2, 3, 17, 24, 26, 27, 29, 30], "reserach": 29, "reset": 21, "reset_activ": 31, "reshap": [20, 21], "resid_dropout": 23, "resid_pr": 31, "residu": 32, "residual_stream_patching_hook": 31, "resourc": [0, 1, 2, 3, 4, 5, 17, 22, 24, 25, 26, 27, 30], "respect": [1, 4, 5, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "respond": 29, "respons": [0, 1, 3, 4, 5, 23, 29], "response_mod": 4, "response_rag": 4, "response_synthes": 4, "response_tensor": 4, "response_vanilla": 4, "responsinbl": 31, "rest": [5, 17, 22, 24, 26], "restaur": 3, "restrict": [17, 25], "result": [1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "resum": 31, "resume_download": 31, "rethink": 10, "retreiv": [0, 1, 27, 29], "retriev": [0, 1, 3, 18, 21, 22, 23, 25, 26, 28, 29, 31], "retrieved_node_scor": 4, "retrieved_node_text": 4, "return": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 26, 28, 29, 31, 32], "return_dict": 28, "return_output": 22, "return_tensor": [0, 1, 3, 4, 17, 22, 24, 25, 26, 28, 29, 31], "reus": [4, 16, 20, 25, 26], "reusabl": 20, "revers": [1, 31], "revert": 19, "review": [3, 4, 22, 26], "revolv": 3, "reward": [4, 30], "reward_fn": 4, "reward_model": 26, "reward_neg": 26, "reward_po": 26, "reward_token": 26, "reynold": 10, "right": [0, 1, 13, 20, 22, 23, 25, 27, 30], "rigor": 16, "rise": [3, 17, 30], "risk": [15, 30], "rl": 3, "rlaif": 26, "rlhf": [0, 1, 17, 26, 30], "rm_hook": 31, "rnn": [20, 23, 24], "road": 3, "robot": [11, 12], "robust": [21, 29, 30], "rocm": 17, "role": [10, 23, 31], "rolling_mean": 21, "rome": 16, "root": 29, "roug": [4, 26, 29], "rouge1": 4, "rouge_scor": 4, "roughli": 20, "round": [20, 21, 28, 32], "row": [1, 3, 23, 26], "row_vector": 18, "royal": 17, "rr": 31, "rr_per_lay": 31, "rt": 5, "ruff": 17, "rule": [0, 1, 20, 21, 23], "rumelhart": 8, "run": [0, 1, 3, 4, 17, 20, 22, 25, 26, 28, 29, 31], "run_with_cach": 31, "run_with_hook": 31, "runtim": [0, 1, 2, 3, 4, 5, 17, 25], "russian": 21, "ryan": 6, "safe": [2, 3], "safer": 17, "safeti": [3, 30], "sai": [4, 5, 12, 17, 25, 30, 31], "said": 25, "sake": 27, "salazar": 29, "salienc": 28, "same": [2, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "sampl": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 26, 29], "santurkar": 30, "sar\u0131ta\u015f": 3, "satisfii": 27, "satoshi": 21, "save": [0, 1, 2, 3, 4, 5, 17, 20, 21, 24, 31], "save_step": 22, "saw": 31, "scalabl": [29, 30], "scalar": [1, 4, 18, 20, 26], "scale": [4, 7, 11, 19, 20, 26, 29, 32], "scari": [2, 3], "scatterplot": 20, "scenario": [3, 29], "scene": [19, 20], "schedul": [22, 24, 26], "scheme": [2, 4, 22], "schmidhub": 9, "schnell": 23, "school": [2, 3], "scienc": [6, 29, 30], "scientif": 26, "scope": 21, "score": [3, 4, 5, 23, 24, 25, 26, 28, 29, 32], "scorer": [5, 29], "scottish": 21, "scratch": [22, 24], "scratchpad": 10, "script": 26, "scrub": 16, "seaborn": [19, 20], "seamlessli": [17, 27], "search": [2, 3, 4, 17, 24, 25, 27], "searchabl": 4, "searhc": 27, "second": [2, 3, 4, 5, 8, 17, 18, 20, 23, 28], "secretli": 26, "section": [2, 3, 5, 17, 26, 29, 30], "secur": 3, "see": [0, 1, 2, 3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "seed": 25, "seek": 19, "seem": [1, 3, 20, 21, 25, 26, 28, 29], "seen": [18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "segmented_token": 28, "select": [3, 5, 17, 20, 22, 24, 25, 26, 28, 29, 30], "self": [0, 1, 3, 10, 20, 21, 22, 23, 26, 28, 31], "self_attn": 23, "self_consist": 3, "sell": [0, 1], "semant": [5, 29], "semest": 17, "seminar": 6, "send": 22, "sens": [0, 1, 4, 21, 22, 23, 25, 26, 30], "sensibl": [17, 22, 26], "sensibli": 3, "sensit": [3, 28, 30], "sentenc": [0, 1, 2, 3, 4, 5, 13, 17, 22, 23, 24, 25, 26, 28, 29, 31, 32], "sentence1": 29, "sentence2": 29, "sentiment": [2, 3, 17, 22, 24, 25, 26, 29], "sep": [25, 28], "separ": [0, 1, 4, 5, 20, 23, 25, 26, 29], "seq2seq": [24, 28], "sequenc": [0, 1, 3, 20, 23, 24, 25, 27, 28, 31], "sequence_length": 28, "sequence_scor": 29, "sequenti": [20, 21], "seri": [19, 22, 24], "serious": 21, "serv": [3, 4, 25, 27], "server": 22, "servic": 3, "session": [17, 22, 25, 26], "set": [0, 1, 3, 4, 5, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "set_format": [4, 17], "set_se": 3, "settl": 17, "setup": 22, "seventh": 13, "sever": [0, 1, 3, 17, 21, 23, 24, 27, 29], "sft": [4, 26], "sfttrainer": 26, "sgd": 19, "shape": [1, 3, 17, 18, 21, 22, 23, 25, 28, 30, 31, 32], "share": [3, 17, 20, 26, 27], "sharehold": 17, "sharpen": 30, "she": [2, 3, 29], "shed": 29, "sheet": [0, 1, 2, 3, 4, 5, 7], "shift": [2, 3, 18, 22], "shima": 21, "ship": [0, 1, 22, 23], "shirt": [2, 3], "shop": [2, 3, 25], "short": [3, 4, 9, 17, 18, 20, 21, 22, 26, 30], "shorter": [3, 17, 20], "shot": [2, 10, 25], "should": [0, 1, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "shouldn": [2, 3], "show": [0, 1, 3, 4, 5, 10, 19, 20, 21, 22, 23, 24, 26, 28, 31], "shown": [3, 4, 21, 26, 29, 30], "shuffl": [0, 1, 17, 20, 21], "shy": 17, "side": [0, 1, 3, 17, 22, 23], "sidewalk": [2, 3], "sigma": 26, "sign": [23, 27], "signal": [4, 17, 20, 23, 26], "signific": [2, 3, 17], "significantli": 17, "sim": 26, "simialar": 3, "similar": [2, 3, 4, 5, 19, 20, 23, 25, 26, 28, 29, 30, 31], "similarity_top_k": 4, "similarli": [18, 29], "simpl": [0, 1, 5, 16, 19, 20, 21, 23, 25, 26, 27, 28, 29, 30, 31], "simplest": 23, "simpli": [23, 26, 28], "simplif": 25, "simplifi": [22, 25], "simulacra": 12, "simultan": [4, 17], "sin": [20, 23], "sinc": [0, 1, 4, 17, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "sine": 23, "sing": [0, 1, 3], "singl": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31], "singular": 5, "sit": [2, 3], "site": [0, 3, 17, 22, 23, 31], "situat": 17, "sixth": 12, "size": [0, 1, 3, 4, 17, 18, 20, 21, 22, 23, 24, 26, 27, 29, 31], "skate": [2, 3], "skateboard": [2, 3], "skill": [0, 1, 2, 3, 4, 5, 20, 30], "skim": 30, "skip": 31, "skip_special_token": [0, 1, 3, 25, 26, 29], "sklearn": 29, "sleep": [0, 1, 3], "slide": [4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22, 25, 26, 28], "slight": 21, "slightli": [17, 18, 20, 24, 28, 29, 31], "slip": 17, "slope": 20, "slot": 17, "slow": 31, "slowdown": 5, "slowli": 19, "small": [0, 1, 2, 3, 4, 6, 16, 17, 19, 22, 23, 26, 28, 29, 31], "smaller": [0, 1, 3, 17, 20, 22, 29], "smart": [2, 3], "smile": [2, 3], "smooth": 3, "smoothen": 25, "sn": [19, 20], "snake": 3, "snli": 3, "so": [3, 4, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "soccer": 3, "social": [5, 29], "societi": 6, "sociocultur": 17, "soft": [25, 31], "softmax": [3, 21, 25, 31, 32], "softmax_sampling_decod": 3, "softwar": [3, 17, 30], "sold": 25, "sole": 3, "solid": 3, "solut": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 24, 26, 30], "solv": [0, 1, 2, 3, 4, 5, 10, 17, 19, 29], "some": [0, 1, 2, 3, 4, 5, 11, 12, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "somehow": 27, "someon": 3, "someth": [0, 1, 5, 19, 20, 21, 26, 30, 31], "sometim": [17, 22, 23, 24, 25, 26, 27, 30], "somewhat": [0, 1, 20, 25, 27, 29], "song": 3, "soon": 24, "sophist": [2, 3], "sort": 26, "sorted_prob": 31, "sosindex": 21, "sota": [3, 23, 26, 29, 30], "sound": [21, 25, 26, 30], "soup": 4, "sourc": [4, 5, 6, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "source_nod": 4, "space": [0, 1, 2, 3, 4, 17, 21, 26, 28, 29, 31], "spaci": 28, "span": [24, 26], "spanish": 21, "spars": [0, 1], "speak": [18, 21], "speaker": 21, "spec": 17, "special": [3, 4, 20, 21, 22, 24, 25, 26, 27, 28, 29], "specicif": 31, "specif": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "specifi": [0, 1, 17, 18, 20, 22, 23, 24, 26, 27, 28], "speech": [7, 28, 29], "speed": [0, 1, 2, 3, 4, 5, 17, 20, 26], "spend": [2, 3], "split": [0, 1, 4, 17, 20, 22, 23, 24, 26, 28, 29], "split_percentag": 21, "spoiler": 25, "sponsor": 27, "sport": 3, "spot": [0, 1, 22], "sprang": 23, "spuriou": 28, "sqrt": [20, 24, 32], "squar": 3, "squeez": [4, 18, 20, 21, 31], "src": 5, "src_mask": 23, "ss": 6, "stabil": [19, 24, 26], "stabl": [0, 3, 4, 17, 18, 20, 22, 24], "stack": [18, 20, 31], "stage": 24, "stai": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 31], "stand": [17, 29], "standard": [3, 4, 17, 19, 24, 26, 29], "stanford": 3, "stanfordnlp": [22, 24], "stanlei": [2, 3], "start": [3, 4, 17, 20, 21, 23, 24, 25, 26, 27, 30, 31], "starter": 5, "startofsequ": 23, "startswith": [26, 28], "stat": 4, "state": [0, 1, 2, 3, 6, 17, 19, 21, 22, 23, 26, 28, 31], "stateless": 27, "statement": [3, 25], "static": 23, "station": 3, "statist": [3, 17, 20], "stdv": 20, "step": [0, 1, 4, 5, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30, 31], "step_scor": 28, "stepwis": 27, "stereotyp": 30, "stick": 17, "still": [3, 17, 19, 21, 22, 23, 25, 29], "stochast": [19, 21, 30], "stock": 17, "stop": [3, 17, 20, 23, 24, 28], "stopword": 17, "storag": [4, 17], "store": [2, 3, 4, 5, 18, 19, 20, 21, 22, 29, 31], "stori": 26, "storycloz": 30, "str": [0, 1, 4, 17, 29, 31, 32], "str_tok": 31, "straightforward": 4, "stranger": 5, "strategi": [10, 17, 29, 30], "stream": [3, 27], "street": [3, 17, 25], "stress": [2, 3], "strictli": 18, "string": [0, 1, 5, 17, 18, 21, 22, 23, 28, 29, 31], "strip": [4, 28], "strong": [17, 26], "strongli": [17, 30], "stroutputpars": 27, "structur": [2, 3, 5, 13, 17, 18, 20, 22, 27, 29], "student": [0, 1, 3, 6, 26], "studi": [17, 19, 21, 26, 27, 29], "studio": 17, "stumbl": 26, "style": [2, 3, 16, 17, 26], "sualli": 17, "sub": [3, 17, 18, 27, 28], "subclass": 22, "subject": [5, 6, 26], "submiss": [0, 1, 2, 3, 4, 5], "submit": [0, 1, 2, 3, 4, 5, 17], "subplot": 24, "subsampled_dataset": [22, 24], "subsect": 21, "subsequ": [3, 19, 20, 21, 26, 30, 31], "subset": [22, 26], "substep": [22, 27], "subtl": 20, "subtract": [18, 20, 31, 32], "subword": 23, "success": [2, 3, 4, 22, 23, 24, 26], "successfulli": [17, 24], "suffici": 22, "sufficintli": 26, "suffix": 3, "suggest": [1, 3, 5, 17, 21, 27], "suiss": 17, "suit": [1, 5, 26, 29], "suitabl": [17, 26], "sum": [0, 1, 3, 17, 19, 21, 23, 25, 26, 28, 29], "sum_": 29, "summar": [3, 22, 24, 26, 29], "summari": [0, 1, 2, 3, 4, 26, 27, 29], "summaris": 26, "summend": 25, "super": [20, 21, 23, 28, 31], "super_glue_boolq": 29, "superglu": 29, "superlative_quantifiers_1": 5, "supermarket": 5, "supervis": [11, 28, 30], "supplement": [4, 29], "supplementari": [9, 10, 11, 12, 13, 14, 15, 16], "suppli": [4, 17, 20, 21], "support": [3, 17, 18, 28, 30], "supporting_modul": 4, "suppos": [4, 17, 22, 26, 29], "suppress": 19, "sure": [0, 1, 2, 3, 5, 17, 20, 21, 22, 23, 25, 26, 28, 29, 31], "surnam": [0, 1, 21], "surname_firstname_hw1": 0, "surname_firstname_hw2": [2, 3], "surname_firstname_hw3": 4, "surname_firstname_hw4": 5, "surname_firtname_hw1": 1, "surp_avg": 21, "surp_avg_dict": 21, "surp_dict": 21, "surp_scal": 21, "surpris": [0, 1, 21], "surprisal_test": 21, "surprisal_train": 21, "surprisl": 21, "surprisl_dict": 21, "survei": 7, "sva_data": 5, "swap": 22, "switch": 24, "swoop": 20, "sy": 28, "symbol": [17, 23], "symmetr": 29, "syntact": [5, 13, 14, 28, 29], "syntax": [5, 18], "syntaxgym": 14, "system": [2, 3, 5, 19, 23, 24, 26, 27, 29, 30], "systemat": [3, 6], "t": [0, 1, 2, 3, 4, 5, 17, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "t5": [24, 28, 29], "t5forconditionalgener": 29, "t5token": 29, "tabl": [2, 3, 5, 17], "tag": [17, 24, 28, 29], "tail": 18, "take": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "taken": [5, 22, 28, 29, 30, 31], "talk": [3, 27], "talmor": [0, 1], "tandem": 29, "tap": 5, "target": [17, 19, 20, 21, 22, 26, 28, 29, 30], "target_id": 28, "target_line_tensor": 21, "target_out": 22, "target_tensor": 21, "task": [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "task_prompt": 3, "tau": [0, 1, 25, 29], "taught": 6, "tbd": 1, "teach": [3, 26], "teacher": 5, "team": [17, 30], "technic": [1, 6, 29], "techniqu": [2, 3, 4, 20, 25, 26, 28, 30, 31], "tediou": 20, "televis": [2, 3], "tell": [2, 3, 4, 18, 19, 20, 21, 26, 29], "temp_hook_fn": 31, "temperatur": [0, 1, 3, 4, 25, 27], "templat": 27, "tempor": 21, "temporari": 31, "ten": 26, "tend": 26, "tendenc": 21, "tennei": [13, 28], "tenni": 5, "tensor": [0, 1, 4, 17, 19, 20, 21, 22, 23, 25, 28, 31, 32], "tensor1": 18, "tensor2": 18, "tensor3": 18, "tensor4": 18, "tensor5": 18, "tensor_0d": 18, "tensor_1": 18, "tensor_1_transpos": 18, "tensor_2": 18, "tensor_2d": 18, "tensor_from_list": 18, "tenth": 16, "tep": 4, "term": [5, 9, 17, 22, 23, 25, 26, 29], "terminologi": [27, 29], "termn": [0, 1], "terribl": 25, "test": [0, 1, 2, 3, 4, 5, 14, 16, 17, 20, 22, 24, 25, 26, 27, 28, 30, 31], "test_accuraci": 28, "test_data": 21, "test_dataload": [0, 1], "test_dataset": [0, 1], "test_df": 4, "test_indic": 21, "test_label": 28, "test_labels_al": 28, "test_layer_represent": 28, "test_loss": [0, 1, 22, 28], "test_output": [0, 1], "test_queri": 4, "test_represent": 28, "test_representations_al": 28, "test_sampl": [0, 1], "test_sent": 28, "test_sentence_represent": 28, "test_set": 3, "test_siz": [17, 21], "test_split": [0, 1], "testabl": 5, "testset": 21, "text": [0, 1, 2, 3, 4, 11, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "text1": 23, "text2": 23, "text3": 23, "text_d": 29, "text_en": 29, "textbook": [7, 8, 9], "textual": [4, 29], "th": [2, 3, 4, 5, 23], "than": [2, 3, 5, 11, 17, 23, 24, 26, 27, 28, 29, 31], "thei": [2, 3, 4, 5, 6, 17, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31], "thelik": 23, "them": [0, 1, 2, 3, 4, 5, 6, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "themselv": 6, "theorem": 26, "theoret": [3, 27, 29], "theori": 29, "therebi": [3, 23, 29], "therefor": [0, 1, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "theses": 1, "theta": 26, "thi": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "thing": [3, 17, 19, 20, 21, 22, 23, 24, 27, 31], "think": [0, 1, 2, 3, 4, 6, 17, 18, 20, 21, 23, 24, 25, 26, 28, 29, 30], "third": [4, 5, 9, 18, 20, 23, 27, 28], "those": [21, 22, 23, 25, 28, 29, 30], "though": [1, 3, 17, 25], "thought": [2, 3, 10, 15, 22, 25, 30], "thousand": [26, 29], "three": [0, 1, 3, 4, 17, 18, 21, 23, 24, 27], "threshold": [3, 25], "through": [0, 1, 3, 17, 18, 19, 21, 22, 23, 25, 26, 28, 31], "throughout": [0, 1, 17, 22, 30, 31], "thu": [20, 29], "tidi": 17, "tightli": 24, "tile": 28, "time": [0, 1, 2, 3, 4, 5, 17, 18, 19, 21, 22, 23, 24, 27, 29], "time_sinc": 21, "times5": [0, 1], "timestamp": 20, "tiramiu": 27, "titl": 31, "tmobil": 17, "to_numpi": 31, "to_single_token": 31, "to_str_token": 31, "to_token": 31, "todo": [1, 18], "tofu": 26, "togeth": [4, 5, 22, 23, 25, 27, 28, 31], "tok": 23, "tokein": 17, "token": [0, 1, 2, 3, 4, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 32], "token_label": 31, "tokenized_dataset": [22, 24], "tokenized_input": [0, 1, 22, 24], "tokenizer_gpt2": 17, "tokenizer_instruct": 26, "tokenizer_lm": 26, "tokenizer_nam": 4, "tokenizer_t5": 29, "tokenizer_typ": [0, 1], "tokenizers_parallel": 31, "told": 19, "tomato": 27, "too": [3, 4, 22, 24, 29], "tooken": 17, "tool": 17, "top": [3, 17, 25, 27, 28, 31], "top_k": [3, 4, 22, 25], "top_k_sampling_decod": 3, "top_p": [3, 4, 25], "top_p_sampling_decod": 3, "topi": 21, "topic": [0, 1, 6, 11, 12, 17, 23, 24, 25, 29, 30], "topk": [21, 31], "topk_per_lay": 31, "topv": 21, "torch": [0, 1, 3, 4, 5, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 31, 32], "torch1": 18, "torch2": 18, "torch_dtyp": [4, 25, 31], "torchrl": 17, "torchtext": 29, "tot": 3, "total": [1, 4, 21, 26], "total_loss": [21, 28], "total_s": 21, "touvron": [10, 26], "toward": 26, "town": 29, "toxic": [17, 29, 30], "tqdm": [0, 1, 3, 4, 17, 22, 31], "tqdmwarn": [0, 3, 17, 22], "tra": 17, "trace": 28, "traceback": 1, "track": [0, 1, 19, 21, 29], "tradit": 17, "train": [0, 1, 2, 3, 4, 5, 6, 8, 9, 11, 18, 22, 23, 25, 29, 30, 31], "train_accuraci": 28, "train_data": [19, 21], "train_dataload": 20, "train_dataset": [0, 1, 22, 26], "train_indic": 21, "train_label": 28, "train_labels_al": 28, "train_layer_represent": 28, "train_loss": [22, 28], "train_represent": 28, "train_representations_al": 28, "train_sent": 28, "train_sentence_represent": 28, "train_siz": [17, 21], "train_split": [0, 1], "train_step": [0, 1], "train_test_split": 17, "trainabl": [0, 1, 19, 20, 26], "trainer": [22, 26], "training_data": [0, 1], "training_data_cutoff": [0, 1], "trainingargu": 22, "tram": [2, 3], "transfer": 30, "transform": [0, 1, 2, 3, 4, 6, 16, 17, 20, 25, 26, 27, 28, 29, 31], "transformer_len": 31, "transformer_model": 23, "transformerdecod": 23, "transformerdecoderlay": 23, "transformerencod": 23, "transformerencoderlay": 23, "transformermodel": 23, "translat": [24, 28, 29], "transpos": [1, 17, 21, 23], "travel": 3, "treat": [3, 20, 22, 28], "tree": [2, 3, 10, 25], "treebank": 29, "trend": 7, "tri": [2, 3, 24, 27], "trial": [5, 26, 29], "trian": [0, 1], "trick": [20, 24], "tricki": [24, 30, 31], "trigram": 29, "triplet": 21, "trivial": 26, "triviaqa": 30, "trl": [4, 26], "troubl": [2, 3], "trough": 17, "true": [0, 1, 3, 4, 5, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31], "true_answ": 29, "true_dist": 19, "true_loc": 19, "true_logit": 31, "true_posit": 29, "truncat": [0, 1, 4, 22, 24], "trust_remote_cod": [4, 25], "truth": [0, 1, 4, 20, 26, 29], "truthful_qa": 22, "truthfulqa": 30, "try": [0, 5, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "tsvilodub": [17, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "tuck": 17, "tue": 6, "tune": [2, 3, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 22, 24, 25, 27, 28, 29, 30], "tupl": [0, 1], "turbo": [27, 29], "turn": [20, 26], "tutor": 26, "tutori": [0, 1, 17, 19, 20, 21, 22, 23, 24], "tweet": 17, "tweet_length": 17, "twice": [4, 31], "twitter": [0, 1, 17], "two": [0, 1, 2, 3, 4, 5, 8, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30], "txt": [17, 28], "type": [0, 1, 2, 3, 4, 5, 17, 22, 23, 24, 26, 27, 30, 31], "typic": [1, 3, 5, 20, 21, 25, 26], "t\u00fcbingen": 6, "u": [3, 4, 5, 17, 18, 19, 20, 21, 22, 26, 27, 29, 30], "ud": 28, "ud_en_pref": 28, "ultim": [3, 26], "umbrella": [3, 22], "umpir": 3, "un": 26, "unanim": 25, "unclear": [20, 26], "uncom": [0, 1, 4, 17, 22, 26], "under": [0, 1, 3, 5, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30], "underfit": 24, "undergo": [23, 31], "undergon": [2, 3], "underli": [4, 22, 29], "underpin": 26, "understand": [2, 3, 4, 9, 10, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "understanding_llm": [0, 17, 22, 23, 31], "understood": 17, "undesir": [17, 26, 30], "unembed": 31, "unexpect": [3, 25], "unexpectedli": 29, "unfortun": [1, 17], "unfortunatelli": 27, "unfrozen": 26, "ungrammat": 29, "ungrammatical_log_prob": 29, "ungrammatical_sent": 29, "uni": 6, "unicod": 23, "unicode_liter": 21, "uniform": [3, 20], "uniform_": 20, "uniformli": 18, "unigram": [23, 29], "union": 28, "uniqu": [0, 1, 17, 21, 23, 28], "unique_label": 28, "unit": [5, 17, 18, 21, 23], "univers": 11, "unk": 23, "unknown": [17, 23, 26], "unless": [0, 1], "unlik": 1, "unnecessari": 23, "unpack": 20, "unrecogn": 28, "unsaf": 30, "unseen": [3, 17], "unsolv": 29, "unsqueez": [18, 22, 23, 31], "unsqueeze_": 21, "unstructur": 4, "unsupervis": [9, 26], "unsurpris": 17, "until": [4, 23, 24, 25], "up": [0, 1, 2, 3, 4, 5, 20, 22, 25, 26, 27, 28, 29, 30, 31], "upcom": 17, "updat": [0, 1, 3, 17, 20, 22, 24, 26, 27, 31], "upload": [0, 1, 2, 3, 4, 5, 22, 28], "upon": [3, 26], "urg": 17, "url": 21, "urllib": 21, "urlopen": 21, "us": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "usa": 5, "usabl": [18, 26], "usag": [1, 17], "usage_custom": 4, "use_cach": 31, "use_mps_devic": 22, "use_nested_tensor": 23, "user": [3, 17, 23, 24, 26, 27, 29, 30], "user_instal": [0, 3, 17, 22], "userwarn": 23, "using_llm": 4, "usual": [0, 1, 3, 5, 17, 18, 21, 22, 23, 24, 26, 27, 29], "util": [0, 1, 3, 4, 17, 22, 25, 28, 31], "v": [0, 1, 5, 20, 22, 23, 29, 31, 32], "v0": 27, "v1": [4, 29], "v2": [1, 4], "v_0": 32, "v_1": 32, "v_4": 32, "v_proj_weight": 23, "v_x": 32, "valid": [0, 1, 4, 17, 23, 24, 26, 27, 29], "valu": [3, 4, 20, 21, 22, 23, 24, 25, 26, 28, 29, 31, 32], "valuabl": 17, "value_var": 20, "valueerror": 28, "vanilla": [3, 4, 26], "vanilla_respons": 4, "vanish": 20, "var": 32, "vari": [3, 25, 26], "variabl": [0, 1, 3, 17, 19, 20, 21, 27, 29, 31], "varianc": 21, "variant": 20, "variat": 5, "varieti": [17, 27, 29], "variou": [2, 3, 4, 6, 17, 18, 24, 25, 26, 27, 28, 29, 30, 31], "vast": [20, 27], "vaswani": 9, "vdim": 23, "ve": 24, "vec": 32, "vecor": 28, "vector": [3, 4, 16, 17, 20, 21, 23, 28, 31], "vector_store_index": 4, "vectorstor": 4, "vectorstorageindex": 4, "vectorstoreindex": 4, "vegetarian": 27, "verb": 5, "verbos": [4, 27], "veri": [2, 3, 4, 17, 18, 21, 22, 23, 24, 25, 26, 27, 29], "versa": [23, 26], "version": [0, 1, 2, 3, 17, 20, 23, 26, 27, 31], "vf_coef": 4, "via": [0, 1, 2, 3, 4, 5, 17, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "vice": [23, 26], "vicuna": [1, 2, 3], "video": [6, 17], "vietnames": 21, "view": [27, 28], "vig": 16, "vignett": 5, "vision": [22, 24, 30], "visual": [3, 4, 5, 17, 23, 25, 30], "vivid": [2, 3], "vocab": [23, 32], "vocab_s": 23, "vocabulari": [0, 1, 3, 17, 20, 21, 23, 24, 25, 31], "vocabulary_s": [0, 1], "volum": 3, "vote": 3, "w": 1, "w_": [1, 25], "w_f": 32, "w_i": [1, 25], "wa": [0, 1, 2, 3, 4, 5, 17, 21, 22, 23, 25, 26, 27, 29, 30, 31], "wai": [0, 1, 2, 3, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 31], "wait": [2, 3], "walk": [3, 5, 28], "wall": 17, "walmart": [2, 3, 17], "wang": [10, 16], "want": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "waren": 29, "warm": 26, "warn": [19, 20, 21, 23, 26, 31], "warsaw": 31, "wash": 20, "wasn": 3, "wave": [2, 3], "we": [0, 1, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "weak": 17, "weaker": 29, "wear": [2, 3], "web": 17, "webbbook": 6, "webbook": 25, "webook": 17, "websit": [0, 1, 22, 23, 27], "webson": [10, 30], "week": [17, 22, 24], "weekli": 6, "wei": 10, "weigh": 4, "weight": [0, 1, 18, 20, 22, 23, 24, 26, 28, 29, 31], "weight_decai": 22, "weight_norm": 20, "weights1": 1, "weights2": 1, "weights3": 1, "weights4": 1, "welcom": 29, "well": [0, 1, 2, 3, 4, 5, 7, 17, 21, 22, 23, 24, 26, 28, 29, 31], "went": 31, "were": [1, 2, 3, 4, 10, 17, 23, 25, 26, 29, 30, 31], "weren": 23, "what": [0, 1, 2, 3, 4, 5, 6, 10, 13, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "when": [0, 1, 3, 4, 5, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31], "whenev": 17, "where": [0, 1, 2, 3, 4, 5, 6, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "wherea": 3, "wherein": [4, 29], "whether": [0, 1, 2, 3, 5, 17, 22, 24, 26, 28, 29, 30, 31], "which": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "while": [0, 1, 2, 3, 4, 17, 20, 21, 22, 23, 24, 25, 26, 29], "white": [2, 3], "whitespac": [17, 23], "who": [3, 6, 17, 23, 24], "whole": [1, 27, 29], "whose": [24, 26, 30], "why": [2, 3, 4, 5, 17, 20, 21, 23, 25, 26, 28, 29, 30, 31], "why_not_sparsity_fast_path": 23, "wide": [26, 29], "wider": 3, "widespread": 23, "width": [18, 21], "wiggl": 20, "wikipedia": [17, 27, 29], "wikipediaapiwrapp": 17, "wikipediaqueryrun": 17, "wikitext": 29, "wilcox": 5, "wild": 16, "window": [3, 4, 17, 28, 29], "wing": [3, 25], "winogend": 29, "winogrand": 30, "wise": [18, 24], "within": [4, 17, 22, 23, 25, 29, 31], "without": [0, 1, 3, 17, 18, 22, 25, 27, 29, 31], "wizardlm": 1, "wkipedia": 29, "wo": 31, "woman": [2, 3], "women": [2, 3], "won": 3, "word": [0, 1, 2, 3, 4, 13, 17, 20, 22, 23, 24, 25, 26, 28, 30], "word2vec": [7, 16, 17], "wordpiec": 23, "work": [0, 1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 20, 21, 23, 24, 25, 26, 29, 31], "worker": [3, 17], "workflow": 22, "worksheet": 6, "world": [1, 18, 30], "worri": 29, "wors": [24, 26], "worthwhil": 20, "would": [1, 3, 5, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "wouldn": 23, "wpe": 23, "wrangl": [0, 1, 22, 29], "wrapper": [17, 22, 23, 31], "write": [0, 1, 2, 3, 5, 20, 21, 22, 23, 24, 26, 27, 29, 30, 31], "written": [2, 3, 4, 26, 29], "wrong": [1, 13, 30], "wrongfuldeath": 17, "wte": 23, "www": 4, "x": [0, 1, 5, 6, 17, 18, 20, 21, 23, 25, 26, 28, 31, 32], "x_": 29, "x_0": 29, "x_1": [0, 1], "x_2": [0, 1], "x_i": 29, "x_n": 29, "x_ob": 20, "x_test": [0, 1], "xaxi": 31, "xie": 10, "xl": 29, "xlabel": [0, 1, 17, 22], "xxx": [0, 1], "y": [1, 5, 17, 18, 20, 25, 31, 32], "y_1": [0, 1, 26], "y_2": [0, 1, 26], "y_3": [0, 1], "y_nois": 20, "y_normal": 20, "y_ob": 20, "y_pred": 20, "yao": 10, "yard": 3, "yaxi": 31, "ye": [1, 4, 21, 22, 28, 30], "year": [2, 3, 17], "yet": [4, 17, 21, 22, 26, 28], "ygjpt2red3": 17, "yield": 18, "ylabel": [0, 1, 22], "york": 3, "you": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "young": 3, "younger": 3, "your": [0, 1, 2, 3, 4, 5, 10, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "your_api_kei": 27, "yourself": [0, 1, 4, 17, 20, 21, 22, 23, 24, 25, 31], "youself": 20, "yu": 16, "z": [17, 20, 32], "z1": 17, "z2": 17, "z37ijmcqzb": 17, "z_0": 32, "zero": [0, 1, 2, 3, 10, 18, 19, 20, 21, 23, 24, 29, 31], "zero_grad": [1, 19, 20, 21, 28], "zeroshot": 17, "zhao": 7, "ziegler": 4, "zip": [0, 1, 4, 5, 28, 29], "zoom": [2, 3, 4, 5, 28, 30], "\u00fcber": 23, "\u03f5": 1, "\u03f5r": 1, "\ud835\udc4e": 3}, "titles": ["Homework 1: Language models (50 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LLMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Implications, Understanding &amp; Philosophy", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "titleterms": {"": [5, 20], "1": [0, 1, 2, 3, 4, 5, 17, 18, 19, 23, 25, 26, 27, 28, 29, 31], "10": 5, "12": [0, 1], "13": 5, "14": [2, 3], "15": [0, 1, 4], "16": [2, 3], "2": [0, 1, 2, 3, 4, 5, 18, 19, 20, 21, 22, 24, 25, 27, 30], "20": [2, 3], "22": 5, "23": [0, 1], "3": [0, 1, 2, 3, 4, 5, 19, 20, 23, 24, 25], "30": 4, "4": [5, 19, 21, 26], "5": [4, 5, 19, 22, 27], "50": [0, 1, 2, 3], "6": 28, "7": [29, 30], "8": 31, "activ": 31, "addit": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "advanc": [2, 3, 20, 30], "agent": [4, 12, 27], "ann": 8, "answer": 1, "ar": 5, "arithmet": 18, "aspect": [4, 30], "assess": [14, 18, 29], "assist": 30, "attent": [23, 28], "attribut": [13, 18, 28], "audienc": 6, "augment": 4, "autograd": 20, "background": 7, "backprop": 19, "backpropag": 19, "behavior": [14, 29], "benchmark": [29, 30], "best": 17, "bias": 5, "bpe": 23, "broadcast": 18, "build": 4, "built": 20, "capabl": 5, "charact": 21, "choic": [2, 3], "code": 17, "colab": 17, "column": 18, "commonsenseqa": 3, "comput": [19, 20], "concept": 17, "concis": 20, "configur": 24, "consist": 30, "core": 17, "cours": 6, "creat": 18, "current": [10, 19], "data": [17, 18, 19, 20, 21], "dataset": [3, 17], "decod": [25, 31], "defin": [20, 21], "definit": 20, "distribut": 19, "document": 17, "dynam": 24, "earli": 31, "eo": 23, "error": 19, "essenti": 18, "estim": 19, "evalu": [1, 5, 14, 21, 28, 29, 30], "excercis": 27, "exercis": [0, 1, 2, 3, 4, 5, 24, 25], "experi": 3, "explicit": 20, "extract": [0, 1], "few": 3, "fine": [0, 1, 4, 11, 26], "fingerprint": [0, 1], "first": [2, 3], "flavour": 26, "formalia": 6, "function": 21, "further": 6, "gener": [2, 3, 4, 21], "global": [20, 21], "gpt": [0, 1], "gradient": 19, "grammat": 5, "graph": 20, "hallucin": 30, "handl": 27, "head": 24, "helper": 21, "homework": [0, 1, 2, 3, 4, 5], "how": 5, "huggingfac": 22, "human": 5, "implic": 15, "index": 18, "infer": [3, 21], "inform": 19, "inspect": 21, "instal": 17, "intend": 6, "interpret": [16, 24, 31], "introduct": 22, "invert": 21, "iter": 6, "join": 18, "just": 18, "knowledg": [3, 30], "langchain": 27, "languag": [0, 1, 3], "layer": 20, "level": 21, "like": 5, "linear": 20, "llama": 5, "llm": [0, 1, 4, 5, 6, 12, 27, 28], "lm": [2, 3, 8, 10, 22], "load": 21, "local": 17, "logist": [0, 1, 2, 3, 4, 5], "loop": 19, "loss": 19, "lstm": 9, "machin": 29, "main": 17, "mask": [23, 24], "materi": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], "matrix": 18, "mechanist": [16, 31], "memori": 27, "method": [13, 28], "metric": 29, "ml": [19, 22], "mlm": 24, "mlp": 20, "model": [0, 1, 20, 21, 22, 24, 26], "modul": 20, "more": 20, "multipl": [2, 3, 18], "natur": 3, "network": 21, "neural": [2, 3], "nli": [2, 3], "nn": 20, "non": 20, "numersens": 3, "oper": 18, "optim": 19, "option": [20, 23, 24, 26], "outlook": [20, 22, 23, 24, 26, 29], "output": 27, "overview": 6, "packag": [19, 20, 21], "paramet": [19, 20, 21], "pars": 27, "part": 19, "patch": 31, "peft": 26, "philosophi": 15, "point": [0, 1, 2, 3, 4, 5], "polici": 26, "possibl": 1, "ppo": 26, "practic": [17, 26], "predict": 19, "prepar": 20, "pretrain": 23, "previou": 6, "probe": 28, "problem": 30, "process": [17, 30], "prompt": [2, 3, 10, 25], "psychologi": 29, "pytorch": [8, 18, 20, 23], "qa": [0, 1, 2, 3], "reason": 30, "regress": 20, "requir": 17, "reset": 19, "reshap": 18, "residu": 31, "retriev": 4, "reward": 26, "rl": [4, 26], "rlhf": [4, 11], "rnn": 21, "row": 18, "schedul": 6, "scheme": [3, 25], "second": 1, "sequenc": 21, "set": 17, "sheet": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "shot": 3, "signal": 19, "slice": 18, "social": 30, "societ": 5, "solv": 30, "special": 23, "split": 21, "step": 17, "strategi": [2, 3, 25], "stream": 31, "summar": 4, "supervis": 26, "surpris": 5, "system": [4, 12], "tensor": 18, "test": [21, 29], "token": 23, "tool": 27, "train": [17, 19, 20, 21, 24, 26, 28], "transform": [9, 22, 23, 24], "transpos": 18, "true": [19, 20], "tune": [0, 1, 4, 11, 26], "type": 18, "understand": [0, 1, 5, 6, 15, 17], "up": 17, "updat": 19, "us": 20, "util": [20, 24], "valu": [18, 19], "vector": 18, "verifi": 17, "via": 22, "visual": 28, "w": [20, 21], "work": 22, "write": 17}})