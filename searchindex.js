Search.setIndex({"alltitles": {"1. Second Possibility": [[2, "second-possibility"]], "1.1 evaluation": [[2, "evaluation"]], "1.2 evaluation": [[2, "id1"]], "1.3 evaluation": [[2, "id2"]], "Activation patching": [[32, "activation-patching"]], "Additional materials": [[8, "additional-materials"], [9, "additional-materials"], [10, "additional-materials"], [11, "additional-materials"], [12, "additional-materials"], [13, "additional-materials"], [14, "additional-materials"], [15, "additional-materials"], [16, "additional-materials"], [17, "additional-materials"]], "Advanced outlook: PyTorch Autograd and computational graph [optional]": [[21, "advanced-outlook-pytorch-autograd-and-computational-graph-optional"]], "Agents": [[28, "agents"]], "Answer Exercise 1: Understanding language modeling (12 points)": [[2, "answer-exercise-1-understanding-language-modeling-12-points"]], "Assessing just the values of a tensor": [[19, "assessing-just-the-values-of-a-tensor"]], "Assistant evaluation": [[31, "assistant-evaluation"]], "Attention masks": [[24, "attention-masks"]], "Attention visualization": [[29, "attention-visualization"]], "Attributes of a tensor": [[19, "attributes-of-a-tensor"]], "Attribution methods": [[14, null], [29, "attribution-methods"]], "BPE tokenization": [[24, "bpe-tokenization"]], "Background": [[8, null]], "Benchmark testing": [[30, "benchmark-testing"]], "Best practices for writing code": [[18, "best-practices-for-writing-code"]], "Broadcasting": [[19, "broadcasting"]], "Colab": [[18, "colab"]], "Core concepts": [[18, "core-concepts"]], "Course formalia": [[7, "course-formalia"]], "Course overview: Understanding LLMs": [[7, null]], "Creating a tensor": [[19, "creating-a-tensor"]], "Dataset documentation": [[18, "dataset-documentation"]], "Decoding schemes": [[26, "decoding-schemes"]], "Defining the MLP using PyTorch\u2019s built-in modules": [[21, "defining-the-mlp-using-pytorchs-built-in-modules"]], "Defining the model": [[22, "defining-the-model"]], "Early decoding": [[32, "early-decoding"]], "Evaluation": [[29, "evaluation"]], "Evaluation & behavioral assessment": [[15, null]], "Evaluation & inference": [[22, "evaluation-inference"]], "Excercise 5.1.1.2": [[28, "excercise-5-1-1-2"]], "Exercise 1: Advanced prompting strategies (16 points)": [[3, "exercise-1-advanced-prompting-strategies-16-points"], [4, "exercise-1-advanced-prompting-strategies-16-points"]], "Exercise 1: Building a retrieval-augmented generation system (30 points)": [[5, "exercise-1-building-a-retrieval-augmented-generation-system-30-points"]], "Exercise 1: Understanding grammatical capabilities of LLMs (10 points)": [[6, "exercise-1-understanding-grammatical-capabilities-of-llms-10-points"]], "Exercise 1: Understanding language modeling (12 points)": [[0, "exercise-1-understanding-language-modeling-12-points"], [1, "exercise-1-understanding-language-modeling-12-points"], [2, "exercise-1-understanding-language-modeling-12-points"]], "Exercise 2": [[4, "exercise-2"]], "Exercise 2: Evaluating societal biases (13 points)": [[6, "exercise-2-evaluating-societal-biases-13-points"]], "Exercise 2: Extracting LLM fingerprints (15 points)": [[1, "exercise-2-extracting-llm-fingerprints-15-points"], [2, "exercise-2-extracting-llm-fingerprints-15-points"]], "Exercise 2: Prompting for NLI & Multiple-choice QA (14 points)": [[3, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"], [4, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"]], "Exercise 2: RLHF for summarization (15 points)": [[5, "exercise-2-rlhf-for-summarization-15-points"]], "Exercise 2: Understanding LLM configuration (13 points)": [[0, "exercise-2-understanding-llm-configuration-13-points"]], "Exercise 3 (15 points):": [[0, "exercise-3-15-points"]], "Exercise 3.3.3.1.": [[26, "exercise-3-3-3-1"]], "Exercise 3.3.3.2.": [[26, "exercise-3-3-3-2"]], "Exercise 3.3.3.3": [[26, "exercise-3-3-3-3"]], "Exercise 3: Aspects of fine-tuning (5 points)": [[5, "exercise-3-aspects-of-fine-tuning-5-points"]], "Exercise 3: Fine-tuning GPT-2 for QA (23 points)": [[0, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"], [1, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"], [2, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"]], "Exercise 3: First neural LM (20 points)": [[3, "exercise-3-first-neural-lm-20-points"], [4, "exercise-3-first-neural-lm-20-points"]], "Exercise 3: LLM evaluations with LLMs (5 points)": [[6, "exercise-3-llm-evaluations-with-llms-5-points"]], "Exercise 4: How human-like are Llama\u2019s surprisals? (22 points)": [[6, "exercise-4-how-human-like-are-llama-s-surprisals-22-points"]], "Experiment Scheme": [[4, "experiment-scheme"], [4, "id2"]], "Few-Shot Prompting with CommonSenseQA": [[4, "few-shot-prompting-with-commonsenseqa"]], "Fine-tuning and RLHF": [[12, null]], "Flavours of fine-tuning": [[27, "flavours-of-fine-tuning"]], "Further materials": [[7, "further-materials"]], "Generated Knowledge Prompting with NumerSense Dataset": [[4, "generated-knowledge-prompting-with-numersense-dataset"]], "Hallucinations": [[31, "hallucinations"]], "Helper functions for training": [[22, "helper-functions-for-training"]], "Homework 1: Language models (50 points)": [[0, null], [1, null], [2, null]], "Homework 2: Prompting & Generation with LMs (50 points)": [[3, null], [4, null]], "Homework 3: LLM agents & RL fine-tuning": [[5, null]], "Homework 4: LLM evaluation": [[6, null]], "HuggingFace \ud83e\udd17": [[23, "huggingface"]], "Implications, Understanding & Philosophy": [[16, null]], "Indexing and slicing": [[19, "indexing-and-slicing"]], "Inference": [[22, "inference"]], "Installing requirements": [[18, "installing-requirements"]], "Intended audience": [[7, "intended-audience"]], "Interpreting training dynamics": [[25, "interpreting-training-dynamics"]], "Introduction: ML models": [[23, "introduction-ml-models"]], "Inverting the generation model": [[22, "inverting-the-generation-model"]], "Joining tensors": [[19, "joining-tensors"]], "Knowledge & Problem solving benchmarks": [[31, "knowledge-problem-solving-benchmarks"]], "LLM systems & agents": [[13, null]], "LSTMs & Transformers": [[10, null]], "LangChain": [[28, "langchain"]], "LangChain agent with tools": [[28, "langchain-agent-with-tools"]], "Loading & inspecting the data": [[22, "loading-inspecting-the-data"]], "Local installation": [[18, "local-installation"]], "Logistics": [[0, "logistics"], [1, "logistics"], [2, "logistics"], [3, "logistics"], [4, "logistics"], [5, "logistics"], [6, "logistics"]], "MLM masking": [[25, "mlm-masking"]], "Machine psychology": [[30, "machine-psychology"]], "Main training data processing steps": [[18, "main-training-data-processing-steps"]], "Matrix Multiplication": [[19, "matrix-multiplication"]], "Mechanistic Interpretability": [[17, null]], "Memory handling": [[28, "memory-handling"]], "Metrics": [[30, "metrics"]], "Model heads": [[25, "model-heads"]], "More concise definition of NN module": [[21, "more-concise-definition-of-nn-module"]], "More explicit definition NN module": [[21, "more-explicit-definition-nn-module"]], "Multiple-choice QA": [[4, "multiple-choice-qa"]], "Natural Language Inference": [[4, "natural-language-inference"], [4, "id1"]], "Operations on tensors": [[19, "operations-on-tensors"]], "Optimizing a parameter: gradients, optimizers, loss & backprop": [[20, "optimizing-a-parameter-gradients-optimizers-loss-backprop"]], "Optional outlook": [[27, "optional-outlook"]], "Outlook": [[23, "outlook"], [30, "outlook"]], "Outlook (optional)": [[24, "outlook-optional"]], "Outlook (optional): EOS tokens": [[24, "outlook-optional-eos-tokens"]], "Outlook and optional exercises": [[25, "outlook-and-optional-exercises"]], "Outlook: PEFT in practice": [[27, "outlook-peft-in-practice"]], "Outlook: PyTorch layers and utils [optional]": [[21, "outlook-pytorch-layers-and-utils-optional"]], "Output parsing": [[28, "output-parsing"]], "PPO training": [[27, "ppo-training"]], "Packages": [[20, "packages"]], "Packages & global parameters": [[21, "packages-global-parameters"], [22, "packages-global-parameters"]], "Part 1: Compute the predictions for current parameter value": [[20, "part-1-compute-the-predictions-for-current-parameter-value"]], "Part 2: Computing the loss for the current prediction": [[20, "part-2-computing-the-loss-for-the-current-prediction"]], "Part 3: Backpropagate the error signal": [[20, "part-3-backpropagate-the-error-signal"]], "Part 4: Update the parameter values": [[20, "part-4-update-the-parameter-values"]], "Part 5: Reset the gradient information": [[20, "part-5-reset-the-gradient-information"]], "Policy": [[27, "policy"]], "Preparing the training data": [[21, "preparing-the-training-data"]], "Pretrained tokenizers": [[24, "pretrained-tokenizers"]], "Pretrained transformers": [[24, "pretrained-transformers"]], "Previous iterations of the course": [[7, "previous-iterations-of-the-course"]], "Probing": [[29, "probing"]], "Process consistency": [[31, "process-consistency"]], "Prompting & Current LMs": [[11, null]], "Prompting strategies": [[26, "prompting-strategies"]], "PyTorch": [[24, "pytorch"]], "PyTorch, ANNs & LMs": [[9, null]], "RL fine-tuning": [[27, "rl-fine-tuning"]], "Reasoning benchmarks": [[31, "reasoning-benchmarks"]], "Reshaping": [[19, "reshaping"]], "Residual stream": [[32, "residual-stream"]], "Reward modeling": [[27, "reward-modeling"]], "Row & column vectors": [[19, "row-column-vectors"]], "Schedule": [[7, "schedule"]], "Sheet 1.1: Practical set-up & Training data": [[18, null]], "Sheet 2.1: PyTorch essentials": [[19, null]], "Sheet 2.2: ML-estimation": [[20, null]], "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)": [[21, null]], "Sheet 2.4: Character-level sequence modeling w/ RNNs": [[22, null]], "Sheet 2.5: Introduction to HuggingFace & LMs": [[23, null]], "Sheet 3.1: Tokenization & Transformers": [[24, null]], "Sheet 3.2: Transformer configurations & Training utilities": [[25, null]], "Sheet 3.3: Prompting & Decoding": [[26, null]], "Sheet 4.1 Supervised fine-tuning and RL fine-tuning": [[27, null]], "Sheet 5.1 LLM agents": [[28, null]], "Sheet 6.1 LLM probing & attribution": [[29, null]], "Sheet 7.1: Behavioral assessment & Evaluation": [[30, null]], "Sheet 7.2: Advanced evaluation": [[31, null]], "Sheet 8.1: Mechanistic interpretability": [[32, null]], "Social aspects": [[31, "social-aspects"]], "Special tokens": [[24, "special-tokens"]], "Supervised fine-tuning": [[27, "supervised-fine-tuning"]], "Tensor arithmetic": [[19, "tensor-arithmetic"]], "Tensor data types": [[19, "tensor-data-types"]], "Tensors": [[19, "tensors"]], "Tokenization": [[24, "tokenization"]], "Train-test split": [[22, "train-test-split"]], "Training": [[29, "training"]], "Training loop": [[20, "training-loop"]], "Training the model": [[21, "training-the-model"]], "Training the network": [[22, "training-the-network"]], "Training utilities": [[25, "training-utilities"]], "Transformers": [[24, "transformers"]], "Transposing": [[19, "transposing"]], "True distribution & training data": [[20, "true-distribution-training-data"]], "True model & training data": [[21, "true-model-training-data"]], "Understanding training data": [[18, "understanding-training-data"]], "Verifying requirement installation": [[18, "verifying-requirement-installation"]], "Working with LMs via \ud83e\udd17 Transformers": [[23, "working-with-lms-via-transformers"]]}, "docnames": ["homework/01-language-modeling", "homework/archive_2024/01-language-modeling", "homework/archive_2024/01_language_modeling_solutions", "homework/archive_2024/02-prompting", "homework/archive_2024/02-prompting_solution", "homework/archive_2024/03-agents-RL", "homework/archive_2024/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/09-philosophy", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["homework/01-language-modeling.ipynb", "homework/archive_2024/01-language-modeling.ipynb", "homework/archive_2024/01_language_modeling_solutions.ipynb", "homework/archive_2024/02-prompting.ipynb", "homework/archive_2024/02-prompting_solution.ipynb", "homework/archive_2024/03-agents-RL.ipynb", "homework/archive_2024/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/09-philosophy.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 2, 4, 5, 7, 16, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "0": [0, 1, 2, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "00": [18, 32], "000": [4, 6, 18], "0000": 19, "00000": 20, "0000001": 20, "00001": 33, "00005": 20, "00007": 20, "00012": 20, "00020": 20, "00033": 20, "0005": 22, "00055": 20, "00059": 20, "00091": 20, "00095": 20, "00097": 20, "001": 33, "00117": 20, "0013": 21, "00130": 20, "00138": 20, "00143": 20, "00146": 20, "00150": 20, "0017": 21, "002": 33, "0024": 21, "00248": 20, "00258": 20, "0028": 24, "0032": 24, "0037": 21, "0039": 24, "004": [21, 33], "00408": 20, "0044": 21, "0046": 24, "00523": 20, "0054": 19, "0059": 21, "006": 20, "0066": 21, "00673": 20, "0070": 24, "0076": 21, "009": 33, "0095": 24, "00960": 20, "01": 19, "0104": 24, "0109": 21, "011": 20, "01110": 20, "0113": 24, "01171875": 26, "012": 33, "0125": 28, "0126": 24, "013": 33, "013982772827148": 4, "0149": 21, "0155": 21, "0156": 24, "015838623046875": 4, "016": 21, "0164": 24, "0166": 21, "01680": 20, "01831": 20, "019416809082031": 4, "0195": 21, "0198": 24, "0199": 21, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 32, "02": [0, 1, 2, 19, 24, 26], "0204": 24, "021014213562012": 4, "0211": 21, "0225": 21, "0227": 21, "023": 21, "0235": 21, "0236": 24, "0239": 24, "0246": 21, "0250": 24, "0255": 2, "0257": 21, "0279": 21, "0282": 21, "02869": 20, "0292": 21, "0293": 24, "03": 24, "03019": 20, "03041934967041": 4, "0309": 21, "0312": 20, "031479835510254": 4, "0318": 24, "0319": 24, "031961441040039": 4, "033": 21, "033587316144933": 22, "0338": 21, "034": 21, "0348": 21, "035849571228027": 4, "0363": 24, "0365": 21, "0369": 21, "0370": 21, "03721284866333": 4, "0374": 21, "0383": 21, "0386": 21, "039": 21, "04": 19, "040278911590576": 4, "0419": 21, "042": 33, "0421": 21, "0429": [21, 24], "043": 21, "0434": 21, "0436": 21, "044040465112291": 22, "0446": 21, "04466724395752": 4, "0447": 21, "045": 33, "0451": 21, "0453": 21, "0454": 21, "0457": 24, "0458984375": 20, "046": 21, "0475": 24, "0479": 21, "04828": 20, "049187345280759": 22, "0493": 21, "04979": 20, "0499": 24, "05": [5, 22, 24], "0505": 21, "0509": 21, "0513": [21, 24], "0516": 24, "0519": 21, "05221": 30, "0523": 21, "0525": 24, "0528": 21, "05326": 4, "0533545017242432": 4, "0540814399719238": 4, "0546": 21, "0547": 21, "0552": 21, "055522918701172": 4, "0556": 21, "0562": 21, "0569": 24, "0575": 21, "0584": 24, "0588": 21, "059": 20, "0591": 21, "0592": 21, "06": 0, "0601": 24, "0612": 24, "0622": 21, "0644": 21, "0646": 21, "0655": 21, "0663": 21, "06640625": 26, "0666": 21, "0671": 21, "0675": 21, "0679": 21, "0695": 24, "0696": 24, "06977367401123": 4, "0706": [21, 24], "071": 21, "074": 21, "0758": 22, "076368400920858": 22, "0769": 21, "077": 33, "0787130945986387": 22, "0789": 21, "08": 33, "08060": 20, "08073": 27, "081": 33, "08211": 20, "083": 2, "0846": 24, "0849": 21, "0853": 21, "0854": 21, "086": 33, "0874": 24, "089089898243062": 22, "08965344": 33, "0909": 21, "0912": 21, "0915": [21, 24], "091569900512695": 4, "0917557944550413": 22, "0919": 24, "0924": 21, "092577934265137": 4, "0928": 21, "0934": 21, "0936": 21, "094": 33, "0941": 24, "094646453857422": 4, "0947": 21, "095": [21, 33], "0955": 21, "095916748046875": 4, "0964": 21, "0968": 21, "0972": 21, "0978": 24, "0994": 21, "0_0": 33, "0_1": 33, "0_4": 33, "0m": 22, "1": [21, 22, 23, 25, 31, 33], "10": [0, 1, 2, 4, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33], "100": [4, 18, 19, 20, 21, 22, 26, 28, 30, 32], "1000": [0, 1, 2, 20, 21, 26], "10000": [20, 21, 22, 24], "100000": 22, "10015": 20, "1002": 24, "100257": 0, "100277": 0, "1003": 24, "100352": 0, "1005": 24, "1006": 21, "1007": 21, "1009": 21, "101": 19, "1014": 21, "102": [4, 21], "1023": 33, "1024": [0, 5, 24, 27, 29], "1025": [21, 24], "1031": 21, "104": 21, "1041": 21, "1043": 24, "1050": 33, "1051": 21, "1056": 24, "1068": 33, "107": 21, "1071": 33, "108": 19, "1081": 22, "10x1": 21, "10x10": 21, "11": [4, 19, 21, 22, 24, 27, 33], "111": [19, 33], "1116": 21, "1128": 21, "1129": 21, "113": 21, "1132": 32, "1136": 21, "114": 19, "114116668701172": 4, "114299774169922": 4, "1143": 24, "11440658569336": 4, "1146": 21, "1149": [21, 33], "1157": 24, "1161": 21, "1163": 21, "1173": 24, "1174": 33, "1179": 21, "118": 21, "118217468261719": 4, "119": 21, "1196": 21, "12": [4, 18, 19, 22, 24, 32, 33], "121": 21, "122": 21, "1222": 21, "1229": 21, "124": 27, "1241": 21, "125": [2, 21, 22], "12500": 21, "1255": 33, "1259": 21, "12620735168457": 4, "1264": 21, "1269": 21, "1277": 21, "128": [5, 22, 24, 28], "129": 21, "1293": 21, "12th": 2, "13": [1, 2, 4, 21, 22, 26, 33], "1302": 26, "1304": 22, "1305": 21, "131": 21, "1315": 21, "1321": 21, "133": 21, "13390": 20, "1341121196746826": 4, "1344274634863063": 22, "13504695892334": 4, "13540": 20, "1359": 21, "1371": 21, "137311827640074": 22, "1385": 24, "139": 22, "1394": 21, "1396": 21, "13th": [0, 6], "13x1": 2, "13x13": 2, "13x2": 2, "13x3": 2, "14": [18, 19, 21, 22, 33], "140": 21, "1407": [21, 24], "1408": 21, "1417": 21, "142420768737793": 4, "14258": 20, "14259": 20, "1426": 21, "14260": 20, "14263": 20, "1427": 21, "14271": 20, "1428": 21, "14292": 20, "1432": 33, "1433": 21, "14350": 20, "1447": 21, "1449": 21, "145": 4, "14508": 20, "1452": 21, "1462": 21, "1464": 21, "147": 21, "1473": 24, "1481": 21, "149": 33, "1491": 21, "149327039718628": 4, "14937": 20, "15": [4, 18, 20, 21, 22, 25, 26, 33], "1500": 20, "15000": [21, 22], "1508": 4, "151": 21, "151007538987999": 22, "1517": 24, "1518": 21, "1524": 21, "1527": 21, "1548": 24, "156": 33, "1574": 21, "1587": [21, 24], "15948522": 33, "1596": [21, 24], "15th": 1, "16": [19, 21, 22, 23, 33], "1600": 21, "160m": [0, 6], "16102": 20, "1630": 21, "1632": 21, "1638": 21, "1640625": 26, "165120124816895": 4, "1652": [21, 26], "165630340576172": 4, "167": 2, "1671": 19, "1673": 24, "1674": 24, "1676781420602698": 22, "1682": 21, "17": [22, 28, 33], "1701001434279856": 22, "1727": 21, "1732": 21, "173294067382812": 4, "1744": [21, 24], "175": 33, "17500": 21, "176395016805715": 22, "1773": 33, "1774": 21, "1777": 22, "17835062349366": 18, "1784": 21, "179": 21, "1793": 21, "1796": 21, "1796875": 26, "179699897766113": 4, "18": [18, 21, 22], "1800": 22, "183": 22, "1839": 21, "184": 33, "1851": 33, "1861": 21, "1869": 24, "1871": 21, "1897": 21, "19": [22, 32], "1908": 21, "1909": 18, "191": 21, "1913": 24, "192": 33, "1924": 24, "1926": 33, "19274": 20, "1927830372943777": 22, "1945": 21, "195": 21, "1959": 21, "1961": 21, "1962": 21, "1966": 24, "1967": 21, "1969": 21, "1971399784088135": 4, "1976": 21, "198206901550293": 4, "1986": 9, "1991": 24, "199512481689453": 4, "1997": 10, "19pt": [0, 1, 2], "19th": 18, "1b": 27, "1e": [0, 21, 24], "1f": [0, 1, 2], "1gb": [1, 2], "1h": 7, "1m": 22, "1x1": 21, "1x10": 21, "1x13": 2, "1x18": 22, "1x3": 2, "2": [10, 11, 17, 18, 24, 27, 29, 30, 32, 33], "20": [5, 18, 19, 21, 22, 24, 30, 33], "200": [19, 22, 30], "2000": [19, 20, 22], "20000": [21, 22], "2003": [3, 4], "2009": 21, "201": [20, 33], "2011": 21, "2013": 8, "201595306396484": 4, "2016": 9, "2017": 10, "2018": [0, 1, 2, 12], "2019": [3, 4, 10, 14, 29, 30, 31], "202": 33, "2020": [5, 8, 17, 18], "2021": [6, 11, 14, 17, 31], "2022": [6, 11, 12, 13, 16, 17, 24, 26, 27, 30, 31], "2023": [8, 11, 12, 13, 16, 17, 27, 31], "2024": [7, 8, 13, 17, 32], "2027": 21, "2028": 21, "2029": 21, "203": 22, "203125": 26, "2032": 30, "2034": [24, 33], "2037": 21, "2050": [1, 2], "205616125930776": 22, "2063": 21, "2064": 33, "2068": 21, "2073": 21, "2081": 21, "209": [21, 22], "2095": 21, "2097": 21, "2099": 21, "21": [0, 1, 4, 18, 19, 21, 23, 33], "2106": 21, "21096220730527": 22, "2114": 19, "212": 21, "2122": 22, "2133": 21, "214": 33, "2143": 21, "2152": 24, "2154": 21, "216497421264648": 4, "2165": 21, "2170": [24, 33], "2174": 33, "21778265": 33, "2180": 21, "2182": 21, "2186": 21, "2188": 21, "2198": 21, "22": 33, "2201": 21, "2207": 30, "2208": 21, "2212": 27, "22179": 20, "2232": 21, "22330": 20, "2239": 21, "22500": 21, "2256": 21, "2263": 33, "2276": 21, "2283": 21, "23": [3, 4, 5, 6, 21, 22, 32, 33], "2304": [24, 27], "2313": 21, "2317": 21, "232": 22, "2323": 21, "2333": 21, "23339557647705": 4, "233652114868164": 4, "2337": 21, "2353": 21, "235928535461426": 4, "237": 21, "2371": 21, "2373": 21, "2380": 33, "2387": 24, "2389": 21, "2393": 21, "239646911621094": 4, "24": [2, 19, 20, 21, 22, 32, 33], "2400": 24, "2406": 21, "241": 22, "2411": 33, "2425": 21, "2455": 21, "2462": 21, "2468": 21, "247": 33, "2478": 21, "2482": 33, "24860143661499": 4, "249": [22, 33], "25": [2, 18, 21, 22, 26], "250": 5, "2500": [20, 21], "25000": [21, 22], "251": 21, "2518": 21, "25248486": 33, "253": [21, 33], "2532": 21, "2536": 21, "2537": 21, "2543": 21, "255": 21, "2553533346": 2, "2557": 21, "256": [21, 27], "2564": 21, "2576": 21, "2579": 21, "258166313171387": 4, "258934020996094": 4, "2591": 21, "2592": 24, "2595": 21, "25966188": 33, "2614": 24, "2615": 21, "262053290805339": 22, "2630": 21, "263005256652832": 4, "2633": 21, "2638578414917": 4, "264": 33, "2647": 21, "26594367422115": 22, "2664": 21, "267": 22, "268": 22, "2682": 21, "2689": 21, "269": 33, "2698": 21, "27": [5, 21, 22, 27, 33], "2706": 21, "2711": 21, "2712": 21, "271496772766113": 4, "2719710113848373": 22, "2738": 21, "2739": 26, "2746": 22, "27500": 21, "2758": 21, "276": [21, 32], "276028633117676": 4, "27648": 0, "277": 22, "27782917022705": 4, "279": 33, "28": 22, "2815": 21, "281587600708008": 4, "284": 20, "2842": 21, "2846": 21, "2852": 21, "286": [21, 24], "2862": 21, "2865": 21, "2872": 21, "289": 33, "28th": 5, "29": [0, 1, 2, 24, 27, 33], "2919": 21, "2934": 21, "2941": 21, "2944": 21, "295": 33, "2954": 21, "2955": 21, "2956": 21, "2958": 22, "2965": 21, "297": 22, "2971": 21, "297186851501465": 4, "2976": 21, "297685623168945": 4, "298": [21, 22, 33], "2984": 21, "2986": 21, "29901123046875": 4, "2d": [0, 1, 2], "2i": 24, "2m": 22, "2nd": [3, 4], "2pt": [0, 1, 2, 5], "2x1": 2, "2x13": 2, "3": [18, 19, 22, 23, 27, 28, 29, 30, 31, 32, 33], "30": [19, 21, 22, 33], "300": 19, "3000": 20, "30000": [21, 22], "3001": 21, "3009": 21, "300px": 19, "3011": 21, "3013": 21, "3025": 21, "3049": 21, "305": 33, "3072": 32, "309": 21, "3099": 21, "31": 33, "3114": 21, "313": 33, "315": 21, "3155701160430908": 4, "3162": 21, "32": [0, 1, 2, 18, 19, 21, 22, 24, 29, 33], "323": 33, "32500": 21, "3271989822387695": 4, "32869": 18, "329": 33, "329154273345582": 22, "33": [19, 22, 33], "3301": 22, "33044753": 33, "3338e": 19, "336479187011719": 4, "337": 33, "33744430690024": 22, "338": 33, "338224411010742": 4, "33836474": 33, "339978218078613": 4, "34": [19, 33], "3403": 21, "342": 21, "343545913696289": 4, "3442": 21, "3451": 21, "3486": 33, "3488": 21, "349": 33, "35": [1, 2, 22, 30], "3500": 20, "35000": [21, 22], "350m": 27, "3515625": 26, "352": 26, "353": 33, "358133316040039": 4, "36": [21, 22, 33], "3607": 22, "361309051513672": 4, "363598346710205": 4, "36674": 20, "3668": [22, 24], "367": 22, "368": 20, "36825": 20, "369648933410645": 4, "37": [21, 24], "370429039001465": 4, "370843410491943": 4, "3746": 21, "3750": 19, "37500": 21, "3759": 33, "3773": 21, "3793": 21, "3797": 21, "38": [21, 33], "383": 33, "384112744200534": 22, "3842": 21, "3850": 22, "3875": 21, "38808536529541": 4, "3889435308678326": 22, "3915": 21, "3927": 21, "3931": 21, "3938": 21, "394": 33, "3945": 33, "39453125": 26, "3946": 21, "3973": 21, "3f": [20, 21, 32], "3m": 22, "3x1": 2, "3x13": 2, "3x5": [0, 1, 2], "4": [0, 1, 2, 3, 4, 5, 18, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33], "40": [0, 1, 2, 19, 22], "400": 19, "4000": [19, 20], "40000": [21, 22], "4001": 21, "4005": 21, "4007": 21, "402": 33, "4070479577071051": 22, "4075": 21, "4078": 21, "407893180847168": 4, "4096": 0, "40b": 2, "41": [21, 22, 24, 33], "4100": 24, "410m": [3, 4], "4118": 21, "4123": 33, "4126": 21, "412652015686035": 4, "4141": 21, "415": 21, "41515987": 33, "4155": 21, "416": 21, "4167": 21, "417": 21, "419": 21, "419055938720703": 4, "419212341308594": 4, "41e": 5, "42": [4, 21, 33], "422": 21, "4230": 21, "424": [21, 33], "424176216125488": 4, "425": 21, "42500": 21, "4264": 21, "427": 21, "428": 21, "4293": 24, "43": [19, 21, 22, 33], "430": 21, "4315": 21, "432": 21, "433": 21, "434816360473633": 4, "436": 21, "4374993423367664": 22, "44": 33, "441": 21, "444": 33, "444657022227277": 22, "445": 33, "447": 21, "448": [26, 33], "4495": 21, "45": [21, 22, 25], "450": 21, "4500": [20, 21], "45000": [21, 22], "452256441116333": 4, "452688217163086": 4, "453125": 26, "454367770907213": 22, "4543e": 19, "4584479331970215": 4, "4591": 22, "4592": 21, "46": [21, 29], "461": 33, "4612": 21, "4614": 21, "4614875316619873": 4, "4619": 21, "462": 21, "4622": 33, "46240755": 33, "4627": 33, "465941429138184": 4, "466972351074219": 4, "467": 22, "46780014038086": 4, "47": [21, 33], "4716": 21, "473": 21, "4738": 24, "475": 21, "47500": 21, "4765625": 26, "4786": 21, "479": 21, "4803": 24, "4812": 21, "4826": 22, "484375": 26, "486684799194336": 4, "49": 22, "4921": 21, "4921875": 26, "4922e": 19, "4924": 19, "497": 21, "4b": [3, 4, 26], "4f": 22, "4gb": 5, "4k": [5, 27], "4m": 22, "4p": 4, "4pt": [0, 1, 2], "5": [0, 1, 2, 4, 18, 19, 21, 22, 24, 26, 27, 30, 31, 33], "50": [19, 22, 30], "500": [5, 20, 22, 23], "5000": [19, 20, 21, 22, 24], "50000": [21, 22], "500000": 0, "501": 33, "501969337463379": 4, "50257": 24, "503078942968957": 22, "5045": 21, "51": 21, "510452270507812": 4, "512": [5, 19, 27], "5120": 0, "5127": 21, "515718460083008": 4, "516082286834717": 4, "51792049407959": 4, "518067359924316": 4, "5181813091977734": 22, "519": 22, "52": [21, 22, 33], "520": 33, "520139694213867": 4, "520474433898926": 4, "5211": 21, "522": 21, "523": 2, "5242": 26, "5254": 24, "528425216674805": 4, "53": 33, "531": [19, 33], "5318": 21, "5321": 21, "533": 20, "5347": 26, "5388": 21, "538839340209961": 4, "539": 33, "5396": 21, "54": 22, "5437": 21, "5453": 21, "55": [21, 22], "5500": [20, 21], "55000": 22, "550px": 22, "5510": 21, "554006576538086": 4, "55483865737915": 4, "555357933044434": 4, "5575783252716064": 4, "557712239995114": 22, "5580": 21, "5581e": 19, "56": [19, 24, 33], "560m": 6, "5617": 21, "5625": 26, "5653": 21, "5669": 33, "57": 33, "570": 33, "5707610099012776": 22, "570777893066406": 4, "5713": 21, "5756": 21, "576825141906738": 4, "577406883239746": 4, "57964344": 33, "58": [0, 1, 2, 22], "5819": 21, "582685867418279": 22, "583547592163086": 4, "5863": 21, "5894": 22, "589640617370605": 4, "59": [0, 1, 2, 3, 4, 5, 6], "591": 20, "5919": 19, "5931": 21, "595": 21, "596774101257324": 4, "5973": 21, "5975": 21, "598419189453125": 4, "5_000": 23, "5d": [20, 21], "5e": [0, 1, 2, 23], "5f": 20, "5m": 22, "6": [0, 2, 4, 7, 19, 21, 22, 23, 24, 26, 27, 31, 32, 33], "60": [19, 22, 24], "600": 19, "6000": 20, "60000": 22, "6002087593078613": 4, "6004": 19, "6013": 21, "60135555267334": 4, "6017": 21, "6051": 21, "6051456928253174": 4, "60579": 20, "606": 33, "607": 33, "60729": 20, "6076": 21, "6087": 21, "6096": 21, "61": 21, "6114": 21, "61173964": 33, "612": 33, "612419128417969": 4, "612512588500977": 4, "6135": 21, "61604118347168": 4, "6166": 21, "6175335252350447": 22, "6177": 21, "6194": 21, "6196": 21, "6199": 21, "62": 24, "621": 33, "622293472290039": 4, "6223": 21, "6236846446990967": 4, "625": 26, "6265": 21, "628": 21, "631083488464355": 4, "63491153717041": 4, "635777473449707": 4, "638": [21, 22], "63901424407959": 4, "6393": 22, "639629364013672": 4, "64": [0, 1, 2, 20, 23, 24, 25], "6406": 26, "6411": 21, "642": 21, "64202727": 33, "6423": 21, "645": 20, "645547866821289": 4, "64605712890625": 4, "6464": 21, "65": [19, 21, 22], "650": 20, "6500": 20, "65000": 22, "650859832763672": 4, "651183128356934": 4, "6514": 21, "652": 22, "6531856900705275": 22, "655148983001709": 4, "6555": 21, "659232139587402": 4, "66": [21, 22], "6612294775126752": 22, "664": [21, 33], "6654": 21, "6659": 21, "666": 33, "668207168579102": 4, "6692703950843093": 22, "66d1a2d3ccf0": 2, "67": [0, 1, 2, 6, 21, 22], "671875": 4, "673873901367188": 4, "67534827": 33, "67751693725586": 4, "68": 33, "681248426437378": 4, "682": 20, "6834": [21, 33], "6843": 21, "687712669372559": 4, "6880": 21, "69": 21, "690098762512207": 4, "690305233001709": 4, "6925": 21, "695": 33, "6955": 21, "6pt": [0, 1, 2], "7": [2, 4, 5, 6, 18, 19, 21, 22, 26, 27, 28, 32, 33], "70": [19, 22], "7000": 20, "70000": 22, "703117370605469": 4, "7046": 22, "7076313495635986": 4, "708530902862549": 4, "7086": 21, "708761215209961": 4, "709": 22, "70b": [2, 27], "71": 22, "710489273071289": 4, "7110": 21, "7121": 21, "713": 33, "716": 33, "716580436309544": 22, "7169": 21, "7172": 21, "7179": 21, "7180": 22, "72": [19, 21, 22, 33], "724": 22, "726918229927053": 22, "7288": 21, "7293": 21, "7298": [21, 26], "73": [22, 33], "73061466217041": 4, "7308": 22, "736490726470947": 4, "738": [32, 33], "73959792": 33, "74": [22, 33], "740": 21, "743338584899902": 4, "743693795963553": 22, "7454": 21, "746094297468178": 22, "746541976928711": 4, "748946189880371": 4, "7494": 21, "7496": 21, "749650001525879": 4, "75": [0, 1, 2, 22, 29, 33], "7500": [20, 21], "75000": 22, "7501": 21, "7502": 21, "7523": 21, "7530": 21, "754240989685059": 4, "7552": 21, "7589095234870911": 4, "76": [5, 21, 30], "7634": 18, "7650": 21, "765625": 26, "7674624919891357": 4, "768": [24, 27, 29], "76948356628418": 4, "77": 21, "7734": 21, "7734375": 26, "7743": 21, "7748951742793246": 22, "7764": 21, "7767": 21, "776968002319336": 4, "78": [5, 33], "780394554138184": 4, "7873": 21, "790425300598145": 4, "7927885055542": 4, "792975425720215": 4, "79754031778924": 22, "798": 33, "7b": [3, 4, 24, 28], "8": [0, 4, 18, 19, 22, 26, 27, 33], "80": [18, 19, 22], "800": 4, "8000": 20, "80000": 22, "8005": 21, "8015": 33, "8022": 21, "8029": 22, "8056986331939697": 4, "8063146353260925e": 33, "8089478089254367": 22, "8123": 21, "815916061401367": 4, "816": 21, "8176": 21, "819": 33, "8191": 21, "819255000074138": 22, "82": 21, "8204474449157715": 4, "82045841217041": 4, "8224": 21, "8238": 26, "8264": 21, "83": [0, 1, 2, 21], "830539703369141": 4, "83149242401123": 4, "832415580749512": 4, "8325": 22, "8344": 22, "8362": 33, "83683439539813": 22, "8398610504968342": 22, "841059684753418": 4, "8415": 21, "843": 33, "84375": 26, "8441": 21, "8467": 22, "84765625": 26, "85": 22, "8500": 20, "85000": 22, "85256576538086": 4, "8540": 21, "8546": 21, "854644775390625": 4, "85546875": 26, "857054710388184": 22, "858763694763184": 4, "8589": 21, "859375": 26, "863": 33, "864": 33, "8666": 21, "8668": 21, "8697": 21, "87": [19, 21], "879318062464732": 22, "88": [21, 33], "8839691281318665": 4, "884116172790527": 4, "8884e": 19, "888652801513672": 4, "889074325561523": 4, "89": [21, 24, 33], "8900933861732483": 4, "890667915344238": 4, "892": 22, "893194198608398": 4, "893522262573242": 4, "8970": 21, "8981": 21, "8b": 2, "9": [4, 18, 19, 22, 26, 33], "90": [19, 21, 22], "9000": 20, "90000": 22, "9023": 21, "9025": 21, "9025e": 19, "90373899401307": 22, "90455436706543": 4, "9046": 21, "905": 33, "9054934978485107": 4, "9079": 21, "908905029296875": 22, "909": 33, "909016609191895": 4, "91": [0, 1, 2, 33], "9101": 21, "9163": 21, "9164": 21, "9166837202752751": 22, "918338775634766": 4, "9185": 21, "9190526549711127": 22, "921": 33, "921186923980713": 4, "9245": 21, "9253905269010243": 22, "929475784301758": 4, "9338192343711853": 4, "94": [21, 22], "94018840789795": 4, "9408": 22, "941": 22, "943814170795518": 22, "9444": 21, "9450": 21, "945132093597879": 22, "9468": 21, "9476": 21, "95": 22, "9500": 20, "95000": 22, "9520": 21, "9521": 21, "9536": 21, "9538": 21, "9543": 18, "955": 33, "955305576324463": 4, "95555591583252": 4, "9574": 21, "959": 21, "96": 24, "9640": 21, "9653": 21, "9675": 22, "97": 32, "9718918800354": 4, "972271919250488": 4, "975": 20, "975641382951965": 22, "976": 20, "977": 20, "979": 20, "9820": 33, "9830674364599212": 22, "98336813": 33, "984375": 26, "986": 20, "986560821533203": 4, "987": [21, 33], "988": 20, "989767319373302": 22, "99": 22, "991": 22, "9920": 21, "9964": 21, "9989984954101563": 20, "9994": 21, "9999999999999994": 22, "9ect": 7, "A": [0, 1, 2, 3, 4, 5, 6, 8, 13, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33], "AND": [0, 1, 6], "And": [19, 28], "As": [4, 13, 21, 23, 24, 26, 27, 28, 29, 30, 31], "At": [24, 28], "Be": 5, "Being": 20, "But": [4, 19, 26, 28], "By": [20, 24, 27], "FOR": 6, "For": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "IT": [0, 1, 28], "If": [0, 1, 2, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 27, 29, 30, 31, 32], "In": [0, 2, 3, 4, 5, 6, 7, 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "It": [2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "Its": [19, 27], "NOT": [1, 2, 5, 18, 23, 27, 28, 31], "No": 2, "Not": [13, 22, 28], "Of": [26, 27, 28], "On": [0, 1, 2, 16, 18, 23, 26], "One": [4, 18, 22, 25, 27, 28, 29, 30, 31, 32], "Or": 19, "Such": [18, 30], "THE": 30, "TO": [0, 1], "That": [4, 18, 21, 23, 24, 27, 31], "The": [0, 1, 2, 3, 4, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "Their": [11, 32], "Then": [5, 24, 25], "There": [0, 1, 2, 3, 4, 7, 18, 19, 20, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32], "These": [2, 5, 18, 21, 22, 23, 24, 26, 27, 28, 30, 31, 32], "To": [3, 4, 5, 7, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30, 32], "With": [0, 1, 2, 19, 23, 26], "_": [2, 5, 27, 32], "__dict__": 24, "__future__": 22, "__getitem__": [1, 2, 21], "__init__": [1, 2, 21, 22, 24, 29, 32], "__len__": [1, 2, 21], "__name__": 4, "_backward_hook": 24, "_backward_pre_hook": 24, "_buffer": 24, "_forward_hook": 24, "_forward_hooks_always_cal": 24, "_forward_hooks_with_kwarg": 24, "_forward_pre_hook": 24, "_forward_pre_hooks_with_kwarg": 24, "_is_full_backward_hook": 24, "_is_hf_initi": 24, "_load_state_dict_post_hook": 24, "_load_state_dict_pre_hook": 24, "_modul": 24, "_non_persistent_buffers_set": 24, "_paramet": 24, "_qkv_same_embed_dim": 24, "_state_dict_hook": 24, "_state_dict_pre_hook": 24, "a_i": 26, "a_list": 19, "ab": [1, 2, 20, 21, 30], "abbrevi": 23, "abil": 31, "abise": 5, "abl": [0, 1, 2, 4, 18, 19, 22, 23, 24, 25, 27, 31, 32], "about": [0, 3, 4, 5, 6, 7, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "abov": [0, 1, 2, 3, 4, 5, 6, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "absenc": 31, "absolut": [23, 24, 27, 29], "abstract": [4, 18, 23, 27, 31], "ac": 21, "acccess": 24, "acceler": [0, 1, 2, 3, 4, 5, 23, 27], "accept": [0, 1, 2, 4, 6, 28], "access": [1, 2, 4, 5, 18, 21, 23, 24, 26, 27, 29, 32], "accid": [3, 4], "accompani": 32, "accomplish": [18, 23, 28], "accord": [0, 1, 2, 18, 24, 31], "accordingli": 26, "account": [18, 23, 28], "accumul": [0, 1, 2, 20], "accur": 5, "accuraci": [0, 1, 2, 3, 4, 6, 25, 29, 30, 31], "achiev": [3, 4, 26, 27], "acquir": [0, 1, 2, 18], "across": [5, 6, 17, 29, 30], "act": [24, 32], "action": [5, 27], "activ": [0, 1, 2, 4, 17, 20, 21, 22, 23, 27], "activations_": 32, "actual": [0, 1, 2, 3, 4, 5, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "acycl": 21, "ad": [4, 18, 20, 23, 24, 25, 26, 28], "adam": [21, 22, 29], "adamw": [0, 1, 2], "adapt": 32, "add": [18, 19, 21, 22, 24, 28, 32], "add_hook": 32, "add_mid_attn_hook": 32, "add_zero_attn": 24, "addit": [5, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30], "additioanli": 23, "additioanlli": [0, 1, 2], "addition": [0, 1, 2, 5, 18, 22, 27, 29, 31], "additional_dim": 23, "address": [26, 29, 30], "adequ": 18, "adher": 18, "adjust": [18, 23, 24, 26, 31], "admir": 27, "advanc": [5, 7, 18, 23, 26], "advantag": [5, 18, 25, 27, 28, 30], "affect": [5, 26, 27, 32], "afford": 13, "after": [0, 1, 2, 4, 18, 20, 21, 23, 24, 25, 26, 27, 32], "again": [2, 18, 20, 21, 24, 25, 26, 27, 28, 32], "against": [5, 22, 25, 30], "agent": [1, 2, 7, 27], "agent_executor": 28, "agent_hf": 28, "agent_hf_executor": 28, "agent_with_tool": 28, "agentexecutor": 28, "aggress": 20, "agnet": 28, "agre": [6, 22], "agreement": 6, "ahead": 18, "ahn": 13, "ahv": 29, "ai": [5, 7, 16, 27], "aim": [4, 30, 31], "aimia": 18, "airplan": [3, 4], "airport": [3, 4], "aka": 17, "al": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 24, 26, 27, 29, 30, 31, 32], "algebra": 19, "algorithm": [5, 6, 24, 25, 26, 27, 31, 32], "alic": 27, "alien": 27, "align": [2, 7, 27], "all": [0, 1, 2, 4, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "all_hidden_st": 29, "all_lett": 22, "all_loss": 22, "alloc": 22, "allow": [0, 1, 2, 3, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32], "allrecip": 28, "almost": [18, 26, 28], "along": 26, "alongsid": 4, "alpha": 21, "alphabet": [18, 24], "alreadi": [5, 18, 19, 23, 24, 26, 27, 28, 30, 31, 32], "also": [0, 1, 2, 3, 4, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "alter": [2, 22], "altern": [2, 4, 19, 22, 23, 25, 27, 29, 30], "although": [4, 18, 26, 27, 30, 31], "alwai": [0, 1, 2, 18, 22, 26, 28, 30, 32], "am": 28, "american": 6, "amnes": 14, "among": [4, 7], "amount": [2, 18, 22], "an": [0, 1, 2, 3, 4, 5, 6, 7, 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "anaconda3": [0, 1, 18, 23, 24, 32], "analog": 6, "analys": [3, 4], "analysi": [6, 17, 25, 32], "anaphor_gender_agr": 6, "ander": 30, "anderen": 30, "andrej": 7, "ani": [0, 1, 2, 3, 4, 6, 18, 19, 21, 22, 23, 24, 26, 27, 29, 30, 31, 32], "anim": 4, "animate_subject_pass": 6, "annot": [18, 27, 29, 31, 32], "anoth": [3, 4, 6, 21, 22, 23, 24, 25, 29, 30, 31, 32], "another_tensor": 19, "answer": [0, 1, 3, 4, 5, 6, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "answer_id": 32, "answer_kei": 6, "answer_log_prob": [4, 26], "answer_opt": [0, 1, 2, 4, 6, 30], "answer_options_list": [0, 1, 2, 30], "answer_options_str": [0, 1, 2], "answer_prob": 32, "answer_scor": 30, "answer_scores_bloom": 6, "answer_scores_gpt2": 6, "answerkei": [0, 1, 2, 30], "anthrop": 27, "anticip": 18, "anymor": 22, "anyth": [0, 1, 2, 4, 18, 21, 24, 27], "ap": 4, "apart": 20, "apect": 27, "api": [23, 28, 29], "api_wrapp": 18, "appar": 31, "appear": 4, "append": [0, 1, 2, 4, 5, 22, 23, 24, 26, 27, 30, 32], "appet": 28, "appetizer_chain": 28, "appli": [4, 18, 19, 21, 22, 23, 24, 25, 29, 30, 32, 33], "applic": [1, 2, 5, 21, 22, 23, 24, 25, 29, 30, 31], "approach": [4, 5, 6, 7, 18, 24, 25, 26, 27, 28, 29, 30, 31], "appropi": [6, 18], "appropri": [6, 25, 30], "approxim": [18, 26, 30], "april": 18, "ar": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "arab": 22, "arang": [2, 24], "arc": 31, "architectur": [1, 2, 3, 4, 7, 18, 21, 22, 23, 24, 25, 27, 28, 29, 32], "architecture_quirk": [1, 2], "architecture_typ": [1, 2], "archiv": 18, "area": [4, 18, 27, 31], "aren": 24, "arg": [5, 18, 23, 24], "argmax": [4, 26, 30], "argsort": 32, "arguabl": [18, 30], "argument": [0, 1, 2, 19, 23, 24, 25, 27, 29, 30, 31], "aris": 25, "arithmet": 17, "around": [0, 1, 2, 3, 4, 18, 20, 21, 22, 23, 24, 26, 27, 28], "arrai": [19, 21, 29, 32, 33], "arriv": [0, 1, 2, 29, 32], "art": [0, 1, 2, 3, 4, 7, 18, 23, 24, 26, 27], "articl": [5, 18], "arxiv": [1, 2, 4, 27, 30], "as_query_engin": 5, "ascii": [22, 24], "ascii_lett": 22, "asian": 4, "ask": [4, 5, 6, 18, 21, 23, 27, 30, 31, 32], "aspect": [4, 6, 18, 24, 26, 27, 29, 30, 32], "aspet": 6, "assert": 29, "assess": [3, 4, 6, 18, 29, 31, 32], "assign": [1, 2, 6, 7, 18, 20, 22, 24, 25, 26, 27, 30, 31, 32], "assisst": 30, "assist": [5, 12, 24, 27], "assit": 31, "associ": [4, 17, 20, 26], "assum": [0, 1, 2, 23, 24, 25, 26], "assumpt": [30, 32], "atla": 4, "atom": 31, "attempt": [4, 29, 31], "attend": [3, 4, 23, 24, 25], "attent": [0, 1, 2, 4, 10, 18, 21, 26, 27, 32, 33], "attention_bia": 0, "attention_dropout": 0, "attention_mask": [0, 1, 2, 4, 18, 23, 24, 25, 26], "attic": [3, 4], "attiont": 29, "attn": [24, 32], "attn_": 32, "attn_dropout": 24, "attn_weight": 32, "attribut": [7, 24, 30, 32], "attribute_target": 29, "attributed_fn": 29, "attribution_model": 29, "audio": 23, "augment": 4, "author": [6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "auto": [0, 1, 4, 5, 18, 23, 24, 27], "autoag": 13, "autoclass": [23, 25], "autom": [23, 30], "automat": [0, 1, 2, 5, 13, 21, 23, 24, 25, 28, 30], "automodelforcausallm": [0, 1, 2, 4, 23, 25, 26, 27, 30, 32], "automodelforcausallmwithvaluehead": 5, "automodelforseq2seqlm": 29, "automodelforsequenceclassif": 27, "autonom": 13, "autonotebook": [0, 1, 4, 18, 23], "autotoken": [0, 1, 2, 4, 5, 18, 23, 24, 25, 26, 27, 29, 30, 32], "auxiliari": [22, 29], "avail": [0, 1, 2, 3, 4, 5, 6, 18, 19, 23, 26, 27, 28, 29, 30], "averag": [0, 1, 2, 4, 6, 18, 22, 26, 30], "average_tweet_length": 18, "avers": 4, "avg": 2, "avoid": [5, 24, 25, 26, 27, 28, 32], "aw": 26, "awai": [4, 18, 24], "awak": [3, 4], "awar": [27, 31], "award": 4, "awesom": 26, "axi": [0, 1, 33], "b": [0, 1, 2, 4, 5, 6, 18, 19, 21, 24, 27, 29, 30], "b_1": 2, "b_2": 2, "b_3": 2, "b_4": 2, "b_f": 33, "b_i": 2, "baai": 5, "bachelor": 7, "back": [9, 19, 23, 24, 26, 32], "backbon": [5, 25, 27, 28], "backend": [0, 1, 2, 4, 6, 18, 23, 26, 29, 30], "background": [3, 4, 5, 6, 12, 23], "backpropag": [9, 10, 29], "backward": [0, 1, 2, 20, 21, 22, 23, 29], "bad": [18, 20, 27], "bag": [3, 4], "baggag": [3, 4], "bai": [12, 27], "balanc": 25, "bank": [4, 18], "bar": [6, 31], "barefoot": 4, "barplot": 6, "base": [0, 1, 2, 3, 4, 5, 6, 11, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "basebal": 4, "baselin": 5, "basic": [2, 8, 18, 19, 20, 21, 22, 23, 28], "batch": [0, 1, 2, 5, 18, 21, 23, 24, 25, 27, 29, 32], "batch_first": 24, "batch_label": 29, "batch_repr": 29, "batch_siz": [0, 1, 2, 5, 21, 23, 29], "bay": 22, "bayesian": [11, 25], "bbq": 31, "bc": 21, "bd": 21, "bd0xbfgjkt": 18, "beam": [3, 4, 26], "beam_search_decod": 4, "bear": 31, "becam": [30, 31], "becaus": [0, 1, 2, 4, 5, 18, 20, 21, 22, 23, 24, 25, 27, 30, 32], "becom": [20, 21, 30], "been": [4, 5, 6, 18, 23, 24, 25, 26, 27, 29, 30, 31, 32], "befor": [0, 1, 2, 3, 4, 5, 6, 18, 21, 22, 23, 27, 28, 30, 32], "begin": [2, 18, 23, 24, 26, 27, 33], "behav": 32, "behavior": [4, 5, 6, 13, 14, 21, 26, 27, 31], "behind": [18, 20, 21, 24, 27, 28, 29, 30, 32], "behvaior": 31, "being": [0, 1, 2, 4, 5, 20, 23, 25, 26, 27, 31, 32], "beings": [4, 26], "believ": [4, 31], "belong": 23, "below": [1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "bench": [30, 31], "benchmark": [4, 6, 15, 18, 26], "bender": 31, "benefici": 31, "benefit": 25, "bengio": [3, 4, 9], "berlin": 29, "bert": [3, 4, 10, 21, 23, 24, 25, 29], "bert_tok": 25, "bertmodel": 29, "berttoken": 29, "bertviz": [18, 29], "besid": [3, 4], "best": [3, 4, 5, 20, 25, 26, 27, 30], "beta": [30, 33], "better": [3, 4, 7, 18, 20, 22, 24, 28, 30], "between": [3, 4, 5, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32], "beyond": [11, 18, 24, 30, 31], "bge": 5, "bia": [2, 6, 17, 21, 24, 27, 30, 31, 33], "bias": [18, 21, 27, 30, 31], "bias_k": 24, "bias_v": 24, "bidirect": [3, 4, 10, 25], "big": [3, 4, 30, 31], "bigger": 21, "bigram": 30, "bigscienc": 6, "billion": 28, "bin": 18, "binari": [25, 27, 30], "biologi": 31, "bird": [0, 4, 26], "bit": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 22], "bite": 28, "bitnet": 2, "bitsandbyt": 5, "black": [4, 18], "blackbox": [23, 30, 32], "blank": 22, "bleu": 30, "bleu_scor": 30, "blimp": 6, "blob": [27, 32], "block": [0, 5, 18, 21, 24, 27, 28, 29, 32], "blog": [2, 5, 26, 27], "blogpost": [12, 13, 17, 21, 27, 30, 31], "bloom": [2, 6], "bloom_predict": 6, "bloom_scor": 6, "bloomtokenizerfast": 32, "blue": 4, "bmatrix": [24, 33], "bnb_4bit_compute_dtyp": 27, "bnb_4bit_quant_typ": 27, "bnb_4bit_use_double_qu": 27, "bnc": 18, "bo": [2, 24, 26, 33], "bodyguard": 4, "boe": 18, "boi": [3, 4], "bommasani": 16, "bonu": 5, "book": [1, 2, 4, 7, 18], "bookstor": 4, "bool": 19, "boolean": 19, "boolq": 30, "boredom": [3, 4], "born": 6, "borrow": 22, "bos_token_id": 0, "bot": 18, "both": [2, 4, 5, 6, 7, 18, 19, 20, 22, 23, 24, 25, 27, 30, 31], "bottl": 32, "bottleneck": 28, "bpe": [1, 2], "brake": 4, "braun": 24, "break": [4, 28], "brian": 7, "bridg": [3, 4], "brief": [0, 1, 2, 3, 4, 6, 26], "briefcas": 4, "briefli": [3, 4, 5, 6, 24, 25, 27], "bright": [3, 4], "bring": 6, "britain": 4, "british": 18, "broad": 27, "broadli": 27, "broken": [3, 4], "brown": [4, 18, 24, 25, 29], "brows": 23, "bruckner": 22, "brun": 29, "brush": 27, "btig": 18, "bug": 5, "bui": [4, 18], "build": [3, 4, 6, 18, 19, 21, 23, 24, 26, 27, 28, 29, 30], "build_classifi": 29, "build_dataset": 5, "bullet": 27, "bullish": 18, "bye": 6, "bynd": 18, "byte": 24, "bytest": 25, "c": [0, 1, 2, 4, 5, 6, 19, 21, 22, 24, 27, 30], "c_attn": 24, "c_fc": 24, "c_proj": 24, "cach": 32, "cacul": 2, "cage": 28, "calcul": [0, 1, 2, 4, 5, 6, 21, 22, 24, 27, 30, 32, 33], "calculu": 21, "calibr": 30, "call": [2, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "calucl": 2, "came": 6, "camera": [3, 4], "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "candid": 20, "cannot": [3, 4, 18, 23, 24, 29, 30], "cap": 21, "capabl": [30, 31], "capac": 27, "capit": [26, 29, 32], "caption": 24, "captur": [6, 22, 25, 27], "car": 4, "carcass": [4, 23], "care": [3, 4, 5, 18, 19, 23, 28, 30, 32], "carefulli": [0, 1, 2, 3, 4, 24, 29], "caribbean": 18, "carniv": 18, "carolina": 4, "carperai": 27, "carri": [4, 18, 24], "carrier": 4, "case": [0, 1, 2, 4, 5, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32], "cashier": 6, "cast": 19, "cat": [0, 1, 2, 4, 19, 22, 23], "catastroph": 27, "categori": [1, 2, 6, 22, 25, 27, 30], "category_tensor": 22, "category_tensor_": 22, "cauliflow": 28, "caus": 6, "causal": [0, 1, 2, 17, 23, 24, 25, 26, 29, 30, 32], "causallm": 25, "cc": 18, "ccl": 18, "cdot": [2, 30], "ce": 21, "ceil": 4, "cell": [0, 5, 6, 18, 23, 25, 32], "celoss": 23, "cemex": 18, "center": 26, "central": 18, "ceo": 18, "certain": [6, 18, 20, 21, 24, 25, 26, 29, 30, 32], "cfg": 32, "cg": 21, "chain": [0, 1, 2, 11, 21, 26, 28, 31], "challeng": [4, 31], "chanc": 30, "chang": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 23, 25, 26, 27, 29, 30, 31], "char": [18, 19, 33], "charact": [18, 19, 24, 25], "character": 17, "charactersitc": 1, "chat": [5, 11, 24, 27, 28], "chatgpt": 12, "chatopenai": 28, "cheat": 8, "check": [3, 4, 5, 6, 18, 19, 21, 24, 25, 26, 27, 29, 30, 31, 32], "checkpoint": [23, 30], "chek": 24, "chen": 13, "chicago": 26, "chien": 29, "childhood": 31, "children": [3, 4, 31], "chimnei": 30, "chines": 22, "chip": 18, "choic": [0, 1, 2, 5, 6, 18, 23, 25, 26, 27, 28, 30, 31], "choir": 4, "chollet": 31, "choos": [18, 20, 22, 25, 26, 27, 30, 32], "chop": 5, "chosen": [5, 26, 27, 30], "chr": 4, "christian": 7, "chunk": [18, 30], "church": 4, "ci": 6, "circuit": 17, "cite": 5, "citi": [3, 4, 25, 26], "cl": 29, "claim": [1, 2], "class": [0, 1, 2, 3, 4, 5, 8, 11, 12, 13, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 31, 32], "classic": 4, "classif": [3, 4, 12, 18, 21, 23, 25, 27, 30], "classifi": [3, 4, 22, 23, 29], "claud": 2, "claus": 6, "clean": [0, 1, 2, 3, 4, 18, 21, 32], "clean_cach": 32, "clean_logit": 32, "clean_logit_diff": 32, "clean_prompt": 32, "clean_resid_pr": 32, "clean_token": 32, "clean_tweet": 18, "cleaned_dataset": 18, "cleaned_dataset_split": 18, "cleaned_tweet": 18, "cleanest": [4, 30], "clear": 21, "clear_output": 5, "click": [18, 19, 20, 21, 22, 23, 25, 27, 29], "clip": [21, 25], "clip_grad_value_": 21, "clone": 27, "close": [23, 25, 26, 27, 30], "closer": [21, 24, 26, 28, 31], "cloth": [3, 4], "cmd": 2, "cnn": 5, "cnn_dailymail": 5, "co": [5, 18, 24], "code": [0, 1, 2, 3, 4, 5, 6, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "coeffici": [5, 6], "coffe": [3, 4], "cognit": [7, 30], "cogsci": 7, "coher": 2, "col": 19, "col_vector": 19, "colab": [0, 1, 2, 3, 4, 5, 6, 23, 26, 27, 29], "cold": [3, 4], "collabor": 18, "collat": [5, 23], "collect": [1, 2, 4, 18, 22, 23, 27], "color": [3, 4, 21, 27, 29], "color_continuous_midpoint": 32, "color_continuous_scal": 32, "column": [0, 1, 2, 4, 18, 22, 30], "column_nam": [18, 23, 25], "com": [22, 27, 32], "comapr": 4, "comaprison": 30, "combin": [0, 1, 2, 4, 18, 22, 24, 25, 26, 30], "come": [3, 4, 6, 18, 22, 23, 24, 26, 27, 28, 30, 31], "comfort": 18, "comma": 0, "commend": 0, "comment": [0, 1, 2, 5, 6, 18, 23, 24], "commerici": 27, "commit": 18, "common": [0, 1, 2, 5, 18, 21, 23, 24, 25, 26, 27, 30, 31], "commonli": [5, 18, 21, 23, 24, 25, 27, 30, 31], "commonsens": [0, 1, 2, 4, 11], "commonsense_qa": [0, 1, 2, 30], "commonsenseqa": [0, 1, 2, 26, 30, 31], "commonsenseqadataset": [1, 2], "commun": [23, 27, 28, 31], "commut": 2, "comp": [0, 1, 2], "compact": 5, "compani": 30, "compar": [0, 1, 2, 3, 4, 5, 6, 19, 20, 22, 23, 26, 27, 28, 29, 30, 31, 32], "comparis": [26, 28], "comparison": [1, 2, 3, 4, 27, 30, 31, 32], "compelt": 6, "competit": [3, 4], "complementari": 26, "complet": [0, 1, 2, 4, 5, 6, 18, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32], "completion_to_prompt": 5, "complex": [19, 26, 28], "complex_np_island": 6, "complic": [21, 24], "compon": [0, 3, 4, 5, 17, 21, 24, 27, 28], "composed_chain": 28, "composed_result": 28, "composit": 31, "comprehens": [1, 2], "compulsori": 7, "comput": [0, 1, 2, 4, 5, 7, 11, 18, 19, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33], "compute_loss": 23, "con": 26, "concaten": [19, 26, 29], "concentr": 28, "concept": [2, 5, 7, 19, 21, 23, 24, 25, 26, 27, 31, 32], "conceptu": [0, 1, 3, 4, 5, 6, 7, 23, 24, 25, 27, 30, 31, 32], "concern": 6, "concis": 5, "conclud": 31, "conclus": [4, 31], "concpetu": 0, "concret": [3, 4, 20, 23, 24, 27, 28], "cond_prob_nam": 22, "conda": [18, 21], "condens": 21, "condit": [6, 20, 22, 30], "conditional_scor": [6, 30], "conduct": [2, 7], "confid": [6, 26, 30], "config": [0, 5, 23, 25], "configr": 0, "configur": [1, 2, 3, 4, 5, 23, 24, 26, 27], "configut": [0, 1, 2], "connect": [4, 18, 21, 31, 32, 33], "consecut": [4, 22], "consent": [1, 2], "consequ": [4, 26], "consid": [0, 1, 2, 3, 4, 6, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31], "consist": [4, 5, 6, 7, 11, 18, 20, 21, 22, 23, 24, 27, 30, 32], "constitu": 18, "constitut": [21, 23, 27], "constrain": 4, "constraint": 30, "construct": [0, 1, 2, 4, 5, 6, 19, 21, 22, 23, 26, 27, 28, 30, 31], "construct_test_sampl": [0, 1, 2], "contain": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31], "contamin": 30, "content": [3, 4, 18, 23, 24, 27, 31], "context": [0, 3, 4, 5, 6, 7, 11, 12, 14, 18, 19, 21, 23, 24, 25, 26, 27, 30, 31, 32], "context_input_id": [4, 26], "context_prompt": [4, 26], "context_window": 5, "contextev": 29, "contextu": [14, 24], "contextualis": 4, "continu": [4, 6, 22, 23, 25, 29, 30], "contradict": [3, 4], "contrast": [4, 6, 23, 24, 29, 30, 31], "contrast_prob_diff": 29, "contrast_target": 29, "contrastive_decod": 4, "contribut": [1, 2, 18, 24, 29, 32], "control": 28, "conv1d": 24, "conveni": [4, 21, 23], "convent": 18, "converg": [25, 27], "convers": [24, 27], "converst": [0, 1, 2], "convert": [0, 1, 2, 5, 18, 19, 23, 24, 29, 30], "convert_ids_to_token": 29, "cook": 27, "core": [0, 5, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32], "corner": [3, 4], "coronaviru": 18, "corpor": [3, 4], "corpora": [4, 18, 30, 31], "corpu": [0, 1, 2, 4, 18, 23, 24, 31], "correct": [0, 1, 2, 3, 4, 24, 25, 26, 27, 28, 30, 31, 32], "correct_answ": [4, 32], "correct_index": 32, "correcti": 30, "correctli": [5, 21, 22, 23, 24, 25, 27, 30], "correl": [6, 29, 30], "correspond": [0, 1, 2, 6, 21, 23, 24, 25, 27, 29, 30], "corrupt": 32, "corrupted_logit": 32, "corrupted_logit_diff": 32, "corrupted_prompt": 32, "corrupted_token": 32, "cosin": [21, 23, 24, 25, 27], "cosinesimilar": 21, "cost": 25, "costli": [4, 23, 27], "costum": 4, "cot": [3, 4], "cotterel": 7, "could": [2, 4, 5, 6, 18, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32], "count": [30, 31], "counterfactu": 14, "countri": [3, 4, 22], "country2idx": 22, "countrysid": 4, "cours": [1, 2, 4, 18, 23, 26, 27, 28, 32], "court": 26, "couru": 29, "courvil": 9, "cover": [0, 7, 11, 12, 13, 18, 23, 25, 26, 30], "coverag": 30, "cow": 4, "cpu": [0, 1, 2, 4, 5, 6, 18, 19, 23, 26, 27, 29, 30, 32], "crack": 4, "craft": 22, "crawl": [18, 30], "creat": [0, 1, 2, 4, 5, 6, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32], "create_react_ag": 28, "creation": 27, "creativ": [3, 4, 26], "credit": 18, "crisp": 18, "criteria": [18, 31], "criterion": [22, 29], "critic": [3, 4, 5, 7, 18, 21, 23, 29, 30, 31, 32], "cross": [25, 29], "cross_attent": 29, "crossentropi": 25, "crossentropyloss": [21, 23, 29], "crowd": [3, 4], "crucial": [4, 18, 29, 30], "csv": [1, 2, 6, 26, 30], "cuda": [0, 1, 2, 4, 5, 6, 18, 23, 26, 27, 29, 30, 32], "cultur": 6, "cumbersom": 27, "cumul": 22, "curat": [23, 30], "curiou": [24, 26, 32], "current": [1, 2, 21, 22, 24, 27, 29, 32], "current_loss": 21, "curs": [3, 4], "curv": [0, 1, 2], "custom": [0, 1, 2, 5, 21, 23, 27, 29], "customiz": 18, "cut": 18, "cv": 23, "cx": 18, "cycl": 20, "czech": 22, "d": [0, 1, 2, 4, 5, 19, 21, 22, 23, 25, 27, 30], "d83d2b": 27, "d_h": 33, "d_model": 24, "d_wide": 21, "dai": 26, "daili": 18, "danger": [3, 4], "danub": 2, "data": [0, 1, 2, 3, 4, 5, 6, 23, 24, 25, 27, 29, 30, 31], "data_col": [5, 23, 25], "data_dir": 29, "data_pref": 29, "data_typ": 29, "databas": [5, 27], "datacollatorforlanguagemodel": [23, 25], "datafil": 22, "datafram": [4, 5, 21, 22, 23], "dataload": [0, 1, 2, 5, 18, 21, 23], "datapoint": [22, 25], "datas": 19, "dataset": [0, 1, 2, 5, 6, 21, 22, 23, 25, 27, 30, 31], "dataset_batch_s": 27, "dataset_df": 5, "dataset_nam": 5, "dataset_s": 18, "dataset_split": [1, 2], "datatyp": 19, "datset": 5, "daughter": [3, 4], "db": 5, "dbrx": 2, "de": [18, 21], "deactiv": [4, 22], "dead": 4, "deadli": [3, 4], "deadlin": [0, 1, 2, 3, 4, 5, 6], "deadlock": 32, "deal": [21, 24, 30], "debat": [16, 18, 30], "debug": [26, 32], "debugg": 32, "decad": 25, "decai": 23, "decid": [4, 27], "decim": 33, "decis": 4, "declar": 19, "decod": [0, 1, 2, 3, 4, 5, 22, 23, 24, 27, 29, 30], "decoder_attent": 29, "decoder_token": 29, "decompos": [28, 31], "decreas": [0, 1, 21, 23, 25, 27], "decrib": 4, "dedic": [3, 4, 23], "deduct": 2, "deem": 29, "deep": [3, 4, 7, 9, 10, 18, 25], "deeper": [3, 4, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21, 24, 31], "deepli": 6, "def": [0, 1, 2, 4, 5, 18, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33], "default": [1, 19, 20, 22, 23, 24, 27, 28, 29, 30, 32], "defin": [0, 1, 2, 4, 5, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 32], "definit": [2, 18, 22, 23, 24, 26], "degre": 20, "deliber": 11, "delin": 24, "deliv": 21, "demand": 4, "demo": [28, 32], "demonstr": [11, 18, 27, 29], "den": 24, "densiti": [3, 4, 20], "denvio": 4, "depart": 4, "depedn": 27, "depend": [0, 1, 2, 4, 18, 19, 22, 23, 24, 25, 27, 28, 29, 31], "deploi": 5, "deploy": [27, 30], "depnd": 5, "deprec": 32, "depth": 23, "der": 24, "deriv": [20, 21], "descend": 32, "descent": 20, "describ": [0, 1, 2, 4, 5, 6, 18, 22, 23, 26, 27, 30, 31], "descript": [0, 1, 2, 4, 5, 6, 28], "design": [21, 30], "desir": [18, 19, 24, 25, 27, 31], "desktop": 4, "dessert": 28, "dessert_chain": 28, "detach": [19, 21, 22, 32], "detail": [2, 4, 5, 18, 23, 24, 25, 26, 27, 28, 30, 31], "detect": 31, "determin": [4, 18, 19, 21, 22, 24, 25, 30], "determiner_noun_agreement_with_adjective_1": 6, "determinisit": 26, "determinist": [4, 22], "detial": 26, "develop": [0, 1, 2, 8, 20, 22, 23, 24, 25, 27, 28, 29, 31], "deviat": 20, "devic": [0, 1, 2, 4, 5, 6, 18, 19, 23, 26, 27, 29, 30, 32], "device_map": [5, 27], "devlin": [3, 4, 10], "df": [4, 6], "df_boolq": 30, "dh": 21, "di": [18, 28], "diagnos": 14, "diagnost": 4, "diagram": 26, "dialogu": [27, 31], "dict": [0, 1, 2, 5, 18, 22, 29, 30], "dict_kei": [0, 1], "dictionari": [1, 2, 22, 24], "did": [0, 1, 2, 5, 18, 21, 23, 25, 26, 27, 32], "didn": 4, "diff": 20, "diffenrenc": 4, "differ": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "differenti": 21, "difficult": [6, 18, 21, 27, 30], "difficulti": [6, 18, 26], "dig": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 21], "digit": 18, "digraph": 21, "dim": [22, 23, 24, 32, 33], "dim_feedforward": 24, "dimens": [0, 1, 2, 18, 19, 21, 23, 24, 25, 27], "dimensi": 4, "dimension": [3, 4, 19, 24], "dimes": 19, "ding": 12, "dinner": 28, "dinnerplan": 28, "direct": [4, 20, 21, 27], "directli": [5, 18, 19, 24, 25], "directori": [23, 29], "dirti": 4, "disabl": 32, "disadvantag": 5, "disclaim": [4, 28, 31], "discov": 27, "discret": 4, "discuss": [3, 4, 6, 15, 16, 17, 18, 23, 24, 26, 27, 28, 29, 30, 31, 32], "dish": 5, "displai": [4, 5], "disregard": 4, "dissect": [3, 4], "dissid": 18, "dissoci": 16, "distilbert": 27, "distinct": 27, "distinctli": 31, "distinguish": [22, 25, 30, 31], "distractor": [4, 30], "distribut": [4, 21, 22, 25, 26, 30], "div_term": 24, "dive": [5, 23, 24, 31], "diverg": [5, 25], "divers": [4, 18, 30], "diviat": 18, "divid": [4, 30, 33], "divis": [19, 22], "dm": 22, "do": [0, 1, 2, 3, 4, 5, 6, 11, 13, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "do_sampl": [0, 1, 2, 4, 5, 23, 26], "doc": [5, 19, 22, 23, 27, 28, 30], "docstr": [2, 18, 24], "doctor": 4, "document": [3, 4, 5, 19, 21, 22, 23, 24, 25, 26, 28, 30], "documet": 19, "doe": [0, 1, 2, 4, 5, 6, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "doesn": [4, 23, 25, 26, 27, 30, 32], "dog": [0, 1, 2, 24, 25, 29], "domain": [23, 24, 30, 31], "don": [0, 1, 2, 4, 5, 6, 18, 21, 22, 23, 24, 26, 27, 28, 30, 32], "done": [18, 23, 24, 25, 26, 30, 31, 32], "door": 4, "dot": [19, 25, 29], "doubl": 29, "doubt": 23, "doveski": 22, "down": [0, 1, 2, 3, 4, 18, 21, 24, 27, 29], "downaload": [0, 1, 2], "download": [0, 1, 2, 5, 6, 18, 23, 24, 25, 28, 29, 32], "downstream": 32, "draw": [4, 21, 26, 30, 31], "drawn": 19, "drawstr": [3, 4], "dream": [3, 4], "dreamwork": [3, 4], "drink": [3, 4], "drive": [3, 4], "driven": 31, "driver": 4, "drop": [18, 24, 26, 29], "dropout": [22, 24], "dropout1": 24, "dropout2": 24, "dropout3": 24, "drug": 4, "dtype": [19, 20, 24], "du": 24, "due": [6, 18, 32], "duplic": [22, 32], "dure": [1, 2, 3, 4, 5, 6, 18, 20, 22, 24, 25, 27, 30, 32], "dust": [3, 4], "dutch": 22, "duti": 4, "dv": 21, "dw": 21, "dx": 21, "dy": 21, "dynam": 23, "dz": 21, "e": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "eabl": 2, "each": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33], "ear": 22, "earli": [25, 27, 29], "earlier": [4, 27, 29], "early_stop": 4, "eas": 29, "easi": [21, 23, 30], "easier": [23, 27, 32], "easiest": 6, "easili": [18, 23, 30, 32], "east": 4, "eat": 26, "ect": 7, "edg": 21, "edit": 17, "educ": 4, "ef": 21, "effect": [18, 21, 23, 27, 30, 32], "effici": [5, 11, 12, 21, 23, 27], "effienc": 22, "eighth": 15, "either": [4, 6, 18, 25, 28, 32], "elazar": 14, "elect": 4, "electron": [4, 18], "element": [19, 22], "elementari": 31, "elementwise_affin": 24, "eleutherai": [0, 4, 26], "elhag": 17, "elicit": [6, 11, 26, 27, 31], "elif": [0, 1, 2, 4, 6, 18, 23, 26, 29, 30, 32, 33], "elmo": 4, "els": [0, 1, 2, 4, 5, 6, 18, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33], "elsewher": 22, "email": [1, 2], "emb": 24, "emb_dim": 29, "embed": [4, 5, 18, 21, 22, 24, 26, 29, 30, 31, 32, 33], "embed_dim": 24, "embed_model": 5, "emerg": 30, "emoji": [18, 24], "emphas": 4, "empir": 20, "empirical_mean": 20, "emploi": [4, 30, 31], "employ": 4, "employe": [3, 4], "empti": [22, 28], "empty_cach": 4, "en": [0, 1, 4, 5, 18, 23, 29], "enabl": [4, 21, 24, 28], "enable_nested_tensor": 24, "enc1": 24, "enc2": 24, "enc3": 24, "encod": [4, 5, 18, 22, 23, 24, 27, 29, 30, 32], "encoder_attent": 29, "encoder_lay": 24, "encoder_token": 29, "encoding_d": 30, "encoding_en": 30, "encount": 25, "encourag": [7, 18], "end": [0, 1, 2, 4, 5, 19, 22, 24, 25, 26, 27, 30, 31, 32, 33], "endofsequ": 24, "endors": 31, "endpoint": [26, 28, 29], "engin": [4, 5, 18, 21, 24, 25, 28, 30, 32], "english": [18, 22, 29, 30], "eniron": 27, "enrich": 18, "ensur": [4, 18, 24], "entail": [3, 4, 25], "entir": [4, 6, 18, 21, 23, 24, 25, 28], "entiti": 25, "entor": [0, 1, 2], "entropi": 25, "enumer": [4, 5, 21, 22, 32, 33], "env": [0, 1, 4, 18, 23, 24, 28, 32], "environ": [0, 1, 2, 5, 18, 23, 27, 32], "eo": [2, 22, 23, 26, 33], "eos_tensor": 23, "eos_token": [0, 1, 2, 5, 23], "eos_token_id": [0, 4, 5, 23, 26], "eosindex": 22, "ep": 24, "epoch": [0, 1, 2, 5, 18, 21, 23, 25, 27, 29], "epsilon": 33, "eq": 29, "equal": [19, 22, 30], "equip": [7, 18, 24, 25], "equival": [18, 26], "eras": 20, "error": [0, 1, 2, 9, 18, 23, 27, 32], "especi": [0, 1, 2, 4, 18, 22, 27, 30, 31], "ess": 18, "essenti": [18, 22, 23, 24, 25, 32], "establish": 18, "estat": [4, 18], "et": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 24, 26, 27, 29, 30, 31, 32], "etc": [0, 1, 2, 5, 18, 21, 23, 24, 25, 29, 30, 31], "ethic": [6, 31], "eval": [0, 1, 2, 32], "eval_dataset": 23, "eval_loss": 23, "eval_step": 23, "evalu": [0, 1, 4, 5, 7, 23, 25, 27], "evaluation_strategi": 23, "evalut": 30, "evas": 5, "even": [2, 4, 18, 19, 21, 23, 25, 27, 28, 29, 30], "eventu": 21, "everi": [0, 1, 2, 4, 18, 21, 22, 23, 24, 25, 26, 27, 29], "everyth": 27, "evid": [6, 30], "evolv": [3, 4], "ex": [1, 3, 4, 5, 25], "ex1": 19, "ex1_col": 19, "ex1_col_tran": 19, "ex1_row": 19, "exact": 21, "exactli": [22, 23, 24, 26, 27, 28, 32], "exam": [7, 31], "exampl": [0, 1, 2, 3, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "examples_df": 26, "exce": [4, 18, 25, 26], "exceed": 26, "excel": [7, 18, 32], "except": [4, 22, 30, 32], "exclud": [0, 23], "exclus": [21, 22], "execis": [0, 1, 2], "execut": [0, 1, 2, 3, 4, 5, 6, 18, 27, 28, 32], "exemplifi": [25, 30], "exercis": [18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32], "exercise1a": 19, "exercise1b": 19, "exercise2": 19, "exercise3": 19, "exerpt": 30, "exhaust": [22, 25, 26, 31], "exhibit": [6, 25, 30, 31], "exist": [4, 18, 21], "existential_there_object_rais": 6, "exot": 4, "exp": [22, 24, 26, 30, 33], "expect": [0, 1, 2, 4, 5, 18, 22, 23, 26, 27, 28, 29, 30], "expens": 4, "experi": [7, 18, 26, 27, 28, 29], "experienc": 26, "experiment": [4, 30], "expert": 31, "explain": [0, 3, 4, 5, 6, 21, 22, 27], "explan": [5, 6, 11, 14, 23, 27, 29, 30], "explanatori": 22, "explicit": [23, 24, 31], "explicit_train": 23, "explicitli": [4, 18, 19, 23, 32], "explor": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29], "exponenti": 4, "express": 32, "extend": [5, 18, 19, 21, 31], "extens": [0, 4, 18, 28], "extent": 30, "extern": 18, "extract": [4, 18, 24, 25, 29], "extrem": 27, "f": [0, 1, 2, 4, 5, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 33], "f1": 30, "f1_score": 30, "f_": 30, "face": [29, 30, 31], "facebook": 27, "facet": 29, "fact": [24, 31], "facto": 18, "factor": 2, "factscor": 31, "factual": [17, 30, 31], "fail": 25, "fair": [4, 31], "fairi": 4, "faith": 31, "falcon": 2, "fals": [0, 5, 19, 21, 22, 23, 24, 26, 27, 29, 30, 32], "false_neg": 30, "false_posit": 30, "famili": 26, "familiar": [5, 18, 19, 22, 23, 28, 29, 30, 31], "fanci": 4, "far": [18, 23, 25, 27, 31], "farm": 4, "farmland": 4, "fashion": [3, 4], "fast": [4, 26], "faul": 24, "faulti": 4, "favor": 22, "favour": 18, "favourit": 26, "fct": 18, "featur": [4, 18, 22, 28, 29], "fed": [18, 22], "feed": [21, 24, 26], "feedback": [12, 27], "feel": [0, 1, 2, 3, 4, 6, 20, 23, 24, 26, 27], "feet": 4, "ferret": 4, "few": [0, 1, 2, 3, 7, 8, 11, 18, 19, 22, 23, 25, 26, 27, 28, 29, 30], "few_shot": 4, "few_shot_exampl": 4, "few_shot_examples_v1": 4, "few_shot_examples_v2": 4, "few_shot_predict": 26, "few_shot_prompt": [4, 26], "few_shot_templ": [4, 26], "fewer": 27, "ffn": [32, 33], "ffnn": 32, "fg": 21, "field": [4, 6, 18, 27, 31], "fifth": 12, "fig": 6, "figur": [4, 5, 21, 22, 25, 27, 28], "file": [0, 1, 2, 3, 4, 5, 6, 18, 22, 23, 24, 25, 26, 28, 29, 30], "file_download": 32, "fill": [2, 4, 6, 19, 28], "filter": [18, 27], "filterwarn": [20, 21, 22], "final": [0, 1, 2, 4, 7, 18, 20, 22, 23, 26, 27, 29, 30, 31], "final_lay": 32, "financi": 18, "find": [1, 2, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31], "fine": [4, 7, 11, 18, 23, 26, 28, 29, 30, 31], "finetun": [4, 5, 27], "finetuning_data": [1, 2], "finetuning_data_s": [1, 2], "finetuning_typ": [1, 2], "finish": [21, 24], "finit": [4, 24], "first": [0, 1, 2, 5, 8, 9, 10, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32], "first_top": 32, "firt": 28, "fit": [20, 21, 23, 25, 27, 30], "five": [4, 24], "fix": [20, 22, 23, 27, 30, 32], "flan": [29, 30], "flask_serv": 32, "flatten": [19, 21], "flaw": 22, "flexibl": [21, 24], "flexibli": [19, 25], "float": [4, 19, 20, 24, 32], "float16": [5, 19, 26, 27, 32], "float32": [0, 19, 20], "float64": [19, 20], "floattensor": 29, "floor": [4, 22], "flow": [3, 4, 21, 32], "flu": [3, 4], "fluenci": 30, "fluent": [18, 23, 30], "fnko": 18, "focu": [4, 24, 27, 30, 31], "focus": [0, 1, 2, 7, 23, 27, 28, 30], "fold": 27, "follow": [0, 1, 2, 3, 4, 5, 6, 12, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "fonder": 31, "food": [4, 26, 28], "footbal": [3, 4], "forc": [26, 29, 32], "force_download": 32, "forest": 4, "forget": [0, 1, 2, 21, 23, 27], "forgot": 0, "fork": 32, "form": [0, 1, 2, 3, 4, 5, 18, 19, 27, 30, 31], "formal": [0, 1, 2, 24, 27, 31], "format": [0, 1, 2, 4, 5, 6, 18, 20, 21, 22, 26, 27, 28, 29, 30], "formatt": 18, "formatting_func": 27, "formatting_prompts_func": 27, "former": [4, 25], "formul": [0, 1, 2, 3, 4, 6], "formula": [2, 24], "forsequenceclassif": 25, "forum": [3, 4], "forward": [0, 1, 2, 21, 22, 23, 24, 29, 32, 33], "forwat": [0, 1, 2], "foster": 18, "found": [0, 1, 2, 3, 4, 5, 6, 7, 8, 13, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "foundat": [11, 16, 18, 31], "four": [0, 1, 2, 4, 26], "fourth": 11, "fox": [4, 24, 25, 33], "fp16": 23, "frac": [2, 25, 26, 27, 29, 30], "fraction": 29, "framework": [4, 13, 17, 26, 27, 28], "franc": [29, 32], "frank": [7, 19, 20, 21, 22, 26], "free": [0, 1, 2, 3, 4, 6, 18, 23, 24, 26, 27, 30], "freeli": 23, "freez": [27, 32], "french": [22, 29], "freq_of_first_el": 24, "freq_of_pair": 24, "freq_of_second_el": 24, "frequenc": 24, "frequent": [18, 19, 23, 24], "fresh": 22, "freuqenc": 24, "fri": 7, "fridai": 18, "fridg": 28, "friendli": 24, "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "from_dict": 22, "from_docu": 5, "from_pretrain": [0, 1, 2, 4, 5, 18, 23, 24, 25, 26, 27, 29, 30, 32], "front": [1, 2, 4], "frown": 4, "frozen": [23, 27, 30], "ftfy": 29, "fuch": 24, "fulfil": 27, "full": [4, 5, 18, 19, 21, 24, 25, 26, 29, 32], "full_prompt": 26, "fuller": 30, "fulli": [18, 23, 29], "fun": [1, 2, 3, 4], "function": [0, 1, 2, 4, 5, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 32], "functool": 32, "funko": 18, "further": [0, 1, 2, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32], "furthermor": [3, 4, 6, 18, 21, 22, 29, 30, 31, 32], "futur": [4, 23, 26, 27], "futurewarn": 32, "fwd_hook": 32, "fyi": 18, "g": [0, 1, 2, 4, 5, 6, 7, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "gain": [3, 4, 18, 25, 27, 29], "game": [3, 4], "gamma": 33, "gao": [18, 27], "garbag": [3, 4, 27], "gaussian": [20, 21], "gave": 32, "gavin124": 5, "gc": 4, "ge": 21, "gebru": 18, "gelu": 21, "gemini": 2, "gemma": 2, "gender": [17, 31], "gener": [0, 1, 2, 6, 7, 8, 9, 10, 11, 13, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "generate_kwarg": 5, "generated_text": 29, "generation_kwarg": 5, "ger": 6, "german": [0, 1, 2, 3, 4, 5, 6, 22, 24, 30], "germani": 6, "get": [0, 1, 2, 3, 4, 5, 6, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "get_act_nam": 32, "get_activ": 32, "get_cont": 5, "get_data": 29, "get_devic": 32, "get_lay": 32, "get_layers_w_attn": 32, "get_model_and_token": 29, "get_past_lay": 32, "get_pos_data": 29, "get_pre_wo_activ": 32, "get_prob": 22, "get_sentence_repr": 29, "get_surprisal_dataset": 22, "get_surprisal_item": 22, "getpass": 28, "giagant": 27, "giant": [4, 15], "git": 18, "github": [18, 27, 32], "githubusercont": 22, "give": [3, 4, 5, 18, 19, 26, 27, 28, 29, 32], "given": [0, 1, 2, 3, 4, 5, 6, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "glare": [3, 4], "glimps": 18, "glue": 30, "go": [0, 1, 2, 4, 5, 18, 19, 20, 23, 24, 26, 27, 30, 31], "goal": [0, 1, 2, 5, 18, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "goal_fun": 21, "goe": [4, 22, 27, 30], "gold": [3, 4, 5, 18, 21, 22, 30], "gone": 20, "good": [3, 4, 5, 6, 18, 20, 22, 23, 26, 27, 28, 30, 31], "goodfellow": 9, "googl": [4, 18, 29, 30], "got": [31, 32], "govern": [3, 4], "gp": 4, "gpt": [3, 4, 5, 6, 7, 10, 17, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "gpt2": [1, 2, 5, 6, 18, 23, 24, 25, 27, 29, 30, 32], "gpt2_lm": 24, "gpt2_model": 27, "gpt2_predict": 6, "gpt2_scorer": 6, "gpt2attent": 24, "gpt2block": 24, "gpt2doubleheadsmodel": 25, "gpt2forsequenceclassif": 25, "gpt2fortokenclassif": 25, "gpt2lmheadmodel": [0, 1, 23, 24, 25], "gpt2mlp": 24, "gpt2model": 24, "gpt2token": [0, 1, 23], "gpt2wrapper": 32, "gpt35": [1, 2], "gpt_metaphor_result": 30, "gpu": [0, 1, 2, 3, 4, 5, 6, 18, 19, 23, 26, 32], "grad": [20, 27], "grad_fn": [2, 20], "grade": [0, 1, 2], "gradient": [0, 1, 2, 21, 22, 25, 27, 29], "gradient_accumulation_step": 23, "gram": 18, "gramamt": [6, 18], "grammar": 30, "grammat": 30, "grammatical_log_prob": 30, "grammatical_sent": 30, "grammaticality_df": 30, "grammaticality_predict": 30, "grammaticality_test": 30, "graph": 22, "graphic": [1, 2], "graphviz": 21, "great": [0, 1, 2, 4, 18, 21, 30], "greedi": [4, 22, 23, 26], "greedy_decod": 4, "greek": 22, "green": 4, "greet": 6, "grid": 25, "grin": 4, "grok": 2, "ground": [0, 1, 2, 3, 4, 5, 13, 21, 27, 30], "group": 7, "grow": 31, "gru": 21, "grucel": 21, "gsm8k": 31, "gt": 4, "guess": [21, 22, 23, 25], "guid": [6, 18, 23, 32], "guidelin": 18, "h": [21, 24, 27, 32], "h1": 21, "h2": 21, "h2o": 2, "h3": 21, "ha": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "habitat": 4, "had": [3, 4, 27], "hallmark": 31, "hamburg": 4, "hand": [0, 4, 5, 7, 18, 22, 26, 28, 29], "handi": 18, "handl": [21, 22, 23], "happen": [0, 1, 2, 4, 22, 23, 28, 30], "happi": 4, "hardwar": 4, "harm": [27, 31], "harmless": [5, 12, 27, 31], "harmon": 30, "haskel": 18, "hasn": 31, "hat": 4, "have": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "haven": [5, 27], "haystack": 28, "he": [3, 4, 25], "head": [0, 3, 4, 5, 6, 19, 23, 27, 29, 30], "head_and_tail": 19, "head_dim": 24, "head_view": 29, "headscarf": 4, "heard": [18, 30], "heart": 31, "heavi": [5, 23, 28, 31], "heavili": 23, "heck": 5, "height": 4, "heimersheim": 17, "held": [18, 25], "hellaswag": 31, "hello": [6, 19], "hello_tensor": 19, "helm": 15, "help": [5, 12, 18, 21, 25, 26, 27, 28, 29, 30, 31, 32], "helper": [0, 1, 2, 23, 25, 30, 32], "henc": 4, "her": 4, "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "heurist": 14, "hf": [0, 1, 2, 3, 4, 5, 21, 23, 24, 25, 26, 28, 29], "hi": [3, 4, 24, 26], "hidden": [0, 1, 2, 21, 22, 25, 32], "hidden1": 2, "hidden2": 2, "hidden3": 2, "hidden_act": 0, "hidden_neuron": 2, "hidden_s": [0, 22, 29], "hidden_st": [29, 32], "hide": [18, 24], "hierarchi": 4, "high": [3, 4, 5, 18, 19, 23, 25, 26, 27, 29, 30, 31], "higher": [4, 6, 18, 19, 20, 22, 24, 25, 27, 31, 32], "highest": [4, 6, 26, 30], "highlevel": 23, "highli": [7, 27], "highlight": [23, 31], "highwai": 4, "him": 4, "hint": [0, 1, 2, 5, 6, 18, 21, 23, 24, 25, 26, 30, 31], "hire": 4, "hist": 18, "histogram": 18, "histori": [23, 31], "hit": 18, "hoc": 29, "hochreit": 10, "hold": [4, 6], "holist": [15, 20, 21], "home": 4, "homework": [7, 18, 27, 30], "honest": [27, 31], "honesti": 31, "hood": [18, 23, 24, 25, 29], "hook": [29, 32], "hookedtransform": 32, "hookpoint": 32, "hors": [3, 4, 21], "host": [7, 23], "hot": [22, 24, 33], "hour": 26, "hous": [3, 4, 30], "how": [0, 1, 2, 3, 4, 5, 7, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "howard": 12, "howev": [2, 4, 5, 18, 20, 21, 23, 24, 25, 27, 30, 31], "html": [0, 1, 4, 18, 19, 23, 29], "http": [0, 1, 2, 4, 5, 18, 19, 22, 23, 27, 29, 30, 32], "httpstcobdxbfgjkt": 18, "httpstcogymzyzi": 18, "httpstcoyfehvc": 18, "httpstcozzaplmfa": 18, "hu": 30, "hub": [23, 28], "hue": 21, "hug": 29, "huggingfac": [0, 1, 2, 5, 12, 18, 24, 27, 28, 29, 32], "huggingface_hub": [5, 32], "huggingface_model_id": [1, 2], "huggingfaceembed": 5, "huggingfaceendpoint": 28, "huggingfacehub_api_token": 28, "huggingfacellm": 5, "human": [4, 5, 12, 13, 18, 23, 24, 26, 27, 28, 29, 30, 31], "human_metaphor": 30, "humanev": 31, "hund": 24, "hungarian": 18, "hungri": 23, "hutch": 4, "hw": 30, "hw1": [25, 30], "hw1_model2group_assign": [1, 2], "hw2": 30, "hwchase17": 28, "hyperparam": [0, 1, 2], "hyperparamet": [4, 18, 25, 27, 28], "hypothes": [17, 30], "hypothesi": [4, 6], "i": [0, 1, 2, 3, 4, 5, 6, 7, 10, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "i2h": 22, "i2o": 22, "ic": 4, "icon": 18, "id": [4, 18, 23, 24, 25, 26, 29, 30, 32], "id_var": 21, "idea": [1, 2, 4, 6, 18, 21, 22, 25, 26, 27, 28, 29, 30, 32], "ideal": [18, 21, 23, 24, 25, 27, 30], "ident": 20, "identif": [17, 32], "identifi": [4, 24, 25, 27, 29, 30, 31, 32], "idx": [1, 2, 4, 21, 24], "ignor": [4, 20, 21, 22, 26], "illeg": [3, 4], "illinoi": 4, "illustr": 25, "imag": [5, 18, 23, 24, 25], "imagenet": 23, "imagin": [3, 4], "imbal": 6, "imdb": [23, 25, 27], "imdb_gpt2": 23, "imdbtrain": 23, "immedi": 18, "impact": 30, "implement": [0, 1, 2, 3, 4, 5, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "impli": 4, "implic": 6, "implicit": [11, 23], "implicitli": [19, 21, 27], "import": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "importantli": [0, 1, 2, 27, 30], "imposs": 27, "impress": [18, 27, 30], "improv": [0, 1, 2, 4, 5, 11, 18, 21, 22, 23, 26], "imshow": 32, "in_": 32, "in_featur": 24, "in_proj_bia": 24, "in_proj_weight": 24, "in_sln": 32, "in_sln_": 32, "inappropri": 6, "incld": 23, "includ": [0, 3, 4, 5, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "inclus": 22, "incom": 24, "incompat": 29, "inconsist": [26, 31], "incorpor": 30, "incorrect": [2, 29, 30, 32], "incorrect_answ": 32, "incorrect_index": 32, "increas": [3, 4, 20, 22, 24, 25, 30], "increasingli": [5, 31], "incrementallmscor": [6, 30], "inde": 31, "indent": 18, "independ": 4, "index": [0, 1, 2, 4, 5, 18, 21, 22, 24, 25, 30, 32], "indic": [0, 1, 2, 4, 6, 22, 23, 24, 26, 27, 29, 30, 31], "indirect": [17, 32], "individu": [0, 1, 2, 3, 4, 5, 6, 29], "inf": [4, 33], "infer": [0, 3, 5, 11, 14, 20, 23, 24, 26, 28, 30], "infix": 19, "inflat": 30, "influenc": [4, 6, 20], "influenti": 30, "info": 5, "infor": 18, "inform": [0, 1, 2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "infrastructur": [18, 23], "ing": [20, 24], "ingredi": [5, 28], "inherit": [18, 21], "init": [0, 1, 2, 24], "init_hidden": 22, "init_weight": 29, "initi": [0, 1, 4, 5, 6, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "initial_sequ": 22, "initialis": 19, "initialize": 25, "initializer_rang": 0, "inject": [24, 32], "injur": 6, "innat": 30, "inner": [2, 18], "innov": 27, "inoffici": 26, "inp_id": 32, "inpid": 32, "inplac": 24, "inpsect": 5, "input": [0, 1, 2, 4, 5, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "input_combin": 22, "input_dim": 29, "input_emb": 24, "input_id": [0, 1, 2, 4, 5, 18, 23, 24, 25, 26, 29, 30, 32], "input_ids_instruct": 27, "input_ids_lm": 27, "input_line_tensor": 22, "input_neg": 27, "input_neuron": 2, "input_po": 27, "input_s": 22, "input_tensor": 22, "input_text": [0, 1, 2, 4, 23, 25, 26, 29], "input_token": [29, 30], "input_vari": 28, "ins": 5, "inscrut": 32, "inseq": 29, "insert": [5, 6, 28], "insid": [23, 24], "insight": [18, 29, 30], "inspect": [0, 1, 2, 4, 5, 6, 19, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32], "inspir": [3, 4, 6, 22, 23, 24, 26, 27, 28, 30], "instal": [0, 1, 2, 5, 19, 21, 23, 27, 28, 29, 30, 32], "instanc": [6, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "instanti": [0, 1, 2, 20, 21, 22, 23, 24, 25, 28], "instati": [21, 23], "instead": [4, 18, 21, 23, 25, 27, 28, 29, 30, 32], "institut": [3, 4], "instruct": [0, 1, 2, 3, 4, 5, 12, 18, 19, 27, 28, 29, 30], "instruction_text": 27, "instructions_menu_summari": 28, "instructions_prompt": 4, "instructions_text_appet": 28, "instructions_text_dessert": 28, "instructions_text_main": 28, "int": [1, 2, 18, 19], "int64": 19, "intang": 18, "integ": [19, 24], "integr": [2, 18, 21, 26, 27, 28, 29], "integrated_gradi": 29, "intellig": 31, "intend": [18, 20, 25, 27, 28, 31], "intens": 31, "intent": 4, "inter": 18, "interact": [3, 4, 13, 29], "intercept": 21, "interchang": [18, 26, 27], "interconnect": 6, "interdisciplinari": 7, "interest": [2, 5, 7, 20, 28, 29, 30, 31], "interestingli": 31, "interfac": [5, 21, 23, 28], "intermedi": [0, 1, 2, 11, 30, 31, 32], "intermediate_residual_": 32, "intermediate_s": 0, "intern": 18, "internet": [4, 18, 30], "interpret": [0, 1, 2, 5, 6, 7, 22, 29, 30, 31], "intersect": 30, "interv": [6, 19], "interven": 32, "intervent": 32, "intric": 31, "intro": [3, 4, 5], "introduc": [0, 1, 2, 3, 4, 7, 9, 10, 11, 18, 19, 20, 22, 24, 25, 26, 27, 30, 31], "introduct": [4, 7, 18, 24, 26], "intuit": [3, 4, 5, 6, 18, 21, 22, 23, 24, 26, 27, 29, 30, 31], "intuititv": 6, "invalid": 0, "invers": 21, "investig": [1, 2, 6, 22, 30], "invok": 28, "involv": [2, 4, 18, 24], "io": [0, 1, 4, 5, 18, 23], "ioi": 32, "ioi_patching_result": 32, "iprogress": [0, 1, 4, 18, 23], "ipynb": [0, 1, 2, 3, 4, 5, 6], "ipython": [2, 5], "ipywidget": [0, 1, 4, 18, 23, 29], "irish": 22, "iron": 31, "irrelev": 4, "is_avail": [0, 1, 2, 4, 5, 6, 18, 23, 26, 27, 29, 30, 32], "is_correct": 30, "is_grammat": 30, "is_top_at_end": 32, "is_tru": 30, "isalpha": 18, "isdigit": 33, "ish": 32, "island": 4, "isol": [6, 30], "isspac": 18, "issu": [5, 18, 25, 28, 30, 31], "itali": 26, "italian": [22, 26, 28], "italien": 28, "item": [0, 1, 2, 4, 6, 19, 20, 21, 22, 24, 26, 29, 30, 32], "item_id": 30, "item_surpr": 22, "itemnum": 30, "iter": [0, 1, 2, 4, 6, 18, 20, 21, 22, 26, 27, 30], "iterrow": [4, 5, 30], "ith": [4, 30], "its": [0, 1, 2, 3, 4, 6, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "itself": [20, 22, 27, 28], "ivestig": 4, "j": [0, 1, 2, 18, 30], "jackson": 22, "jaffrai": 18, "jamba": 2, "jame": 4, "japanes": 22, "jetmo": 2, "jewelri": [3, 4], "jo": 18, "job": [0, 1, 2, 4, 5, 18, 21, 26, 30], "john": 32, "join": [0, 1, 2, 4, 18, 26, 29, 30], "joint": 4, "joke": 2, "joyou": 4, "jpg": 1, "jpmorgan": 18, "json": [0, 1, 2, 22, 32], "judgement": 18, "juic": [3, 4], "juli": 6, "jump": [3, 4, 24, 25, 33], "june": [3, 4, 5], "jupyt": [0, 1, 4, 18, 23], "jurafski": 8, "just": [0, 1, 2, 18, 20, 21, 22, 23, 24, 26, 27, 28, 30, 32], "justext": 18, "justif": 6, "justifi": 29, "k": [4, 19, 22, 24, 26, 32, 33], "k_2": 0, "k_proj_weight": 24, "k_q": 26, "k_x": 33, "kadavath": 30, "kaplan": 8, "karab": 4, "karahan": 4, "karpathi": 7, "kdeplot": 20, "kdim": 24, "keep": [0, 4, 18, 20, 22, 23, 26, 27], "kei": [0, 1, 2, 3, 4, 5, 18, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33], "kept": 27, "kernel": [0, 1, 2, 23], "kid": 4, "kill": 4, "kind": [0, 1, 2, 3, 4, 5, 18, 21, 23, 24, 25, 26, 27, 29], "kindli": 18, "kl": 5, "kn1g4awfib": 18, "know": [4, 6, 18, 20, 21, 23, 24, 26, 27, 28, 29, 31, 32], "knowledg": [2, 6, 7, 11, 26, 27, 29, 30], "knowledge_exampl": 26, "knowledge_examples_chain": 26, "knowledge_examples_chain_incorrect": 26, "knowledge_stat": [4, 26], "known": [6, 18, 20, 23, 24, 27, 29, 30], "kojima": 11, "korean": 22, "krakauer": 16, "kwarg": [28, 32], "l": [22, 27, 29, 32, 33], "l57": 32, "lab": 7, "label": [0, 1, 2, 3, 4, 5, 18, 21, 22, 23, 25, 26, 27, 29, 30, 32], "label2index": 29, "ladi": [3, 4], "lambada": 31, "lambd": 32, "lambda": [0, 1, 2, 18, 30], "lambdalay": 32, "lampinen": 11, "langaug": [3, 4], "langchain": [18, 26], "langchain_commun": [18, 28], "langchain_cor": 28, "langchain_openai": 28, "langchainhub": 28, "languag": [3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30, 31], "larg": [1, 2, 4, 7, 11, 12, 16, 18, 23, 24, 25, 27, 28, 29, 30, 31, 32], "larger": [4, 6, 18, 19, 28, 29, 30], "last": [2, 6, 18, 20, 21, 22, 23, 25, 27, 29, 30, 31, 32], "last_past": 32, "lastli": 25, "later": [5, 21, 22, 32], "latest": [1, 2, 29], "latg": 30, "latter": [18, 23, 25, 28, 29, 31], "laugh": 4, "law": [8, 22, 27, 31], "lawsuit": 18, "layer": [0, 1, 2, 22, 23, 24, 25, 27, 29, 32, 33], "layer_decod": 32, "layer_logit": 32, "layer_past": 32, "layer_residual_": 32, "layernorm": 24, "layers_to_unfreez": 27, "layout": 30, "lazi": [24, 25], "ldquo": 27, "le": 29, "lead": [3, 4, 22, 26, 27, 30, 32], "leader": [3, 4], "learn": [0, 1, 2, 4, 5, 6, 7, 9, 10, 11, 12, 14, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "learnabl": 30, "learner": 10, "learning_r": [5, 20, 22, 23], "learnt": 4, "least": [19, 23, 26, 27, 28], "leav": 22, "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "led": 27, "left": [0, 1, 2, 4, 5, 23, 24, 28], "leg": 26, "legend": [2, 23], "len": [1, 2, 4, 17, 18, 21, 22, 26, 27, 29, 30, 32], "lend": 27, "lenght": 18, "length": [1, 2, 6, 18, 19, 21, 22, 24, 26, 27, 30], "lens": 6, "less": [19, 21, 24, 26], "lesson": 18, "let": [0, 1, 2, 3, 4, 5, 18, 19, 20, 22, 24, 25, 27, 28, 30], "letter": [22, 24], "letter_index": 22, "level": [23, 24, 25, 29, 31], "levi": 30, "lharri": 18, "li": [22, 30], "liang": 7, "lib": [0, 1, 4, 18, 23, 24, 32], "librari": [0, 3, 4, 5, 19, 24, 27, 32], "liek": 4, "light": [29, 30], "like": [0, 1, 2, 3, 4, 5, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "likelihood": [2, 20, 22, 30], "limb": [4, 26], "limit": [4, 18, 22, 24, 26, 28, 30, 31], "line": [0, 1, 2, 5, 18, 21, 22, 23, 24, 25, 29], "linear": [0, 1, 2, 22, 24, 25, 29, 32], "linear1": [21, 24], "linear2": [21, 24], "linear3": 21, "linear4": 21, "lineplot": 21, "ling": 18, "linguist": [6, 7, 18, 29, 30, 31], "lingusit": 18, "link": [0, 1, 2, 5, 6, 28], "linspac": 21, "list": [0, 1, 2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32], "list_decod": 32, "liter": 30, "literari": 18, "literatur": [3, 4, 18], "littl": [26, 28], "liu": [11, 26], "live": 30, "ll": 29, "llama": [2, 3, 4, 5, 7, 11, 18, 23, 24, 27, 31], "llama_index": 5, "llamaindex": 5, "llm": [3, 4, 8, 18, 25, 27, 30, 31, 32], "llm_hf": 28, "llok": 26, "lm": [0, 1, 2, 5, 6, 7, 15, 18, 24, 25, 26, 27, 29, 30, 31, 32], "lm_head": [24, 32], "lm_scorer": [6, 30], "lmhead": 25, "lmql": 28, "ln_1": [24, 32], "ln_2": [24, 32], "ln_f": [24, 27, 32], "lnaguag": 15, "load": [0, 1, 2, 3, 4, 5, 6, 18, 19, 23, 24, 25, 26, 27, 28, 29, 30, 32], "load_dataset": [0, 1, 2, 5, 6, 18, 23, 25, 27, 30], "load_dotenv": 28, "load_gpt2": 32, "load_in_4bit": 27, "load_in_8bit": 5, "load_model": 29, "load_tool": 28, "loader": [0, 1, 2], "loc": [4, 20, 21, 26], "local": [0, 1, 2, 19, 22, 23, 26, 27, 28, 29, 32], "locat": [17, 19, 20, 25, 26, 29], "log": [0, 1, 2, 4, 5, 6, 22, 23, 24, 26, 27, 30, 32], "log_histori": 23, "log_p": [4, 26], "log_prob": [20, 22], "log_probs_for_a": 4, "log_stat": 5, "logging_step": 23, "logic": 31, "logit": [17, 23, 25, 32, 33], "logits_to_logit_diff": 32, "logp_": 2, "logsoftmax": [21, 22], "logspac": 22, "lone": 4, "long": [1, 2, 4, 5, 10, 18, 23, 25, 26, 29, 30, 31], "longer": [4, 20, 24, 27, 30], "longest": 0, "longtensor": 22, "look": [0, 1, 2, 4, 5, 6, 7, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "loop": [0, 1, 2, 5, 21, 22, 23, 25, 28], "lora": 27, "loss": [0, 1, 2, 4, 5, 21, 22, 23, 24, 25, 26, 27, 29, 30], "loss_funct": 21, "lot": [4, 5, 18, 26, 27], "love": 6, "low": [26, 27], "lower": [4, 18, 20, 22, 24, 26, 27], "lowest": 30, "lr": [0, 1, 2, 20, 21, 22], "lr_scheduler_typ": 23, "lstm": 25, "luckili": [21, 23, 25], "luggag": 4, "lvwerra": 27, "ly": 19, "m": [0, 1, 2, 4, 19, 22, 24, 26, 29], "m1": 18, "m3hrdadfi": 5, "m_1": [0, 1, 2], "m_2": 2, "m_3": 2, "m_4": 2, "m_coef": 32, "m_i": 2, "m_out": 33, "mac": 18, "machin": [18, 19, 21, 23, 25, 27, 31], "made": [3, 4, 18, 20, 21, 23], "magazin": 4, "magnitud": [21, 29], "mahowald": 16, "mai": [0, 1, 2, 4, 5, 6, 20, 24, 26, 28, 30], "main": [1, 2, 4, 5, 6, 20, 21, 22, 27, 28, 31], "main_chain": 28, "main_cours": 28, "mainli": [18, 21], "major": [4, 18], "majority_vot": 4, "make": [0, 1, 2, 4, 5, 6, 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "make_df": 22, "male": 4, "mall": 4, "mamba": 2, "man": [3, 4], "manag": [6, 22], "mani": [0, 1, 2, 4, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "manipul": [6, 19], "manner": 18, "manual": [4, 20, 21, 23, 24], "manual_se": 4, "map": [0, 1, 2, 4, 5, 18, 21, 22, 23, 24, 25, 29, 30, 32], "mari": [30, 32], "market": 4, "markup": 18, "martin": 8, "mask": [1, 2, 4, 18, 23, 26, 29, 30], "masked_label": [4, 26], "mass": 4, "massag": [0, 1, 2, 18, 20, 23], "massage_input_text": [0, 1, 2, 30], "massaged_dataset": [0, 1, 2], "massaged_dataset_v": 30, "master": 7, "match": [2, 3, 4, 5, 6, 18, 22, 24, 29, 30], "materi": 18, "math": [21, 22, 24, 30, 31], "mathbb": 27, "mathc": 30, "mathemat": [0, 1, 2, 8, 17, 19, 24, 31], "matmul": [19, 32], "matplotlib": [0, 1, 2, 18, 20, 21, 22, 23], "matric": [0, 1, 2, 19, 21, 23, 24, 27], "matrix": [0, 1, 2, 18, 22, 24, 27, 32, 33], "matrix1": 19, "matrix2": 19, "matrixprod": 19, "matriz": 2, "matter": 4, "max": [3, 4, 24, 25, 26, 29], "max_len": 24, "max_length": [1, 2, 5, 22, 23, 25], "max_new_token": [0, 1, 2, 4, 5, 26, 28], "max_ord": 30, "max_position_embed": 0, "max_prob": 4, "max_prob_idx": [4, 26], "max_seq_length": 27, "max_token": 28, "maxim": [1, 3, 4, 5, 6, 18, 20, 23, 25, 26, 27], "maximizing_answ": 4, "maximizing_log_prob": 4, "maximum": [4, 20, 27], "mayb": [2, 23, 27, 32], "mccoi": 14, "mcdonnel": 11, "mcyftsxc2n": 18, "mdoel": 32, "mdp": 27, "me": [2, 28], "mean": [4, 5, 11, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 33], "meaning": 32, "meant": [4, 18, 20], "measur": [4, 5, 6, 20, 24, 30], "meat": 18, "mechan": [17, 23, 27, 29, 32], "mechanist": 7, "mediat": 17, "medic": 27, "medicin": 4, "medium": 32, "meet": 31, "mega002": 32, "meinung": 30, "meister": 26, "melt": 21, "memor": 25, "memori": [0, 1, 5, 10, 18, 19, 22], "men": 4, "meng": 17, "mention": [4, 5, 8, 11, 17, 24, 25, 26, 29, 30, 31], "menu": 28, "merg": 24, "merullo": [17, 32], "messag": [20, 28], "meta": [0, 24], "metaphor": 30, "metaphor_results_gpt": 30, "metaphor_results_human": 30, "meteor": 30, "method": [1, 2, 4, 5, 7, 17, 18, 21, 23, 27, 30, 31, 32], "methodolog": [27, 30], "methodologi": 4, "metric": [5, 6, 22, 23, 31, 32], "michael": [7, 19, 20, 21, 22, 26], "microsoft": [5, 27, 28], "mid": [22, 26, 30], "mid_attn_": 32, "middl": [3, 4, 24, 25], "midwest": 4, "might": [0, 1, 2, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "mikolov": 8, "militari": [3, 4], "milk": 32, "million": [4, 25, 27], "min": [11, 25], "min_length": 5, "mind": [18, 27, 28, 30], "mini": [5, 21, 27], "mini_batch_s": 5, "minicon": [6, 30], "minim": [0, 1, 2, 6, 18, 20, 21, 24, 28, 31], "minimum": [25, 27], "minist": 6, "minor": 2, "minut": 22, "mismatch": 6, "misrepresent": 18, "miss": [18, 31], "mistak": [2, 26], "mistral": [2, 28], "mistralai": 28, "mitchel": 16, "mix": [18, 19], "mix2": 19, "mix3": 19, "mix4": 19, "mix5": 19, "mix6": 19, "mix7": 19, "mix8": 19, "mixtral": 2, "mixtur": [1, 2, 18], "ml": [18, 31], "mll": 6, "mlm": 23, "mlm_probabl": 25, "mlp": [24, 32], "mlp_": 32, "mlp_19": 32, "mlp_condens": 21, "mlp_explicit": 21, "mlpcondens": 21, "mlpexplicit": 21, "mmlu": [30, 31], "mode": [0, 1, 2, 5, 27, 30], "model": [3, 4, 5, 6, 7, 8, 10, 11, 12, 15, 16, 17, 18, 19, 20, 24, 26, 28, 29, 30, 31, 32], "model_": 30, "model_instruct": 27, "model_kwarg": 5, "model_lm": 27, "model_nam": [1, 2, 5, 29], "model_s": [0, 1, 2], "model_t5": [29, 30], "model_typ": 24, "model_view": 29, "model_xl": 30, "modelout": 23, "modelwrapp": 32, "modern": [3, 4, 28, 30], "modifi": [0, 6, 18, 19, 28], "modul": [2, 22, 24, 29, 32], "module_guid": 5, "modulelist": 24, "modulenotfounderror": 2, "moe": 2, "moment": [4, 26, 27], "monitor": [0, 1, 2, 18, 22], "monolingu": 6, "moodl": [0, 1, 2, 3, 4, 5, 6], "moral": 31, "more": [3, 4, 5, 6, 7, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "morgan": 18, "morphologi": 6, "mortuari": 4, "most": [2, 4, 6, 18, 22, 23, 24, 26, 27, 30, 31], "mostli": [6, 18, 21, 23, 25, 27, 31], "motiv": [29, 30], "mous": [1, 2], "mouth": 4, "move": [0, 1, 2, 30, 32], "movi": [5, 23, 27], "mp": [0, 1, 2, 4, 6, 18, 23, 26, 29, 30], "mrr": 32, "mse": 25, "mseloss": 21, "mtx": 33, "much": [4, 18, 19, 21, 23, 24, 26, 27, 29, 30, 32], "multi": [18, 21, 31], "multihead_attn": 24, "multiheadattent": 24, "multilanguag": 18, "multilingu": [2, 6], "multimod": 2, "multipl": [2, 6, 18, 21, 24, 25, 26, 30, 31], "multipli": [2, 18, 19, 25, 33], "multitask": 10, "mupltipli": 2, "must": [18, 20, 21, 24, 26, 31], "my": [18, 26, 28], "m\u00fcll": 22, "m\u00fcller": 22, "n": [2, 4, 5, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 33], "n_": 2, "n_categori": 22, "n_hidden": 21, "n_input": 21, "n_item": 22, "n_iter": 22, "n_layer": 32, "n_letter": 22, "n_name": 22, "n_ob": [20, 21], "n_output": 21, "n_train_step": 21, "n_training_step": 20, "naiv": 27, "name": [0, 1, 2, 3, 4, 5, 6, 7, 18, 20, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33], "named_paramet": 27, "names_data": 22, "nanda": 17, "nanswer": [0, 1, 2], "nappet": 28, "nation": 18, "nativ": [23, 32], "natur": [3, 5, 14, 18, 23, 26, 27, 30, 32], "naturalqa": 31, "navig": [0, 1, 2, 3, 4, 5, 6, 18], "nb": [18, 19, 20, 21, 23], "ndessert": 28, "neat": 28, "neatli": 21, "necess": [24, 28], "necessari": [24, 27, 28, 32], "necessarili": [0, 1, 2, 20, 27], "need": [0, 1, 2, 3, 4, 5, 10, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "neg": [2, 20, 22, 25, 27, 30], "negative_sent": 27, "negbackward0": 20, "ner": 25, "net": [21, 22, 23, 24], "network": [0, 1, 2, 4, 7, 9, 10, 21, 23, 24, 25, 28, 29], "neural": [0, 1, 2, 7, 8, 9, 10, 17, 21, 22, 23, 24, 25], "neural_pragmatic_nlg": 22, "neuron": [0, 1, 2, 29], "neutral": [3, 4, 18, 25, 26], "never": [18, 22], "new": [0, 1, 2, 4, 5, 18, 19, 22, 23, 24, 27, 32], "new_tensor": 19, "newer": 30, "newgeluactiv": 24, "newli": 23, "next": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "nf": 24, "nf4": 27, "nhead": 24, "nhid": 24, "nice": [23, 24], "nightmar": [3, 4], "ninp": 24, "ninth": 16, "nlayer": 24, "nlg": [7, 26, 30], "nll": 30, "nllloss": 22, "nlp": [0, 1, 2, 3, 4, 7, 8, 17, 18, 23, 25, 30], "nmain": 28, "nmean": 22, "nn": [22, 23, 24, 25, 29, 32], "no_grad": [0, 1, 2, 22, 29], "no_knowledge_stat": 4, "noce": 26, "node": [5, 21, 25], "nois": 21, "nomura": 18, "non": [18, 22, 25, 26, 29], "nondynamicallyquantizablelinear": 24, "none": [1, 2, 4, 20, 21, 24, 25, 32], "nonetheless": [2, 4, 18, 28], "nonlinearregressiondata": 21, "nonliter": 30, "nonsens": [6, 27], "noodl": 5, "noption": 4, "norm": [24, 32], "norm1": 24, "norm2": 24, "norm3": 24, "normal": [20, 21, 24, 25, 32], "normalis": 33, "north": 4, "notabl": 21, "notat": [8, 19], "note": [0, 1, 2, 4, 5, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32], "notebook": [0, 1, 2, 6, 18, 20, 22, 23, 27, 29, 32], "notebook_tqdm": [0, 1, 4, 18, 23], "notic": [19, 20, 22, 26], "notion": [18, 22], "noun": [6, 27], "now": [4, 20, 21, 22, 24, 25, 27, 29, 30, 31], "nowadai": 18, "np": [0, 1, 2, 4, 19, 21, 22, 26, 29, 30, 32, 33], "np_arrai": 19, "np_array_to_tensor": 19, "np_conv": 33, "npi_present_1": 6, "npleas": 28, "npnlg": 22, "nquestion": 4, "nselect": 4, "ntoken": 24, "nuber": 25, "nucleu": 4, "nudg": 27, "null": 0, "num": [0, 1, 2, 21, 32], "num_attention_head": 0, "num_beam": 4, "num_class": 23, "num_correct": 29, "num_decoder_lay": 24, "num_encoder_lay": 24, "num_epoch": 29, "num_head": 24, "num_hidden_lay": 0, "num_key_value_head": 0, "num_label": 29, "num_lay": [29, 32], "num_posit": 32, "num_process": 5, "num_test_step": [0, 1, 2], "num_token": 32, "num_tot": 29, "num_train_epoch": 23, "num_word": 29, "number": [0, 1, 2, 4, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30], "number_training_token": [1, 2], "numel": [0, 1, 2, 27], "numer": [4, 18, 19, 20, 24, 27], "numpi": [0, 1, 2, 4, 19, 21, 22, 26, 29, 30, 32, 33], "numpydoc": 18, "nwhich": 28, "nye": 11, "nyu": 6, "o": [5, 21, 22, 28, 29, 30, 31, 33], "o2o": 22, "o_citi": 32, "object": [1, 5, 6, 17, 18, 19, 20, 21, 22, 23, 25, 27, 32], "obscur": 29, "observ": [4, 5, 6, 21, 25, 26, 28, 29, 32], "obtain": [4, 18, 19, 20, 22, 26, 27, 31], "obviou": 19, "obvious": [3, 4], "occupi": [18, 19], "occur": [4, 6, 18, 21, 25, 30], "odd": 5, "off": [3, 4, 18], "offer": [4, 7, 27, 28, 29], "offic": 4, "offici": 4, "often": [0, 1, 2, 4, 5, 18, 19, 23, 24, 25, 26, 27, 30, 31, 32], "oftentim": 28, "old": 19, "older": [3, 4], "ollama": 5, "ollamaembed": 5, "ommit": 18, "onc": [18, 21, 24, 27], "one": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], "ones": [18, 19, 20, 21, 27, 32], "ones_lik": [4, 26], "onli": [0, 1, 2, 3, 4, 5, 6, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32], "onlin": [23, 26, 27], "onto": [18, 21, 24, 30, 32], "onward": 21, "oon": 2, "open": [1, 2, 4, 5, 6, 11, 18, 22, 23, 26, 27, 28, 29, 30], "openai": [12, 23, 27, 28], "openai_api_kei": 28, "openai_summarize_tldr": 27, "oper": [21, 24, 32], "operation": [6, 32], "opinion": [30, 31], "opportun": [16, 21], "oppos": [4, 18, 22], "opprotun": 31, "opt": [0, 1, 18, 20, 23, 24, 27, 32], "optim": [0, 1, 2, 4, 5, 18, 21, 22, 23, 24, 25, 26, 27, 28, 29], "optima": 25, "optimis": 27, "option": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 26, 28, 29, 30, 31, 32], "orang": [3, 4], "orc": 6, "ord": [4, 19], "order": [2, 5, 18, 19, 21, 23, 24, 25, 27, 28, 29, 30, 31], "ordereddict": 24, "ordin": 27, "org": [1, 2, 4, 19, 27, 29, 30], "orient": 30, "origin": [18, 22, 27, 30, 32], "original_summari": 5, "orini": 2, "other": [2, 3, 4, 6, 7, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "otherwis": [0, 1, 2, 5, 18, 20, 23, 26, 27, 30], "our": [0, 1, 2, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 32], "ourselv": [18, 23, 24, 28, 29], "out": [0, 1, 2, 4, 5, 6, 7, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "out_contrast": 29, "out_featur": 24, "out_intermediate_residual_": 32, "out_proj": 24, "out_with_gener": 29, "outcom": [27, 31, 32], "outdoor": [3, 4], "outlier": 18, "outlin": 31, "outlook": [18, 26], "outperform": 4, "output": [0, 1, 2, 4, 5, 18, 19, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 33], "output_": 30, "output_attent": [29, 32], "output_combin": 22, "output_dim": 29, "output_dir": 23, "output_hidden_st": [29, 32], "output_max_length": 5, "output_neuron": 2, "output_pars": 28, "output_s": 22, "output_text": 27, "output_xl": 30, "outset": 20, "outsid": [3, 4], "ouyang": 12, "over": [0, 1, 2, 3, 4, 5, 6, 16, 18, 20, 21, 24, 25, 26, 27, 28, 30, 32, 33], "overal": [4, 5, 20, 24, 26, 28, 29, 30], "overfit": [23, 25, 26], "overlap": [18, 30], "overoptim": 27, "overrepres": 6, "overris": 23, "overview": [12, 15, 18, 21, 23, 25, 26, 27, 28, 31], "overwhelm": 23, "own": [2, 4, 5, 6, 18, 21, 22, 23, 24, 26, 27, 28], "p": [0, 1, 2, 4, 18, 19, 22, 24, 25, 26, 27], "p_": [2, 22, 26, 30], "p_categori": 22, "p_name": 22, "pack": 21, "pack_padded_sequ": 21, "packag": [0, 1, 2, 3, 4, 5, 18, 23, 24, 26, 27, 28, 29, 30, 31, 32], "pad": [0, 1, 2, 4, 5, 18, 21, 23, 24, 25, 26], "pad_packed_sequ": 21, "pad_sequ": 21, "pad_token": [0, 1, 2, 5, 23], "pad_token_id": [0, 1, 2, 4, 5, 23, 25, 26], "padding_sid": [0, 1, 2, 5, 23], "page": [18, 28], "pai": 21, "pain": [4, 21], "pair": [0, 1, 2, 6, 18, 21, 22, 24, 27, 30], "palm": 2, "panda": [4, 5, 6, 21, 22, 26, 30], "paper": [1, 2, 3, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17, 18, 24, 25, 26, 27, 30, 31, 32], "paper_url": [1, 2], "paradigm": [11, 30], "parallel": [4, 18, 23, 24, 26, 32], "parallelis": 24, "parallelogram": 4, "param": [21, 27], "paramet": [0, 1, 2, 3, 4, 5, 12, 18, 23, 24, 25, 26, 27, 28, 29, 30, 32], "parameter": 23, "paramt": [5, 26], "paraphras": 30, "parent": 4, "parenthes": 6, "pari": [29, 32], "park": 13, "parrot": 31, "part": [4, 5, 6, 18, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "partial": [1, 2, 4, 27, 32], "particip": [7, 30], "particular": [0, 1, 2, 3, 4, 5, 6, 18, 22, 23, 24, 27, 28, 29, 31], "particularli": 21, "particulat": 26, "pass": [0, 1, 2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33], "passag": 25, "passs": 28, "past_key_valu": 32, "past_layer_": 32, "patch": 17, "patched_logit": 32, "patched_logit_diff": 32, "path": [18, 26, 29], "patient": 28, "pattern": [25, 29, 31, 32], "pavlick": [11, 31], "paywal": 28, "pd": [4, 5, 6, 21, 26, 30], "pdf": [4, 27], "pe": 24, "peak": 18, "peft": [12, 23], "penalti": 4, "penalty_alpha": 4, "penguin": [4, 26], "penn": 30, "peopl": [3, 4, 6, 18, 30], "pep8": 18, "per": [3, 4, 22, 23, 25, 26, 27, 29], "per_device_eval_batch_s": 23, "per_device_train_batch_s": 23, "percentag": 31, "perceptron": 21, "perci": 7, "perez": 6, "perfect": [22, 30], "perform": [0, 1, 2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "perhap": [0, 25, 27, 30], "permut": 23, "perpetu": 31, "perplex": [4, 22, 30], "perplexity_": 30, "perplexity_xl": 30, "perplxti": 22, "perplxty_dict": 22, "person": [3, 4, 18, 25], "perspect": [7, 30, 31], "pertain": 4, "perturb": 29, "pet": 4, "phenomena": 6, "phenomenon": [6, 30, 31], "phi": [2, 5, 27], "phrase": 6, "physic": 31, "pick": [0, 1, 2, 18, 24, 27, 32], "pictur": [0, 4, 22, 24, 26], "piec": [18, 24, 28, 30], "pile": [18, 23], "pilot": 6, "pinecon": 5, "pip": [0, 1, 2, 5, 18, 23, 27, 28, 29, 32], "pipe_output": 23, "pipelin": [0, 1, 2, 5, 18, 23, 26], "piper": 18, "pizza": [4, 26], "pizzeria": 26, "place": [4, 5, 26], "placement": 5, "plai": [0, 1, 2, 3, 4, 20, 22, 23, 24, 26, 27, 28, 31], "plan": 28, "platform": [18, 23], "plausibl": 31, "pleas": [0, 1, 2, 3, 4, 5, 6, 18, 21, 23, 24, 26, 27, 28, 29, 30], "plot": [0, 1, 2, 5, 6, 18, 19, 20, 21, 22, 23, 25, 31], "plot_everi": 22, "plotli": 32, "plt": [0, 1, 2, 18, 20, 21, 22, 23], "plu": [22, 24, 29], "plural": 6, "png": 1, "po": [24, 25, 29], "point": [18, 21, 24, 25, 26, 27, 28, 30], "pointer": 24, "pointwis": 18, "pol_tok": 32, "poland": 32, "poland_id": 32, "poland_text": 32, "polic": 4, "polici": 5, "polina": [18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "polish": 22, "polit": 31, "poor": 18, "popul": 19, "popular": [4, 5, 23, 25, 28, 31], "pork": 5, "portugues": 22, "pos_encod": 24, "posencod": 24, "posit": [19, 24, 25, 26, 27, 30, 32], "positionalencod": 24, "positive_sent": 27, "possess": 31, "possibl": [4, 6, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32], "possibli": [18, 24, 27], "post": [3, 4, 5, 26, 27, 29], "potenit": 30, "potenti": [18, 25, 26, 27, 28, 29, 30], "power": [4, 13, 21, 30], "pp": 6, "ppl": 30, "ppl_": 30, "ppo": 5, "ppo_epoch": 5, "ppo_train": 5, "ppoconfig": 5, "ppotrain": 5, "practic": [0, 1, 2, 7, 21, 23, 24, 25, 26, 30], "practition": [3, 4], "pragmat": [7, 30], "prder": 19, "pre": [0, 3, 4, 10, 12, 18, 21, 22, 24, 29, 32], "pre_wo_attn": 32, "preced": [4, 18, 24, 25, 26], "precis": [19, 30], "pred": [4, 26, 29], "predict": [0, 1, 2, 3, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "predicted_answ": 30, "predicted_d": 30, "predicted_decoded_d": 30, "predicted_label": 30, "prediction_instruct": 27, "prediction_lm": 27, "prefer": [5, 6, 12, 18, 27], "prefix": [4, 24, 30], "preliminari": 7, "premis": 4, "prep": [0, 1, 2], "prepair": 18, "prepar": [0, 1, 2, 4, 5, 18, 20, 23], "prepend": 24, "preposit": 6, "preprocess": [0, 1, 2, 18, 24], "preprocessed_train_dataset": 18, "present": [2, 3, 4, 21, 22, 31], "presid": [3, 4], "press": [4, 18], "presuppos": [4, 30], "pretrain": [0, 1, 2, 5, 18, 19, 23, 27, 28, 32], "pretraining_data_s": [1, 2], "pretty_print": 4, "prevent": [3, 4, 23, 26], "previou": [2, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32], "price": 18, "primarili": [4, 31], "primit": 21, "principl": [0, 23, 24], "principle_a_case_1": 6, "print": [0, 1, 2, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33], "print_everi": 22, "print_funct": 22, "print_top": 32, "prior": [7, 31], "priori": 24, "pro": 26, "prob": [22, 33], "prob_of_answ": 32, "probabl": [0, 1, 2, 4, 5, 6, 18, 20, 21, 22, 24, 25, 26, 27, 30, 32], "probe": [4, 7, 14, 22], "probing_dir": 29, "problem": [4, 5, 7, 11, 18, 30], "problemat": [5, 31], "probs_t": 33, "procedur": [5, 20, 26, 30], "proces": [0, 1, 2], "process": [0, 1, 2, 4, 6, 8, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32], "prod": 2, "prodcut": 19, "produc": [18, 21, 22, 23, 32], "product": [19, 27, 29], "program": [7, 11, 25], "progress": [3, 4, 25], "project": [7, 18, 32, 33], "promin": [18, 24], "promot": 32, "prompt": [5, 6, 7, 22, 24, 27, 28, 29, 30, 31, 32], "prompt_input_id": [4, 26], "prompt_template_appet": 28, "prompt_template_dessert": 28, "prompt_template_main": 28, "prompt_template_summari": 28, "prompttempl": 28, "propag": 9, "propens": 31, "proper": 22, "properli": 28, "properti": [1, 2, 19], "proport": [6, 18, 22, 30], "proprietari": 5, "propto": 26, "provd": 31, "proven": 27, "provid": [0, 1, 2, 3, 4, 5, 6, 15, 16, 17, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "proxim": [5, 27], "pseudo": [6, 23, 30], "psuchologi": 30, "pt": [0, 1, 2, 4, 5, 18, 23, 25, 26, 27, 29, 30, 32], "publicli": 28, "publish": 18, "pull": 28, "punctuat": [0, 1, 2, 18, 24], "pure": [4, 23, 26], "pure_sampling_decod": 4, "purpos": [5, 18, 19, 21, 23, 27, 28, 29], "push": 18, "push_to_hub": 23, "put": [0, 1, 2, 5, 23, 29, 30, 32], "puzzl": 31, "px": 32, "py": [0, 1, 4, 18, 23, 24, 27, 32], "pyplot": [0, 1, 2, 18, 20, 21, 22, 23], "pythia": [0, 3, 4, 6, 26], "python": [7, 18, 21, 29, 30], "python3": [0, 1, 18, 23, 24, 32], "pytorch": [2, 18, 20, 22, 23, 25, 29, 32], "q": [4, 5, 24, 26, 32, 33], "q_2": 0, "q_proj_weight": 24, "q_x": 33, "qa": [25, 27], "qlora": 27, "qquestion": [0, 1, 2], "qualiti": [18, 25, 30], "quantifi": 25, "quantit": 6, "queri": [5, 18, 24, 26, 28, 29, 33], "query_engin": 5, "query_tensor": 5, "question": [0, 1, 2, 3, 4, 5, 6, 18, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32], "quick": [22, 24, 25], "quickstart": 29, "quiet": 22, "quit": [18, 23, 27, 28, 30, 31, 32], "quot": 31, "qwen": 2, "r": [0, 1, 2, 5, 18, 27, 30, 33], "r_": 27, "race": 4, "radford": 10, "rafailov": 27, "rag": [2, 5], "rag_respons": 5, "rais": [4, 29, 30, 32], "ran": 29, "rand": [18, 19, 21], "randint": 22, "random": [4, 5, 19, 22, 25, 26, 29, 32], "random_choic": 22, "random_training_exampl": 22, "random_training_pair": 22, "random_weight": 29, "randomli": [18, 22, 25], "rang": [0, 1, 2, 4, 6, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32], "rank": [27, 32], "rare": 31, "rate": [0, 1, 2, 4, 18, 20, 22, 23, 25, 26, 27], "rather": [4, 12, 18, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32], "raw": [18, 22, 24, 30], "rcl": 18, "rdbu": 32, "rdquo": 27, "re": [4, 24, 25, 28], "reach": [4, 24, 25], "react": 28, "read": [3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 26, 32], "read_csv": [6, 26, 30], "readabl": [18, 23, 24], "reader": 32, "readi": 20, "readlin": 29, "readm": 18, "readthedoc": [0, 1, 4, 18, 23], "real": [4, 28, 31], "realis": 32, "realiti": [3, 4], "realiz": [22, 31], "realli": 11, "realtoxicityprompt": [30, 31], "reason": [0, 1, 2, 3, 4, 11, 14, 27, 30], "recal": [17, 28, 30, 32], "recap": [27, 30], "receiv": [5, 18, 27, 29], "recent": [2, 3, 4, 6, 18, 24, 26, 30, 31], "recevi": 27, "recip": [5, 27, 28], "recipe_nlg_lit": 5, "recipi": 28, "reciproc": 32, "recognit": 25, "recommend": [7, 18, 22], "record": [5, 18, 30], "recov": 32, "rectangular": 4, "recurr": [22, 23], "recycl": 19, "red": [3, 4, 31], "reduc": [24, 26], "reduct": [4, 22], "reel": 18, "ref_model": 5, "refer": [3, 4, 5, 6, 13, 18, 21, 23, 25, 26, 27, 29, 30, 31, 32], "reflect": [4, 6, 18, 31], "reformat": 18, "regard": [3, 4, 18, 22, 27, 30, 31], "regex": 30, "regim": 22, "register_buff": 24, "register_forward_hook": 32, "regress": 24, "regular": 29, "reimplement": 24, "reinforc": [12, 27], "reject": 27, "rel": [4, 6, 23, 24, 27], "relat": [3, 4, 7, 12, 18, 20, 22, 24, 30, 31], "relev": [5, 7, 18, 20, 23, 25, 27, 28, 30, 31], "reli": [4, 24, 25, 29, 31], "reliabl": [4, 26, 30, 31], "reload": [0, 1, 2, 23], "relu": [0, 1, 2, 21, 22], "remain": [23, 31], "rememb": [21, 22, 26], "remind": [4, 23, 26, 29], "remov": [18, 19, 22, 24, 32], "remove_column": [23, 25], "render": [6, 32], "repeat": [20, 24, 26], "replac": [4, 32], "replic": [19, 26], "repo_id": 28, "report": [2, 3, 4, 18, 20, 22, 27], "repositori": [18, 27, 32], "repres": [3, 4, 6, 18, 19, 21, 22, 23, 24, 27, 29, 30, 32], "represen": 29, "represent": [4, 5, 9, 14, 18, 19, 21, 22, 24, 25, 29, 32], "representation_dim": 29, "reproduc": [4, 18], "req_res_oop": 32, "request": [22, 26], "requir": [0, 1, 2, 4, 5, 7, 19, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "requires_grad": [20, 24, 27], "research": [3, 4, 18, 25, 27, 28, 30, 31], "reserach": 30, "reset": 22, "reset_activ": 32, "reshap": [21, 22], "resid_dropout": 24, "resid_pr": 32, "residu": 33, "residual_stream_patching_hook": 32, "resourc": [0, 1, 2, 3, 4, 5, 6, 18, 23, 25, 26, 27, 28, 31], "respect": [2, 5, 6, 18, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31], "respond": 30, "respons": [1, 2, 4, 5, 6, 24, 30], "response_mod": 5, "response_rag": 5, "response_synthes": 5, "response_tensor": 5, "response_vanilla": 5, "responsinbl": 32, "rest": [6, 18, 23, 25, 27], "restaur": 4, "restrict": [18, 26], "result": [2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "resum": 32, "resume_download": 32, "rethink": 11, "retreiv": [0, 1, 2, 28, 30], "retriev": [1, 2, 4, 19, 22, 23, 24, 26, 27, 29, 30, 32], "retrieved_node_scor": 5, "retrieved_node_text": 5, "return": [0, 1, 2, 4, 5, 18, 19, 21, 22, 23, 24, 25, 27, 29, 30, 32, 33], "return_dict": 29, "return_output": 23, "return_tensor": [0, 1, 2, 4, 5, 18, 23, 25, 26, 27, 29, 30, 32], "reus": [5, 17, 21, 26, 27], "reusabl": 21, "revers": [2, 32], "revert": 20, "review": [4, 5, 23, 27], "revolv": 4, "reward": [5, 31], "reward_fn": 5, "reward_model": 27, "reward_neg": 27, "reward_po": 27, "reward_token": 27, "reynold": 11, "right": [0, 1, 2, 14, 21, 23, 24, 26, 28, 31], "rigor": 17, "rise": [4, 18, 31], "risk": [16, 31], "rl": 4, "rlaif": 27, "rlhf": [1, 2, 18, 27, 31], "rm_hook": 32, "rms_norm_ep": 0, "rnn": [21, 24, 25], "road": 4, "robot": [12, 13], "robust": [22, 30, 31], "rocm": 18, "role": [11, 24, 32], "rolling_mean": 22, "rome": 17, "root": 30, "rope_sc": 0, "rope_theta": 0, "roug": [5, 27, 30], "rouge1": 5, "rouge_scor": 5, "roughli": 21, "round": [21, 22, 29, 33], "row": [2, 4, 24, 27], "row_vector": 19, "royal": 18, "rr": 32, "rr_per_lay": 32, "rt": 6, "ruff": 18, "rule": [0, 1, 2, 21, 22, 24], "rumelhart": 9, "run": [0, 1, 2, 4, 5, 18, 21, 23, 26, 27, 29, 30, 32], "run_with_cach": 32, "run_with_hook": 32, "runtim": [0, 1, 2, 3, 4, 5, 6, 18, 26], "russian": 22, "ryan": 7, "safe": [3, 4], "safer": 18, "safeti": [4, 31], "sai": [5, 6, 13, 18, 26, 31, 32], "said": 26, "sake": 28, "salazar": 30, "salienc": 29, "same": [3, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "sampl": [0, 1, 2, 3, 4, 5, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30], "santurkar": 31, "sar\u0131ta\u015f": 4, "satisfii": 28, "satoshi": 22, "save": [0, 1, 2, 3, 4, 5, 6, 18, 21, 22, 25, 32], "save_step": 23, "saw": 32, "scalabl": [30, 31], "scalar": [2, 5, 19, 21, 27], "scale": [0, 5, 8, 12, 20, 21, 27, 30, 33], "scan": 0, "scari": [3, 4], "scatterplot": 21, "scenario": [4, 30], "scene": [20, 21], "schedul": [23, 25, 27], "scheme": [3, 5, 23], "schmidhub": 10, "schnell": 24, "school": [3, 4], "scienc": [7, 30, 31], "scientif": 27, "scope": 22, "score": [4, 5, 6, 24, 25, 26, 27, 29, 30, 33], "scorer": [6, 30], "scottish": 22, "scratch": [23, 25], "scratchpad": 11, "script": 27, "scrub": 17, "seaborn": [20, 21], "seamlessli": [18, 28], "search": [3, 4, 5, 18, 25, 26, 28], "searchabl": 5, "searhc": 28, "second": [0, 3, 4, 5, 6, 9, 18, 19, 21, 24, 29], "secretli": 27, "section": [3, 4, 6, 18, 27, 30, 31], "secur": 4, "see": [0, 1, 2, 3, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "seed": 26, "seek": 20, "seem": [2, 4, 21, 22, 26, 27, 29, 30], "seen": [19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "segmented_token": 29, "select": [4, 6, 18, 21, 23, 25, 26, 27, 29, 30, 31], "self": [0, 1, 2, 4, 11, 21, 22, 23, 24, 27, 29, 32], "self_attn": 24, "self_consist": 4, "sell": [1, 2], "semant": [6, 30], "semest": 18, "seminar": 7, "send": 23, "sens": [0, 1, 2, 5, 22, 23, 24, 26, 27, 31], "sensibl": [18, 23, 27], "sensibli": 4, "sensit": [4, 29, 31], "sentenc": [0, 1, 2, 3, 4, 5, 6, 14, 18, 23, 24, 25, 26, 27, 29, 30, 32, 33], "sentence1": 30, "sentence2": 30, "sentiment": [3, 4, 18, 23, 25, 26, 27, 30], "sep": [26, 29], "separ": [0, 1, 2, 5, 6, 21, 24, 26, 27, 30], "seq2seq": [25, 29], "sequenc": [0, 1, 2, 4, 21, 24, 25, 26, 28, 29, 32], "sequence_length": 29, "sequence_scor": 30, "sequenti": [21, 22], "seri": [20, 23, 25], "serious": 22, "serv": [4, 5, 26, 28], "server": 23, "servic": 4, "session": [18, 23, 26, 27], "set": [0, 1, 2, 4, 5, 6, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "set_format": [5, 18], "set_se": 4, "settl": 18, "setup": 23, "seventh": 14, "sever": [0, 1, 2, 4, 18, 22, 24, 25, 28, 30], "sft": [5, 27], "sfttrainer": 27, "sgd": 20, "shape": [2, 4, 18, 19, 22, 23, 24, 26, 29, 31, 32, 33], "share": [4, 18, 21, 27, 28], "sharehold": 18, "sharpen": 31, "she": [3, 4, 30], "shed": 30, "sheet": [0, 1, 2, 3, 4, 5, 6, 8], "shift": [3, 4, 19, 23], "shima": 22, "ship": [0, 1, 2, 23, 24], "shirt": [3, 4], "shop": [3, 4, 26], "short": [4, 5, 10, 18, 19, 21, 22, 23, 27, 31], "shorter": [4, 18, 21], "shot": [3, 11, 26], "should": [0, 1, 2, 4, 5, 6, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "shouldn": [3, 4], "show": [1, 2, 4, 5, 6, 11, 20, 21, 22, 23, 24, 25, 27, 29, 32], "shown": [4, 5, 22, 27, 30, 31], "shuffl": [0, 1, 2, 18, 21, 22], "shy": 18, "side": [0, 1, 2, 4, 18, 23, 24], "sidewalk": [3, 4], "sigma": 27, "sign": [24, 28], "signal": [5, 18, 21, 24, 27], "signific": [3, 4, 18], "significantli": 18, "silu": 0, "sim": 27, "simialar": 4, "similar": [3, 4, 5, 6, 20, 21, 24, 26, 27, 29, 30, 31, 32], "similarity_top_k": 5, "similarli": [19, 30], "simpl": [1, 2, 6, 17, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32], "simplest": 24, "simpli": [24, 27, 29], "simplif": 26, "simplifi": [23, 26], "simulacra": 13, "simultan": [5, 18], "sin": [21, 24], "sinc": [0, 1, 2, 5, 18, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "sine": 24, "sing": [0, 1, 2, 4], "singl": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32], "singular": 6, "sit": [3, 4], "site": [0, 1, 4, 18, 23, 24, 32], "situat": 18, "sixth": 13, "size": [0, 1, 2, 4, 5, 18, 19, 21, 22, 23, 24, 25, 27, 28, 30, 32], "skate": [3, 4], "skateboard": [3, 4], "skill": [0, 1, 2, 3, 4, 5, 6, 21, 31], "skim": 31, "skip": 32, "skip_special_token": [0, 1, 2, 4, 26, 27, 30], "sklearn": 30, "sleep": [1, 2, 4], "slide": [5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 23, 26, 27, 29], "slight": 22, "slightli": [18, 19, 21, 25, 29, 30, 32], "slip": 18, "slope": 21, "slot": 18, "slow": 32, "slowdown": 6, "slowli": 20, "small": [1, 2, 3, 4, 5, 7, 17, 18, 20, 23, 24, 27, 29, 30, 32], "smaller": [0, 1, 2, 4, 18, 21, 23, 30], "smart": [3, 4], "smile": [3, 4], "smooth": 4, "smoothen": 26, "sn": [20, 21], "snake": 4, "sneez": 0, "snli": 4, "so": [0, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "soccer": 4, "social": [6, 30], "societi": 7, "sociocultur": 18, "soft": [26, 32], "softmax": [4, 22, 26, 32, 33], "softmax_sampling_decod": 4, "softwar": [4, 18, 31], "sold": 26, "sole": 4, "solid": 4, "solut": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 25, 27, 31], "solv": [0, 1, 2, 3, 4, 5, 6, 11, 18, 20, 30], "some": [0, 1, 2, 3, 4, 5, 6, 12, 13, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "somehow": 28, "someon": 4, "someth": [0, 1, 2, 6, 20, 21, 22, 27, 31, 32], "sometim": [18, 23, 24, 25, 26, 27, 28, 31], "somewhat": [1, 2, 21, 26, 28, 30], "song": 4, "soon": 25, "sophist": [3, 4], "sort": 27, "sorted_prob": 32, "sosindex": 22, "sota": [4, 24, 27, 30, 31], "sound": [22, 26, 27, 31], "soup": 5, "sourc": [5, 6, 7, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31], "source_nod": 5, "space": [0, 1, 2, 3, 4, 5, 18, 22, 27, 29, 30, 32], "spaci": 29, "span": [25, 27], "spanish": 22, "spars": [1, 2], "speak": [19, 22], "speaker": 22, "spec": 18, "special": [4, 5, 21, 22, 23, 25, 26, 27, 28, 29, 30], "specicif": 32, "specif": [0, 1, 2, 3, 4, 5, 6, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "specifi": [1, 2, 18, 19, 21, 23, 24, 25, 27, 28, 29], "speech": [8, 29, 30], "speed": [0, 1, 2, 3, 4, 5, 6, 18, 21, 27], "spend": [3, 4], "split": [0, 1, 2, 5, 18, 21, 23, 24, 25, 27, 29, 30], "split_percentag": 22, "spoiler": 26, "sponsor": 28, "sport": 4, "spot": [0, 1, 2, 23], "sprang": 24, "spuriou": 29, "sqrt": [21, 25, 33], "squar": 4, "squeez": [5, 19, 21, 22, 32], "src": 6, "src_mask": 24, "ss": 7, "stabil": [20, 25, 27], "stabl": [0, 1, 4, 5, 18, 19, 21, 23, 25], "stack": [19, 21, 32], "stage": 25, "stai": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 32], "stand": [18, 30], "standard": [4, 5, 18, 20, 25, 27, 30], "stanford": 4, "stanfordnlp": [23, 25], "stanlei": [3, 4], "start": [0, 4, 5, 18, 21, 22, 24, 25, 26, 27, 28, 31, 32], "starter": 6, "startofsequ": 24, "startswith": [27, 29], "stat": 5, "state": [0, 1, 2, 3, 4, 7, 18, 20, 22, 23, 24, 27, 29, 32], "stateless": 28, "statement": [4, 26], "static": 24, "station": 4, "statist": [4, 18, 21], "stdv": 21, "step": [0, 1, 2, 5, 6, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32], "step_scor": 29, "stepwis": 28, "stereotyp": 31, "stick": 18, "still": [4, 18, 20, 22, 23, 24, 26, 30], "stochast": [20, 22, 31], "stock": 18, "stop": [4, 18, 21, 24, 25, 29], "stopword": 18, "storag": [5, 18], "store": [3, 4, 5, 6, 19, 20, 21, 22, 23, 30, 32], "stori": 27, "storycloz": 31, "str": [0, 1, 2, 5, 18, 30, 32, 33], "str_tok": 32, "straightforward": 5, "stranger": 6, "strategi": [11, 18, 30, 31], "stream": [4, 28], "street": [4, 18, 26], "stress": [3, 4], "strictli": 19, "string": [0, 1, 2, 6, 18, 19, 22, 23, 24, 29, 30, 32], "strip": [5, 29], "strong": [18, 27], "strongli": [18, 31], "stroutputpars": 28, "structur": [3, 4, 6, 14, 18, 19, 21, 23, 28, 30], "student": [0, 1, 2, 4, 7, 27], "studi": [18, 20, 22, 27, 28, 30], "studio": 18, "stumbl": 27, "style": [3, 4, 17, 18, 27], "sualli": 18, "sub": [4, 18, 19, 28, 29], "subclass": 23, "subject": [6, 7, 27], "submiss": [0, 1, 2, 3, 4, 5, 6], "submit": [0, 1, 2, 3, 4, 5, 6, 18], "subplot": 25, "subsampled_dataset": [23, 25], "subsect": 22, "subsequ": [4, 20, 21, 22, 27, 31, 32], "subset": [23, 27], "substep": [23, 28], "subtl": 21, "subtract": [19, 21, 32, 33], "subword": 24, "success": [3, 4, 5, 23, 24, 25, 27], "successfulli": [18, 25], "suffici": [0, 23], "sufficintli": 27, "suffix": 4, "suggest": [2, 4, 6, 18, 22, 28], "suiss": 18, "suit": [2, 6, 27, 30], "suitabl": [18, 27], "sum": [0, 1, 2, 4, 18, 20, 22, 24, 26, 27, 29, 30], "sum_": 30, "summar": [4, 23, 25, 27, 30], "summari": [1, 2, 3, 4, 5, 27, 28, 30], "summaris": 27, "summend": 26, "super": [21, 22, 24, 29, 32], "super_glue_boolq": 30, "superglu": 30, "superlative_quantifiers_1": 6, "supermarket": 6, "supervis": [12, 29, 31], "supplement": [5, 30], "supplementari": [10, 11, 12, 13, 14, 15, 16, 17], "suppli": [5, 18, 21, 22], "support": [4, 18, 19, 29, 31], "supporting_modul": 5, "suppos": [5, 18, 23, 27, 30], "suppress": 20, "sure": [0, 1, 2, 3, 4, 6, 18, 21, 22, 23, 24, 26, 27, 29, 30, 32], "surnam": [1, 2, 22], "surname_firstname_hw1": [0, 1], "surname_firstname_hw2": [3, 4], "surname_firstname_hw3": 5, "surname_firstname_hw4": 6, "surname_firtname_hw1": 2, "surp_avg": 22, "surp_avg_dict": 22, "surp_dict": 22, "surp_scal": 22, "surpris": [0, 1, 2, 22], "surprisal_test": 22, "surprisal_train": 22, "surprisl": 22, "surprisl_dict": 22, "survei": 8, "sva_data": 6, "swap": 23, "switch": 25, "swoop": 21, "sy": 29, "symbol": [18, 24], "symmetr": 30, "syntact": [6, 14, 15, 29, 30], "syntax": [0, 6, 19], "syntaxerror": 0, "syntaxgym": 15, "system": [3, 4, 6, 20, 24, 25, 27, 28, 30, 31], "systemat": [4, 7], "t": [0, 1, 2, 3, 4, 5, 6, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33], "t5": [25, 29, 30], "t5forconditionalgener": 30, "t5token": 30, "tabl": [3, 4, 6, 18], "tag": [18, 25, 29, 30], "tail": 19, "take": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "taken": [6, 23, 29, 30, 31, 32], "talk": [4, 28], "talmor": [0, 1, 2], "tandem": 30, "tap": 6, "target": [18, 20, 21, 22, 23, 27, 29, 30, 31], "target_id": 29, "target_line_tensor": 22, "target_out": 23, "target_tensor": 22, "task": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "task_prompt": 4, "tau": [0, 1, 2, 26, 30], "taught": 7, "tbd": 2, "teach": [4, 27], "teacher": 6, "team": [18, 31], "technic": [2, 7, 30], "techniqu": [3, 4, 5, 21, 26, 27, 29, 31, 32], "tediou": 21, "televis": [3, 4], "tell": [0, 3, 4, 5, 19, 20, 21, 22, 27, 30], "temp_hook_fn": 32, "temperatur": [0, 1, 2, 4, 5, 26, 28], "templat": 28, "tempor": 22, "temporari": 32, "ten": 27, "tend": 27, "tendenc": 22, "tennei": [14, 29], "tenni": 6, "tensor": [0, 1, 2, 5, 18, 20, 21, 22, 23, 24, 26, 29, 32, 33], "tensor1": 19, "tensor2": 19, "tensor3": 19, "tensor4": 19, "tensor5": 19, "tensor_0d": 19, "tensor_1": 19, "tensor_1_transpos": 19, "tensor_2": 19, "tensor_2d": 19, "tensor_from_list": 19, "tenth": 17, "tep": 5, "term": [6, 10, 18, 23, 24, 26, 27, 30], "terminologi": [28, 30], "termn": [0, 1, 2], "terribl": 26, "test": [0, 1, 2, 3, 4, 5, 6, 15, 17, 18, 21, 23, 25, 26, 27, 28, 29, 31, 32], "test_accuraci": 29, "test_data": 22, "test_dataload": [0, 1, 2], "test_dataset": [0, 1, 2], "test_df": 5, "test_indic": 22, "test_label": 29, "test_labels_al": 29, "test_layer_represent": 29, "test_loss": [0, 1, 2, 23, 29], "test_output": [0, 1, 2], "test_queri": 5, "test_represent": 29, "test_representations_al": 29, "test_sampl": [0, 1, 2], "test_sent": 29, "test_sentence_represent": 29, "test_set": 4, "test_siz": [18, 22], "test_split": [1, 2], "testabl": 6, "testset": 22, "text": [0, 1, 2, 3, 4, 5, 12, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "text1": 24, "text2": 24, "text3": 24, "text_d": 30, "text_en": 30, "textbook": [8, 9, 10], "textual": [5, 30], "th": [3, 4, 5, 6, 24], "than": [3, 4, 6, 12, 18, 24, 25, 27, 28, 29, 30, 32], "thei": [3, 4, 5, 6, 7, 18, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32], "thelik": 24, "them": [0, 1, 2, 3, 4, 5, 6, 7, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "themselv": 7, "theorem": 27, "theoret": [4, 28, 30], "theori": 30, "therebi": [4, 24, 30], "therefor": [0, 1, 2, 4, 5, 6, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "theses": 2, "theta": 27, "thi": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "thing": [4, 18, 20, 21, 22, 23, 24, 25, 28, 32], "think": [0, 1, 2, 3, 4, 5, 7, 18, 19, 21, 22, 24, 25, 26, 27, 29, 30, 31], "third": [5, 6, 10, 19, 21, 24, 28, 29], "those": [22, 23, 24, 26, 29, 30, 31], "though": [2, 4, 18, 26], "thought": [3, 4, 11, 16, 23, 26, 31], "thousand": [27, 30], "three": [0, 1, 2, 4, 5, 18, 19, 22, 24, 25, 28], "threshold": [4, 26], "through": [0, 1, 2, 4, 18, 19, 20, 22, 23, 24, 26, 27, 29, 32], "throughout": [0, 1, 2, 18, 23, 31, 32], "thu": [21, 30], "tidi": 18, "tie_word_embed": 0, "tightli": 25, "tile": 29, "time": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 22, 23, 24, 25, 28, 30], "time_sinc": 22, "times5": [0, 1, 2], "timestamp": 21, "tiramiu": 28, "titl": 32, "tmobil": 18, "to_numpi": 32, "to_single_token": 32, "to_str_token": 32, "to_token": 32, "todo": [2, 19], "tofu": 27, "togeth": [5, 6, 23, 24, 26, 28, 29, 32], "tok": 24, "tokein": 18, "token": [0, 1, 2, 3, 4, 5, 18, 21, 22, 23, 25, 26, 27, 28, 29, 30, 32, 33], "token_label": 32, "tokenized_dataset": [0, 23, 25], "tokenized_input": [1, 2, 23, 25], "tokenizer_gpt2": 18, "tokenizer_instruct": 27, "tokenizer_lm": 27, "tokenizer_nam": 5, "tokenizer_t5": 30, "tokenizer_typ": [1, 2], "tokenizers_parallel": 32, "told": 20, "tomato": 28, "too": [4, 5, 23, 25, 30], "tooken": 18, "tool": 18, "top": [4, 18, 26, 28, 29, 32], "top_k": [4, 5, 23, 26], "top_k_sampling_decod": 4, "top_p": [4, 5, 26], "top_p_sampling_decod": 4, "topi": 22, "topic": [1, 2, 7, 12, 13, 18, 24, 25, 26, 30, 31], "topk": [22, 32], "topk_per_lay": 32, "topv": 22, "torch": [0, 1, 2, 4, 5, 6, 18, 19, 20, 21, 22, 23, 24, 26, 27, 29, 30, 32, 33], "torch1": 19, "torch2": 19, "torch_dtyp": [0, 5, 26, 32], "torchrl": 18, "torchtext": 30, "tot": 4, "total": [2, 5, 22, 27], "total_loss": [22, 29], "total_s": 22, "touvron": [11, 27], "toward": 27, "town": 30, "toxic": [18, 30, 31], "tqdm": [0, 1, 2, 4, 5, 18, 23, 32], "tqdmwarn": [0, 1, 4, 18, 23], "tra": 18, "trace": 29, "traceback": 2, "track": [0, 1, 2, 20, 22, 30], "tradit": 18, "train": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 19, 23, 24, 26, 30, 31, 32], "train_accuraci": 29, "train_data": [20, 22], "train_dataload": 21, "train_dataset": [0, 1, 2, 23, 27], "train_indic": 22, "train_label": 29, "train_labels_al": 29, "train_layer_represent": 29, "train_loss": [23, 29], "train_represent": 29, "train_representations_al": 29, "train_sent": 29, "train_sentence_represent": 29, "train_siz": [18, 22], "train_split": [1, 2], "train_step": [0, 1, 2], "train_test_split": 18, "trainabl": [0, 1, 2, 20, 21, 27], "trainer": [23, 27], "training_data": [1, 2], "training_data_cutoff": [1, 2], "trainingargu": 23, "tram": [3, 4], "transfer": 31, "transform": [0, 1, 2, 3, 4, 5, 7, 17, 18, 21, 26, 27, 28, 29, 30, 32], "transformer_len": 32, "transformer_model": 24, "transformerdecod": 24, "transformerdecoderlay": 24, "transformerencod": 24, "transformerencoderlay": 24, "transformermodel": 24, "translat": [25, 29, 30], "transpos": [2, 18, 22, 24], "travel": 4, "treat": [4, 21, 23, 29], "tree": [3, 4, 11, 26], "treebank": 30, "trend": 8, "tri": [3, 4, 25, 28], "trial": [6, 27, 30], "trian": [0, 1, 2], "trick": [21, 25], "tricki": [25, 31, 32], "trigram": 30, "triplet": 22, "trivial": 27, "triviaqa": 31, "trl": [5, 27], "troubl": [3, 4], "trough": 18, "true": [0, 1, 2, 4, 5, 6, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32], "true_answ": 30, "true_dist": 20, "true_loc": 20, "true_logit": 32, "true_posit": 30, "truncat": [0, 1, 2, 5, 23, 25], "trust_remote_cod": [5, 26], "truth": [0, 1, 2, 5, 21, 27, 30], "truthful_qa": 23, "truthfulqa": 31, "try": [0, 1, 6, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "tsvilodub": [18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "tuck": 18, "tue": 7, "tune": [3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 23, 25, 26, 28, 29, 30, 31], "tupl": [0, 1, 2], "turbo": [28, 30], "turn": [21, 27], "tutor": 27, "tutori": [0, 1, 2, 18, 20, 21, 22, 23, 24, 25], "tweet": 18, "tweet_length": 18, "twice": [5, 32], "twitter": [1, 2, 18], "two": [0, 1, 2, 3, 4, 5, 6, 9, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31], "txt": [18, 29], "type": [0, 1, 2, 3, 4, 5, 6, 18, 23, 24, 25, 27, 28, 31, 32], "typic": [2, 4, 6, 21, 22, 26, 27], "t\u00fcbingen": 7, "u": [4, 5, 6, 18, 19, 20, 21, 22, 23, 27, 28, 30, 31], "ud": 29, "ud_en_pref": 29, "ultim": [4, 27], "umbrella": [4, 23], "umpir": 4, "un": 27, "unanim": 26, "unclear": [21, 27], "uncom": [0, 1, 2, 5, 18, 23, 27], "under": [0, 1, 2, 4, 6, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31], "underfit": 25, "undergo": [24, 32], "undergon": [3, 4], "underli": [5, 23, 30], "underpin": 27, "understand": [3, 4, 5, 10, 11, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "understanding_llm": [0, 1, 18, 23, 24, 32], "understood": 18, "undesir": [18, 27, 31], "unembed": 32, "unexpect": [4, 26], "unexpectedli": 30, "unfortun": [2, 18], "unfortunatelli": 28, "unfrozen": 27, "ungrammat": 30, "ungrammatical_log_prob": 30, "ungrammatical_sent": 30, "uni": 7, "unicod": 24, "unicode_liter": 22, "uniform": [4, 21], "uniform_": 21, "uniformli": 19, "unigram": [24, 30], "union": 29, "uniqu": [1, 2, 18, 22, 24, 29], "unique_label": 29, "unit": [6, 18, 19, 22, 24], "univers": 12, "unk": 24, "unknown": [18, 24, 27], "unless": [0, 1, 2], "unlik": 2, "unnecessari": 24, "unpack": 21, "unrecogn": 29, "unsaf": 31, "unseen": [4, 18], "unsolv": 30, "unsqueez": [19, 23, 24, 32], "unsqueeze_": 22, "unstructur": 5, "unsupervis": [10, 27], "unsurpris": 18, "until": [5, 24, 25, 26], "up": [0, 1, 2, 3, 4, 5, 6, 21, 23, 26, 27, 28, 29, 30, 31, 32], "upcom": 18, "updat": [0, 1, 2, 4, 18, 21, 23, 25, 27, 28, 32], "upload": [0, 1, 2, 3, 4, 5, 6, 23, 29], "upon": [4, 27], "urg": 18, "url": 22, "urllib": 22, "urlopen": 22, "us": [0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "usa": 6, "usabl": [19, 27], "usag": [2, 18], "usage_custom": 5, "use_cach": [0, 32], "use_mps_devic": 23, "use_nested_tensor": 24, "user": [4, 18, 24, 25, 27, 28, 30, 31], "user_instal": [0, 1, 4, 18, 23], "userwarn": 24, "using_llm": 5, "usual": [0, 1, 2, 4, 6, 18, 19, 22, 23, 24, 25, 27, 28, 30], "util": [0, 1, 2, 4, 5, 18, 23, 26, 29, 32], "v": [0, 1, 2, 6, 21, 23, 24, 30, 32, 33], "v0": 28, "v1": [5, 30], "v2": [2, 5], "v_0": 33, "v_1": 33, "v_2": 0, "v_4": 33, "v_proj_weight": 24, "v_x": 33, "valid": [0, 1, 2, 5, 18, 24, 25, 27, 28, 30], "valu": [4, 5, 21, 22, 23, 24, 25, 26, 27, 29, 30, 32, 33], "valuabl": 18, "value_var": 21, "valueerror": 29, "vanilla": [4, 5, 27], "vanilla_respons": 5, "vanish": 21, "var": 33, "vari": [4, 26, 27], "variabl": [0, 1, 2, 4, 18, 20, 21, 22, 28, 30, 32], "varianc": 22, "variant": 21, "variat": 6, "varieti": [18, 28, 30], "variou": [3, 4, 5, 7, 18, 19, 25, 26, 27, 28, 29, 30, 31, 32], "vast": [21, 28], "vaswani": 10, "vdim": 24, "ve": 25, "vec": 33, "vecor": 29, "vector": [4, 5, 17, 18, 21, 22, 24, 29, 32], "vector_store_index": 5, "vectorstor": 5, "vectorstorageindex": 5, "vectorstoreindex": 5, "vegetarian": 28, "verb": 6, "verbos": [5, 28], "veri": [3, 4, 5, 18, 19, 22, 23, 24, 25, 26, 27, 28, 30], "versa": [24, 27], "version": [1, 2, 3, 4, 18, 21, 24, 27, 28, 32], "vf_coef": 5, "via": [0, 1, 2, 3, 4, 5, 6, 18, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32], "vice": [24, 27], "vicuna": [2, 3, 4], "video": [7, 18], "vietnames": 22, "view": [28, 29], "vig": 17, "vignett": 6, "vision": [23, 25, 31], "visual": [4, 5, 6, 18, 24, 26, 31], "vivid": [3, 4], "vocab": [24, 33], "vocab_s": [0, 24], "vocabulari": [0, 1, 2, 4, 18, 21, 22, 24, 25, 26, 32], "vocabulary_s": [1, 2], "volum": 4, "vote": 4, "w": 2, "w_": [2, 26], "w_f": 33, "w_i": [2, 26], "wa": [0, 1, 2, 3, 4, 5, 6, 18, 22, 23, 24, 26, 27, 28, 30, 31, 32], "wai": [0, 1, 2, 3, 4, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 32], "wait": [3, 4], "walk": [4, 6, 29], "wall": 18, "walmart": [3, 4, 18], "wang": [11, 17], "want": [0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "waren": 30, "warm": 27, "warn": [20, 21, 22, 24, 27, 32], "warsaw": 32, "wash": 21, "wasn": 4, "wave": [3, 4], "we": [0, 1, 2, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "weak": 18, "weaker": 30, "wear": [3, 4], "web": 18, "webbbook": 7, "webbook": 26, "webook": 18, "websit": [1, 2, 23, 24, 28], "webson": [11, 31], "week": [18, 23, 25], "weekli": 7, "wei": 11, "weigh": 5, "weight": [0, 1, 2, 19, 21, 23, 24, 25, 27, 29, 30, 32], "weight_decai": 23, "weight_norm": 21, "weights1": 2, "weights2": 2, "weights3": 2, "weights4": 2, "welcom": 30, "well": [0, 1, 2, 3, 4, 5, 6, 8, 18, 22, 23, 24, 25, 27, 29, 30, 32], "went": 32, "were": [2, 3, 4, 5, 11, 18, 24, 26, 27, 30, 31, 32], "weren": 24, "what": [0, 1, 2, 3, 4, 5, 6, 7, 11, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "when": [0, 1, 2, 4, 5, 6, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32], "whenev": 18, "where": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "wherea": 4, "wherein": [5, 30], "whether": [0, 1, 2, 3, 4, 6, 18, 23, 25, 27, 29, 30, 31, 32], "which": [0, 1, 2, 3, 4, 5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "while": [0, 1, 2, 3, 4, 5, 18, 21, 22, 23, 24, 25, 26, 27, 30], "white": [3, 4], "whitespac": [18, 24], "who": [4, 7, 18, 24, 25], "whole": [2, 28, 30], "whose": [25, 27, 31], "why": [3, 4, 5, 6, 18, 21, 22, 24, 26, 27, 29, 30, 31, 32], "why_not_sparsity_fast_path": 24, "wide": [27, 30], "wider": 4, "widespread": 24, "width": [19, 22], "wiggl": 21, "wikipedia": [18, 28, 30], "wikipediaapiwrapp": 18, "wikipediaqueryrun": 18, "wikitext": 30, "wilcox": 6, "wild": 17, "window": [0, 4, 5, 18, 29, 30], "wing": [4, 26], "winogend": 30, "winogrand": 31, "wise": [19, 25], "within": [5, 18, 23, 24, 26, 30, 32], "without": [0, 1, 2, 4, 18, 19, 23, 26, 28, 30, 32], "witin": 0, "wizardlm": 2, "wkipedia": 30, "wo": 32, "woman": [3, 4], "women": [3, 4], "won": 4, "word": [0, 1, 2, 3, 4, 5, 14, 18, 21, 23, 24, 25, 26, 27, 29, 31], "word2vec": [8, 17, 18], "wordpiec": 24, "work": [0, 1, 2, 3, 4, 5, 6, 7, 11, 18, 19, 20, 21, 22, 24, 25, 26, 27, 30, 32], "worker": [4, 18], "workflow": 23, "worksheet": 7, "world": [2, 19, 31], "worri": 30, "wors": [25, 27], "worthwhil": 21, "would": [0, 2, 4, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "wouldn": 24, "wpe": 24, "wrangl": [0, 1, 2, 23, 30], "wrapper": [18, 23, 24, 32], "write": [0, 1, 2, 3, 4, 6, 21, 22, 23, 24, 25, 27, 28, 30, 31, 32], "written": [0, 3, 4, 5, 27, 30], "wrong": [2, 14, 31], "wrongfuldeath": 18, "wte": 24, "www": 5, "x": [0, 1, 2, 6, 7, 18, 19, 21, 22, 24, 26, 27, 29, 32, 33], "x_": 30, "x_0": 30, "x_1": [0, 1, 2], "x_2": [0, 1, 2], "x_i": 30, "x_n": 30, "x_ob": 21, "x_test": [0, 1, 2], "xaxi": 32, "xie": 11, "xl": 30, "xlabel": [0, 1, 2, 18, 23], "xxx": [1, 2], "y": [2, 6, 18, 19, 21, 26, 32, 33], "y_1": [0, 1, 2, 27], "y_2": [0, 1, 2, 27], "y_3": [0, 1, 2], "y_nois": 21, "y_normal": 21, "y_ob": 21, "y_pred": 21, "yao": 11, "yard": 4, "yaxi": 32, "ye": [2, 5, 22, 23, 29, 31], "year": [3, 4, 18], "yet": [5, 18, 22, 23, 27, 29], "ygjpt2red3": 18, "yield": 19, "ylabel": [0, 1, 2, 23], "york": 4, "you": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "young": 4, "younger": 4, "your": [0, 1, 2, 3, 4, 5, 6, 11, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32], "your_api_kei": 28, "yourself": [0, 1, 2, 5, 18, 21, 22, 23, 24, 25, 26, 32], "youself": 21, "yu": 17, "z": [18, 21, 33], "z1": 18, "z2": 18, "z37ijmcqzb": 18, "z_0": 33, "zero": [0, 1, 2, 3, 4, 11, 19, 20, 21, 22, 24, 25, 30, 32], "zero_grad": [2, 20, 21, 22, 29], "zeroshot": 18, "zhao": 8, "ziegler": 5, "zip": [0, 1, 2, 5, 6, 29, 30], "zoom": [3, 4, 5, 6, 29, 31], "\u00fcber": 24, "\u03f5": 2, "\u03f5r": 2, "\ud835\udc4e": 4}, "titles": ["Homework 1: Language models (50 points)", "Homework 1: Language models (50 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LLMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Implications, Understanding &amp; Philosophy", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "titleterms": {"": [6, 21], "1": [0, 1, 2, 3, 4, 5, 6, 18, 19, 20, 24, 26, 27, 28, 29, 30, 32], "10": 6, "12": [0, 1, 2], "13": [0, 6], "14": [3, 4], "15": [0, 1, 2, 5], "16": [3, 4], "2": [0, 1, 2, 3, 4, 5, 6, 19, 20, 21, 22, 23, 25, 26, 28, 31], "20": [3, 4], "22": 6, "23": [0, 1, 2], "3": [0, 1, 2, 3, 4, 5, 6, 20, 21, 24, 25, 26], "30": 5, "4": [6, 20, 22, 27], "5": [5, 6, 20, 23, 28], "50": [0, 1, 2, 3, 4], "6": 29, "7": [30, 31], "8": 32, "activ": 32, "addit": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "advanc": [3, 4, 21, 31], "agent": [5, 13, 28], "ann": 9, "answer": 2, "ar": 6, "arithmet": 19, "aspect": [5, 31], "assess": [15, 19, 30], "assist": 31, "attent": [24, 29], "attribut": [14, 19, 29], "audienc": 7, "augment": 5, "autograd": 21, "background": 8, "backprop": 20, "backpropag": 20, "behavior": [15, 30], "benchmark": [30, 31], "best": 18, "bias": 6, "bpe": 24, "broadcast": 19, "build": 5, "built": 21, "capabl": 6, "charact": 22, "choic": [3, 4], "code": 18, "colab": 18, "column": 19, "commonsenseqa": 4, "comput": [20, 21], "concept": 18, "concis": 21, "configur": [0, 25], "consist": 31, "core": 18, "cours": 7, "creat": 19, "current": [11, 20], "data": [18, 19, 20, 21, 22], "dataset": [4, 18], "decod": [26, 32], "defin": [21, 22], "definit": 21, "distribut": 20, "document": 18, "dynam": 25, "earli": 32, "eo": 24, "error": 20, "essenti": 19, "estim": 20, "evalu": [2, 6, 15, 22, 29, 30, 31], "excercis": 28, "exercis": [0, 1, 2, 3, 4, 5, 6, 25, 26], "experi": 4, "explicit": 21, "extract": [1, 2], "few": 4, "fine": [0, 1, 2, 5, 12, 27], "fingerprint": [1, 2], "first": [3, 4], "flavour": 27, "formalia": 7, "function": 22, "further": 7, "gener": [3, 4, 5, 22], "global": [21, 22], "gpt": [0, 1, 2], "gradient": 20, "grammat": 6, "graph": 21, "hallucin": 31, "handl": 28, "head": 25, "helper": 22, "homework": [0, 1, 2, 3, 4, 5, 6], "how": 6, "huggingfac": 23, "human": 6, "implic": 16, "index": 19, "infer": [4, 22], "inform": 20, "inspect": 22, "instal": 18, "intend": 7, "interpret": [17, 25, 32], "introduct": 23, "invert": 22, "iter": 7, "join": 19, "just": 19, "knowledg": [4, 31], "langchain": 28, "languag": [0, 1, 2, 4], "layer": 21, "level": 22, "like": 6, "linear": 21, "llama": 6, "llm": [0, 1, 2, 5, 6, 7, 13, 28, 29], "lm": [3, 4, 9, 11, 23], "load": 22, "local": 18, "logist": [0, 1, 2, 3, 4, 5, 6], "loop": 20, "loss": 20, "lstm": 10, "machin": 30, "main": 18, "mask": [24, 25], "materi": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17], "matrix": 19, "mechanist": [17, 32], "memori": 28, "method": [14, 29], "metric": 30, "ml": [20, 23], "mlm": 25, "mlp": 21, "model": [0, 1, 2, 21, 22, 23, 25, 27], "modul": 21, "more": 21, "multipl": [3, 4, 19], "natur": 4, "network": 22, "neural": [3, 4], "nli": [3, 4], "nn": 21, "non": 21, "numersens": 4, "oper": 19, "optim": 20, "option": [21, 24, 25, 27], "outlook": [21, 23, 24, 25, 27, 30], "output": 28, "overview": 7, "packag": [20, 21, 22], "paramet": [20, 21, 22], "pars": 28, "part": 20, "patch": 32, "peft": 27, "philosophi": 16, "point": [0, 1, 2, 3, 4, 5, 6], "polici": 27, "possibl": 2, "ppo": 27, "practic": [18, 27], "predict": 20, "prepar": 21, "pretrain": 24, "previou": 7, "probe": 29, "problem": 31, "process": [18, 31], "prompt": [3, 4, 11, 26], "psychologi": 30, "pytorch": [9, 19, 21, 24], "qa": [0, 1, 2, 3, 4], "reason": 31, "regress": 21, "requir": 18, "reset": 20, "reshap": 19, "residu": 32, "retriev": 5, "reward": 27, "rl": [5, 27], "rlhf": [5, 12], "rnn": 22, "row": 19, "schedul": 7, "scheme": [4, 26], "second": 2, "sequenc": 22, "set": 18, "sheet": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32], "shot": 4, "signal": 20, "slice": 19, "social": 31, "societ": 6, "solv": 31, "special": 24, "split": 22, "step": 18, "strategi": [3, 4, 26], "stream": 32, "summar": 5, "supervis": 27, "surpris": 6, "system": [5, 13], "tensor": 19, "test": [22, 30], "token": 24, "tool": 28, "train": [18, 20, 21, 22, 25, 27, 29], "transform": [10, 23, 24, 25], "transpos": 19, "true": [20, 21], "tune": [0, 1, 2, 5, 12, 27], "type": 19, "understand": [0, 1, 2, 6, 7, 16, 18], "up": 18, "updat": 20, "us": 21, "util": [21, 25], "valu": [19, 20], "vector": 19, "verifi": 18, "via": 23, "visual": 29, "w": [21, 22], "work": 23, "write": 18}})