Search.setIndex({"docnames": ["homework/01-language-modeling", "homework/01_language_modeling_solutions", "homework/02-prompting", "homework/02-prompting_solution", "homework/03-agents-RL", "homework/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "filenames": ["homework/01-language-modeling.ipynb", "homework/01_language_modeling_solutions.ipynb", "homework/02-prompting.ipynb", "homework/02-prompting_solution.ipynb", "homework/03-agents-RL.ipynb", "homework/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "titles": ["Homework 1: Language models (50 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LLMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "terms": {"The": [0, 1, 2, 3, 4, 5, 6, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "first": [0, 4, 7, 8, 9, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30], "focus": [0, 1, 6, 21, 25, 26, 28], "follow": [0, 1, 2, 3, 4, 5, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "skill": [0, 1, 2, 3, 4, 5, 19, 29], "being": [0, 1, 3, 4, 18, 21, 23, 24, 25, 29, 30], "abl": [0, 1, 3, 16, 17, 20, 21, 22, 23, 25, 29, 30], "work": [0, 1, 2, 4, 5, 6, 10, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 30], "simpl": [0, 1, 5, 15, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30], "formal": [0, 1, 8, 22, 25, 29], "properti": [0, 1, 17], "configur": [0, 1, 2, 3, 4, 21, 22, 24, 25], "state": [0, 1, 2, 3, 6, 16, 18, 20, 21, 22, 25, 27, 30], "art": [0, 1, 2, 3, 6, 16, 21, 22, 24, 25], "final": [0, 1, 3, 6, 16, 18, 20, 21, 24, 25, 27, 28, 29], "train": [0, 1, 2, 4, 5, 6, 8, 9, 11, 17, 21, 22, 24, 28, 29, 30], "yourself": [0, 1, 4, 16, 19, 20, 21, 22, 23, 24, 30], "submiss": [0, 1, 2, 3, 4, 5], "deadlin": [0, 1, 2, 3, 4, 5], "mai": [0, 1, 3, 4, 5, 18, 22, 24, 26, 28], "15th": 0, "59": [0, 1, 2, 3, 4, 5], "german": [0, 1, 2, 3, 4, 5, 20, 22, 28], "time": [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 21, 22, 23, 26, 28], "via": [0, 1, 2, 3, 4, 5, 16, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "moodl": [0, 1, 2, 3, 4, 5], "pleas": [0, 1, 2, 3, 4, 5, 16, 19, 21, 22, 24, 25, 26, 27, 28], "upload": [0, 1, 2, 3, 4, 5, 21, 27], "singl": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30], "zip": [0, 1, 4, 5, 27, 28], "file": [0, 1, 2, 3, 4, 5, 16, 20, 21, 22, 23, 24, 26, 27, 28], "name": [0, 1, 2, 3, 4, 5, 6, 16, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31], "surname_firstname_hw1": 0, "contain": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29], "ipynb": [0, 1, 2, 3, 4, 5], "notebook": [0, 1, 5, 16, 18, 20, 21, 25, 27, 30], "you": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "solv": [0, 1, 2, 3, 4, 5, 10, 16, 18, 28], "colab": [0, 1, 2, 3, 4, 5, 21, 24, 25, 27], "can": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "go": [0, 1, 3, 4, 16, 17, 18, 21, 22, 24, 25, 28, 29], "download": [0, 1, 4, 5, 16, 21, 22, 23, 26, 27, 30], "json": [0, 1, 20, 30], "ex": [0, 2, 3, 4, 23], "png": 0, "jpg": 0, "your": [0, 1, 2, 3, 4, 5, 10, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "loss": [0, 1, 3, 4, 19, 20, 21, 22, 23, 24, 25, 27, 28], "plot": [0, 1, 4, 5, 16, 17, 18, 19, 20, 21, 23, 29], "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "submit": [0, 1, 2, 3, 4, 5, 16], "individu": [0, 1, 2, 3, 4, 5, 27], "us": [0, 1, 2, 4, 5, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "speed": [0, 1, 2, 3, 4, 5, 16, 19, 25], "up": [0, 1, 2, 3, 4, 5, 19, 21, 24, 25, 26, 27, 28, 29, 30], "execut": [0, 1, 2, 3, 4, 5, 16, 25, 26, 30], "code": [0, 1, 2, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "especi": [0, 1, 3, 16, 20, 25, 28, 29], "avail": [0, 1, 2, 3, 4, 5, 16, 17, 21, 24, 25, 26, 27, 28], "gpu": [0, 1, 2, 3, 4, 5, 16, 17, 21, 24, 30], "resourc": [0, 1, 2, 3, 4, 5, 16, 21, 23, 24, 25, 26, 29], "allow": [0, 1, 2, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30], "For": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "befor": [0, 1, 2, 3, 4, 5, 16, 19, 20, 21, 25, 26, 28, 30], "navig": [0, 1, 2, 3, 4, 5, 16], "runtim": [0, 1, 2, 3, 4, 5, 16, 24], "chang": [0, 1, 2, 3, 4, 5, 6, 16, 17, 18, 19, 21, 23, 24, 25, 27, 28, 29], "type": [0, 1, 2, 3, 4, 5, 16, 21, 22, 23, 25, 26, 29, 30], "save": [0, 1, 2, 3, 4, 5, 16, 19, 20, 23, 30], "answer": [0, 2, 4, 5, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "importantli": [0, 1, 25, 28], "reason": [0, 1, 2, 3, 10, 13, 25, 28], "step": [0, 1, 4, 5, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30], "i": [0, 1, 2, 3, 4, 5, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "e": [0, 1, 2, 3, 4, 5, 6, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "where": [0, 1, 2, 3, 4, 5, 6, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "calcul": [0, 1, 3, 4, 5, 19, 20, 22, 25, 28, 30, 31], "ar": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "requir": [0, 1, 3, 4, 6, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "provid": [0, 1, 2, 3, 4, 5, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "intermedi": [0, 1, 10, 28, 29, 30], "how": [0, 1, 2, 4, 6, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "arriv": [0, 1, 27, 30], "solut": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 23, 25, 29], "do": [0, 1, 2, 3, 4, 5, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "need": [0, 1, 2, 3, 4, 9, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "write": [0, 1, 2, 3, 5, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "ani": [0, 1, 2, 5, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30], "just": [0, 1, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30], "mathemat": [0, 1, 7, 15, 17, 22, 29], "6pt": [0, 1], "consid": [0, 1, 2, 3, 5, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29], "corpu": [0, 1, 3, 16, 21, 22, 29], "c": [0, 1, 3, 4, 5, 17, 19, 20, 22, 25, 28], "sentenc": [0, 1, 2, 3, 4, 5, 13, 16, 21, 22, 23, 24, 25, 27, 28, 30, 31], "cat": [0, 1, 3, 17, 20, 21], "sleep": [0, 1, 3], "mous": [0, 1], "sing": [0, 1, 3], "A": [0, 1, 2, 4, 5, 7, 12, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31], "dog": [0, 1, 22, 23, 27], "defin": [0, 1, 3, 4, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30], "vocabulari": [0, 1, 3, 16, 19, 20, 22, 23, 24, 30], "v": [0, 1, 19, 22, 31], "thi": [0, 1, 2, 3, 4, 5, 6, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "assum": [0, 1, 21, 22, 23, 24], "word": [0, 1, 2, 4, 13, 16, 19, 21, 22, 23, 24, 25, 27, 29], "token": [0, 1, 2, 4, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31], "b": [0, 1, 3, 4, 5, 16, 17, 19, 22, 25, 27, 28], "pick": [0, 1, 16, 22, 25, 30], "one": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "four": [0, 1, 3, 24], "formul": [0, 1, 2, 3, 5], "probabl": [0, 1, 3, 4, 5, 16, 18, 19, 20, 22, 23, 24, 25, 28, 30], "form": [0, 1, 2, 3, 4, 16, 17, 25, 28, 29], "chain": [0, 1, 10, 19, 24, 26, 29], "rule": [0, 1, 19, 20, 22], "each": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31], "termn": [0, 1], "given": [0, 1, 2, 3, 4, 5, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "4pt": [0, 1], "we": [0, 1, 3, 4, 5, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "want": [0, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "neural": [0, 1, 6, 7, 8, 9, 15, 19, 20, 21, 22, 23], "network": [0, 1, 3, 6, 8, 9, 19, 21, 22, 23, 26, 27], "take": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "input": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "two": [0, 1, 2, 3, 4, 5, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29], "number": [0, 1, 3, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28], "x_1": [0, 1], "x_2": [0, 1], "pass": [0, 1, 3, 4, 5, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 31], "them": [0, 1, 2, 3, 4, 5, 6, 13, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28], "through": [0, 1, 3, 16, 17, 18, 20, 21, 22, 24, 25, 27, 30], "three": [0, 1, 3, 4, 16, 17, 20, 22, 23, 26], "hidden": [0, 1, 19, 20, 23, 30], "linear": [0, 1, 20, 22, 23, 27, 30], "layer": [0, 1, 20, 21, 22, 23, 25, 27, 30, 31], "13": [0, 1, 3, 19, 20, 24, 31], "neuron": [0, 1, 27], "relu": [0, 1, 19, 20], "activ": [0, 1, 3, 15, 18, 19, 20, 21, 25], "function": [0, 1, 3, 4, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30], "output": [0, 1, 3, 4, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31], "y_1": [0, 1, 25], "y_2": [0, 1, 25], "y_3": [0, 1], "down": [0, 1, 2, 3, 16, 19, 22, 25, 27], "all": [0, 1, 3, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "weight": [0, 1, 17, 19, 21, 22, 23, 25, 27, 28, 30], "matric": [0, 1, 17, 19, 21, 22, 25], "dimens": [0, 1, 16, 17, 19, 21, 22, 23, 25], "exampl": [0, 1, 2, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "matrix": [0, 1, 16, 20, 22, 25, 30, 31], "ha": [0, 1, 2, 3, 4, 5, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "3x5": [0, 1], "m_1": [0, 1], "r": [0, 1, 4, 16, 25, 28, 31], "times5": [0, 1], "2pt": [0, 1, 4], "sequenc": [0, 1, 3, 19, 22, 23, 24, 26, 27, 30], "some": [0, 1, 2, 3, 4, 5, 10, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "student": [0, 1, 3, 6, 25], "space": [0, 1, 2, 3, 4, 16, 20, 25, 27, 28, 30], "punctuat": [0, 1, 16, 22], "correspond": [0, 1, 5, 19, 21, 22, 23, 25, 27, 28], "under": [0, 1, 3, 5, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29], "p": [0, 1, 3, 16, 17, 20, 22, 23, 24, 25], "0": [0, 1, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "67": [0, 1, 5, 19, 20], "91": [0, 1, 31], "83": [0, 1, 19], "40": [0, 1, 17, 20], "29": [0, 1, 22, 25, 31], "58": [0, 1, 20], "75": [0, 1, 20, 27, 31], "comput": [0, 1, 3, 4, 6, 10, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], "averag": [0, 1, 3, 5, 16, 20, 24, 28], "surpris": [0, 1, 20], "note": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30], "class": [0, 1, 2, 3, 4, 7, 10, 11, 12, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "alwai": [0, 1, 16, 20, 24, 26, 28, 30], "base": [0, 1, 2, 3, 4, 5, 10, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "log": [0, 1, 3, 4, 5, 20, 21, 22, 24, 25, 28, 30], "unless": [0, 1], "indic": [0, 1, 3, 5, 20, 21, 22, 24, 25, 27, 28, 29], "otherwis": [0, 1, 4, 16, 18, 21, 24, 25, 28], "also": [0, 1, 2, 3, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "usual": [0, 1, 3, 5, 16, 17, 20, 21, 22, 23, 25, 26, 28], "case": [0, 1, 3, 4, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30], "throughout": [0, 1, 16, 21, 29, 30], "nlp": [0, 1, 2, 3, 6, 7, 15, 16, 21, 23, 28], "task": [0, 1, 2, 3, 4, 5, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "job": [0, 1, 3, 4, 16, 19, 24, 28], "larg": [0, 1, 3, 6, 10, 11, 16, 21, 22, 23, 25, 26, 27, 28, 29, 30], "paper": [0, 1, 2, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 22, 23, 24, 25, 28, 29, 30], "specif": [0, 1, 2, 3, 4, 5, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "find": [0, 1, 3, 4, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29], "assign": [0, 1, 5, 6, 16, 18, 20, 22, 23, 24, 25, 28, 29, 30], "surnam": [0, 1, 20], "list": [0, 1, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30], "hw1_model2group_assign": [0, 1], "csv": [0, 1, 5, 24, 28], "found": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28], "topic": [0, 1, 6, 11, 12, 14, 15, 16, 22, 23, 24, 28, 29], "02": [0, 1, 17, 22, 24], "investig": [0, 1, 5, 20, 28], "latest": [0, 1, 27], "version": [0, 1, 2, 3, 16, 19, 22, 25, 26, 30], "specifi": [0, 1, 16, 17, 19, 21, 22, 23, 25, 26, 27], "out": [0, 1, 3, 4, 5, 6, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "charactersitc": 0, "respons": [0, 1, 3, 4, 5, 22, 28], "format": [0, 1, 3, 4, 5, 16, 18, 19, 20, 24, 25, 26, 27, 28], "below": [0, 1, 3, 4, 5, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "partial": [0, 1, 3, 25, 30], "cours": [0, 1, 3, 16, 21, 24, 25, 26, 30], "might": [0, 1, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "inform": [0, 1, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "categori": [0, 1, 5, 20, 23, 25, 28], "applic": [0, 1, 4, 19, 20, 21, 22, 23, 27, 28, 29], "idea": [0, 1, 3, 5, 16, 19, 20, 23, 24, 25, 26, 27, 28, 30], "creat": [0, 1, 3, 4, 5, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30], "fun": [0, 1, 2, 3], "websit": [0, 1, 21, 22, 26], "which": [0, 1, 2, 4, 5, 6, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "show": [0, 1, 3, 4, 5, 10, 18, 19, 20, 21, 22, 23, 25, 27, 30], "somewhat": [0, 1, 19, 24, 26, 28], "comprehens": [0, 1], "graphic": [0, 1], "comparison": [0, 1, 2, 3, 25, 28, 29, 30], "current": [0, 1, 19, 20, 22, 25, 27, 30], "collect": [0, 1, 3, 16, 20, 21, 25], "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "set": [0, 1, 3, 4, 5, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "front": [0, 1, 3], "end": [0, 1, 3, 4, 17, 20, 22, 23, 24, 25, 28, 29, 30, 31], "dure": [0, 1, 2, 3, 4, 5, 16, 18, 20, 22, 23, 25, 28, 30], "import": [0, 1, 3, 4, 5, 6, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "email": [0, 1], "NOT": [0, 1, 4, 16, 21, 25, 26, 29], "consent": [0, 1], "model_nam": [0, 1, 4, 27], "35": [0, 1, 20, 28], "huggingface_model_id": [0, 1], "gpt35": [0, 1], "paper_url": [0, 1], "http": [0, 1, 3, 4, 16, 17, 20, 21, 25, 27, 28, 30], "arxiv": [0, 1, 3, 25, 28], "org": [0, 1, 3, 17, 25, 27, 28], "ab": [0, 1, 18, 19, 28], "xxx": [0, 1], "tokenizer_typ": [0, 1], "bpe": [0, 1], "vocabulary_s": [0, 1], "architectur": [0, 1, 2, 3, 6, 9, 15, 16, 19, 20, 21, 22, 23, 25, 26, 27, 30], "mixtur": [0, 1, 16], "transform": [0, 1, 2, 3, 4, 6, 13, 15, 16, 19, 24, 25, 26, 27, 28, 30], "agent": [0, 1, 6, 25], "architecture_typ": [0, 1], "decod": [0, 1, 2, 3, 4, 20, 21, 22, 25, 27, 28], "onli": [0, 1, 2, 3, 4, 5, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "architecture_quirk": [0, 1], "spars": [0, 1], "attent": [0, 1, 3, 9, 13, 16, 19, 24, 25, 30, 31], "paramet": [0, 1, 2, 3, 4, 11, 16, 21, 22, 23, 24, 25, 26, 27, 28, 30], "finetuning_typ": [0, 1], "rlhf": [0, 1, 16, 25, 29], "training_data_cutoff": [0, 1], "2050": [0, 1], "number_training_token": [0, 1], "pretraining_data_s": [0, 1], "1gb": [0, 1], "finetuning_data_s": [0, 1], "training_data": [0, 1], "book": [0, 1, 3, 6, 16], "twitter": [0, 1, 16], "finetuning_data": [0, 1], "access": [0, 1, 3, 4, 16, 19, 21, 22, 24, 25, 27, 30], "open": [0, 1, 3, 4, 5, 10, 16, 20, 21, 24, 25, 26, 27, 28], "summari": [0, 1, 2, 3, 4, 25, 26, 28], "few": [0, 1, 2, 6, 7, 10, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28], "what": [0, 1, 2, 4, 5, 6, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "claim": [0, 1], "uniqu": [0, 1, 16, 20, 22, 27], "sell": [0, 1], "main": [0, 1, 3, 4, 5, 18, 19, 20, 25, 26, 29], "contribut": [0, 1, 16, 22, 27, 30], "learn": [0, 1, 3, 4, 5, 6, 8, 9, 10, 11, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "goal": [0, 1, 4, 14, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "practic": [0, 1, 6, 19, 21, 22, 23, 24, 28], "pretrain": [0, 1, 4, 16, 17, 21, 25, 26, 30], "lm": [0, 1, 4, 5, 6, 11, 14, 16, 22, 23, 24, 25, 27, 28, 29, 30], "small": [0, 1, 2, 3, 4, 6, 15, 16, 18, 21, 22, 25, 27, 28, 30], "particular": [0, 1, 2, 3, 4, 5, 11, 16, 20, 21, 22, 25, 26, 27, 29], "commonsens": [0, 1, 3, 10], "question": [0, 1, 2, 3, 4, 5, 16, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "dataset": [0, 1, 4, 5, 19, 20, 21, 23, 25, 28, 29], "commonsenseqa": [0, 1, 24, 28, 29], "wa": [0, 1, 2, 4, 5, 16, 20, 21, 22, 24, 25, 26, 28, 29, 30], "introduc": [0, 1, 2, 3, 6, 8, 9, 10, 16, 17, 18, 20, 22, 23, 24, 25, 28, 29], "talmor": [0, 1], "et": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 22, 24, 25, 27, 28, 29, 30], "al": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 22, 24, 25, 27, 28, 29, 30], "2018": [0, 1, 11], "evalu": [0, 3, 4, 6, 21, 23, 25], "perform": [0, 1, 3, 4, 5, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "our": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30], "test": [0, 1, 2, 3, 4, 5, 14, 15, 16, 19, 21, 23, 24, 25, 26, 27, 29, 30], "split": [0, 1, 4, 16, 19, 21, 22, 23, 25, 27, 28], "over": [0, 1, 2, 3, 4, 5, 16, 18, 19, 22, 23, 24, 25, 26, 28, 30, 31], "monitor": [0, 1, 16, 20], "whether": [0, 1, 2, 3, 5, 16, 21, 23, 25, 27, 28, 29, 30], "s": [0, 1, 3, 4, 6, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "improv": [0, 1, 3, 4, 10, 16, 19, 20, 21, 24], "compar": [0, 1, 2, 3, 4, 5, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30], "prepar": [0, 1, 3, 4, 16, 18, 21], "data": [0, 1, 2, 4, 5, 21, 22, 23, 25, 27, 28, 29], "accord": [0, 1, 16, 22, 29], "describ": [0, 1, 3, 4, 5, 16, 20, 21, 24, 25, 28, 29], "sheet": [0, 1, 2, 3, 4, 5, 7], "addition": [0, 1, 4, 16, 20, 25, 27, 29], "custom": [0, 1, 4, 19, 21, 25, 27], "like": [0, 1, 2, 3, 4, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "massag": [0, 1, 16, 18, 21], "ship": [0, 1, 21, 22], "huggingfac": [0, 1, 4, 11, 16, 22, 25, 26, 27, 30], "string": [0, 1, 5, 16, 17, 20, 21, 22, 27, 28, 30], "proces": [0, 1], "happen": [0, 1, 3, 20, 21, 26, 28], "load": [0, 1, 2, 3, 4, 5, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 30], "pipelin": [0, 1, 4, 16, 21, 24], "5": [0, 1, 3, 16, 17, 19, 20, 22, 24, 25, 28, 29, 31], "run": [0, 1, 3, 4, 16, 19, 21, 24, 25, 27, 28, 30], "while": [0, 1, 2, 3, 4, 16, 19, 20, 21, 22, 23, 24, 25, 28], "track": [0, 1, 18, 20, 28], "19pt": [0, 1], "complet": [0, 1, 3, 4, 5, 16, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30], "spot": [0, 1, 21], "comment": [0, 1, 4, 5, 16, 21, 22], "here": [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "There": [0, 1, 2, 3, 6, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "instruct": [0, 1, 2, 3, 4, 11, 16, 17, 25, 26, 27, 28], "should": [0, 1, 3, 4, 5, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "implement": [0, 1, 2, 4, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "With": [0, 1, 17, 21, 24], "let": [0, 1, 2, 3, 4, 16, 17, 18, 20, 22, 23, 25, 26, 28], "without": [0, 1, 3, 16, 17, 21, 24, 26, 28, 30], "error": [0, 1, 8, 16, 21, 25, 30], "necessarili": [0, 1, 18, 25], "expect": [0, 1, 3, 4, 16, 20, 21, 24, 25, 26, 27, 28], "great": [0, 1, 3, 16, 19, 28], "actual": [0, 1, 2, 3, 4, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "grade": [0, 1], "often": [0, 1, 3, 4, 16, 17, 21, 22, 23, 24, 25, 28, 29, 30], "sever": [0, 1, 3, 16, 20, 22, 23, 26, 28], "correct": [0, 1, 2, 3, 22, 23, 24, 25, 26, 28, 29, 30], "wai": [0, 1, 2, 3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30], "someth": [0, 1, 5, 18, 19, 20, 25, 29, 30], "anyth": [0, 1, 3, 16, 19, 22, 25], "accept": [0, 1, 3, 5, 26], "execis": [0, 1], "instal": [0, 1, 4, 17, 19, 21, 25, 26, 27, 28, 30], "did": [0, 1, 4, 16, 19, 21, 23, 24, 25, 30], "don": [0, 1, 3, 4, 5, 16, 19, 20, 21, 22, 24, 25, 26, 28, 30], "t": [0, 1, 2, 3, 4, 5, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "forget": [0, 1, 19, 21, 25], "local": [0, 1, 17, 20, 21, 24, 25, 26, 27, 30], "environ": [0, 1, 4, 16, 21, 25, 30], "load_dataset": [0, 1, 4, 5, 16, 21, 23, 25, 28], "autotoken": [0, 1, 3, 4, 16, 21, 22, 23, 24, 25, 27, 28, 30], "automodelforcausallm": [0, 1, 3, 21, 23, 24, 25, 28, 30], "gpt2token": [0, 21], "gpt2lmheadmodel": [0, 21, 22, 23], "torch": [0, 1, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "util": [0, 1, 3, 4, 16, 21, 24, 27, 30], "dataload": [0, 1, 4, 16, 19, 21], "numpi": [0, 1, 3, 17, 19, 20, 24, 27, 28, 30, 31], "np": [0, 1, 3, 17, 19, 20, 24, 27, 28, 30, 31], "matplotlib": [0, 1, 16, 18, 19, 20, 21], "pyplot": [0, 1, 16, 18, 19, 20, 21], "plt": [0, 1, 16, 18, 19, 20, 21], "tqdm": [0, 1, 3, 4, 16, 21, 30], "opt": [0, 16, 18, 21, 22, 25, 30], "anaconda3": [0, 16, 21, 22, 30], "env": [0, 3, 16, 21, 22, 26, 30], "understanding_llm": [0, 16, 21, 22, 30], "lib": [0, 3, 16, 21, 22, 30], "python3": [0, 16, 21, 22, 30], "10": [0, 1, 3, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "site": [0, 3, 16, 21, 22, 30], "packag": [0, 1, 2, 3, 4, 16, 21, 22, 24, 25, 26, 27, 28, 29, 30], "auto": [0, 3, 4, 16, 21, 22, 25], "py": [0, 3, 16, 21, 22, 25, 30], "21": [0, 3, 16, 17, 19, 21, 31], "tqdmwarn": [0, 3, 16, 21], "iprogress": [0, 3, 16, 21], "updat": [0, 1, 3, 16, 19, 21, 23, 25, 26, 30], "jupyt": [0, 3, 16, 21], "ipywidget": [0, 3, 16, 21, 27], "see": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "readthedoc": [0, 3, 16, 21], "io": [0, 3, 4, 16, 21], "en": [0, 3, 4, 16, 21, 27], "stabl": [0, 3, 4, 16, 17, 19, 21, 23], "user_instal": [0, 3, 16, 21], "html": [0, 3, 16, 17, 21, 27], "autonotebook": [0, 3, 16, 21], "notebook_tqdm": [0, 3, 16, 21], "additioanlli": [0, 1], "acceler": [0, 1, 2, 3, 4, 21, 25], "uncom": [0, 1, 4, 16, 21, 25], "line": [0, 1, 4, 16, 19, 20, 21, 22, 23, 27], "pip": [0, 1, 4, 16, 21, 25, 26, 27, 30], "reload": [0, 1, 21], "kernel": [0, 1, 21], "after": [0, 1, 3, 16, 18, 19, 21, 22, 23, 24, 25, 30], "get": [0, 1, 2, 3, 4, 5, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "depend": [0, 1, 3, 16, 17, 20, 21, 22, 23, 25, 26, 27, 29], "prep": [0, 1], "acquir": [0, 1, 16], "minim": [0, 1, 5, 16, 18, 19, 22, 26, 29], "explor": [0, 1, 2, 3, 4, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27], "clean": [0, 1, 2, 3, 16, 19, 30], "wrangl": [0, 1, 21, 28], "combin": [0, 1, 3, 16, 20, 22, 23, 24, 28], "4": [0, 1, 2, 3, 4, 16, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "abov": [0, 1, 2, 3, 4, 5, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "d": [0, 1, 3, 4, 17, 19, 20, 21, 23, 25, 28], "hyperparam": [0, 1], "further": [0, 1, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 30], "make": [0, 1, 3, 4, 5, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "sure": [0, 1, 2, 3, 5, 16, 19, 20, 21, 22, 24, 25, 27, 28, 30], "batch": [0, 1, 4, 16, 19, 21, 22, 23, 25, 27, 30], "converst": [0, 1], "2d": [0, 1], "tensor": [0, 1, 4, 16, 18, 19, 20, 21, 22, 24, 27, 30, 31], "common": [0, 1, 4, 16, 19, 21, 22, 23, 24, 25, 28, 29], "when": [0, 1, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30], "text": [0, 1, 2, 3, 4, 11, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "downaload": [0, 1], "hf": [0, 1, 2, 3, 4, 19, 21, 22, 23, 24, 26, 27], "tau": [0, 1, 24, 28], "commonsense_qa": [0, 1, 28], "inspect": [0, 1, 3, 4, 5, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30], "print": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "kei": [0, 1, 2, 3, 4, 16, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31], "sampl": [0, 1, 2, 3, 4, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28], "dict_kei": 0, "valid": [0, 1, 4, 16, 22, 23, 25, 26, 28], "doe": [0, 1, 3, 4, 5, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "have": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "ground": [0, 1, 2, 3, 4, 12, 19, 25, 28], "truth": [0, 1, 4, 19, 25, 28], "label": [0, 1, 2, 3, 4, 16, 19, 20, 21, 23, 24, 25, 27, 28, 30], "therefor": [0, 1, 3, 4, 5, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "from_pretrain": [0, 1, 3, 4, 16, 21, 22, 23, 24, 25, 27, 28, 30], "gpt2": [0, 1, 4, 5, 16, 21, 22, 23, 25, 27, 28, 30], "pad_token": [0, 1, 4, 21], "eos_token": [0, 1, 4, 21], "pad": [0, 1, 3, 4, 16, 19, 21, 22, 23, 24], "side": [0, 1, 3, 16, 21, 22], "left": [0, 1, 3, 4, 21, 22, 26], "becaus": [0, 1, 3, 4, 16, 18, 19, 20, 21, 22, 23, 25, 28, 30], "causal": [0, 1, 15, 21, 22, 23, 24, 27, 28, 30], "padding_sid": [0, 1, 4, 21], "def": [0, 1, 3, 4, 16, 19, 20, 21, 22, 23, 25, 27, 28, 30, 31], "massage_input_text": [0, 1, 28], "helper": [0, 1, 21, 23, 28, 30], "convert": [0, 1, 4, 16, 17, 21, 22, 27, 28], "separ": [0, 1, 4, 5, 19, 22, 24, 25, 28], "qquestion": [0, 1], "option": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 21, 24, 26, 27, 28, 29, 30], "argument": [0, 1, 17, 21, 22, 23, 25, 27, 28, 29], "dict": [0, 1, 4, 16, 20, 27, 28], "g": [0, 1, 3, 4, 5, 6, 12, 13, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "return": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 25, 27, 28, 30, 31], "input_text": [0, 1, 3, 21, 23, 24, 27], "str": [0, 1, 4, 16, 28, 30, 31], "forwat": [0, 1], "etc": [0, 1, 4, 12, 16, 19, 21, 22, 23, 27, 28, 29], "its": [0, 1, 2, 3, 5, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30], "answer_options_list": [0, 1, 28], "choic": [0, 1, 4, 5, 16, 21, 23, 24, 25, 26, 28, 29], "join": [0, 1, 3, 16, 24, 27, 28], "answer_opt": [0, 1, 3, 5, 28], "answer_options_str": [0, 1], "append": [0, 1, 3, 4, 20, 21, 22, 24, 25, 28, 30], "true": [0, 1, 3, 4, 5, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "new": [0, 1, 3, 4, 16, 17, 20, 21, 22, 25, 30], "nanswer": [0, 1], "answerkei": [0, 1, 28], "process": [0, 1, 3, 5, 7, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30], "massaged_dataset": [0, 1], "map": [0, 1, 3, 4, 16, 19, 20, 21, 22, 23, 27, 28, 30], "lambda": [0, 1, 16, 28], "preprocess": [0, 1, 16, 22], "commonsenseqadataset": [0, 1], "__init__": [0, 1, 19, 20, 22, 27, 30], "self": [0, 1, 3, 10, 19, 20, 21, 22, 25, 27, 30], "train_split": [0, 1], "test_split": [0, 1], "max_length": [0, 1, 4, 20, 21, 23], "64": [0, 1, 18, 21, 22, 23], "dataset_split": [0, 1], "none": [0, 1, 3, 18, 19, 22, 23, 30], "initi": [0, 3, 4, 5, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28], "object": [0, 4, 5, 15, 16, 17, 18, 19, 20, 21, 23, 25, 30], "dictionari": [0, 1, 20, 22], "differ": [0, 1, 2, 4, 5, 6, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "column": [0, 1, 3, 16, 20, 28], "int": [0, 1, 16, 17], "maxim": [0, 2, 3, 4, 5, 16, 18, 21, 23, 24, 25], "length": [0, 1, 5, 16, 17, 19, 20, 22, 24, 25, 28], "truncat": [0, 1, 4, 21, 23], "default": [0, 17, 18, 20, 21, 22, 25, 26, 27, 28, 30], "__len__": [0, 1, 19], "method": [0, 1, 3, 4, 6, 14, 15, 16, 19, 21, 25, 28, 29, 30], "__getitem__": [0, 1, 19], "idx": [0, 1, 3, 19, 22], "mask": [0, 1, 3, 16, 21, 24, 27, 28], "index": [0, 1, 3, 4, 16, 19, 20, 22, 23, 28, 30], "retriev": [0, 1, 3, 17, 20, 21, 22, 24, 25, 27, 28, 30], "tokenized_input": [0, 1, 21, 23], "input_id": [0, 1, 3, 4, 16, 21, 22, 23, 24, 27, 28, 30], "an": [0, 1, 2, 3, 4, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "attention_mask": [0, 1, 3, 16, 21, 22, 23, 24], "hint": [0, 1, 4, 5, 16, 19, 21, 22, 23, 24, 28, 29], "return_tensor": [0, 1, 3, 4, 16, 21, 23, 24, 25, 27, 28, 30], "pt": [0, 1, 3, 4, 16, 21, 23, 24, 25, 27, 28, 30], "pad_token_id": [0, 1, 3, 4, 21, 23, 24], "long": [0, 1, 3, 4, 9, 16, 21, 23, 24, 27, 28, 29], "move": [0, 1, 28, 30], "devic": [0, 1, 3, 4, 5, 16, 17, 21, 24, 25, 27, 28, 30], "cuda": [0, 1, 3, 4, 5, 16, 21, 24, 25, 27, 28, 30], "is_avail": [0, 1, 3, 4, 5, 16, 21, 24, 25, 27, 28, 30], "f": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "elif": [0, 1, 3, 5, 16, 21, 24, 27, 28, 30, 31], "backend": [0, 1, 3, 5, 16, 21, 24, 27, 28], "mp": [0, 1, 3, 5, 16, 21, 24, 27, 28], "els": [0, 1, 3, 4, 5, 16, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31], "cpu": [0, 1, 3, 4, 5, 16, 17, 21, 24, 25, 27, 28, 30], "init": [0, 1, 22], "num": [0, 1, 19, 30], "trainabl": [0, 1, 18, 19, 25], "model_s": [0, 1], "sum": [0, 1, 3, 16, 18, 20, 22, 24, 25, 27, 28], "numel": [0, 1, 25], "size": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 30], "1000": [0, 1, 18, 19, 24], "1f": [0, 1], "m": [0, 1, 3, 17, 20, 22, 24, 27], "If": [0, 1, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 29, 30], "memori": [0, 4, 9, 16, 17, 20], "try": [0, 5, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "decreas": [0, 19, 21, 23, 25], "loop": [0, 1, 4, 19, 20, 21, 23, 26], "instanti": [0, 1, 18, 19, 20, 21, 22, 23, 26], "train_dataset": [0, 1, 21, 25], "test_dataset": [0, 1], "loader": [0, 1], "automat": [0, 1, 4, 12, 19, 21, 22, 23, 26, 28], "iter": [0, 1, 3, 5, 16, 18, 19, 20, 24, 25, 28], "pair": [0, 1, 5, 16, 19, 20, 22, 25, 28], "batch_siz": [0, 1, 4, 19, 21, 27], "32": [0, 1, 16, 17, 19, 20, 22, 27, 31], "shuffl": [0, 1, 16, 19, 20], "retreiv": [0, 1, 26, 28], "test_dataload": [0, 1], "forward": [0, 1, 19, 20, 21, 22, 27, 30, 31], "carefulli": [0, 1, 2, 3, 22, 27], "look": [0, 1, 3, 4, 5, 6, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "link": [0, 1, 4, 5, 26], "tutori": [0, 1, 16, 18, 19, 20, 21, 22, 23], "put": [0, 1, 4, 21, 27, 28, 30], "mode": [0, 1, 4, 25, 28], "trian": [0, 1], "configut": [0, 1], "feel": [0, 1, 2, 3, 5, 18, 21, 22, 24, 25], "free": [0, 1, 2, 3, 5, 16, 21, 22, 24, 25, 28], "plai": [0, 1, 2, 3, 18, 20, 21, 22, 24, 25, 26, 29], "around": [0, 1, 2, 3, 16, 18, 19, 20, 21, 22, 24, 25, 26], "epoch": [0, 1, 4, 16, 19, 21, 23, 25, 27], "train_step": [0, 1], "len": [0, 1, 3, 15, 16, 19, 20, 24, 25, 27, 28, 30], "everi": [0, 1, 3, 16, 19, 20, 21, 22, 23, 24, 25, 27], "smaller": [0, 1, 3, 16, 19, 21, 28], "entor": [0, 1], "comp": [0, 1], "num_test_step": [0, 1], "optim": [0, 1, 3, 4, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27], "rate": [0, 1, 3, 16, 18, 20, 21, 23, 24, 25], "adamw": [0, 1], "lr": [0, 1, 18, 19, 20], "5e": [0, 1, 21], "variabl": [0, 1, 3, 16, 18, 19, 20, 26, 28, 30], "accumul": [0, 1, 18], "test_loss": [0, 1, 21, 27], "rang": [0, 1, 3, 5, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "x": [0, 1, 5, 6, 16, 17, 19, 20, 22, 24, 25, 27, 30, 31], "next": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "backward": [0, 1, 18, 19, 20, 21, 27], "item": [0, 1, 3, 5, 17, 18, 19, 20, 22, 24, 27, 28, 30], "zero": [0, 1, 2, 3, 10, 17, 18, 19, 20, 22, 23, 28, 30], "gradient": [0, 1, 19, 20, 23, 25, 27], "j": [0, 1, 16, 28], "x_test": [0, 1], "no_grad": [0, 1, 20, 27], "test_output": [0, 1], "TO": 0, "IT": [0, 26], "AND": [0, 5], "axi": [0, 31], "xlabel": [0, 1, 16, 21], "ylabel": [0, 1, 21], "predict": [0, 1, 2, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "eval": [0, 1, 30], "construct": [0, 1, 3, 4, 5, 17, 19, 20, 21, 24, 25, 26, 28, 29], "construct_test_sampl": [0, 1], "tupl": [0, 1], "sinc": [0, 1, 4, 16, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "test_sampl": [0, 1], "gener": [0, 1, 5, 6, 7, 8, 9, 10, 12, 14, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "max_new_token": [0, 1, 3, 4, 24, 26], "do_sampl": [0, 1, 3, 4, 21, 24], "temperatur": [0, 1, 3, 4, 24, 26], "skip_special_token": [0, 1, 3, 24, 25, 28], "brief": [0, 1, 2, 3, 5, 24], "descript": [0, 1, 3, 4, 5, 26], "kind": [0, 1, 2, 3, 4, 16, 19, 21, 22, 23, 24, 25, 27], "develop": [0, 1, 7, 18, 20, 21, 22, 23, 25, 26, 27, 29], "conceptu": [0, 2, 3, 4, 5, 6, 21, 22, 23, 25, 28, 29, 30], "curv": [0, 1], "think": [0, 1, 2, 3, 4, 6, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29], "well": [0, 1, 2, 3, 4, 5, 7, 10, 14, 16, 20, 21, 22, 23, 25, 27, 28, 30], "sens": [0, 1, 4, 20, 21, 22, 24, 25, 29], "right": [0, 1, 13, 19, 21, 22, 24, 26, 29], "interpret": [0, 1, 4, 5, 6, 20, 27, 28, 29], "On": [0, 1, 16, 21, 24], "mani": [0, 1, 3, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "accuraci": [0, 1, 2, 3, 5, 23, 27, 28, 29], "eabl": 1, "conduct": [1, 6], "12th": 1, "surname_firtname_hw1": 1, "usag": [1, 16], "bo": [1, 22, 24, 31], "eo": [1, 20, 21, 24, 31], "typic": [1, 3, 5, 19, 20, 24, 25], "theses": 1, "nonetheless": [1, 3, 16, 26], "both": [1, 3, 4, 5, 6, 16, 17, 18, 20, 21, 22, 23, 25, 28, 29], "begin": [1, 16, 21, 22, 24, 25, 31], "align": [1, 6, 25], "p_": [1, 20, 24, 28], "prod": 1, "n_": 1, "n": [1, 3, 4, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 31], "w_i": [1, 24], "w_": [1, 24], "frac": [1, 23, 24, 25, 27, 28], "6": [1, 3, 6, 17, 19, 20, 21, 22, 24, 25, 29, 30, 31], "167": 1, "24": [1, 17, 18, 19, 20, 30, 31], "125": [1, 19, 20], "083": 1, "25": [1, 16, 19, 20, 24], "incorrect": [1, 27, 28, 30], "formula": [1, 22], "deduct": 1, "minor": 1, "mistak": [1, 24], "cacul": 1, "altern": [1, 3, 17, 20, 21, 23, 25, 27, 28], "other": [1, 2, 3, 5, 6, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "alter": [1, 20], "multipli": [1, 16, 17, 23, 31], "w": 1, "cdot": [1, 28], "unlik": 1, "scalar": [1, 4, 17, 19, 25], "multipl": [1, 5, 16, 19, 22, 23, 24, 28, 29], "commut": 1, "pytorch": [1, 16, 18, 20, 21, 23, 27, 30], "would": [1, 3, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "input_neuron": 1, "hidden_neuron": 1, "output_neuron": 1, "\u03f5": 1, "13x2": 1, "hidden1": 1, "b_1": 1, "\u03f5r": 1, "13x1": 1, "bia": [1, 5, 15, 19, 22, 25, 28, 29, 31], "weights1": 1, "m_2": 1, "13x13": 1, "hidden2": 1, "b_2": 1, "weights2": 1, "m_3": 1, "hidden3": 1, "b_3": 1, "weights3": 1, "m_4": 1, "3x13": 1, "b_4": 1, "3x1": 1, "weights4": 1, "In": [1, 2, 3, 4, 5, 6, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "transpos": [1, 16, 20, 22], "2x1": 1, "mupltipli": 1, "It": [1, 3, 4, 5, 6, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "inner": [1, 16], "match": [1, 2, 3, 4, 5, 16, 20, 22, 27, 28], "result": [1, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "row": [1, 3, 22, 25], "howev": [1, 3, 4, 16, 18, 19, 21, 22, 23, 25, 28, 29], "previou": [1, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30], "revers": [1, 30], "order": [1, 4, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29], "factor": 1, "orini": 1, "again": [1, 16, 18, 19, 22, 23, 24, 25, 26, 30], "shape": [1, 3, 16, 17, 20, 21, 22, 24, 27, 29, 30, 31], "1x13": 1, "2x13": 1, "13x3": 1, "1x3": 1, "matriz": 1, "m_i": 1, "definit": [1, 16, 20, 21, 22, 24], "b_i": 1, "amount": [1, 16, 20], "0255": 1, "avg": 1, "_": [1, 4, 25, 30], "logp_": 1, "7": [1, 3, 4, 5, 16, 17, 19, 20, 24, 25, 26, 30, 31], "2553533346": 1, "523": 1, "calucl": 1, "mayb": [1, 21, 25, 30], "could": [1, 3, 4, 5, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30], "even": [1, 3, 16, 17, 19, 21, 23, 25, 26, 27, 28], "own": [1, 3, 4, 5, 16, 19, 20, 21, 22, 24, 25, 26], "tbd": 1, "phi": [1, 4, 25], "mixtral": 1, "mistral": [1, 26], "v2": [1, 4], "mamba": 1, "jamba": 1, "ye": [1, 4, 20, 21, 27, 29], "joke": 1, "llama": [1, 2, 3, 4, 6, 10, 16, 21, 22, 25, 29], "suit": [1, 5, 25, 28], "8b": 1, "70b": [1, 25], "gemini": 1, "whole": [1, 26, 28], "multimod": 1, "though": [1, 3, 16, 24], "claud": 1, "seem": [1, 3, 19, 20, 24, 25, 27, 28], "technic": [1, 6, 28], "report": [1, 2, 3, 16, 18, 20, 25], "detail": [1, 3, 4, 16, 21, 22, 23, 24, 25, 26, 28, 29], "palm": 1, "bloom": [1, 5], "interest": [1, 4, 6, 18, 26, 27, 28, 29], "multilingu": [1, 5], "grok": 1, "vicuna": [1, 2, 3], "blog": [1, 4, 24, 25], "falcon": 1, "40b": 1, "gemma": 1, "dbrx": 1, "cmd": 1, "rag": [1, 4], "integr": [1, 16, 19, 24, 25, 26, 27], "coher": 1, "h2o": 1, "danub": 1, "bitnet": 1, "jetmo": 1, "qwen": 1, "moe": 1, "wizardlm": 1, "modulenotfounderror": 1, "traceback": 1, "most": [1, 3, 5, 16, 20, 21, 22, 24, 25, 28, 29], "recent": [1, 2, 3, 5, 16, 22, 24, 28, 29], "call": [1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "last": [1, 5, 16, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30], "ipython": [1, 4], "66d1a2d3ccf0": 1, "modul": [1, 20, 22, 27, 30], "No": 1, "unfortun": [1, 16], "docstr": [1, 16, 22], "were": [1, 2, 4, 10, 16, 22, 24, 25, 28, 29, 30], "wrong": [1, 13, 29], "respect": [1, 4, 5, 14, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "suggest": [1, 3, 5, 16, 20, 26], "fill": [1, 3, 5, 17, 26], "me": [1, 26], "zero_grad": [1, 18, 19, 20, 27], "todo": [1, 17], "arang": [1, 22], "y": [1, 5, 16, 17, 19, 24, 30, 31], "legend": [1, 21], "involv": [1, 3, 16, 22], "basic": [1, 7, 16, 17, 18, 19, 20, 21, 26], "world": [1, 17, 29], "knowledg": [1, 5, 6, 10, 24, 25, 27, 28], "These": [1, 4, 16, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30], "present": [1, 2, 3, 19, 20, 29], "concept": [1, 4, 6, 17, 19, 21, 22, 23, 24, 25, 29, 30], "neg": [1, 18, 20, 23, 25, 28], "likelihood": [1, 18, 20, 28], "grad_fn": [1, 18], "oon": 1, "total": [1, 4, 20, 25], "second": [2, 3, 4, 5, 8, 16, 17, 19, 22, 27], "zoom": [2, 3, 4, 5, 27, 29], "gain": [2, 3, 16, 23, 25, 27], "deeper": [2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 22, 29], "understand": [2, 3, 4, 9, 10, 13, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "techniqu": [2, 3, 4, 13, 19, 24, 25, 27, 29, 30], "critic": [2, 3, 4, 6, 16, 19, 21, 27, 28, 29, 30], "regard": [2, 3, 16, 20, 25, 28, 29], "research": [2, 3, 16, 23, 25, 26, 28, 29], "june": [2, 3, 4], "2nd": [2, 3], "th": [2, 3, 4, 5, 22], "23": [2, 3, 4, 5, 19, 20, 30, 31], "surname_firstname_hw2": [2, 3], "discuss": [2, 3, 5, 14, 15, 16, 21, 22, 24, 25, 26, 27, 28, 29, 30], "variou": [2, 3, 4, 6, 12, 14, 15, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30], "sophist": [2, 3], "languag": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29], "model": [2, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 22, 24, 26, 27, 28, 29, 30], "about": [2, 3, 4, 5, 6, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29], "context": [2, 4, 5, 6, 10, 11, 13, 16, 17, 19, 21, 22, 23, 24, 25, 28, 29, 30], "briefli": [2, 3, 4, 5, 22, 23, 25], "explain": [2, 3, 4, 5, 19, 20, 25], "max": [2, 3, 22, 23, 24, 27], "build": [2, 3, 5, 16, 17, 19, 21, 22, 24, 25, 26, 27, 28], "intuit": [2, 3, 4, 5, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29], "gpt": [2, 3, 4, 5, 6, 9, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "tune": [2, 3, 6, 10, 16, 18, 21, 23, 24, 26, 27, 28, 29], "7b": [2, 3, 22, 26], "beam": [2, 3, 24], "search": [2, 3, 4, 16, 23, 24, 26], "tree": [2, 3, 10, 24], "thought": [2, 3, 10, 21, 24, 29], "shot": [2, 10, 24], "cot": [2, 3], "why": [2, 3, 4, 5, 16, 19, 20, 22, 24, 25, 27, 28, 29, 30], "thei": [2, 3, 4, 5, 6, 16, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30], "better": [2, 3, 6, 16, 18, 20, 22, 26, 28], "than": [2, 3, 5, 11, 16, 22, 23, 25, 26, 27, 28, 30], "creativ": [2, 3, 24], "flow": [2, 3, 19, 30], "come": [2, 3, 5, 16, 20, 21, 22, 24, 25, 26, 28, 29], "achiev": [2, 3, 24, 25], "inspir": [2, 3, 5, 20, 21, 22, 24, 25, 26, 28], "sentiment": [2, 3, 16, 21, 23, 24, 25, 28], "classif": [2, 3, 11, 16, 19, 21, 23, 25, 28], "scheme": [2, 4, 21], "interact": [2, 3, 12, 27], "intro": [2, 3, 4], "best": [2, 3, 4, 18, 23, 24, 25, 28], "tri": [2, 3, 23, 26], "pythia": [2, 3, 5, 24], "410m": [2, 3], "4b": [2, 3, 24], "natur": [2, 4, 13, 16, 21, 24, 25, 28, 30], "infer": [2, 4, 10, 13, 18, 21, 22, 24, 26, 28], "classifi": [2, 3, 20, 21, 27], "contradict": [2, 3], "entail": [2, 3, 23], "relat": [2, 3, 6, 11, 16, 18, 20, 22, 28, 29], "neutral": [2, 3, 16, 23, 24], "gold": [2, 3, 4, 16, 19, 20, 28], "refer": [2, 3, 4, 5, 12, 16, 19, 21, 23, 24, 25, 27, 28, 29, 30], "obvious": [2, 3], "shouldn": [2, 3], "person": [2, 3, 16, 23], "hors": [2, 3, 19], "jump": [2, 3, 22, 23, 31], "broken": [2, 3], "airplan": [2, 3], "hi": [2, 3, 22, 24], "competit": [2, 3], "outdoor": [2, 3], "children": [2, 3, 29], "smile": [2, 3], "wave": [2, 3], "camera": [2, 3], "boi": [2, 3], "skateboard": [2, 3], "middl": [2, 3, 22, 23], "red": [2, 3, 29], "bridg": [2, 3], "skate": [2, 3], "sidewalk": [2, 3], "older": [2, 3], "man": [2, 3], "sit": [2, 3], "orang": [2, 3], "juic": [2, 3], "tabl": [2, 3, 5, 16], "coffe": [2, 3], "shop": [2, 3, 24], "employe": [2, 3], "bright": [2, 3], "color": [2, 3, 19, 25, 27], "shirt": [2, 3], "background": [2, 3, 4, 5, 11, 21], "drink": [2, 3], "he": [2, 3, 23], "wait": [2, 3], "daughter": [2, 3], "off": [2, 3, 16], "high": [2, 3, 4, 16, 17, 21, 23, 24, 25, 27, 28, 29], "fashion": [2, 3], "ladi": [2, 3], "outsid": [2, 3], "tram": [2, 3], "besid": [2, 3], "crowd": [2, 3], "peopl": [2, 3, 5, 16, 28], "citi": [2, 3, 23, 24], "women": [2, 3], "care": [2, 3, 4, 16, 17, 21, 26, 28, 30], "cloth": [2, 3], "wear": [2, 3], "baggag": [2, 3], "woman": [2, 3], "check": [2, 3, 4, 5, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 30], "drawstr": [2, 3], "bag": [2, 3], "she": [2, 3, 28], "head": [2, 3, 4, 5, 17, 21, 25, 27, 28], "garbag": [2, 3, 25], "militari": [2, 3], "jewelri": [2, 3], "store": [2, 3, 4, 5, 17, 18, 19, 20, 21, 28, 30], "safe": [2, 3], "airport": [2, 3], "To": [2, 3, 4, 6, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 28, 30], "prevent": [2, 3, 21, 24], "glare": [2, 3], "big": [2, 3, 28, 29], "footbal": [2, 3], "game": [2, 3], "made": [2, 3, 16, 18, 19, 21], "dust": [2, 3], "televis": [2, 3], "attic": [2, 3], "corner": [2, 3], "cannot": [2, 3, 16, 21, 22, 27, 28], "librari": [2, 3, 4, 17, 22, 25, 30], "presid": [2, 3], "leader": [2, 3], "institut": [2, 3], "walmart": [2, 3, 16], "white": [2, 3], "hous": [2, 3, 28], "countri": [2, 3, 20], "corpor": [2, 3], "govern": [2, 3], "drive": [2, 3], "lead": [2, 3, 20, 24, 25, 28, 30], "accid": [2, 3], "stress": [2, 3], "danger": [2, 3], "illeg": [2, 3], "deadli": [2, 3], "good": [2, 3, 4, 5, 16, 18, 20, 21, 24, 25, 26, 28, 29], "attend": [2, 3, 21, 22, 23], "school": [2, 3], "smart": [2, 3], "boredom": [2, 3], "cold": [2, 3], "flu": [2, 3], "spend": [2, 3], "stanlei": [2, 3], "had": [2, 3, 25], "dream": [2, 3], "veri": [2, 3, 4, 16, 17, 20, 21, 22, 23, 24, 25, 26, 28], "vivid": [2, 3], "scari": [2, 3], "troubl": [2, 3], "tell": [2, 3, 4, 17, 18, 19, 20, 25, 28], "imagin": [2, 3], "realiti": [2, 3], "dreamwork": [2, 3], "nightmar": [2, 3], "awak": [2, 3], "read": [2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 30], "document": [2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 26, 28], "practition": [2, 3], "assess": [2, 3, 5, 16, 27, 29, 30], "literatur": [2, 3, 16], "densiti": [2, 3, 18], "style": [2, 3, 15, 16, 25], "undergon": [2, 3], "signific": [2, 3, 16], "shift": [2, 3, 17, 21], "year": [2, 3, 16], "increas": [2, 3, 18, 20, 22, 23, 28], "progress": [2, 3, 23], "success": [2, 3, 4, 21, 22, 23, 25], "langaug": [2, 3], "compon": [2, 4, 15, 19, 22, 25, 26], "evolv": [2, 3], "modern": [2, 9, 26, 28], "system": [2, 3, 5, 18, 22, 23, 25, 26, 28, 29], "bengio": [2, 8], "2003": 2, "repres": [2, 5, 16, 17, 19, 20, 21, 22, 25, 27, 28, 30], "similar": [2, 4, 5, 18, 19, 22, 24, 25, 27, 28, 29, 30], "llm": [2, 7, 9, 13, 14, 16, 23, 25, 28, 29, 30], "curs": 2, "dimension": [2, 17, 22], "give": [2, 4, 16, 17, 24, 25, 26, 27, 30], "concret": [2, 18, 21, 22, 25, 26], "same": [2, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "post": [2, 3, 4, 24, 25, 27], "dedic": [2, 3, 21], "forum": [2, 3], "furthermor": [2, 3, 5, 16, 19, 20, 27, 28, 29, 30], "dissect": [2, 3], "analys": [2, 3], "structur": [2, 3, 5, 13, 16, 17, 19, 21, 26, 28], "anoth": [2, 3, 5, 19, 20, 21, 22, 23, 27, 28, 29, 30], "more": [2, 3, 4, 5, 6, 9, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "devlin": [2, 3, 9], "2019": [2, 3, 9, 13, 27, 28, 29], "bert": [2, 3, 9, 19, 21, 22, 23, 27], "pre": [2, 3, 9, 11, 16, 19, 20, 22, 27, 30], "deep": [2, 3, 6, 8, 9, 16, 23], "bidirect": [2, 3, 9, 23], "section": [2, 5, 16, 25, 28, 29], "between": [2, 3, 4, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 30], "written": [2, 3, 4, 25, 28], "includ": [2, 3, 4, 12, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "content": [2, 3, 16, 21, 22, 25, 29], "per": [2, 20, 21, 23, 24, 25, 27], "4p": 3, "aspect": [3, 5, 16, 22, 24, 25, 27, 28, 30], "mention": [3, 4, 7, 10, 15, 22, 23, 24, 27, 28, 29], "been": [3, 4, 5, 16, 21, 22, 23, 24, 25, 27, 28, 29, 30], "shown": [3, 4, 20, 25, 28, 29], "standard": [3, 4, 16, 18, 23, 25, 28], "liek": 3, "too": [3, 4, 21, 23, 28], "fanci": 3, "except": [3, 20, 28, 30], "costli": [3, 21, 25], "tot": 3, "wasn": 3, "rl": 3, "matter": 3, "much": [3, 16, 17, 19, 21, 22, 24, 25, 27, 28, 30], "sensibl": [3, 16, 21, 25], "reflect": [3, 5, 16, 29], "upon": [3, 25], "ask": [3, 4, 5, 16, 19, 21, 25, 28, 29, 30], "possibl": [3, 5, 16, 17, 22, 23, 24, 25, 26, 28, 29, 30], "manual": [3, 18, 19, 21, 22], "fine": [3, 6, 10, 16, 21, 24, 26, 27, 28, 29], "continu": [3, 5, 20, 21, 23, 27, 28], "rather": [3, 11, 16, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30], "larger": [3, 5, 12, 16, 17, 26, 27, 28], "thing": [3, 16, 18, 19, 20, 21, 22, 23, 26, 30], "karahan": 3, "sar\u0131ta\u015f": 3, "systemat": [3, 6], "approach": [3, 4, 5, 6, 16, 22, 23, 24, 25, 26, 27, 28, 29], "ivestig": 3, "panda": [3, 4, 5, 19, 20, 24, 28], "pd": [3, 4, 5, 19, 24, 28], "eleutherai": [3, 24], "user": [3, 16, 22, 23, 25, 26, 28, 29], "karab": 3, "desktop": 3, "special": [3, 4, 19, 20, 21, 23, 24, 25, 26, 27, 28], "ad": [3, 16, 18, 21, 22, 23, 24, 26], "associ": [3, 15, 18, 24], "embed": [3, 4, 16, 19, 20, 22, 24, 27, 28, 29, 30, 31], "set_se": 3, "reproduc": [3, 16], "manual_se": 3, "42": [3, 19, 31], "test_set": 3, "pretty_print": 3, "replac": [3, 30], "100": [3, 16, 17, 18, 19, 20, 24, 26, 28, 30], "greedi": [3, 20, 21, 24], "greedy_decod": 3, "eos_token_id": [3, 4, 21, 24], "beam_search_decod": 3, "num_beam": 3, "early_stop": 3, "impli": 3, "stop": [3, 16, 19, 22, 23, 27], "reach": [3, 22, 23], "pure_sampling_decod": 3, "deactiv": [3, 20], "top_k": [3, 4, 21, 24], "softmax_sampling_decod": 3, "higher": [3, 5, 16, 17, 18, 20, 22, 23, 25, 29, 30], "mean": [3, 4, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31], "random": [3, 4, 17, 20, 23, 24, 27, 30], "top_k_sampling_decod": 3, "k": [3, 17, 20, 22, 24, 30, 31], "exce": [3, 16, 23, 24], "threshold": [3, 24], "nucleu": 3, "top_p_sampling_decod": 3, "9": [3, 16, 17, 20, 24, 31], "top_p": [3, 4, 24], "contrastive_decod": 3, "penalty_alpha": 3, "intent": 3, "prefix": [3, 22, 28], "engin": [3, 4, 16, 19, 22, 23, 26, 28, 30], "One": [3, 16, 20, 23, 25, 26, 27, 28, 29, 30], "consist": [3, 4, 5, 6, 10, 16, 18, 19, 20, 21, 22, 25, 28, 30], "softmax": [3, 20, 24, 30, 31], "major": [3, 16], "vote": 3, "scenario": [3, 28], "pure": [3, 21, 24], "top": [3, 16, 24, 26, 27, 30], "contrast": [3, 5, 21, 22, 27, 28, 29], "penalti": 3, "appli": [3, 16, 17, 19, 20, 21, 22, 23, 27, 28, 30, 31], "disclaim": [3, 26, 29], "As": [3, 12, 19, 21, 22, 24, 25, 26, 27, 28, 29], "hyperparamet": [3, 16, 23, 25, 26], "fair": [3, 29], "believ": [3, 29], "stanford": 3, "snli": 3, "pdf": [3, 25], "1508": 3, "05326": 3, "entir": [3, 5, 16, 19, 21, 22, 23, 26], "independ": 3, "hypothesi": [3, 5], "premis": 3, "reli": [3, 22, 23, 27, 29], "sole": 3, "select": [3, 5, 16, 19, 21, 23, 24, 25, 27, 28, 29], "highest": [3, 5, 24, 28], "disregard": 3, "determin": [3, 16, 17, 19, 20, 22, 23, 28], "decid": [3, 25], "observ": [3, 4, 5, 19, 23, 24, 26, 27, 30], "doesn": [3, 21, 23, 24, 25, 28, 30], "although": [3, 16, 24, 25, 28, 29], "explicitli": [3, 16, 17, 21, 30], "attempt": [3, 27, 29], "irrelev": 3, "appear": 3, "hierarchi": 3, "among": [3, 6], "vari": [3, 24, 25], "outperform": 3, "draw": [3, 19, 24, 28, 29], "solid": 3, "few_shot_examples_v1": 3, "uniform": [3, 19], "figur": [3, 4, 19, 20, 23, 25, 26], "east": 3, "asian": 3, "younger": 3, "men": 3, "laugh": 3, "floor": [3, 20], "church": 3, "choir": 3, "mass": 3, "joyou": 3, "song": 3, "black": [3, 16], "race": 3, "car": 3, "start": [3, 4, 16, 19, 20, 22, 23, 24, 25, 26, 29, 30], "lone": 3, "road": 3, "costum": 3, "hold": [3, 5], "umbrella": [3, 21], "happi": 3, "fairi": 3, "soccer": 3, "male": 3, "sport": 3, "dirti": 3, "barefoot": 3, "kid": 3, "won": 3, "award": 3, "cleanest": [3, 28], "feet": 3, "green": 3, "headscarf": 3, "blue": 3, "grin": 3, "young": 3, "few_shot_examples_v2": 3, "frown": 3, "parent": 3, "basebal": 3, "crack": 3, "ceil": 3, "few_shot_exampl": 3, "__name__": 3, "enumer": [3, 4, 19, 20, 30, 31], "suffix": 3, "few_shot": 3, "encod": [3, 4, 16, 20, 21, 22, 25, 27, 28, 30], "majority_vot": 3, "gt": 3, "gc": 3, "empty_cach": 3, "self_consist": 3, "12": [3, 16, 17, 20, 22, 30, 31], "102": [3, 19], "distractor": [3, 28], "numer": [3, 16, 17, 18, 22, 25], "probe": [3, 6, 13, 20], "diagnost": 3, "145": 3, "primarili": [3, 29], "statement": [3, 24], "pertain": 3, "subsequ": [3, 18, 19, 20, 25, 29, 30], "methodolog": [3, 25, 28], "enabl": [3, 19, 22, 26], "either": [3, 5, 16, 23, 26, 30], "support": [3, 15, 16, 17, 27, 29], "oppos": [3, 16, 20], "emploi": [3, 28, 29], "extract": [3, 16, 22, 23, 27], "score": [3, 4, 5, 22, 23, 24, 25, 27, 28, 31], "classic": 3, "henc": 3, "former": [3, 23], "constrain": 3, "therebi": [3, 22, 28], "limit": [3, 16, 20, 22, 24, 26, 28, 29], "five": [3, 22], "\ud835\udc4e": 3, "identifi": [3, 15, 22, 23, 25, 27, 28, 29, 30], "augment": 3, "maximum": [3, 18, 25], "ultim": [3, 25], "overal": [3, 4, 18, 22, 24, 26, 27, 28], "vanilla": [3, 4, 25], "wing": [3, 24], "penguin": [3, 24], "parallelogram": 3, "limb": [3, 24], "human": [3, 4, 11, 12, 16, 21, 22, 24, 25, 26, 27, 28, 29], "yard": 3, "bird": [3, 24], "rectangular": 3, "squar": 3, "beings": [3, 24], "datafram": [3, 4, 19, 20, 21], "df": [3, 5], "few_shot_templ": [3, 24], "q": [3, 4, 22, 24, 30, 31], "know": [3, 5, 16, 18, 19, 21, 22, 24, 25, 26, 27, 29, 30], "few_shot_prompt": [3, 24], "loc": [3, 18, 19, 24], "lower": [3, 16, 18, 20, 22, 24, 25], "googl": [3, 16, 27, 28], "highwai": 3, "street": [3, 16, 24], "gp": 3, "servic": 3, "fox": [3, 22, 23, 31], "walk": [3, 5, 27], "forest": 3, "share": [3, 16, 19, 25, 26], "someon": 3, "connect": [3, 16, 19, 29, 30, 31], "exot": 3, "snake": 3, "demand": 3, "carri": [3, 16, 22], "bodyguard": 3, "duti": 3, "who": [3, 6, 16, 22, 23], "hire": 3, "him": 3, "electron": [3, 16], "atla": 3, "habitat": 3, "awai": [3, 16, 22], "internet": [3, 16, 28], "rais": [3, 27, 28, 30], "pet": 3, "ensur": [3, 16, 22], "safeti": [3, 29], "secur": 3, "employ": 3, "visual": [3, 4, 5, 13, 16, 22, 24, 29], "prompt_input_id": [3, 24], "knowledge_stat": [3, 24], "15": [3, 16, 18, 19, 20, 23, 24, 31], "id": [3, 16, 21, 22, 23, 24, 27, 28, 30], "consequ": [3, 24], "unexpect": [3, 24], "behavior": [3, 4, 5, 12, 13, 19, 24, 25, 29], "obtain": [3, 16, 17, 18, 20, 24, 25, 29], "reliabl": [3, 24, 28, 29], "so": [3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "no_knowledge_stat": 3, "answer_log_prob": [3, 24], "now": [3, 18, 19, 20, 22, 23, 25, 27, 28, 29], "hand": [3, 4, 6, 16, 20, 24, 26, 27], "maximizing_answ": 3, "maximizing_log_prob": 3, "float": [3, 17, 18, 22, 30], "inf": [3, 31], "log_probs_for_a": 3, "full": [3, 4, 16, 17, 19, 22, 23, 24, 27, 30], "context_prompt": [3, 24], "context_input_id": [3, 24], "ignor": [3, 18, 19, 20, 24], "masked_label": [3, 24], "ones_lik": [3, 24], "pred": [3, 24, 27], "log_p": [3, 24], "max_prob": 3, "her": 3, "luggag": 3, "didn": 3, "re": [3, 22, 23, 26], "carrier": 3, "briefcas": 3, "8": [3, 16, 17, 20, 24, 25, 31], "651183128356934": 3, "358133316040039": 3, "2638578414917": 3, "854644775390625": 3, "918338775634766": 3, "746541976928711": 3, "27782917022705": 3, "510452270507812": 3, "339978218078613": 3, "297685623168945": 3, "776968002319336": 3, "095916748046875": 3, "659232139587402": 3, "95555591583252": 3, "486684799194336": 3, "11": [3, 17, 19, 20, 22, 25, 31], "570777893066406": 3, "832415580749512": 3, "639629364013672": 3, "748946189880371": 3, "790425300598145": 3, "538839340209961": 3, "888652801513672": 3, "38808536529541": 3, "434816360473633": 3, "631083488464355": 3, "umpir": 3, "field": [3, 5, 16, 25, 29], "polic": 3, "offic": 3, "ic": 3, "softwar": [3, 16, 29], "worker": [3, 16], "goe": [3, 20, 25, 28], "235928535461426": 3, "407893180847168": 3, "890667915344238": 3, "370429039001465": 3, "198206901550293": 3, "596774101257324": 3, "11440658569336": 3, "61604118347168": 3, "67751693725586": 3, "281587600708008": 3, "031961441040039": 3, "703117370605469": 3, "687712669372559": 3, "021014213562012": 3, "909016609191895": 3, "271496772766113": 3, "655148983001709": 3, "51792049407959": 3, "4584479331970215": 3, "452688217163086": 3, "554006576538086": 3, "23339557647705": 3, "114116668701172": 3, "754240989685059": 3, "520474433898926": 3, "decis": 3, "elect": 3, "lot": [3, 4, 16, 24, 25], "power": [3, 12, 19, 28], "offici": 3, "142420768737793": 3, "972271919250488": 3, "90455436706543": 3, "03041934967041": 3, "8204474449157715": 3, "612419128417969": 3, "63491153717041": 3, "091569900512695": 3, "645547866821289": 3, "576825141906738": 3, "13504695892334": 3, "369648933410645": 3, "64605712890625": 3, "518067359924316": 3, "83149242401123": 3, "276028633117676": 3, "06977367401123": 3, "650859832763672": 3, "893194198608398": 3, "85256576538086": 3, "173294067382812": 3, "73061466217041": 3, "749650001525879": 3, "258166313171387": 3, "929475784301758": 3, "faulti": 3, "brake": 3, "driver": 3, "influenc": [3, 5, 18], "drug": 3, "708761215209961": 3, "258934020996094": 3, "46780014038086": 3, "419212341308594": 3, "7927885055542": 3, "114299774169922": 3, "092577934265137": 3, "165120124816895": 3, "094646453857422": 3, "583547592163086": 3, "501969337463379": 3, "986560821533203": 3, "233652114868164": 3, "622293472290039": 3, "889074325561523": 3, "216497421264648": 3, "336479187011719": 3, "792975425720215": 3, "515718460083008": 3, "635777473449707": 3, "690098762512207": 3, "63901424407959": 3, "035849571228027": 3, "710489273071289": 3, "199512481689453": 3, "expens": 3, "meant": [3, 16, 18], "educ": 3, "teach": [3, 25], "place": [3, 4, 24], "ith": [3, 28], "589640617370605": 3, "743338584899902": 3, "013982772827148": 3, "673873901367188": 3, "343545913696289": 3, "858763694763184": 3, "82045841217041": 3, "263005256652832": 3, "9718918800354": 3, "668207168579102": 3, "3271989822387695": 3, "516082286834717": 3, "24860143661499": 3, "370843410491943": 3, "465941429138184": 3, "29901123046875": 3, "830539703369141": 3, "338224411010742": 3, "12620735168457": 3, "884116172790527": 3, "690305233001709": 3, "893522262573242": 3, "179699897766113": 3, "780394554138184": 3, "239646911621094": 3, "avers": 3, "height": 3, "medicin": 3, "treat": [3, 19, 21, 27], "pain": [3, 19], "361309051513672": 3, "466972351074219": 3, "520139694213867": 3, "94018840789795": 3, "04466724395752": 3, "76948356628418": 3, "612512588500977": 3, "671875": 3, "55483865737915": 3, "412652015686035": 3, "165630340576172": 3, "419055938720703": 3, "055522918701172": 3, "118217468261719": 3, "015838623046875": 3, "019416809082031": 3, "555357933044434": 3, "577406883239746": 3, "60135555267334": 3, "841059684753418": 3, "815916061401367": 3, "528425216674805": 3, "598419189453125": 3, "201595306396484": 3, "424176216125488": 3, "revolv": 3, "door": 3, "conveni": [3, 19, 21], "direct": [3, 18, 19, 25], "travel": 3, "serv": [3, 4, 24, 26], "measur": [3, 4, 5, 18, 22, 28], "bank": [3, 16], "depart": 3, "mall": 3, "york": 3, "aim": [3, 28, 29], "kill": 3, "anim": 3, "hat": 3, "talk": [3, 26], "magazin": 3, "alongsid": 3, "doctor": 3, "bookstor": 3, "market": 3, "station": 3, "mortuari": 3, "hamburg": 3, "fast": [3, 24], "food": [3, 24, 26], "restaur": 3, "pizza": [3, 24], "dead": 3, "cow": 3, "mouth": 3, "carcass": [3, 21], "jame": 3, "bui": [3, 16], "farmland": 3, "midwest": 3, "countrysid": 3, "estat": [3, 16], "farm": 3, "area": [3, 16, 25, 29], "illinoi": 3, "island": 3, "ferret": 3, "popular": [3, 4, 21, 23, 26, 29], "home": 3, "north": 3, "carolina": 3, "britain": 3, "hutch": 3, "correct_answ": [3, 30], "task_prompt": 3, "instructions_prompt": 3, "review": [3, 4, 21, 25], "iterrow": [3, 4, 28], "noption": 3, "displai": [3, 4], "nquestion": 3, "chr": 3, "ord": [3, 17], "nselect": 3, "moment": [3, 24, 25], "max_prob_idx": [3, 24], "argmax": [3, 24, 28], "149327039718628": 3, "8839691281318665": 3, "7674624919891357": 3, "4614875316619873": 3, "297186851501465": 3, "6051456928253174": 3, "3155701160430908": 3, "452256441116333": 3, "5575783252716064": 3, "7076313495635986": 3, "0540814399719238": 3, "9338192343711853": 3, "921186923980713": 3, "363598346710205": 3, "736490726470947": 3, "7589095234870911": 3, "0533545017242432": 3, "1971399784088135": 3, "8056986331939697": 3, "040278911590576": 3, "03721284866333": 3, "8900933861732483": 3, "955305576324463": 3, "6002087593078613": 3, "708530902862549": 3, "9054934978485107": 3, "1341121196746826": 3, "681248426437378": 3, "6236846446990967": 3, "031479835510254": 3, "real": [3, 26, 29], "vector": [3, 4, 15, 16, 19, 20, 22, 27, 30], "instead": [3, 16, 19, 21, 23, 25, 26, 27, 28, 30], "discret": 3, "determinist": [3, 20], "That": [3, 16, 19, 21, 22, 25, 29], "featur": [3, 13, 16, 20, 26, 27], "remind": [3, 21, 24, 27], "distribut": [3, 19, 20, 23, 24, 28], "represent": [3, 4, 8, 13, 16, 17, 19, 20, 22, 23, 27, 30], "sensit": [3, 27, 29], "divid": [3, 28, 31], "sub": [3, 16, 17, 26, 27], "learnt": 3, "preced": [3, 16, 22, 23, 24], "occur": [3, 5, 16, 19, 23, 28], "wider": 3, "window": [3, 4, 16, 27, 28], "decrib": 3, "rise": [3, 16, 29], "volum": 3, "exponenti": 3, "problem": [3, 4, 6, 10, 16, 28], "still": [3, 16, 18, 20, 21, 22, 24, 28], "dimensi": 3, "rel": [3, 5, 21, 22, 25], "simialar": 3, "joint": 3, "consecut": [3, 20], "000": [3, 5, 16], "smooth": 3, "valu": [3, 4, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "crucial": [3, 16, 27, 28], "finit": [3, 22], "brown": [3, 16, 22, 23, 27], "800": 3, "press": [3, 16], "stream": [3, 26], "million": [3, 23, 25], "divers": [3, 16, 28], "unseen": [3, 16], "contextualis": 3, "challeng": [3, 29], "statist": [3, 16, 19], "offer": [3, 6, 25, 26, 27], "focu": [3, 22, 25, 28, 29], "exist": [3, 16, 19], "theoret": [3, 26, 28], "framework": [3, 12, 15, 24, 25, 26], "wherea": 3, "denvio": 3, "earlier": [3, 25, 27], "elmo": 3, "giant": [3, 14], "finetun": [3, 4, 25], "pictur": [3, 20, 22, 24], "But": [3, 17, 24, 26], "presuppos": [3, 28], "emphas": 3, "diffenrenc": 3, "hardwar": 3, "longer": [3, 18, 22, 25, 28], "comapr": 3, "perplex": [3, 20, 28], "reduct": [3, 20], "ap": 3, "corpora": [3, 16, 28, 29], "sota": [3, 22, 25, 28, 29], "benchmark": [3, 5, 14, 16, 24], "keep": [3, 16, 18, 20, 21, 24, 25], "part": [3, 4, 5, 12, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29], "short": [3, 4, 9, 16, 17, 19, 20, 21, 25, 29], "summar": [3, 21, 23, 25, 28], "break": [3, 26], "shorter": [3, 16, 19], "third": [4, 5, 9, 17, 19, 22, 26, 27], "advanc": [4, 6, 9, 16, 21, 24], "dive": [4, 11, 21, 22, 29], "28th": 4, "surname_firstname_hw3": 4, "issu": [4, 16, 23, 26, 28, 29], "increasingli": [4, 29], "wherein": [4, 28], "suppli": [4, 16, 19, 20], "addit": [4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28], "textual": [4, 28], "storag": [4, 16], "queri": [4, 16, 22, 24, 26, 27, 31], "proprietari": 4, "databas": [4, 12, 25], "db": 4, "searchabl": 4, "relev": [4, 6, 16, 18, 21, 23, 25, 26, 28, 29], "www": 4, "pinecon": 4, "chosen": [4, 24, 25, 28], "ins": 4, "tep": 4, "depnd": 4, "extend": [4, 16, 17, 19, 29], "imag": [4, 16, 21, 22, 23], "sourc": [4, 5, 6, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29], "until": [4, 22, 23, 24], "within": [4, 15, 16, 21, 22, 24, 28, 30], "recip": [4, 25, 26], "directli": [4, 16, 17, 22, 23], "llamaindex": 4, "mini": [4, 19, 25], "4k": [4, 25], "backbon": [4, 23, 25, 26], "baai": 4, "bge": 4, "v1": [4, 28], "unstructur": 4, "m3hrdadfi": 4, "recipe_nlg_lit": 4, "supplement": [4, 28], "familiar": [4, 16, 17, 20, 21, 26, 27, 28, 29], "alreadi": [4, 16, 17, 21, 22, 24, 25, 26, 28, 29, 30], "haven": [4, 25], "yet": [4, 16, 20, 21, 25, 27], "huggingface_hub": [4, 30], "bitsandbyt": 4, "clear_output": 4, "os": [4, 26, 27], "llama_index": 4, "core": [4, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30], "vectorstoreindex": 4, "ollama": 4, "ollamaembed": 4, "huggingfaceembed": 4, "huggingfacellm": 4, "dataset_df": 4, "vectorstorageindex": 4, "ingredi": [4, 26], "accur": 4, "correctli": [4, 19, 20, 21, 22, 23, 25, 28], "prompt": [4, 5, 6, 20, 22, 25, 26, 27, 28, 29, 30], "co": [4, 16, 22], "microsoft": [4, 25, 26], "heck": 4, "completion_to_prompt": 4, "cell": [4, 5, 16, 21, 23, 30], "block": [4, 16, 19, 22, 25, 26, 27, 30], "togeth": [4, 5, 21, 22, 24, 26, 27, 30], "reus": [4, 15, 19, 24, 25], "across": [4, 5, 15, 27, 28], "doc": [4, 17, 20, 21, 25, 26, 28], "ai": [4, 6, 25], "module_guid": 4, "supporting_modul": 4, "embed_model": 4, "info": 4, "using_llm": 4, "usage_custom": 4, "tokenizer_nam": 4, "context_window": 4, "1024": [4, 22, 25, 27], "128": [4, 20, 22, 26], "generate_kwarg": 4, "device_map": [4, 25], "model_kwarg": 4, "torch_dtyp": [4, 24, 30], "float16": [4, 17, 24, 25, 30], "load_in_8bit": 4, "trust_remote_cod": [4, 24], "vector_store_index": 4, "vectorstor": 4, "node": [4, 19, 23], "from_docu": 4, "help": [4, 11, 16, 19, 23, 24, 25, 26, 27, 28, 29, 30], "explan": [4, 5, 10, 13, 21, 25, 27, 28], "paramt": [4, 24], "deploi": 4, "query_engin": 4, "interfac": [4, 19, 21, 26], "as_query_engin": 4, "response_mod": 4, "compact": 4, "similarity_top_k": 4, "verbos": [4, 26], "response_synthes": 4, "pork": 4, "chop": 4, "noodl": 4, "soup": 4, "source_nod": 4, "get_cont": 4, "rag_respons": 4, "vanilla_respons": 4, "retrieved_node_text": 4, "retrieved_node_scor": 4, "20": [4, 16, 17, 19, 20, 22, 28, 31], "dish": 4, "test_df": 4, "test_queri": 4, "against": [4, 20, 23, 28], "response_rag": 4, "record": [4, 16, 28], "straightforward": 4, "response_vanilla": 4, "prefer": [4, 5, 11, 16, 25], "inpsect": 4, "advantag": [4, 16, 23, 25, 26, 28], "disadvantag": 4, "underli": [4, 21, 28], "Is": [4, 5, 20, 26, 29], "procedur": [4, 18, 24, 28], "movi": [4, 21, 25], "ziegler": 4, "2020": [4, 7, 15, 16], "polici": 4, "sft": [4, 25], "reward": [4, 29], "signal": [4, 16, 19, 22, 25], "roug": [4, 25, 28], "cnn": 4, "datset": 4, "4gb": 4, "ppo": 4, "trl": [4, 25], "insert": [4, 5, 26], "sai": [4, 5, 12, 16, 24, 29, 30], "dig": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19], "bit": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20], "proxim": [4, 25], "algorithm": [4, 5, 22, 23, 24, 25, 29, 30], "27": [4, 19, 20, 25, 31], "rouge_scor": 4, "ppotrain": 4, "ppoconfig": 4, "automodelforcausallmwithvaluehead": 4, "config": [4, 21, 23], "gavin124": 4, "learning_r": [4, 18, 20, 21], "41e": 4, "250": 4, "mini_batch_s": 4, "ppo_epoch": 4, "500": [4, 18, 20, 21], "heavi": [4, 21, 26, 29], "Then": [4, 22, 23], "build_dataset": 4, "dataset_nam": 4, "abise": 4, "cnn_dailymail": 4, "arg": [4, 16, 21, 22], "ds": [4, 20], "512": [4, 17, 25], "fals": [4, 17, 19, 20, 21, 22, 24, 25, 27, 28, 30], "set_format": [4, 16], "collat": [4, 21], "twice": [4, 30], "kl": 4, "diverg": [4, 23], "ref_model": 4, "baselin": 4, "slide": [4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 21, 24, 25, 27], "76": [4, 19, 28], "78": [4, 31], "05": [4, 20, 22], "simultan": [4, 16], "action": [4, 25], "placement": 4, "later": [4, 19, 20, 30], "ppo_train": 4, "data_col": [4, 21, 23], "num_process": 4, "avoid": [4, 22, 23, 24, 25, 26, 30], "bug": 4, "reward_fn": 4, "original_summari": 4, "o": [4, 19, 20, 28, 29, 31], "strip": [4, 27], "rouge1": 4, "output_max_length": 4, "generation_kwarg": 4, "min_length": 4, "query_tensor": 4, "squeez": [4, 17, 19, 20, 30], "response_tensor": 4, "stat": 4, "log_stat": 4, "cite": 4, "suppos": [4, 16, 21, 25, 28], "metric": [4, 5, 20, 21, 29, 30], "Be": 4, "concis": 4, "articl": [4, 16], "problemat": [4, 29], "bonu": 4, "receiv": [4, 16, 25, 27], "weigh": 4, "coeffici": [4, 5], "vf_coef": 4, "affect": [4, 24, 25, 30], "assist": [4, 11, 22, 25], "harmless": [4, 11, 25, 29], "odd": 4, "evas": 4, "commonli": [4, 16, 19, 21, 22, 23, 25, 28, 29], "chat": [4, 10, 22, 25, 26], "purpos": [4, 16, 17, 19, 21, 25, 26, 27], "effici": [4, 10, 11, 19, 21, 25], "scale": [4, 7, 11, 18, 19, 25, 28, 31], "aspet": 5, "juli": 5, "13th": 5, "surname_firstname_hw4": 5, "render": [5, 30], "blimp": 5, "linguist": [5, 6, 16, 27, 28, 29], "known": [5, 16, 18, 21, 22, 25, 27, 28], "isol": [5, 28], "phenomenon": [5, 28, 29], "syntax": [5, 17], "morpholog": 5, "semant": [5, 28], "author": [5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "160m": 5, "anaphor_gender_agr": 5, "determiner_noun_agreement_with_adjective_1": 5, "animate_subject_pass": 5, "complex_np_island": 5, "npi_present_1": 5, "superlative_quantifiers_1": 5, "existential_there_object_rais": 5, "principle_a_case_1": 5, "phenomena": 5, "confid": [5, 24, 28], "interv": [5, 17], "difficult": [5, 16, 19, 25, 28], "easiest": 5, "gramamt": [5, 16], "captur": [5, 20, 23, 25], "minicon": [5, 28], "scorer": [5, 28], "nyu": 5, "mll": 5, "lm_scorer": [5, 28], "incrementallmscor": [5, 28], "bar": [5, 29], "ci": 5, "social": [5, 28], "implic": 5, "deepli": 5, "interconnect": 5, "overrepres": 5, "certain": [5, 16, 18, 19, 22, 23, 24, 27, 28, 30], "cultur": 5, "due": [5, 16, 30], "imbal": 5, "appropri": [5, 23, 28], "exhibit": [5, 23, 28, 29], "instanc": [5, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "lens": 5, "mostli": [5, 16, 19, 21, 23, 25, 29], "monolingu": 5, "bigscienc": 5, "560m": 5, "compelt": 5, "parenthes": 5, "analog": 5, "supermarket": 5, "cashier": 5, "greet": 5, "american": 5, "hello": [5, 17], "intuititv": 5, "appropi": [5, 16], "germani": 5, "condit": [5, 18, 20, 28], "bye": 5, "inappropri": 5, "stranger": 5, "ethic": [5, 29], "fig": 5, "came": 5, "tap": 5, "variat": 5, "usa": 5, "evid": [5, 28], "caus": 5, "justif": 5, "starter": 5, "gpt2_scorer": 5, "bloom_scor": 5, "gpt2_predict": 5, "bloom_predict": 5, "answer_kei": 5, "ger": 5, "nonsens": [5, 25], "vignett": 5, "answer_scores_gpt2": 5, "conditional_scor": [5, 28], "answer_scores_bloom": 5, "perez": 5, "2022": [5, 10, 11, 12, 15, 22, 24, 25, 28, 29], "pseudo": [5, 21, 28], "elicit": [5, 10, 24, 25, 29], "concern": 5, "guid": [5, 16, 21, 30], "subject": [5, 6, 25], "verb": 5, "agreement": 5, "taken": [5, 21, 27, 28, 29, 30], "wilcox": 5, "2021": [5, 10, 13, 15, 29], "rest": [5, 16, 21, 23, 25], "rt": 5, "agre": [5, 20], "mismatch": 5, "term": [5, 9, 16, 21, 22, 24, 25, 28], "manipul": [5, 17], "syntact": [5, 13, 14, 27, 28], "plural": 5, "singular": 5, "noun": [5, 25], "src": 5, "claus": 5, "modifi": [5, 16, 17, 26], "pilot": 5, "injur": 5, "teacher": 5, "bring": 5, "love": 5, "orc": 5, "minist": 5, "manag": [5, 20], "tenni": 5, "pp": 5, "preposit": 5, "phrase": 5, "difficulti": [5, 16, 24], "quantit": 5, "testabl": 5, "operation": [5, 30], "unit": [5, 16, 17, 20, 22], "trial": [5, 25, 28], "proport": [5, 16, 20, 28], "born": 5, "barplot": 5, "correl": [5, 27, 28], "slowdown": 5, "read_csv": [5, 24, 28], "sva_data": 5, "FOR": 5, "vs": [5, 21, 28, 30], "analysi": [5, 15, 23, 30], "taught": 6, "uni": 6, "t\u00fcbingen": 6, "cover": [6, 10, 11, 12, 14, 15, 16, 21, 23, 24, 28], "equip": [6, 16, 22, 23], "particip": [6, 28], "mechanist": 6, "perspect": [6, 28, 29], "encourag": [6, 16], "cognit": [6, 28], "scienc": [6, 28, 29], "societi": 6, "master": 6, "bachelor": 6, "interdisciplinari": 6, "prior": [6, 29], "experi": [6, 16, 24, 25, 26, 27], "program": [6, 10, 23], "python": [6, 16, 19, 27, 28], "highli": [6, 25], "ss": 6, "2024": [6, 7, 12, 15, 30], "weekli": 6, "tue": 6, "seminar": 6, "fri": 6, "worksheet": 6, "themselv": 6, "webbbook": 6, "host": [6, 21], "ect": 6, "compulsori": 6, "homework": [6, 16, 25, 28], "exam": [6, 29], "9ect": 6, "group": 6, "project": [6, 16, 30, 31], "preliminari": 6, "introduct": [6, 16, 22, 24], "attribut": [6, 22, 28, 30], "excel": [6, 16, 30], "ryan": 6, "cotterel": 6, "lab": 6, "perci": 6, "liang": 6, "pragmat": [6, 28], "nlg": [6, 24, 28], "michael": [6, 17, 18, 19, 20, 24], "frank": [6, 17, 18, 19, 20, 24], "andrej": 6, "karpathi": 6, "1h": 6, "video": [6, 16], "recommend": [6, 16, 20], "brian": 6, "christian": 6, "cogsci": 6, "cheat": 7, "notat": [7, 17], "trend": 7, "textbook": [7, 8, 9], "jurafski": 7, "martin": 7, "speech": [7, 27, 28], "zhao": 7, "2023": [7, 10, 11, 12, 15, 25, 29], "survei": 7, "kaplan": 7, "law": [7, 20, 25, 29], "mikolov": 7, "2013": 7, "word2vec": [7, 15, 16], "artifici": 8, "recurr": [8, 20, 21], "backpropag": [8, 9, 27], "goodfellow": 8, "courvil": 8, "2016": 8, "rumelhart": 8, "1986": 8, "back": [8, 17, 21, 22, 24, 30], "propag": 8, "rnn": [9, 19, 22, 23], "behind": [9, 16, 18, 19, 22, 25, 26, 27, 28, 30], "supplementari": [9, 10, 11, 12, 13, 14, 15], "hochreit": 9, "schmidhub": 9, "1997": 9, "vaswani": 9, "2017": 9, "radford": 9, "unsupervis": [9, 25], "multitask": 9, "learner": 9, "2": [9, 10, 15, 16, 22, 25, 27, 28, 30, 31], "fourth": 10, "strategi": [10, 16, 28, 29], "foundat": [10, 16, 29], "wei": 10, "kojima": 10, "webson": [10, 29], "pavlick": [10, 29], "realli": 10, "Their": [10, 30], "nye": 10, "scratchpad": 10, "reynold": 10, "mcdonnel": 10, "beyond": [10, 16, 22, 28, 29], "paradigm": [10, 28], "wang": [10, 15], "liu": [10, 24], "yao": 10, "deliber": 10, "xie": 10, "implicit": [10, 21], "bayesian": [10, 23], "min": [10, 23], "rethink": 10, "role": [10, 22, 30], "demonstr": [10, 16, 25, 27], "lampinen": 10, "touvron": [10, 25], "session": [11, 12, 13, 14, 15, 16, 21, 24, 25], "reinforc": [11, 25], "feedback": [11, 25], "supervis": [11, 27, 29], "ding": 11, "howard": 11, "univers": 11, "peft": [11, 21], "blogpost": [11, 12, 15, 19, 25, 28, 29], "robot": [11, 12], "openai": [11, 21, 25, 26], "ouyang": 11, "overview": [11, 14, 16, 19, 21, 23, 24, 25, 26, 29], "chatgpt": 11, "bai": [11, 25], "tool": [12, 16], "autonom": 12, "park": 12, "simulacra": 12, "chen": 12, "autoag": 12, "ahn": 12, "Not": [12, 20, 26], "afford": 12, "intern": [13, 16], "mccoi": 13, "diagnos": 13, "heurist": 13, "tennei": [13, 27], "contextu": [13, 22], "elazar": 13, "amnes": 13, "counterfactu": 13, "qualiti": [14, 16, 23, 28], "syntaxgym": 14, "holist": [14, 18, 19], "lnaguag": 14, "helm": 14, "cut": [15, 16], "edg": [15, 19], "towatd": 15, "mechan": [15, 21, 25, 27, 30], "logit": [15, 21, 23, 30, 31], "merullo": [15, 30], "arithmet": 15, "elhag": 15, "circuit": 15, "meng": 15, "locat": [15, 17, 18, 23, 24, 27], "edit": 15, "factual": [15, 28, 29], "aka": 15, "rome": 15, "vig": 15, "mediat": 15, "gender": [15, 29], "heimersheim": 15, "nanda": 15, "patch": 15, "wild": 15, "indirect": [15, 30], "identif": [15, 30], "scrub": 15, "rigor": 15, "hypothes": [15, 28], "yu": 15, "character": 15, "recal": [15, 26, 28, 30], "polina": [16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "tsvilodub": [16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "page": [16, 26], "materi": 16, "april": 16, "19th": 16, "exercis": [16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30], "upcom": 16, "ahead": 16, "ideal": [16, 19, 21, 22, 23, 25, 28], "fridai": 16, "semest": 16, "machin": [16, 17, 19, 21, 23, 25, 29], "easili": [16, 21, 28, 30], "latter": [16, 21, 23, 26, 27, 29], "icon": 16, "webook": 16, "safer": 16, "comfort": 16, "platform": [16, 21], "account": [16, 21, 26], "mind": [16, 25, 26, 28], "frequent": [16, 17, 21, 22], "choos": [16, 18, 20, 23, 24, 25, 28, 30], "langchain": [16, 24], "torchrl": 16, "bertviz": [16, 27], "wikipedia": [16, 26, 28], "strongli": [16, 29], "conda": [16, 19], "suitabl": [16, 25], "significantli": 16, "spec": 16, "rocm": 16, "occupi": [16, 17], "3": [16, 17, 20, 21, 25, 26, 27, 28, 29, 30, 31], "txt": [16, 27], "onc": [16, 19, 22, 25], "adjust": [16, 21, 22, 24, 29], "path": [16, 24, 27], "successfulli": [16, 23], "shy": 16, "wikipediaqueryrun": 16, "langchain_commun": [16, 26], "wikipediaapiwrapp": 16, "mac": 16, "m1": 16, "chip": 16, "randomli": [16, 20, 23], "rand": [16, 17, 19], "ones": [16, 17, 18, 19, 25, 30], "pointwis": 16, "manner": 16, "z": [16, 19, 31], "must": [16, 18, 19, 22, 24, 29], "z1": 16, "z2": 16, "nb": [16, 17, 18, 19, 21], "api_wrapp": 16, "infrastructur": [16, 21], "tokenizer_gpt2": 16, "debat": [16, 28], "daili": 16, "commit": 16, "produc": [16, 19, 20, 21, 30], "readm": 16, "immedi": 16, "de": [16, 19], "facto": 16, "crisp": 16, "adher": 16, "pep8": 16, "convent": 16, "indent": 16, "handi": 16, "reformat": 16, "Such": [16, 28], "seamlessli": [16, 26], "ruff": 16, "formatt": 16, "extens": [16, 26], "studio": 16, "fct": 16, "slightli": [16, 17, 19, 23, 27, 28, 30], "numpydoc": 16, "bad": [16, 18, 25], "add": [16, 17, 19, 20, 22, 26, 30], "github": [16, 25, 30], "repositori": [16, 25, 30], "fyi": 16, "tidi": 16, "collabor": 16, "git": 16, "studi": [16, 18, 20, 25, 26, 28], "team": [16, 29], "stick": 16, "guidelin": 16, "ourselv": [16, 21, 22, 26, 27], "kindli": 16, "urg": 16, "gram": 16, "potenti": [16, 23, 24, 25, 26, 27, 28], "bias": [16, 19, 25, 28, 29], "inherit": [16, 19], "heard": [16, 28], "target": [16, 18, 19, 20, 21, 25, 27, 28, 29], "fluent": [16, 21, 28], "interchang": [16, 24, 25], "ling": 16, "piec": [16, 22, 26, 28], "extern": 16, "criteria": [16, 29], "far": [16, 21, 23, 25, 29], "varieti": [16, 26, 28], "literari": 16, "british": 16, "nation": 16, "bnc": 16, "ml": [16, 29], "sualli": 16, "held": [16, 23], "drop": [16, 22, 24, 27], "sometim": [16, 21, 22, 23, 24, 25, 26, 29], "ommit": 16, "done": [16, 21, 22, 23, 24, 28, 29, 30], "approxim": [16, 24, 28], "my": [16, 24, 26], "raw": [16, 20, 22, 28], "web": 16, "accomplish": [16, 21, 26], "remov": [16, 17, 20, 22, 30], "markup": 16, "tag": [16, 23, 27, 28], "annot": [16, 25, 27, 29, 30], "enrich": 16, "judgement": 16, "promin": [16, 22], "onto": [16, 19, 22, 28, 30], "readabl": [16, 21, 22], "charact": [16, 17, 22, 23], "multi": [16, 19, 29], "chunk": [16, 28], "whenev": 16, "notion": [16, 20], "equival": [16, 24], "lingusit": 16, "hide": [16, 22], "week": [16, 21, 23], "tooken": 16, "understood": 16, "parallel": [16, 21, 22, 24, 30], "effect": [16, 19, 21, 25, 28, 30], "inter": 16, "nowadai": 16, "fulli": [16, 21, 27], "anticip": 16, "toxic": [16, 28, 29], "desir": [16, 17, 22, 23, 25, 29], "mix": [16, 17], "filter": [16, 25], "non": [16, 20, 23, 24, 27], "undesir": [16, 25, 29], "digit": 16, "arguabl": [16, 28], "stopword": 16, "symbol": [16, 22], "emoji": [16, 22], "valuabl": 16, "prepair": 16, "overlap": [16, 28], "fed": [16, 20], "restrict": [16, 24], "insight": [16, 27, 28], "tradit": 16, "tweet": 16, "financi": 16, "origin": [16, 20, 25, 28, 30], "intend": [16, 18, 23, 25, 26, 29], "slot": 16, "adequ": 16, "bot": 16, "zeroshot": 16, "column_nam": [16, 21, 23], "dataset_s": 16, "whitespac": [16, 22], "tweet_length": 16, "average_tweet_length": 16, "histogram": 16, "click": [16, 17, 18, 19, 20, 21, 23, 25, 27], "hist": 16, "bin": 16, "bynd": 16, "jpmorgan": 16, "reel": 16, "meat": 16, "bd0xbfgjkt": 16, "ccl": 16, "rcl": 16, "nomura": 16, "point": [16, 19, 22, 23, 24, 25, 26, 28], "weak": 16, "carniv": 16, "royal": 16, "caribbean": 16, "ygjpt2red3": 16, "cx": 16, "cemex": 16, "credit": 16, "suiss": 16, "morgan": 16, "outlook": [16, 24], "kn1g4awfib": 16, "ess": 16, "btig": 16, "mcyftsxc2n": 16, "fnko": 16, "funko": 16, "piper": 16, "jaffrai": 16, "z37ijmcqzb": 16, "9543": 16, "17835062349366": 16, "lenght": 16, "peak": 16, "almost": [16, 24, 26], "never": [16, 20], "quit": [16, 21, 25, 26, 28, 29, 30], "alphabet": [16, 22], "clean_tweet": 16, "cleaned_tweet": 16, "cleaned_dataset": 16, "char": [16, 17, 31], "isalpha": 16, "isspac": 16, "httpstcobdxbfgjkt": 16, "80": [16, 17, 20], "train_siz": [16, 20], "test_siz": [16, 20], "cleaned_dataset_split": 16, "train_test_split": 16, "7634": 16, "1909": 16, "aimia": 16, "settl": 16, "dissid": 16, "sharehold": 16, "hit": 16, "wrongfuldeath": 16, "lawsuit": 16, "di": [16, 26], "coronaviru": 16, "httpstcozzaplmfa": 16, "lharri": 16, "stock": 16, "price": 16, "intang": 16, "push": 16, "central": 16, "boe": 16, "haskel": 16, "httpstcogymzyzi": 16, "httpstcoyfehvc": 16, "bullish": 16, "tmobil": 16, "unsurpris": 16, "ceo": 16, "wall": 16, "slip": 16, "wrapper": [16, 21, 22, 30], "tokein": 16, "hood": [16, 21, 22, 23, 27], "preprocessed_train_dataset": 16, "00": [16, 30], "32869": 16, "18": [16, 19, 20], "customiz": 16, "essenti": [16, 20, 21, 22, 23, 30], "tuck": 16, "pile": [16, 21], "gao": [16, 25], "trough": 16, "abstract": [16, 21, 25, 29], "glimps": 16, "stand": [16, 28], "foster": 16, "mainli": [16, 19], "hungarian": 16, "crawl": [16, 28], "miss": [16, 29], "english": [16, 20, 27, 28], "14": [16, 17, 19, 20, 31], "multilanguag": 16, "poor": 16, "favour": 16, "cc": 16, "justext": 16, "archiv": 16, "constitu": 16, "diviat": 16, "infor": 16, "strong": [16, 25], "outlier": 16, "impress": [16, 25, 28], "establish": 16, "tra": 16, "publish": 16, "unknown": [16, 22, 25], "misrepresent": 16, "situat": 16, "jo": 16, "gebru": 16, "lesson": 16, "sociocultur": 16, "usabl": [17, 25], "algebra": 17, "arrai": [17, 19, 27, 30, 31], "And": [17, 26], "documet": 17, "width": [17, 20], "300px": 17, "tensor1": 17, "tensor2": 17, "tensor3": 17, "tensor4": 17, "tensor5": 17, "prder": 17, "initialis": 17, "a_list": 17, "tensor_from_list": 17, "Or": 17, "new_tensor": 17, "replic": [17, 24], "tensor_0d": 17, "tensor_2d": 17, "np_arrai": 17, "np_array_to_tensor": 17, "dtype": [17, 18, 22], "float64": [17, 18], "popul": 17, "drawn": 17, "uniformli": 17, "6004": 17, "1671": 17, "2114": 17, "4924": 17, "5919": 17, "0054": 17, "30": [17, 19, 20, 31], "50": [17, 20, 28], "60": [17, 20, 22], "ly": 17, "exercise1a": 17, "exercise1b": 17, "exercise2": 17, "exercise3": 17, "9025e": 17, "01": 17, "4543e": 17, "3338e": 17, "04": 17, "5581e": 17, "8884e": 17, "4922e": 17, "row_vector": 17, "strictli": 17, "speak": [17, 20], "col_vector": 17, "boolean": 17, "complex": [17, 24, 26], "float32": [17, 18], "integ": [17, 22], "int64": 17, "declar": 17, "bool": 17, "implicitli": [17, 19, 25], "cast": 17, "hello_tensor": 17, "72": [17, 19, 20, 31], "101": 17, "108": 17, "111": [17, 31], "87": [17, 19], "114": 17, "33": [17, 20, 31], "less": [17, 19, 22, 24], "datatyp": 17, "seen": [17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "equal": [17, 20, 28], "mix2": 17, "mix3": 17, "mix4": 17, "mix5": 17, "mix6": 17, "mix7": 17, "mix8": 17, "0000": 17, "2000": [17, 18, 20], "datas": 17, "element": [17, 20], "concaten": [17, 24, 27], "tail": 17, "head_and_tail": 17, "stack": [17, 19, 30], "Its": [17, 25], "old": 17, "tensor_1": 17, "tensor_2": 17, "col": 17, "unsqueez": [17, 21, 22, 30], "posit": [17, 22, 23, 24, 25, 28, 30], "flatten": [17, 19], "least": [17, 21, 24, 25, 26], "dimes": 17, "70": [17, 20], "90": [17, 19, 20], "tensor_1_transpos": 17, "infix": 17, "wise": [17, 23], "5000": [17, 18, 19, 20, 22], "3750": 17, "16": [17, 19, 20, 21, 31], "similarli": [17, 28], "recycl": 17, "obviou": 17, "divis": [17, 20], "4000": [17, 18], "subtract": [17, 19, 30, 31], "precis": [17, 28], "matmul": [17, 30], "200": [17, 20, 28], "34": [17, 31], "400": 17, "56": [17, 22, 31], "600": 17, "notic": [17, 18, 20, 24], "flexibl": [17, 19, 22, 23], "yield": 17, "product": [17, 25, 27], "dot": [17, 23, 27], "prodcut": 17, "43": [17, 19, 20, 31], "65": [17, 19, 20], "another_tensor": 17, "detach": [17, 19, 20, 30], "ex1": 17, "ex1_row": 17, "ex1_col": 17, "ex1_col_tran": 17, "torch1": 17, "torch2": 17, "matrix1": 17, "matrix2": 17, "matrixprod": 17, "531": [17, 31], "300": 17, "fit": [18, 19, 21, 23, 25, 28], "normal": [18, 19, 22, 23, 30], "gaussian": [18, 19], "candid": 18, "By": [18, 22, 25], "stochast": [18, 20, 29], "descent": 18, "seek": 18, "seaborn": [18, 19], "warn": [18, 19, 20, 22, 25, 30], "suppress": 18, "messag": [18, 26], "sn": [18, 19], "filterwarn": [18, 19, 20], "true_loc": 18, "deviat": 18, "fix": [18, 20, 21, 25, 28, 30], "readi": 18, "n_ob": [18, 19], "10000": [18, 19, 20, 22], "true_dist": 18, "train_data": [18, 20], "empir": 18, "ident": 18, "empirical_mean": 18, "5f": 18, "00150": 18, "kdeplot": 18, "seri": [18, 21, 23], "becom": [18, 19, 28], "Being": 18, "deriv": [18, 19], "stabil": [18, 23, 25], "requires_grad": [18, 22, 25], "scene": [18, 19], "sgd": 18, "aggress": 18, "0000001": 18, "degre": 18, "log_prob": [18, 20], "19274": 18, "0312": 18, "negbackward0": 18, "outset": 18, "grad": [18, 25], "10015": 18, "0458984375": 18, "told": 18, "itself": [18, 20, 25, 26], "9989984954101563": 18, "repeat": [18, 22, 24], "eras": 18, "ing": [18, 22], "gone": 18, "cycl": 18, "n_training_step": 18, "5s": 18, "diff": 18, "5d": [18, 19], "3f": [18, 19, 30], "16102": 18, "988": 18, "60579": 18, "60729": 18, "14937": 18, "011": 18, "36674": 18, "36825": 18, "1500": 18, "14508": 18, "284": 18, "22179": 18, "22330": 18, "14350": 18, "645": 18, "13390": 18, "13540": 18, "2500": [18, 19], "14292": 18, "682": 18, "08060": 18, "08211": 18, "3000": 18, "14271": 18, "368": 18, "04828": 18, "04979": 18, "3500": 18, "14263": 18, "533": 18, "02869": 18, "03019": 18, "14260": 18, "650": 18, "01680": 18, "01831": 18, "4500": [18, 19], "14259": 18, "591": 18, "00960": 18, "01110": 18, "201": [18, 31], "00523": 18, "00673": 18, "5500": [18, 19], "059": 18, "00258": 18, "00408": 18, "6000": 18, "006": 18, "00097": 18, "00248": 18, "6500": 18, "14258": 18, "986": 18, "00000": 18, "7000": 18, "979": 18, "00059": 18, "00091": 18, "7500": [18, 19], "977": 18, "00095": 18, "00055": 18, "8000": 18, "00117": 18, "00033": 18, "8500": 18, "00130": 18, "00020": 18, "9000": 18, "975": 18, "00138": 18, "00012": 18, "9500": 18, "976": 18, "00143": 18, "00007": 18, "00146": 18, "00005": 18, "revert": 18, "apart": 18, "slowli": 18, "perceptron": 19, "feed": [19, 22, 24], "goal_fun": 19, "sin": [19, 22], "linspac": 19, "lineplot": 19, "nois": 19, "y_normal": 19, "y_nois": 19, "x_ob": 19, "y_ob": 19, "scatterplot": 19, "n_input": 19, "1": [19, 20, 21, 23, 29, 31], "n_hidden": 19, "n_output": 19, "exclus": [19, 20], "instati": [19, 21], "design": [19, 28], "constitut": [19, 21, 25], "variant": 19, "exact": 19, "eventu": 19, "mlpexplicit": 19, "super": [19, 20, 22, 27, 30], "linear1": [19, 22], "linear2": [19, 22], "linear3": 19, "linear4": 19, "h1": 19, "h2": 19, "h3": 19, "mlp_explicit": 19, "param": [19, 25], "round": [19, 20, 27, 31], "0076": 19, "8415": 19, "9536": 19, "6464": 19, "9964": 19, "7288": 19, "1196": 19, "462": 19, "8668": 19, "9444": 19, "5211": 19, "0849": 19, "2557": 19, "9653": 19, "4786": 19, "5713": 19, "6843": 19, "2133": 19, "342": 19, "0769": 19, "2313": 19, "0227": 19, "2852": 19, "0166": 19, "2986": 19, "0292": 19, "1179": 19, "2564": 19, "2944": 19, "1009": 19, "0552": 19, "0447": 19, "2081": 19, "2009": 19, "033": 19, "1969": 19, "1945": 19, "1427": 19, "0546": 19, "2106": 19, "1128": 19, "0149": 19, "237": 19, "095": [19, 31], "2698": 19, "0059": 19, "1793": 19, "2842": 19, "2865": 19, "1744": [19, 22], "0109": 19, "1259": 19, "1426": 19, "0955": 19, "3025": 19, "2543": 19, "2068": 19, "0964": 19, "0934": 19, "0013": 19, "2462": 19, "2037": 19, "0994": 19, "2537": 19, "1462": 19, "2201": 19, "1222": 19, "2095": 19, "107": 19, "253": [19, 31], "1784": 19, "1452": 19, "0968": 19, "1959": 19, "0706": [19, 22], "0282": 19, "2097": 19, "1417": 19, "0523": 19, "2028": 19, "2256": 19, "1229": 19, "1682": 19, "0451": 19, "0309": 19, "1407": [19, 22], "1962": 19, "0854": 19, "2872": 19, "0421": 19, "3001": 19, "0915": [19, 22], "0519": 19, "2862": 19, "1163": 19, "2389": 19, "0924": 19, "2941": 19, "2323": 19, "0592": 19, "212": 19, "071": 19, "0909": 19, "1527": 19, "0588": 19, "2353": 19, "0547": 19, "0211": 19, "1491": 19, "2182": 19, "2239": 19, "2984": 19, "1006": 19, "1116": 19, "0044": 19, "251": 19, "2208": 19, "039": 19, "0528": 19, "3162": 19, "0257": 19, "0663": 19, "2846": 19, "0646": 19, "1269": 19, "2371": 19, "3099": 19, "2536": 19, "0446": 19, "1587": [19, 22], "255": 19, "074": 19, "1321": 19, "2919": 19, "1839": 19, "1293": 19, "0429": [19, 22], "2682": 19, "2615": 19, "0671": 19, "2576": 19, "1129": 19, "0199": 19, "0655": 19, "043": 19, "1449": 19, "1796": 19, "0972": 19, "1241": 19, "2595": 19, "151": 19, "1908": 19, "286": [19, 22], "2029": 19, "2647": 19, "1574": 19, "2976": 19, "1041": 19, "0947": 19, "0225": 19, "0479": 19, "0493": 19, "2154": 19, "2965": 19, "2934": 19, "0936": 19, "3114": 19, "2956": 19, "2425": 19, "1305": 19, "046": 19, "1408": 19, "023": 19, "0155": 19, "1967": 19, "2333": 19, "179": 19, "0348": 19, "2954": 19, "2073": 19, "2232": 19, "1136": 19, "0556": 19, "0454": 19, "315": 19, "2971": 19, "0509": 19, "1394": 19, "2337": 19, "0912": 19, "256": [19, 25], "1774": 19, "2738": 19, "0386": 19, "034": 19, "2706": 19, "0666": 19, "2664": 19, "0419": 19, "1732": 19, "0622": 19, "2011": 19, "276": [19, 30], "0453": 19, "1481": 19, "0383": 19, "2165": 19, "1897": 19, "1638": 19, "1007": 19, "2027": 19, "3049": 19, "0017": 19, "2579": 19, "0675": 19, "1464": 19, "1149": [19, 31], "195": 19, "1961": 19, "2143": 19, "2373": 19, "0853": 19, "016": 19, "1031": 19, "1161": 19, "1396": 19, "0505": 19, "2276": 19, "2393": 19, "1518": 19, "2711": 19, "1264": 19, "2712": 19, "2633": 19, "1861": 19, "2758": 19, "2591": 19, "3013": 19, "2468": 19, "2455": 19, "guess": [19, 20, 21, 23], "slope": 19, "roughli": 19, "intercept": 19, "10x1": 19, "10x10": 19, "1x10": 19, "1x1": 19, "stdv": 19, "math": [19, 20, 22, 28, 29], "sqrt": [19, 23, 31], "uniform_": 19, "condens": 19, "sequenti": [19, 20], "neatli": 19, "thu": [19, 28], "swoop": 19, "mlpcondens": 19, "mlp_condens": 19, "onward": 19, "tediou": 19, "primit": 19, "reusabl": 19, "easi": [19, 21, 28], "nonlinearregressiondata": 19, "reshap": [19, 20], "train_dataload": 19, "deliv": 19, "4495": 19, "5819": 19, "7650": 19, "1632": 19, "3451": 19, "6135": 19, "6223": 19, "1976": 19, "7169": 19, "3746": 19, "5931": 19, "8005": 19, "0434": 19, "8540": 19, "0562": 19, "4078": 19, "9046": 19, "4005": 19, "7086": 19, "1871": 19, "0338": 19, "3793": 19, "7298": [19, 24], "7743": 19, "4155": 19, "121": 19, "0789": 19, "133": 19, "6013": 19, "2198": 19, "6659": 19, "4612": 19, "7734": 19, "6199": 19, "61": 19, "5975": 19, "4716": 19, "3842": 19, "3931": 19, "2188": 19, "4141": 19, "6194": 19, "131": 19, "9025": 19, "4001": 19, "46": [19, 27], "9520": 19, "0037": 19, "1146": 19, "4007": 19, "94": [19, 20], "9994": 19, "147": 19, "9163": 19, "52": [19, 20, 31], "8589": 19, "2630": 19, "0369": 19, "3773": 19, "2532": 19, "5453": 19, "2955": 19, "3915": 19, "7552": 19, "6925": 19, "3938": 19, "6076": 19, "6834": [19, 31], "8546": 19, "2283": 19, "8123": 19, "3403": 19, "9574": 19, "0644": 19, "9521": 19, "0436": 19, "2180": 19, "3797": 19, "7454": 19, "7530": 19, "8264": 19, "3442": 19, "122": 19, "4230": 19, "2478": 19, "3011": 19, "104": 19, "4167": 19, "6514": 19, "1359": 19, "3875": 19, "5973": 19, "5617": 19, "8176": 19, "5437": 19, "1630": 19, "9920": 19, "55": [19, 20], "6051": 19, "41": [19, 20, 22, 31], "1025": [19, 22], "38": [19, 31], "8970": 19, "9164": 19, "8666": 19, "2518": 19, "0591": 19, "5863": 19, "6087": 19, "5321": 19, "3973": 19, "9640": 19, "6017": 19, "6880": 19, "9468": 19, "4264": 19, "0024": 19, "7179": 19, "5653": 19, "5318": 19, "0374": 19, "7767": 19, "7110": 19, "6955": 19, "7494": 19, "0279": 19, "5396": 19, "4075": 19, "9538": 19, "6411": 19, "8022": 19, "9450": 19, "4118": 19, "7496": 19, "6096": 19, "6654": 19, "77": 19, "7501": 19, "7172": 19, "36": [19, 20, 31], "9245": 19, "8191": 19, "6196": 19, "5388": 19, "88": [19, 31], "0235": 19, "45": [19, 20, 23], "1277": 19, "0365": 19, "0066": 19, "0195": 19, "6423": 19, "5127": 19, "7764": 19, "69": 19, "8224": 19, "5756": 19, "9476": 19, "37": [19, 22], "1051": 19, "119": 19, "4592": 19, "4126": 19, "1727": 19, "47": [19, 31], "0679": 19, "6114": 19, "0246": 19, "5510": 19, "9079": 19, "1315": 19, "0575": 19, "4921": 19, "7523": 19, "3927": 19, "9023": 19, "3946": 19, "3009": 19, "0370": 19, "2317": 19, "1652": [19, 24], "1014": 19, "9101": 19, "1524": 19, "2815": 19, "0928": 19, "2689": 19, "6177": 19, "7121": 19, "7293": 19, "4614": 19, "3488": 19, "1371": 19, "82": 19, "1433": 19, "2099": 19, "7502": 19, "5580": 19, "6555": 19, "113": 19, "4812": 19, "6265": 19, "7873": 19, "2406": 19, "8441": 19, "0513": [19, 22], "140": 19, "1428": 19, "4315": 19, "9185": 19, "66": [19, 20], "8981": 19, "1600": 19, "2063": 19, "89": [19, 22, 31], "8697": 19, "129": 19, "4619": 19, "118": 19, "5045": 19, "51": 19, "6166": 19, "1447": 19, "2186": 19, "loss_funct": 19, "mseloss": 19, "adam": [19, 20, 27], "1e": [19, 22], "n_train_step": 19, "50000": [19, 20], "current_loss": 19, "finish": [19, 22], "y_pred": 19, "d_wide": 19, "melt": 19, "id_var": 19, "value_var": 19, "hue": 19, "alpha": 19, "298": [19, 20, 31], "1596": [19, 22], "497": 19, "740": 19, "628": 19, "522": 19, "447": 19, "12500": 19, "473": 19, "209": [19, 20], "15000": [19, 20], "450": 19, "191": 19, "17500": 19, "441": 19, "309": 19, "20000": [19, 20], "436": 19, "642": 19, "22500": 19, "433": 19, "959": 19, "25000": [19, 20], "432": 19, "27500": 19, "430": 19, "475": 19, "30000": [19, 20], "428": 19, "987": [19, 31], "32500": 19, "427": 19, "638": [19, 20], "35000": [19, 20], "425": 19, "664": [19, 31], "37500": 19, "424": [19, 31], "004": [19, 31], "40000": [19, 20], "422": 19, "595": 19, "42500": 19, "419": 19, "45000": [19, 20], "417": 19, "816": 19, "47500": 19, "416": 19, "479": 19, "415": 19, "unclear": [19, 25], "notabl": 19, "pai": 19, "closer": [19, 22, 24, 26, 29], "subtl": 19, "wiggl": 19, "wash": 19, "vast": [19, 26], "trick": [19, 23], "net": [19, 20, 21, 22], "opportun": 19, "particularli": 19, "clear": 19, "youself": 19, "gelu": 19, "logsoftmax": [19, 20], "gru": 19, "grucel": 19, "cosinesimilar": 19, "crossentropyloss": [19, 21, 27], "clip_grad_value_": 19, "weight_norm": 19, "pad_sequ": 19, "pad_packed_sequ": 19, "deal": [19, 22, 28], "vanish": 19, "rememb": [19, 20, 24], "timestamp": 19, "cosin": [19, 21, 22, 23, 25], "clip": [19, 23], "bigger": 19, "cap": 19, "magnitud": [19, 27], "unpack": 19, "pack": 19, "invers": 19, "pack_padded_sequ": 19, "differenti": 19, "calculu": 19, "complic": [19, 22], "turn": [19, 25], "luckili": [19, 21, 23], "handl": [19, 20, 21], "acycl": 19, "oper": [19, 22, 30], "worthwhil": 19, "graphviz": 19, "digraph": 19, "ac": 19, "bd": 19, "ce": 19, "ef": 19, "fg": 19, "dz": 19, "dy": 19, "dv": 19, "dw": 19, "dx": 19, "h": [19, 22, 25, 30], "bc": 19, "cg": 19, "dh": 19, "ge": 19, "quick": [20, 22, 23], "__future__": 20, "unicode_liter": 20, "print_funct": 20, "urllib": 20, "request": [20, 24], "nn": [20, 21, 22, 23, 27, 30], "urlopen": 20, "githubusercont": 20, "com": [20, 25, 30], "npnlg": 20, "neural_pragmatic_nlg": 20, "url": 20, "names_data": 20, "datafil": 20, "n_categori": 20, "ascii": [20, 22], "letter": [20, 22], "plu": [20, 22, 27], "all_lett": 20, "ascii_lett": 20, "n_letter": 20, "sosindex": 20, "eosindex": 20, "sound": [20, 24, 25, 29], "ear": 20, "bruckner": 20, "duplic": [20, 30], "czech": 20, "519": 20, "724": 20, "arab": 20, "japanes": 20, "991": 20, "chines": 20, "268": 20, "vietnames": 20, "73": [20, 31], "russian": 20, "9408": 20, "french": [20, 27], "277": 20, "irish": 20, "232": 20, "3668": [20, 22], "spanish": 20, "greek": 20, "203": 20, "italian": [20, 24, 26], "709": 20, "portugues": 20, "74": [20, 31], "scottish": 20, "dutch": 20, "297": 20, "korean": 20, "polish": 20, "139": 20, "realiz": [20, 29], "test_data": 20, "split_percentag": 20, "total_s": 20, "train_indic": 20, "test_indic": 20, "467": 20, "652": 20, "1800": 20, "892": 20, "99": 20, "241": 20, "8467": 20, "941": 20, "249": [20, 31], "28": 20, "3301": 20, "367": 20, "183": 20, "71": 20, "267": 20, "85": 20, "alloc": 20, "exhaust": [20, 23, 24, 29], "testset": 20, "datapoint": [20, 23], "craft": 20, "borrow": 20, "550px": 20, "hot": [20, 22, 31], "blank": 20, "dropout": [20, 22], "inclus": 20, "input_s": 20, "hidden_s": [20, 27], "output_s": 20, "i2h": 20, "i2o": 20, "o2o": 20, "dim": [20, 21, 22, 30, 31], "input_combin": 20, "output_combin": 20, "init_hidden": 20, "graph": 20, "slight": 20, "quiet": 20, "random_training_pair": 20, "random_choic": 20, "l": [20, 25, 27, 30, 31], "randint": 20, "distinguish": [20, 23, 28, 29], "those": [20, 21, 22, 24, 27, 28, 29], "input_tensor": 20, "target_tensor": 20, "category_tensor": 20, "li": [20, 28], "letter_index": 20, "longtensor": 20, "proper": 20, "random_training_exampl": 20, "category_tensor_": 20, "input_line_tensor": 20, "target_line_tensor": 20, "explanatori": 20, "1x18": 20, "elsewher": 20, "time_sinc": 20, "dm": 20, "triplet": 20, "fresh": 20, "unsqueeze_": 20, "reset": 20, "cumul": 20, "criterion": [20, 27], "minut": 20, "nllloss": 20, "0005": 20, "n_iter": 20, "100000": 20, "print_everi": 20, "plot_everi": 20, "all_loss": 20, "total_loss": [20, 27], "rolling_mean": 20, "4f": 20, "0m": 20, "19": [20, 30], "8029": 20, "7308": 20, "54": 20, "1777": 20, "1m": 20, "17": [20, 26, 31], "7180": 20, "3607": 20, "49": 20, "0758": 20, "2m": 20, "7s": 20, "8325": 20, "6393": 20, "4591": 20, "3m": 20, "0s": 20, "2746": 20, "55000": 20, "1081": 20, "60000": 20, "9675": 20, "65000": 20, "8344": 20, "4m": 20, "70000": 20, "7046": 20, "75000": 20, "5894": 20, "80000": 20, "4826": 20, "85000": 20, "3850": 20, "5m": 20, "90000": 20, "2958": 20, "95000": 20, "95": 20, "2122": 20, "1304": 20, "tempor": 20, "regim": 20, "exactli": [20, 21, 22, 24, 25, 26, 30], "auxiliari": [20, 27], "get_surprisal_item": 20, "get_surprisal_dataset": 20, "surprisl_dict": 20, "surp_avg_dict": 20, "perplxty_dict": 20, "surprisl": 20, "surp_avg": 20, "perplxti": 20, "item_surpr": 20, "n_item": 20, "make_df": 20, "surp_dict": 20, "from_dict": 20, "surp_scal": 20, "surprisal_test": 20, "surprisal_train": 20, "nmean": 20, "743693795963553": 20, "90373899401307": 20, "anymor": 20, "effienc": 20, "initial_sequ": 20, "topv": 20, "topi": 20, "topk": [20, 30], "m\u00fcll": 20, "m\u00fcller": 20, "empti": [20, 26], "shima": 20, "robust": [20, 28, 29], "favor": 20, "perfect": [20, 28], "serious": 20, "flaw": 20, "subsect": 20, "varianc": 20, "leav": 20, "speaker": 20, "scope": 20, "mid": [20, 24, 28], "857054710388184": 20, "908905029296875": 20, "bay": 20, "doveski": 20, "jackson": 20, "satoshi": 20, "n_name": 20, "get_prob": 20, "exp": [20, 22, 24, 28, 31], "p_categori": 20, "cond_prob_nam": 20, "country2idx": 20, "prob": [20, 31], "p_name": 20, "logspac": 20, "329154273345582": 20, "049187345280759": 20, "044040465112291": 20, "5707610099012776": 20, "9830674364599212": 20, "176395016805715": 20, "557712239995114": 20, "26594367422115": 20, "1344274634863063": 20, "089089898243062": 20, "989767319373302": 20, "4374993423367664": 20, "746094297468178": 20, "2719710113848373": 20, "503078942968957": 20, "7748951742793246": 20, "33744430690024": 20, "9166837202752751": 20, "6531856900705275": 20, "6175335252350447": 20, "8089478089254367": 20, "3889435308678326": 20, "6692703950843093": 20, "384112744200534": 20, "6612294775126752": 20, "262053290805339": 20, "21096220730527": 20, "1701001434279856": 20, "137311827640074": 20, "9253905269010243": 20, "8398610504968342": 20, "879318062464732": 20, "4070479577071051": 20, "943814170795518": 20, "79754031778924": 20, "0787130945986387": 20, "9999999999999994": 20, "582685867418279": 20, "205616125930776": 20, "151007538987999": 20, "819255000074138": 20, "5181813091977734": 20, "454367770907213": 20, "9190526549711127": 20, "945132093597879": 20, "83683439539813": 20, "1927830372943777": 20, "975641382951965": 20, "726918229927053": 20, "1676781420602698": 20, "0917557944550413": 20, "076368400920858": 20, "444657022227277": 20, "716580436309544": 20, "033587316144933": 20, "tendenc": 20, "nativ": [21, 30], "workflow": 21, "futur": [21, 24, 25], "principl": [21, 22], "suffici": 21, "autom": [21, 28], "hungri": 21, "parameter": 21, "domain": [21, 22, 28, 29], "vision": [21, 23, 29], "cv": 21, "level": [21, 22, 23, 27, 29], "imagenet": 21, "curat": [21, 28], "scratch": [21, 23], "absolut": [21, 22, 25, 27], "doubt": 21, "imdb": [21, 23, 25], "highlevel": 21, "freeli": 21, "close": [21, 23, 24, 25, 28], "insid": [21, 22], "send": 21, "server": 21, "api": [21, 26, 27], "commun": [21, 25, 26, 29], "heavili": 21, "audio": 21, "abbrevi": 21, "nice": [21, 22], "onlin": [21, 24, 25], "hub": [21, 26], "checkpoint": [21, 28], "brows": 21, "incld": 21, "overwhelm": 21, "highlight": [21, 29], "remain": [21, 29], "trainer": [21, 25], "setup": 21, "blackbox": [21, 28, 30], "depth": 21, "newli": 21, "datacollatorforlanguagemodel": [21, 23], "trainingargu": 21, "additioanli": 21, "belong": 21, "easier": [21, 25, 30], "pipe_output": 21, "explicit": [21, 22, 29], "frozen": [21, 25, 28], "simplifi": [21, 24], "substep": [21, 26], "truthful_qa": 21, "stanfordnlp": [21, 23], "mlm": 21, "tokenized_dataset": [21, 23], "remove_column": [21, 23], "subset": [21, 25], "subsampled_dataset": [21, 23], "output_dir": 21, "imdb_gpt2": 21, "per_device_train_batch_s": 21, "per_device_eval_batch_s": 21, "evaluation_strategi": 21, "eval_step": 21, "logging_step": 21, "gradient_accumulation_step": 21, "num_train_epoch": 21, "weight_decai": 21, "lr_scheduler_typ": 21, "save_step": 21, "5_000": 21, "fp16": 21, "push_to_hub": 21, "use_mps_devic": 21, "eval_dataset": 21, "directori": [21, 27], "decai": 21, "overfit": [21, 23, 24], "schedul": [21, 23, 25], "overris": 21, "compute_loss": 21, "imdbtrain": 21, "return_output": 21, "celoss": 21, "modelout": 21, "num_class": 21, "additional_dim": 21, "swap": 21, "permut": 21, "eos_tensor": 21, "exclud": 21, "target_out": 21, "explicit_train": 21, "dynam": 21, "histori": [21, 29], "log_histori": 21, "train_loss": [21, 27], "eval_loss": 21, "autoclass": [21, 23], "subclass": 21, "friendli": 22, "convers": [22, 25], "subword": 22, "simplest": 22, "priori": 22, "wouldn": 22, "byte": 22, "undergo": [22, 30], "unnecessari": 22, "unicod": 22, "frequenc": 22, "merg": 22, "freuqenc": 22, "wordpiec": 22, "simpli": [22, 25, 27], "prepend": 22, "act": [22, 30], "startofsequ": 22, "thelik": 22, "At": [22, 26], "endofsequ": 22, "fact": [22, 29], "necess": [22, 26], "regress": 22, "unk": 22, "aren": 22, "delin": 22, "necessari": [22, 25, 26, 30], "du": 22, "vocab_s": 22, "vocab": [22, 31], "vice": [22, 25], "versa": [22, 25], "text1": 22, "lazi": [22, 23], "enc1": 22, "chek": 22, "tok": 22, "text2": 22, "enc2": 22, "text3": 22, "der": 22, "schnell": 22, "braun": 22, "fuch": 22, "sprang": 22, "\u00fcber": 22, "den": 22, "faul": 22, "hund": 22, "enc3": 22, "meta": 22, "freq_of_pair": 22, "freq_of_first_el": 22, "freq_of_second_el": 22, "unigram": [22, 28], "reduc": [22, 24], "static": 22, "parallelis": 22, "widespread": 22, "weren": 22, "curiou": [22, 24, 30], "sign": [22, 26], "bmatrix": [22, 31], "62": 22, "03": 22, "positionalencod": 22, "inject": [22, 30], "sine": 22, "posencod": 22, "po": [22, 23, 27], "2i": 22, "d_model": 22, "emb": 22, "max_len": 22, "incom": 22, "pos_encod": 22, "pe": 22, "div_term": 22, "register_buff": 22, "transformermodel": 22, "ntoken": 22, "ninp": 22, "nhead": 22, "nhid": 22, "nlayer": 22, "dim_feedforward": 22, "num_encoder_lay": 22, "num_decoder_lay": 22, "model_typ": 22, "src_mask": 22, "input_emb": 22, "transformer_model": 22, "userwarn": 22, "enable_nested_tensor": 22, "use_nested_tensor": 22, "encoder_lay": 22, "self_attn": 22, "batch_first": 22, "why_not_sparsity_fast_path": 22, "transformerencod": 22, "modulelist": 22, "transformerencoderlay": 22, "multiheadattent": 22, "out_proj": 22, "nondynamicallyquantizablelinear": 22, "in_featur": 22, "out_featur": 22, "inplac": 22, "norm1": 22, "layernorm": 22, "ep": 22, "elementwise_affin": 22, "norm2": 22, "dropout1": 22, "dropout2": 22, "norm": [22, 30], "transformerdecod": 22, "transformerdecoderlay": 22, "multihead_attn": 22, "norm3": 22, "dropout3": 22, "__dict__": 22, "_paramet": 22, "ordereddict": 22, "in_proj_weight": 22, "1548": 22, "1673": 22, "2034": [22, 31], "0239": 22, "0457": 22, "0236": 22, "1674": 22, "1002": 22, "2152": 22, "1966": 22, "0204": 22, "0941": 22, "1385": 22, "1005": 22, "0104": 22, "0569": 22, "0696": 22, "1157": 22, "0846": 22, "1056": 22, "0601": 22, "1913": 22, "1003": 22, "0028": 22, "1869": 22, "1173": 22, "0612": 22, "0919": 22, "q_proj_weight": 22, "k_proj_weight": 22, "v_proj_weight": 22, "in_proj_bia": 22, "_buffer": 22, "_non_persistent_buffers_set": 22, "_backward_pre_hook": 22, "_backward_hook": 22, "_is_full_backward_hook": 22, "_forward_hook": 22, "_forward_hooks_with_kwarg": 22, "_forward_hooks_always_cal": 22, "_forward_pre_hook": 22, "_forward_pre_hooks_with_kwarg": 22, "_state_dict_hook": 22, "_state_dict_pre_hook": 22, "_load_state_dict_pre_hook": 22, "_load_state_dict_post_hook": 22, "_modul": 22, "embed_dim": 22, "kdim": 22, "vdim": 22, "_qkv_same_embed_dim": 22, "num_head": 22, "head_dim": 22, "bias_k": 22, "bias_v": 22, "add_zero_attn": 22, "96": 22, "reimplement": 22, "gpt2_lm": 22, "gpt2model": 22, "wte": 22, "50257": 22, "768": [22, 25, 27], "wpe": 22, "gpt2block": 22, "ln_1": [22, 30], "attn": [22, 30], "gpt2attent": 22, "c_attn": 22, "conv1d": 22, "c_proj": 22, "attn_dropout": 22, "resid_dropout": 22, "ln_2": [22, 30], "mlp": [22, 30], "gpt2mlp": 22, "c_fc": 22, "newgeluactiv": 22, "ln_f": [22, 25, 30], "lm_head": [22, 30], "4738": 22, "2614": 22, "0978": 22, "0584": 22, "0250": 22, "0874": 22, "1473": 22, "2387": 22, "0525": 22, "0113": 22, "0156": 22, "0039": 22, "0695": 22, "1143": 22, "0363": 22, "0318": 22, "2592": 22, "0164": 22, "1991": 22, "0095": 22, "0516": 22, "0319": 22, "1517": 22, "2170": [22, 31], "1043": 22, "0293": 22, "0475": 22, "4100": 22, "1924": 22, "2400": 22, "0046": 22, "0070": 22, "0198": 22, "4803": 22, "5254": 22, "4293": 22, "0126": 22, "0499": 22, "0032": 22, "nf": 22, "2304": [22, 25], "_is_hf_initi": 22, "acccess": 22, "pointer": 22, "caption": 22, "whose": [23, 25, 29], "ve": 23, "initialize": 23, "causallm": 23, "lmhead": 23, "gpt2forsequenceclassif": 23, "gpt2fortokenclassif": 23, "entiti": 23, "recognit": 23, "ner": 23, "crossentropi": 23, "forsequenceclassif": 23, "passag": 23, "perhap": [23, 25, 28], "qa": [23, 25], "translat": [23, 27, 28], "nuber": 23, "mse": 23, "cross": [23, 27], "entropi": 23, "binari": [23, 25, 28], "span": [23, 25], "gpt2doubleheadsmodel": 23, "tricki": [23, 29, 30], "decad": 23, "bytest": 23, "encount": 23, "optima": 23, "grid": 23, "balanc": 23, "converg": [23, 25], "minimum": [23, 25], "benefit": 23, "lastli": 23, "quantifi": 23, "hw1": [23, 28], "aris": 23, "memor": 23, "cost": 23, "illustr": 23, "subplot": 23, "stage": 23, "underfit": 23, "fail": 23, "pattern": [23, 27, 29, 30], "tightli": 23, "wors": [23, 25], "earli": [23, 25, 27], "soon": 23, "mlm_probabl": 23, "switch": 23, "bert_tok": 23, "exemplifi": [23, 28], "seq2seq": [23, 27], "t5": [23, 27, 28], "lstm": 23, "address": [24, 27, 28], "determinisit": 24, "forc": [24, 27, 30], "seed": 24, "soft": [24, 30], "propto": 24, "famili": 24, "said": 24, "along": 24, "unanim": 24, "endpoint": [24, 26, 27], "noce": 24, "detial": 24, "awesom": 24, "terribl": 24, "favourit": 24, "full_prompt": 24, "few_shot_predict": 24, "aw": 24, "pizzeria": 24, "chicago": 24, "littl": [24, 26], "itali": 24, "court": 24, "capit": [24, 27, 30], "k_q": 24, "a_i": 24, "simplif": 24, "examples_df": 24, "knowledge_exampl": 24, "sep": [24, 27], "center": 24, "448": [24, 31], "765625": 24, "6406": 24, "4921875": 24, "352": 24, "5242": 24, "4765625": 24, "2739": 24, "1302": 24, "484375": 24, "5347": 24, "8238": 24, "1640625": 24, "diagram": 24, "pro": 24, "con": 24, "low": [24, 25], "smoothen": 24, "exceed": 24, "summend": 24, "accordingli": 24, "comparis": [24, 26], "meister": 24, "complementari": 24, "particulat": 24, "Of": [24, 25, 26], "experienc": 24, "inoffici": 24, "dai": 24, "hour": 24, "debug": [24, 30], "inconsist": [24, 29], "eat": 24, "203125": 24, "5625": 24, "84765625": 24, "85546875": 24, "84375": 24, "knowledge_examples_chain": 24, "sold": 24, "39453125": 24, "3515625": 24, "625": 24, "1796875": 24, "453125": 24, "knowledge_examples_chain_incorrect": 24, "leg": 24, "01171875": 24, "859375": 24, "06640625": 24, "7734375": 24, "984375": 24, "llok": 24, "webbook": 24, "spoiler": 24, "creation": 25, "brush": 25, "distinct": 25, "recap": [25, 28], "ten": 25, "tofu": 25, "bullet": 25, "scientif": 25, "tutor": 25, "medic": 25, "awar": [25, 29], "broad": 25, "stori": 25, "cook": 25, "dialogu": [25, 29], "everyth": 25, "optimis": 25, "summaris": 25, "alic": 25, "admir": 25, "fulfil": 25, "tokenizer_instruct": 25, "model_instruct": 25, "load_in_4bit": 25, "bnb_4bit_use_double_qu": 25, "bnb_4bit_quant_typ": 25, "nf4": 25, "bnb_4bit_compute_dtyp": 25, "tokenizer_lm": 25, "model_lm": 25, "instruction_text": 25, "input_ids_instruct": 25, "input_ids_lm": 25, "prediction_instruct": 25, "prediction_lm": 25, "naiv": 25, "un": 25, "freez": [25, 30], "gpt2_model": 25, "named_paramet": 25, "layers_to_unfreez": 25, "unfrozen": 25, "startswith": [25, 27], "rank": [25, 30], "lora": 25, "124": 25, "fewer": 25, "catastroph": 25, "qlora": 25, "broadli": 25, "discov": 25, "underpin": 25, "mdp": 25, "outcom": [25, 29, 30], "trivial": 25, "innov": 25, "led": 25, "toward": 25, "commerici": 25, "lend": 25, "recevi": 25, "honest": [25, 29], "sufficintli": 25, "1b": 25, "capac": 25, "wide": [25, 28], "tend": 25, "imposs": 25, "fold": 25, "nudg": 25, "giagant": 25, "stumbl": 25, "clone": 25, "apect": 25, "sort": 25, "sfttrainer": 25, "kept": 25, "harm": [25, 29], "alien": 25, "eniron": 25, "carperai": 25, "openai_summarize_tldr": 25, "facebook": 25, "350m": 25, "extrem": 25, "deploy": [25, 28], "formatting_prompts_func": 25, "output_text": 25, "formatting_func": 25, "max_seq_length": 25, "dataset_batch_s": 25, "blob": [25, 30], "script": 25, "thousand": [25, 28], "cumbersom": 25, "reject": 25, "theta": 25, "mathbb": 25, "sim": 25, "sigma": 25, "r_": 25, "proven": 25, "anthrop": 25, "rlaif": 25, "2212": 25, "08073": 25, "ldquo": 25, "d83d2b": 25, "rdquo": 25, "ordin": 25, "automodelforsequenceclassif": 25, "reward_token": 25, "lvwerra": 25, "distilbert": 25, "reward_model": 25, "positive_sent": 25, "negative_sent": 25, "input_po": 25, "input_neg": 25, "reward_po": 25, "reward_neg": 25, "depedn": 25, "theorem": 25, "warm": 25, "rafailov": 25, "secretli": 25, "overoptim": 25, "patient": 26, "demo": [26, 30], "view": [26, 27], "passs": 26, "somehow": 26, "terminolog": [26, 28], "oftentim": 26, "templat": 26, "invok": 26, "neat": 26, "sponsor": 26, "haystack": 26, "dinner": 26, "menu": 26, "turbo": [26, 28], "langchainhub": 26, "langchain_openai": 26, "chatopenai": 26, "langchain_cor": 26, "output_pars": 26, "stroutputpars": 26, "prompttempl": 26, "kwarg": [26, 30], "max_token": 26, "cauliflow": 26, "tomato": 26, "instructions_text_appet": 26, "fridg": 26, "nwhich": 26, "appet": 26, "instructions_text_main": 26, "am": 26, "plan": 26, "instructions_menu_summari": 26, "nappet": 26, "nmain": 26, "main_cours": 26, "npleas": 26, "0125": 26, "openai_api_kei": 26, "prompt_template_appet": 26, "input_vari": 26, "prompt_template_main": 26, "prompt_template_summari": 26, "appetizer_chain": 26, "main_chain": 26, "composed_chain": 26, "composed_result": 26, "instructions_text_dessert": 26, "dessert": 26, "ndessert": 26, "load_dotenv": 26, "your_api_kei": 26, "prompt_template_dessert": 26, "dessert_chain": 26, "decompos": [26, 29], "bite": 26, "react": 26, "agentexecutor": 26, "create_react_ag": 26, "pull": 26, "hwchase17": 26, "agent_executor": 26, "vegetarian": 26, "unfortunatelli": 26, "cage": 26, "allrecip": 26, "satisfii": 26, "dinnerplan": 26, "tiramiu": 26, "load_tool": 26, "agent_with_tool": 26, "searhc": 26, "stepwis": 26, "firt": 26, "italien": 26, "recipi": 26, "concentr": 26, "sake": 26, "paywal": 26, "billion": 26, "getpass": 26, "huggingfacehub_api_token": 26, "huggingfaceendpoint": 26, "publicli": 26, "repo_id": 26, "mistralai": 26, "v0": 26, "llm_hf": 26, "agent_hf": 26, "agent_hf_executor": 26, "bottleneck": 26, "properli": 26, "lmql": 26, "control": 26, "stateless": 26, "agnet": 26, "trace": 27, "vecor": 27, "ran": 27, "le": 27, "chien": 27, "brun": 27, "couru": 27, "flan": [27, 28], "automodelforseq2seqlm": 27, "model_view": 27, "head_view": 27, "model_t5": [27, 28], "target_id": 27, "output_attent": [27, 30], "return_dict": 27, "attiont": 27, "encoder_attent": 27, "cross_attent": 27, "decoder_attent": 27, "eas": 27, "input_token": [27, 28], "convert_ids_to_token": 27, "decoder_token": 27, "facet": 27, "encoder_token": 27, "doubl": 27, "tile": 27, "franc": [27, 30], "pari": [27, 30], "hoc": 27, "spuriou": 27, "inseq": 27, "perturb": 27, "obscur": 27, "load_model": 27, "salienc": 27, "hook": [27, 30], "integrated_gradi": 27, "justifi": 27, "light": [27, 28], "out_with_gener": 27, "generated_text": 27, "quickstart": 27, "regular": 27, "berlin": 27, "attribution_model": 27, "out_contrast": 27, "attributed_fn": 27, "contrast_prob_diff": 27, "contrast_target": 27, "attribute_target": 27, "step_scor": 27, "ahv": 27, "deem": 27, "motiv": [27, 28], "ud": 27, "spaci": 27, "ftfy": 27, "berttoken": 27, "bertmodel": 27, "sy": 27, "data_dir": 27, "ud_en_pref": 27, "get_model_and_token": 27, "random_weight": 27, "output_hidden_st": [27, 30], "emb_dim": 27, "valueerror": 27, "unrecogn": 27, "init_weight": 27, "get_sentence_repr": 27, "hug": 27, "face": [27, 28, 29], "floattensor": 27, "sequence_length": 27, "hidden_st": [27, 30], "all_hidden_st": 27, "contextev": 27, "num_lay": [27, 30], "representation_dim": 27, "segmented_token": 27, "assert": 27, "incompat": 27, "cl": 27, "get_pos_data": 27, "probing_dir": 27, "get_data": 27, "data_typ": 27, "data_pref": 27, "train_sent": 27, "readlin": 27, "test_sent": 27, "train_label": 27, "test_label": 27, "fraction": 27, "unique_label": 27, "union": 27, "label2index": 27, "num_label": 27, "input_dim": 27, "output_dim": 27, "build_classifi": 27, "ll": 27, "num_epoch": 27, "train_represent": 27, "num_tot": 27, "num_correct": 27, "batch_repr": 27, "batch_label": 27, "eq": 27, "test_represent": 27, "num_word": 27, "train_sentence_represent": 27, "test_sentence_represent": 27, "represen": 27, "train_representations_al": 27, "train_layer_represent": 27, "test_representations_al": 27, "test_layer_represent": 27, "train_labels_al": 27, "test_labels_al": 27, "train_accuraci": 27, "test_accuraci": 27, "experiment": 28, "fuller": 28, "ppl": 28, "f1": 28, "orient": 28, "grammat": 28, "penn": 28, "treebank": 28, "glue": 28, "paraphras": 28, "unexpectedli": 28, "fluenci": 28, "incorpor": 28, "capabl": [28, 29], "mmlu": [28, 29], "bench": [28, 29], "assisst": 28, "becam": [28, 29], "potenit": 28, "impact": 28, "realtoxicityprompt": [28, 29], "winogend": 28, "assumpt": [28, 30], "count": [28, 29], "coverag": 28, "newer": 28, "worri": 28, "contamin": 28, "inflat": 28, "scalabl": [28, 29], "unsolv": 28, "root": 28, "ppl_": 28, "x_0": 28, "x_n": 28, "sum_": 28, "x_i": 28, "x_": 28, "exerpt": 28, "wkipedia": 28, "nll": 28, "wikitext": 28, "model_": 28, "model_xl": 28, "xl": 28, "output_": 28, "output_xl": 28, "perplexity_": 28, "perplexity_xl": 28, "constraint": 28, "weaker": 28, "regex": 28, "hw2": 28, "chanc": 28, "massaged_dataset_v": 28, "answer_scor": 28, "predicted_label": 28, "is_correct": 28, "harmon": 28, "symmetr": 28, "f_": 28, "beta": [28, 31], "lowest": 28, "boolq": 28, "superglu": 28, "sklearn": 28, "df_boolq": 28, "super_glue_boolq": 28, "is_tru": 28, "predicted_answ": 28, "true_answ": 28, "sentence1": 28, "sentence2": 28, "true_posit": 28, "false_posit": 28, "false_neg": 28, "f1_score": 28, "bleu": 28, "meteor": 28, "hw": 28, "bigram": 28, "trigram": 28, "max_ord": 28, "torchtext": 28, "bleu_scor": 28, "t5token": 28, "t5forconditionalgener": 28, "tokenizer_t5": 28, "text_en": 28, "opinion": [28, 29], "text_d": 28, "anderen": 28, "waren": 28, "ander": 28, "meinung": 28, "encoding_en": 28, "encoding_d": 28, "predicted_d": 28, "predicted_decoded_d": 28, "THE": 28, "salazar": 28, "hu": 28, "levi": 28, "2032": 28, "calibr": 28, "influenti": 28, "kadavath": 28, "2207": 28, "05221": 28, "evalut": 28, "tandem": 28, "emerg": 28, "psucholog": 28, "latg": 28, "extent": 28, "shed": 28, "learnabl": 28, "grammar": 28, "innat": 28, "layout": 28, "comaprison": 28, "ungrammat": 28, "grammaticality_df": 28, "grammaticality_test": 28, "grammaticality_predict": 28, "grammatical_sent": 28, "ungrammatical_sent": 28, "grammatical_log_prob": 28, "sequence_scor": 28, "ungrammatical_log_prob": 28, "is_grammat": 28, "reserach": 28, "intersect": 28, "theori": 28, "mathc": 28, "metaphor": 28, "mari": [28, 30], "town": 28, "respond": 28, "chimnei": 28, "nonliter": 28, "live": 28, "welcom": 28, "liter": 28, "compani": 28, "metaphor_results_gpt": 28, "gpt_metaphor_result": 28, "metaphor_results_human": 28, "human_metaphor": 28, "correcti": 28, "itemnum": 28, "item_id": 28, "intric": 29, "sharpen": 29, "possess": 29, "elementari": 29, "childhood": 29, "biologi": 29, "physic": 29, "interestingli": 29, "composit": 29, "driven": 29, "puzzl": 29, "logic": 29, "intens": 29, "iron": 29, "humanev": 29, "appar": 29, "abil": 29, "hellaswag": 29, "lambada": 29, "triviaqa": 29, "storycloz": 29, "naturalqa": 29, "gsm8k": 29, "intellig": 29, "conclud": 29, "conclus": 29, "quot": 29, "absenc": 29, "heart": 29, "grow": 29, "fonder": 29, "plausibl": 29, "faith": 29, "propens": 29, "detect": 29, "truthfulqa": 29, "skim": 29, "factscor": 29, "atom": 29, "percentag": 29, "provd": 29, "behvaior": 29, "got": [29, 30], "benefici": 29, "rare": 29, "transfer": 29, "distinctli": 29, "arc": 29, "chollet": 29, "bear": 29, "outlin": 29, "hallmark": 29, "parrot": 29, "bender": 29, "perpetu": 29, "stereotyp": 29, "winogrand": 29, "bbq": 29, "polit": 29, "endors": 29, "santurkar": 29, "moral": 29, "opprotun": 29, "risk": 29, "hasn": 29, "assit": 29, "inde": 29, "meet": 29, "unsaf": 29, "expert": 29, "honesti": 29, "inscrut": 30, "behav": 30, "mdoel": 30, "unembed": 30, "accompani": 30, "bloomtokenizerfast": 30, "get_devic": 30, "load_gpt2": 30, "lambdalay": 30, "lambd": 30, "modelwrapp": 30, "activations_": 30, "layer_past": 30, "list_decod": 30, "inpid": 30, "layer_decod": 30, "get_lay": 30, "true_logit": 30, "get_layers_w_attn": 30, "rr_per_lay": 30, "reciproc": 30, "answer_id": 30, "rr": 30, "sorted_prob": 30, "argsort": 30, "descend": 30, "prob_of_answ": 30, "answer_prob": 30, "first_top": 30, "mrr": 30, "is_top_at_end": 30, "print_top": 30, "topk_per_lay": 30, "get_activ": 30, "mega002": 30, "debugg": 30, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 30, "flask_serv": 30, "req_res_oop": 30, "l57": 30, "in_sln": 30, "num_token": 30, "m_coef": 30, "in_": 30, "3072": 30, "layer_residual_": 30, "intermediate_residual_": 30, "final_lay": 30, "mlp_": 30, "reset_activ": 30, "gpt2wrapper": 30, "add_hook": 30, "register_forward_hook": 30, "in_sln_": 30, "attn_": 30, "out_intermediate_residual_": 30, "get_pre_wo_activ": 30, "wo": 30, "use_cach": 30, "past_key_valu": 30, "attn_weight": 30, "pre_wo_attn": 30, "get_past_lay": 30, "add_mid_attn_hook": 30, "mid_attn_": 30, "past_layer_": 30, "rm_hook": 30, "last_past": 30, "medium": 30, "inp_id": 30, "str_tok": 30, "poland_text": 30, "poland": 30, "poland_id": 30, "pol_tok": 30, "skip": 30, "realis": 30, "ffnn": 30, "specicif": 30, "promot": 30, "warsaw": 30, "responsinbl": 30, "saw": 30, "adapt": 30, "ffn": [30, 31], "stai": 30, "o_citi": 30, "mlp_19": 30, "layer_logit": 30, "intervent": 30, "meaning": 30, "corrupt": 30, "downstream": 30, "transformer_len": 30, "john": 30, "went": 30, "gave": 30, "bottl": 30, "milk": 30, "interven": 30, "recov": 30, "plotli": 30, "hookedtransform": 30, "express": 30, "px": 30, "functool": 30, "file_download": 30, "1132": 30, "futurewarn": 30, "resume_download": 30, "deprec": 30, "resum": 30, "force_download": 30, "clean_prompt": 30, "corrupted_prompt": 30, "clean_token": 30, "to_token": 30, "corrupted_token": 30, "logits_to_logit_diff": 30, "incorrect_answ": 30, "to_single_token": 30, "correct_index": 30, "incorrect_index": 30, "cach": 30, "clean_logit": 30, "clean_cach": 30, "run_with_cach": 30, "clean_logit_diff": 30, "corrupted_logit": 30, "corrupted_logit_diff": 30, "738": [30, 31], "imshow": 30, "xaxi": 30, "yaxi": 30, "to_numpi": 30, "color_continuous_midpoint": 30, "color_continuous_scal": 30, "rdbu": 30, "resid_pr": 30, "reader": 30, "residual_stream_patching_hook": 30, "hookpoint": 30, "clean_resid_pr": 30, "slow": 30, "num_posit": 30, "ioi_patching_result": 30, "cfg": 30, "n_layer": 30, "temporari": 30, "temp_hook_fn": 30, "patched_logit": 30, "run_with_hook": 30, "fwd_hook": 30, "get_act_nam": 30, "patched_logit_diff": 30, "ish": 30, "fork": 30, "disabl": 30, "deadlock": 30, "tokenizers_parallel": 30, "97": 30, "token_label": 30, "to_str_token": 30, "titl": 30, "ioi": 30, "np_conv": 31, "mtx": 31, "isdigit": 31, "w_f": 31, "b_f": 31, "m_out": 31, "vec": 31, "q_x": 31, "k_x": 31, "v_x": 31, "44": 31, "31": 31, "68": 31, "612": 31, "2411": 31, "2064": 31, "570": 31, "501": 31, "2263": 31, "1071": 31, "1926": 31, "2482": 31, "2174": 31, "9820": 31, "4622": 31, "8362": 31, "1050": 31, "921": 31, "4123": 31, "1851": 31, "3486": 31, "1773": 31, "8015": 31, "3759": 31, "d_h": 31, "normalis": 31, "decim": 31, "520": 31, "z_0": 31, "0_0": 31, "v_0": 31, "0_1": 31, "v_1": 31, "0_4": 31, "v_4": 31, "residu": 31, "353": 31, "33836474": 31, "329": 31, "08965344": 31, "289": 31, "25248486": 31, "1432": 31, "98336813": 31, "1255": 31, "15948522": 31, "5669": 31, "57964344": 31, "606": 31, "21778265": 31, "73959792": 31, "2380": 31, "41515987": 31, "1068": 31, "67534827": 31, "1174": 31, "33044753": 31, "1023": 31, "64202727": 31, "4627": 31, "46240755": 31, "25966188": 31, "3945": 31, "61173964": 31, "8063146353260925e": 31, "57": 31, "53": 31, "epsilon": 31, "00001": 31, "gamma": 31, "var": 31, "probs_t": 31, "313": 31, "402": 31, "247": 31, "269": 31, "202": 31, "539": 31, "22": 31, "045": 31, "863": 31, "175": 31, "798": 31, "461": 31, "955": 31, "905": 31, "909": 31, "394": 31, "192": 31, "323": 31, "666": 31, "383": 31, "607": 31, "843": 31, "264": 31, "279": 31, "156": 31, "695": 31, "864": 31, "819": 31, "08": 31, "713": 31, "716": 31, "077": 31, "621": 31, "444": 31, "305": 31, "094": 31, "001": 31, "009": 31, "002": 31, "149": 31, "184": 31, "042": 31, "445": 31, "349": 31, "081": 31, "013": 31, "295": 31, "338": 31, "086": 31, "012": 31, "337": 31, "214": 31}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 1, 2, 3, 4, 5], "1": [0, 1, 2, 3, 4, 5, 16, 17, 18, 22, 24, 25, 26, 27, 28, 30], "languag": [0, 1, 3], "model": [0, 1, 3, 19, 20, 21, 23, 25], "50": [0, 1, 2, 3], "point": [0, 1, 2, 3, 4, 5], "logist": [0, 1, 2, 3, 4, 5], "exercis": [0, 1, 2, 3, 4, 5, 23, 24], "understand": [0, 1, 5, 6, 16], "12": [0, 1], "2": [0, 1, 2, 3, 4, 5, 17, 18, 19, 20, 21, 23, 24, 26, 29], "extract": [0, 1], "llm": [0, 1, 3, 4, 5, 6, 12, 26, 27], "fingerprint": [0, 1], "15": [0, 1, 4], "3": [0, 1, 2, 3, 4, 5, 18, 19, 22, 23, 24], "fine": [0, 1, 4, 11, 25], "tune": [0, 1, 4, 11, 25], "gpt": [0, 1], "qa": [0, 1, 2, 3], "23": [0, 1], "answer": [1, 3], "first": [1, 2, 3], "possibl": 1, "second": 1, "evalu": [1, 5, 14, 20, 27, 28, 29], "prompt": [2, 3, 10, 24], "gener": [2, 3, 4, 20], "lm": [2, 3, 8, 10, 21], "advanc": [2, 3, 19, 29], "strategi": [2, 3, 24], "16": [2, 3], "nli": [2, 3], "multipl": [2, 3, 17], "choic": [2, 3], "14": [2, 3], "neural": [2, 3], "20": [2, 3], "experi": 3, "scheme": [3, 24], "natur": 3, "infer": [3, 20], "knowledg": [3, 29], "numersens": 3, "dataset": [3, 16], "few": 3, "shot": 3, "commonsenseqa": 3, "how": [3, 5], "were": 3, "word": 3, "token": [3, 22], "repres": 3, "what": 3, "differ": 3, "similar": 3, "modern": 3, "wa": 3, "context": 3, "curs": 3, "dimension": 3, "give": 3, "concret": 3, "exampl": 3, "which": 3, "train": [3, 16, 18, 19, 20, 23, 25, 27], "data": [3, 16, 17, 18, 19, 20], "us": [3, 19], "compon": 3, "bengio": 3, "et": 3, "al": 3, "2003": 3, "ani": 3, "can": 3, "found": 3, "per": 3, "section": 3, "abstract": 3, "introduct": [3, 21], "A": 3, "parallel": 3, "implement": 3, "experiment": 3, "result": 3, "extens": 3, "futur": 3, "work": [3, 21], "conclus": 3, "agent": [4, 12, 26], "rl": [4, 25], "build": 4, "retriev": 4, "augment": 4, "system": [4, 12], "30": 4, "rlhf": [4, 11], "summar": 4, "aspect": [4, 29], "5": [4, 5, 18, 21, 26], "4": [5, 18, 20, 25], "grammat": 5, "capabl": 5, "10": 5, "societ": 5, "bias": 5, "13": 5, "human": 5, "like": 5, "ar": 5, "llama": 5, "s": [5, 19], "surpris": 5, "22": 5, "cours": 6, "overview": 6, "intend": 6, "audienc": 6, "formalia": 6, "schedul": 6, "further": 6, "materi": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "background": 7, "addit": [7, 8, 9, 10, 11, 12, 13, 14, 15], "pytorch": [8, 17, 19, 22], "ann": 8, "lstm": 9, "transform": [9, 21, 22, 23], "current": [10, 18], "attribut": [13, 17, 27], "method": [13, 27], "behavior": [14, 28], "assess": [14, 17, 28], "mechanist": [15, 30], "interpret": [15, 23, 30], "sheet": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "practic": [16, 25], "set": 16, "up": 16, "instal": 16, "requir": 16, "colab": 16, "local": 16, "verifi": 16, "best": 16, "write": 16, "code": 16, "core": 16, "concept": 16, "main": 16, "process": [16, 29], "step": 16, "document": 16, "essenti": 17, "tensor": 17, "creat": 17, "row": 17, "column": 17, "vector": 17, "type": 17, "oper": 17, "index": 17, "slice": 17, "join": 17, "reshap": 17, "transpos": 17, "arithmet": 17, "broadcast": 17, "matrix": 17, "just": 17, "valu": [17, 18], "ml": [18, 21], "estim": 18, "packag": [18, 19, 20], "true": [18, 19], "distribut": 18, "optim": 18, "paramet": [18, 19, 20], "gradient": 18, "loss": 18, "backprop": 18, "part": 18, "comput": [18, 19], "predict": 18, "backpropag": 18, "error": 18, "signal": 18, "updat": 18, "reset": 18, "inform": 18, "loop": 18, "non": 19, "linear": 19, "regress": 19, "mlp": 19, "w": [19, 20], "modul": 19, "global": [19, 20], "defin": [19, 20], "built": 19, "more": 19, "explicit": 19, "definit": 19, "nn": 19, "concis": 19, "prepar": 19, "outlook": [19, 21, 22, 23, 25, 28], "layer": 19, "util": [19, 23], "option": [19, 22, 23, 25], "autograd": 19, "graph": 19, "charact": 20, "level": 20, "sequenc": 20, "rnn": 20, "load": 20, "inspect": 20, "test": [20, 28], "split": 20, "helper": 20, "function": 20, "network": 20, "invert": 20, "huggingfac": 21, "via": 21, "bpe": 22, "special": 22, "eo": 22, "pretrain": 22, "attent": [22, 27], "mask": [22, 23], "configur": 23, "head": 23, "dynam": 23, "mlm": 23, "decod": [24, 30], "supervis": 25, "flavour": 25, "peft": 25, "polici": 25, "reward": 25, "ppo": 25, "langchain": 26, "excercis": 26, "tool": 26, "output": 26, "pars": 26, "memori": 26, "handl": 26, "6": 27, "probe": 27, "visual": 27, "7": [28, 29], "benchmark": [28, 29], "metric": 28, "machin": 28, "psycholog": 28, "problem": 29, "solv": 29, "hallucin": 29, "consist": 29, "reason": 29, "social": 29, "assist": 29, "8": 30, "earli": 30, "residu": 30, "stream": 30, "activ": 30, "patch": 30}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})