Search.setIndex({"alltitles": {"Activation patching": [[30, "activation-patching"]], "Additional materials": [[6, "additional-materials"], [7, "additional-materials"], [8, "additional-materials"], [9, "additional-materials"], [10, "additional-materials"], [11, "additional-materials"], [12, "additional-materials"], [13, "additional-materials"], [14, "additional-materials"], [15, "additional-materials"]], "Advanced outlook: PyTorch Autograd and computational graph [optional]": [[19, "advanced-outlook-pytorch-autograd-and-computational-graph-optional"]], "Agents": [[26, "agents"]], "Assessing just the values of a tensor": [[17, "assessing-just-the-values-of-a-tensor"]], "Assistant evaluation": [[29, "assistant-evaluation"]], "Attention masks": [[22, "attention-masks"]], "Attention visualization": [[27, "attention-visualization"]], "Attributes of a tensor": [[17, "attributes-of-a-tensor"]], "Attribution methods": [[12, null], [27, "attribution-methods"]], "BPE tokenization": [[22, "bpe-tokenization"]], "Background": [[6, null]], "Benchmark testing": [[28, "benchmark-testing"]], "Best practices for writing code": [[16, "best-practices-for-writing-code"]], "Broadcasting": [[17, "broadcasting"]], "Colab": [[16, "colab"]], "Core concepts": [[16, "core-concepts"]], "Course formalia": [[5, "course-formalia"]], "Course overview: Understanding LMs": [[5, null]], "Creating a tensor": [[17, "creating-a-tensor"]], "Dataset documentation": [[16, "dataset-documentation"]], "Decoding schemes": [[24, "decoding-schemes"]], "Defining the MLP using PyTorch\u2019s built-in modules": [[19, "defining-the-mlp-using-pytorchs-built-in-modules"]], "Defining the model": [[20, "defining-the-model"]], "Early decoding": [[30, "early-decoding"]], "Evaluation": [[27, "evaluation"]], "Evaluation & behavioral assessment": [[13, null]], "Evaluation & inference": [[20, "evaluation-inference"]], "Excercise 5.1.1.2": [[26, "excercise-5-1-1-2"]], "Exercise 1: Advanced prompting strategies (16 points)": [[2, "exercise-1-advanced-prompting-strategies-16-points"]], "Exercise 1: Building a retrieval-augmented generation system (30 points)": [[3, "exercise-1-building-a-retrieval-augmented-generation-system-30-points"]], "Exercise 1: Understanding grammatical capabilities of LLMs (10 points)": [[4, "exercise-1-understanding-grammatical-capabilities-of-llms-10-points"]], "Exercise 1: Understanding language modeling (12 points)": [[0, "exercise-1-understanding-language-modeling-12-points"], [1, "exercise-1-understanding-language-modeling-12-points"]], "Exercise 2: Evaluating societal biases (13 points)": [[4, "exercise-2-evaluating-societal-biases-13-points"]], "Exercise 2: Extracting LLM fingerprints (15 points)": [[1, "exercise-2-extracting-llm-fingerprints-15-points"]], "Exercise 2: Prompting for NLI & Multiple-choice QA (14 points)": [[2, "exercise-2-prompting-for-nli-multiple-choice-qa-14-points"]], "Exercise 2: RLHF for summarization (15 points)": [[3, "exercise-2-rlhf-for-summarization-15-points"]], "Exercise 2: Understanding LLM configuration (8 points)": [[0, "exercise-2-understanding-llm-configuration-8-points"]], "Exercise 3 (15 points):": [[0, "exercise-3-15-points"]], "Exercise 3.3.3.1.": [[24, "exercise-3-3-3-1"]], "Exercise 3.3.3.2.": [[24, "exercise-3-3-3-2"]], "Exercise 3.3.3.3": [[24, "exercise-3-3-3-3"]], "Exercise 3: Aspects of fine-tuning (5 points)": [[3, "exercise-3-aspects-of-fine-tuning-5-points"]], "Exercise 3: Fine-tuning GPT-2 for QA (23 points)": [[1, "exercise-3-fine-tuning-gpt-2-for-qa-23-points"]], "Exercise 3: First neural LM (20 points)": [[2, "exercise-3-first-neural-lm-20-points"]], "Exercise 3: LLM evaluations with LLMs (5 points)": [[4, "exercise-3-llm-evaluations-with-llms-5-points"]], "Exercise 4: Fine-tuning Pythia for Question Answering (23 points)": [[0, "exercise-4-fine-tuning-pythia-for-question-answering-23-points"]], "Exercise 4: How human-like are Llama\u2019s surprisals? (22 points)": [[4, "exercise-4-how-human-like-are-llama-s-surprisals-22-points"]], "Fine-tuning and RLHF": [[10, null]], "Flavours of fine-tuning": [[25, "flavours-of-fine-tuning"]], "Further materials": [[5, "further-materials"]], "Hallucinations": [[29, "hallucinations"]], "Helper functions for training": [[20, "helper-functions-for-training"]], "Homework 1: Language models (50 points)": [[1, null]], "Homework 1: Language models (58 points)": [[0, null]], "Homework 2: Prompting & Generation with LMs (50 points)": [[2, null]], "Homework 3: LLM agents & RL fine-tuning": [[3, null]], "Homework 4: LLM evaluation": [[4, null]], "HuggingFace \ud83e\udd17": [[21, "huggingface"]], "Implications, Understanding & Philosophy": [[14, null]], "Indexing and slicing": [[17, "indexing-and-slicing"]], "Inference": [[20, "inference"]], "Installing requirements": [[16, "installing-requirements"]], "Intended audience": [[5, "intended-audience"]], "Interpreting training dynamics": [[23, "interpreting-training-dynamics"]], "Introduction: ML models": [[21, "introduction-ml-models"]], "Inverting the generation model": [[20, "inverting-the-generation-model"]], "Joining tensors": [[17, "joining-tensors"]], "Knowledge & Problem solving benchmarks": [[29, "knowledge-problem-solving-benchmarks"]], "LLM systems & agents": [[11, null]], "LSTMs & Transformers": [[8, null]], "LangChain": [[26, "langchain"]], "LangChain agent with tools": [[26, "langchain-agent-with-tools"]], "Loading & inspecting the data": [[20, "loading-inspecting-the-data"]], "Local installation": [[16, "local-installation"]], "Logistics": [[0, "logistics"], [1, "logistics"], [2, "logistics"], [3, "logistics"], [4, "logistics"]], "MLM masking": [[23, "mlm-masking"]], "Machine psychology": [[28, "machine-psychology"]], "Main training data processing steps": [[16, "main-training-data-processing-steps"]], "Matrix Multiplication": [[17, "matrix-multiplication"]], "Mechanistic Interpretability": [[15, null]], "Memory handling": [[26, "memory-handling"]], "Metrics": [[28, "metrics"]], "Model heads": [[23, "model-heads"]], "More concise definition of NN module": [[19, "more-concise-definition-of-nn-module"]], "More explicit definition NN module": [[19, "more-explicit-definition-nn-module"]], "NVIDIA API": [[16, "nvidia-api"]], "Operations on tensors": [[17, "operations-on-tensors"]], "Optimizing a parameter: gradients, optimizers, loss & backprop": [[18, "optimizing-a-parameter-gradients-optimizers-loss-backprop"]], "Optional outlook": [[25, "optional-outlook"]], "Outlook": [[21, "outlook"], [28, "outlook"]], "Outlook (optional)": [[22, "outlook-optional"]], "Outlook (optional): EOS tokens": [[22, "outlook-optional-eos-tokens"]], "Outlook and optional exercises": [[23, "outlook-and-optional-exercises"]], "Outlook: PEFT in practice": [[25, "outlook-peft-in-practice"]], "Outlook: PyTorch layers and utils [optional]": [[19, "outlook-pytorch-layers-and-utils-optional"]], "Output parsing": [[26, "output-parsing"]], "PPO training": [[25, "ppo-training"]], "Packages": [[18, "packages"]], "Packages & global parameters": [[19, "packages-global-parameters"], [20, "packages-global-parameters"]], "Part 1: Compute the predictions for current parameter value": [[18, "part-1-compute-the-predictions-for-current-parameter-value"]], "Part 2: Computing the loss for the current prediction": [[18, "part-2-computing-the-loss-for-the-current-prediction"]], "Part 3: Backpropagate the error signal": [[18, "part-3-backpropagate-the-error-signal"]], "Part 4: Update the parameter values": [[18, "part-4-update-the-parameter-values"]], "Part 5: Reset the gradient information": [[18, "part-5-reset-the-gradient-information"]], "Policy": [[25, "policy"]], "Preparing the training data": [[19, "preparing-the-training-data"]], "Pretrained tokenizers": [[22, "pretrained-tokenizers"]], "Pretrained transformers": [[22, "pretrained-transformers"]], "Previous iterations of the course": [[5, "previous-iterations-of-the-course"]], "Probing": [[27, "probing"]], "Process consistency": [[29, "process-consistency"]], "Prompting & Current LMs": [[9, null]], "Prompting strategies": [[24, "prompting-strategies"]], "PyTorch": [[22, "pytorch"]], "PyTorch, ANNs & LMs": [[7, null]], "RL fine-tuning": [[25, "rl-fine-tuning"]], "Reasoning benchmarks": [[29, "reasoning-benchmarks"]], "Reshaping": [[17, "reshaping"]], "Residual stream": [[30, "residual-stream"]], "Reward modeling": [[25, "reward-modeling"]], "Row & column vectors": [[17, "row-column-vectors"]], "Schedule": [[5, "schedule"]], "Sheet 1.1: Practical set-up & Training data": [[16, null]], "Sheet 2.1: PyTorch essentials": [[17, null]], "Sheet 2.2: ML-estimation": [[18, null]], "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)": [[19, null]], "Sheet 2.4: Character-level sequence modeling w/ RNNs": [[20, null]], "Sheet 2.5: Introduction to HuggingFace & LMs": [[21, null]], "Sheet 3.1: Tokenization & Transformers": [[22, null]], "Sheet 3.2: Transformer configurations & Training utilities": [[23, null]], "Sheet 3.3: Prompting & Decoding": [[24, null]], "Sheet 4.1 Supervised fine-tuning and RL fine-tuning": [[25, null]], "Sheet 5.1 LLM agents": [[26, null]], "Sheet 6.1 LLM probing & attribution": [[27, null]], "Sheet 7.1: Behavioral assessment & Evaluation": [[28, null]], "Sheet 7.2: Advanced evaluation": [[29, null]], "Sheet 8.1: Mechanistic interpretability": [[30, null]], "Social aspects": [[29, "social-aspects"]], "Special tokens": [[22, "special-tokens"]], "Supervised fine-tuning": [[25, "supervised-fine-tuning"]], "Tensor arithmetic": [[17, "tensor-arithmetic"]], "Tensor data types": [[17, "tensor-data-types"]], "Tensors": [[17, "tensors"]], "Tokenization": [[22, "tokenization"]], "Train-test split": [[20, "train-test-split"]], "Training": [[27, "training"]], "Training loop": [[18, "training-loop"]], "Training the model": [[19, "training-the-model"]], "Training the network": [[20, "training-the-network"]], "Training utilities": [[23, "training-utilities"]], "Transformers": [[22, "transformers"]], "Transposing": [[17, "transposing"]], "True distribution & training data": [[18, "true-distribution-training-data"]], "True model & training data": [[19, "true-model-training-data"]], "Understanding training data": [[16, "understanding-training-data"]], "Verifying requirement installation": [[16, "verifying-requirement-installation"]], "Working with LMs via \ud83e\udd17 Transformers": [[21, "working-with-lms-via-transformers"]], "bwJupyter": [[16, "bwjupyter"]]}, "docnames": ["homework/01-language-modeling", "homework/archive_2024/01-language-modeling", "homework/archive_2024/02-prompting", "homework/archive_2024/03-agents-RL", "homework/archive_2024/04-evaluation", "intro", "lectures/01-introduction", "lectures/02-torch-ANNs-RNNs", "lectures/03-LSTMs-Transformers", "lectures/04-LLMs-Prompting", "lectures/05-finetuning-RLHF", "lectures/06-agents", "lectures/07-attribution", "lectures/08-evaluation", "lectures/09-philosophy", "lectures/10-mechanistic-interpretability", "tutorials/01-introduction", "tutorials/02a-pytorch-intro", "tutorials/02b-MLE", "tutorials/02c-MLP-pytorch", "tutorials/02d-char-level-RNN", "tutorials/02e-intro-to-hf", "tutorials/03a-tokenization-transformers", "tutorials/03b-transformers-heads-training", "tutorials/03c-decoding-prompting", "tutorials/04a-finetuning-RL", "tutorials/05a-agents", "tutorials/06a-attribution", "tutorials/07a-behavioral-assessment", "tutorials/07b-biases-assessment", "tutorials/08a-mechanistic-interpretability", "tutorials/scripts/transformer_example"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["homework/01-language-modeling.ipynb", "homework/archive_2024/01-language-modeling.ipynb", "homework/archive_2024/02-prompting.ipynb", "homework/archive_2024/03-agents-RL.ipynb", "homework/archive_2024/04-evaluation.ipynb", "intro.md", "lectures/01-introduction.md", "lectures/02-torch-ANNs-RNNs.md", "lectures/03-LSTMs-Transformers.md", "lectures/04-LLMs-Prompting.md", "lectures/05-finetuning-RLHF.md", "lectures/06-agents.md", "lectures/07-attribution.md", "lectures/08-evaluation.md", "lectures/09-philosophy.md", "lectures/10-mechanistic-interpretability.md", "tutorials/01-introduction.ipynb", "tutorials/02a-pytorch-intro.ipynb", "tutorials/02b-MLE.ipynb", "tutorials/02c-MLP-pytorch.ipynb", "tutorials/02d-char-level-RNN.ipynb", "tutorials/02e-intro-to-hf.ipynb", "tutorials/03a-tokenization-transformers.ipynb", "tutorials/03b-transformers-heads-training.ipynb", "tutorials/03c-decoding-prompting.ipynb", "tutorials/04a-finetuning-RL.ipynb", "tutorials/05a-agents.ipynb", "tutorials/06a-attribution.ipynb", "tutorials/07a-behavioral-assessment.ipynb", "tutorials/07b-biases-assessment.ipynb", "tutorials/08a-mechanistic-interpretability.ipynb", "tutorials/scripts/transformer_example.ipynb"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 1, 3, 5, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "0": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "00": [16, 30], "000": [4, 16], "0000": 17, "00000": 18, "0000001": 18, "00001": 31, "00005": 18, "00007": 18, "00012": 18, "00020": 18, "00033": 18, "0005": 20, "00055": 18, "00059": 18, "00091": 18, "00095": 18, "00097": 18, "001": 31, "00117": 18, "0013": 19, "00130": 18, "00138": 18, "00143": 18, "00146": 18, "00150": 18, "0017": 19, "002": 31, "0024": 19, "00248": 18, "00258": 18, "0028": 22, "0032": 22, "0037": 19, "0039": 22, "004": [19, 31], "00408": 18, "0044": 19, "0046": 22, "00523": 18, "0059": 19, "006": 18, "0066": 19, "00673": 18, "0070": 22, "0076": 19, "009": 31, "0095": 22, "00960": 18, "0104": 22, "0109": 19, "011": 18, "01110": 18, "0113": 22, "01171875": 24, "012": 31, "0125": 26, "0126": 22, "013": 31, "0149": 19, "0155": 19, "0156": 22, "016": 19, "0164": 22, "0166": 19, "01680": 18, "01831": 18, "0195": 19, "0198": 22, "0199": 19, "01ba7413b3c671af08bc1c315e9cc64f9f4abee2": 30, "02": [0, 1, 22, 24], "0204": 22, "0211": 19, "0225": 19, "0227": 19, "023": 19, "0235": 19, "0236": 22, "0239": 22, "0246": 19, "0250": 22, "0257": 19, "0279": 19, "0282": 19, "02869": 18, "0292": 19, "0293": 22, "03": 22, "03019": 18, "0309": 19, "0312": 18, "0318": 22, "0319": 22, "033": 19, "033587316144933": 20, "0338": 19, "034": 19, "0348": 19, "0363": 22, "0365": 19, "0369": 19, "0370": 19, "0374": 19, "0383": 19, "0386": 19, "039": 19, "0419": 19, "042": 31, "0421": 19, "0429": [19, 22], "043": 19, "0434": 19, "0436": 19, "044040465112291": 20, "0446": 19, "0447": 19, "045": 31, "0451": 19, "0453": 19, "0454": 19, "0457": 22, "0458984375": 18, "046": 19, "0475": 22, "0479": 19, "04828": 18, "049187345280759": 20, "0493": 19, "04979": 18, "0499": 22, "05": [3, 20, 22], "0505": 19, "0509": 19, "0513": [19, 22], "0516": 22, "0519": 19, "05221": 28, "0523": 19, "0525": 22, "0528": 19, "0546": 19, "0547": 19, "0552": 19, "0556": 19, "0562": 19, "0569": 22, "0575": 19, "0584": 22, "0588": 19, "059": 18, "0591": 19, "0592": 19, "06": 0, "0601": 22, "0612": 22, "0622": 19, "0644": 19, "0646": 19, "0655": 19, "0663": 19, "06640625": 24, "0666": 19, "0671": 19, "0675": 19, "0679": 19, "0695": 22, "0696": 22, "0706": [19, 22], "071": 19, "0721": 17, "074": 19, "0758": 20, "076368400920858": 20, "0769": 19, "077": 31, "0787130945986387": 20, "0789": 19, "08": 31, "08060": 18, "08073": 25, "081": 31, "08211": 18, "0846": 22, "0849": 19, "0853": 19, "0854": 19, "086": 31, "0874": 22, "089089898243062": 20, "08965344": 31, "0909": 19, "0912": 19, "0915": [19, 22], "0917557944550413": 20, "0919": 22, "0924": 19, "0928": 19, "0934": 19, "0936": 19, "094": 31, "0941": 22, "0947": 19, "095": [19, 31], "0955": 19, "0964": 19, "0968": 19, "0972": 19, "0978": 22, "0994": 19, "0_0": 31, "0_1": 31, "0_4": 31, "0m": 20, "1": [19, 20, 21, 23, 29, 31], "10": [0, 1, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "100": [16, 17, 18, 19, 20, 24, 26, 28, 30], "1000": [0, 1, 18, 19, 24], "10000": [18, 19, 20, 22], "100000": 20, "10015": 18, "1002": 22, "100257": 0, "100277": 0, "1003": 22, "100352": 0, "1005": 22, "1006": 19, "1007": 19, "1009": 19, "101": 17, "1014": 19, "102": 19, "1023": 31, "1024": [0, 3, 22, 25, 27], "1025": [19, 22], "1031": 19, "104": 19, "1041": 19, "1043": 22, "1050": 31, "1051": 19, "1056": 22, "1068": 31, "107": 19, "1071": 31, "108": 17, "1081": 20, "10x1": 19, "10x10": 19, "11": [17, 19, 20, 22, 25, 31], "111": [17, 31], "1116": 19, "1128": 19, "1129": 19, "113": 19, "1132": 30, "1136": 19, "114": 17, "1143": 22, "1146": 19, "1149": [19, 31], "1157": 22, "1161": 19, "1163": 19, "1173": 22, "1174": 31, "1179": 19, "118": 19, "119": 19, "1196": 19, "12": [5, 16, 17, 20, 22, 30, 31], "121": 19, "122": 19, "1222": 19, "1229": 19, "124": 25, "1241": 19, "125": [19, 20], "12500": 19, "1255": 31, "1259": 19, "1264": 19, "1269": 19, "1277": 19, "128": [3, 20, 22, 26], "129": 19, "1293": 19, "13": [0, 1, 19, 20, 24, 31], "1302": 24, "1304": 20, "1305": 19, "131": 19, "1315": 19, "1321": 19, "133": 19, "13390": 18, "1344274634863063": 20, "13540": 18, "1359": 19, "1371": 19, "137311827640074": 20, "1385": 22, "139": 20, "1394": 19, "1396": 19, "13th": [0, 4], "14": [5, 16, 17, 19, 20, 31], "140": 19, "1407": [19, 22], "1408": 19, "1417": 19, "14258": 18, "14259": 18, "1426": 19, "14260": 18, "14263": 18, "1427": 19, "14271": 18, "1428": 19, "14292": 18, "1432": 31, "1433": 19, "14350": 18, "1447": 19, "1449": 19, "14508": 18, "1452": 19, "1462": 19, "1464": 19, "147": 19, "1473": 22, "1481": 19, "149": 31, "1491": 19, "14937": 18, "15": [16, 18, 19, 20, 23, 24, 31], "1500": 18, "15000": [19, 20], "151": 19, "151007538987999": 20, "1517": 22, "1518": 19, "1524": 19, "1527": 19, "1548": 22, "156": 31, "1574": 19, "1587": [19, 22], "15948522": 31, "1596": [19, 22], "15th": 1, "16": [0, 5, 17, 19, 20, 21, 31], "1600": 19, "160m": [0, 4], "16102": 18, "1630": 19, "1632": 19, "1638": 19, "1640625": 24, "1652": [19, 24], "1673": 22, "1674": 22, "1676781420602698": 20, "1682": 19, "17": [20, 26, 31], "1701001434279856": 20, "1727": 19, "1732": 19, "1744": [19, 22], "175": 31, "17500": 19, "176395016805715": 20, "1773": 31, "1774": 19, "1777": 20, "17835062349366": 16, "1784": 19, "179": 19, "1793": 19, "1796": 19, "1796875": 24, "18": [16, 19, 20], "1800": 20, "1811": 17, "183": 20, "1839": 19, "184": 31, "1851": 31, "1861": 19, "1869": 22, "1871": 19, "1897": 19, "19": [20, 30], "1908": 19, "1909": 16, "191": 19, "1913": 22, "192": 31, "1924": 22, "1926": 31, "19274": 18, "1927830372943777": 20, "1945": 19, "195": 19, "1959": 19, "1961": 19, "1962": 19, "1966": 22, "1967": 19, "1969": 19, "1976": 19, "1986": 7, "1991": 22, "1997": 7, "19pt": [0, 1], "1b": 25, "1e": [0, 19, 22], "1f": [0, 1], "1gb": 1, "1h": 5, "1m": 20, "1x1": 19, "1x10": 19, "1x18": 20, "2": [8, 9, 15, 16, 22, 25, 27, 28, 30, 31], "20": [3, 16, 17, 19, 20, 22, 28, 31], "200": [0, 17, 20, 28], "2000": [17, 18, 20], "20000": [19, 20], "2003": 2, "2009": 19, "201": [18, 31], "2011": 19, "2013": 6, "2016": 7, "2017": 8, "2018": [0, 1, 10], "2019": [2, 8, 12, 27, 28, 29], "202": 31, "2020": [3, 6, 15, 16], "2021": [4, 9, 12, 15, 29], "2022": [4, 9, 10, 11, 14, 15, 22, 24, 25, 28, 29], "2023": [6, 9, 10, 11, 14, 15, 25, 29], "2024": [5, 6, 11, 15, 30], "2025": 5, "2027": 19, "2028": 19, "2029": 19, "203": 20, "203125": 24, "2032": 28, "2034": [22, 31], "2037": 19, "2050": 1, "205616125930776": 20, "2063": 19, "2064": 31, "2068": 19, "2073": 19, "2081": 19, "209": [19, 20], "2095": 19, "2097": 19, "2099": 19, "21": [0, 1, 16, 17, 19, 21, 31], "2106": 19, "21096220730527": 20, "212": 19, "2122": 20, "2133": 19, "214": 31, "2143": 19, "2152": 22, "2154": 19, "2165": 19, "2170": [22, 31], "2174": 31, "21778265": 31, "2180": 19, "2182": 19, "2186": 19, "2188": 19, "2198": 19, "22": 31, "2201": 19, "2205": 17, "2207": 28, "2208": 19, "2212": 25, "22179": 18, "2232": 19, "22330": 18, "2239": 19, "22500": 19, "2256": 19, "2263": 31, "2276": 19, "2283": 19, "23": [2, 3, 4, 19, 20, 30, 31], "2304": [22, 25], "2313": 19, "2317": 19, "232": 20, "2323": 19, "2333": 19, "2337": 19, "2353": 19, "237": 19, "2371": 19, "2373": 19, "2380": 31, "2387": 22, "2389": 19, "2393": 19, "24": [17, 18, 19, 20, 30, 31], "2400": 22, "2406": 19, "241": 20, "2411": 31, "2425": 19, "2455": 19, "2462": 19, "2468": 19, "247": 31, "2478": 19, "2482": 31, "249": [20, 31], "25": [16, 19, 20, 24], "250": 3, "2500": [18, 19], "25000": [19, 20], "251": 19, "2518": 19, "25248486": 31, "253": [19, 31], "2532": 19, "2536": 19, "2537": 19, "2543": 19, "255": 19, "2557": 19, "256": [19, 25], "2564": 19, "2576": 19, "2579": 19, "2591": 19, "2592": 22, "2595": 19, "25966188": 31, "2614": 22, "2615": 19, "262053290805339": 20, "2630": 19, "2633": 19, "264": 31, "2647": 19, "26594367422115": 20, "2664": 19, "267": 20, "268": 20, "2682": 19, "2689": 19, "269": 31, "2698": 19, "27": [3, 19, 20, 25, 31], "2706": 19, "2711": 19, "2712": 19, "2719710113848373": 20, "2738": 19, "2739": 24, "2746": 20, "27500": 19, "2758": 19, "276": [19, 30], "27648": 0, "277": 20, "279": 31, "28": 20, "2815": 19, "284": 18, "2842": 19, "2846": 19, "2852": 19, "286": [19, 22], "2862": 19, "2865": 19, "2872": 19, "289": 31, "28th": 3, "29": [0, 1, 22, 25, 31], "2919": 19, "2934": 19, "2941": 19, "2944": 19, "295": 31, "2954": 19, "2955": 19, "2956": 19, "2958": 20, "2965": 19, "297": 20, "2971": 19, "2976": 19, "298": [19, 20, 31], "2984": 19, "2986": 19, "2d": [0, 1], "2gb": 16, "2i": 22, "2m": 20, "2nd": 2, "2pt": [0, 1, 3], "3": [16, 17, 20, 21, 25, 26, 27, 28, 29, 30, 31], "30": [17, 19, 20, 31], "3000": 18, "30000": [19, 20], "3001": 19, "3009": 19, "300px": 17, "3011": 19, "3013": 19, "3025": 19, "3049": 19, "305": 31, "3072": 30, "3073": 17, "309": 19, "3099": 19, "31": [17, 31], "3114": 19, "313": 31, "315": 19, "3162": 19, "32": [1, 16, 17, 19, 20, 22, 27, 31], "323": 31, "32500": 19, "32869": 16, "329": 31, "329154273345582": 20, "33": [17, 20, 31], "3301": 20, "33044753": 31, "337": 31, "33744430690024": 20, "338": 31, "33836474": 31, "34": [17, 31], "3403": 19, "342": 19, "3442": 19, "3451": 19, "3486": 31, "3488": 19, "349": 31, "35": [1, 20, 28], "3500": 18, "35000": [19, 20], "350m": 25, "3515625": 24, "352": 24, "3523": 17, "353": 31, "36": [19, 20, 31], "3607": 20, "36674": 18, "3668": [20, 22], "367": 20, "368": 18, "36825": 18, "37": [19, 22], "3746": 19, "3750": 17, "37500": 19, "3759": 31, "3773": 19, "3793": 19, "3797": 19, "38": [19, 31], "383": 31, "384112744200534": 20, "3842": 19, "3850": 20, "3875": 19, "3889435308678326": 20, "3915": 19, "3927": 19, "3931": 19, "3938": 19, "394": 31, "3945": 31, "39453125": 24, "3946": 19, "3973": 19, "3f": [18, 19, 30], "3m": 20, "3x5": [0, 1], "4": [1, 2, 3, 16, 17, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31], "40": [0, 1, 17, 20], "400": 17, "4000": [17, 18], "40000": [19, 20], "4001": 19, "4005": 19, "4007": 19, "402": 31, "4070479577071051": 20, "4075": 19, "4078": 19, "4096": 0, "41": [19, 20, 22, 31], "4100": 22, "410m": 2, "4118": 19, "4123": 31, "4126": 19, "4141": 19, "415": 19, "41515987": 31, "4155": 19, "416": 19, "4167": 19, "417": 19, "419": 19, "41e": 3, "42": [17, 19, 31], "422": 19, "4230": 19, "424": [19, 31], "425": 19, "42500": 19, "4264": 19, "427": 19, "428": 19, "4293": 22, "43": [17, 19, 20, 31], "430": 19, "4315": 19, "432": 19, "433": 19, "436": 19, "4374993423367664": 20, "44": 31, "441": 19, "444": 31, "444657022227277": 20, "445": 31, "447": 19, "448": [24, 31], "4495": 19, "45": [19, 20, 23], "450": 19, "4500": [18, 19], "45000": [19, 20], "453125": 24, "454367770907213": 20, "4591": 20, "4592": 19, "46": [19, 27], "461": 31, "4612": 19, "4614": 19, "4619": 19, "462": 19, "4622": 31, "46240755": 31, "4627": 31, "467": 20, "47": [19, 31], "4716": 19, "473": 19, "4738": 22, "475": 19, "47500": 19, "4765625": 24, "4786": 19, "479": 19, "4803": 22, "4812": 19, "4826": 20, "484375": 24, "49": 20, "4921": 19, "4921875": 24, "497": 19, "4b": [2, 24], "4f": 20, "4gb": 3, "4k": [3, 25], "4m": 20, "4pt": [0, 1], "5": [0, 1, 16, 17, 19, 20, 22, 24, 25, 28, 29, 31], "50": [17, 20, 28], "500": [3, 18, 20, 21], "5000": [17, 18, 19, 20, 22], "50000": [19, 20], "500000": 0, "501": 31, "50257": 22, "503078942968957": 20, "5045": 19, "51": [19, 21], "512": [3, 17, 25], "5120": 0, "5127": 19, "5181813091977734": 20, "519": 20, "52": [19, 20, 31], "520": 31, "5211": 19, "522": 19, "5242": 24, "5254": 22, "53": 31, "531": 31, "5318": 19, "5321": 19, "533": 18, "5336": 17, "5347": 24, "5388": 19, "539": 31, "5396": 19, "54": 20, "5437": 19, "5453": 19, "5473": 17, "5489": 17, "55": [19, 20], "5500": [18, 19], "55000": 20, "550px": 20, "5510": 19, "557712239995114": 20, "5580": 19, "56": [17, 22, 31], "560m": 4, "5617": 19, "5625": 24, "5653": 19, "5669": 31, "57": 31, "570": 31, "5707610099012776": 20, "5713": 19, "5756": 19, "57964344": 31, "58": [1, 20], "5819": 19, "582685867418279": 20, "5863": 19, "5894": 20, "59": [0, 1, 2, 3, 4], "591": 18, "5931": 19, "595": 19, "5973": 19, "5975": 19, "5995": 17, "5_000": 21, "5d": [18, 19], "5e": [0, 1, 21], "5f": 18, "5m": 20, "6": [0, 5, 17, 19, 20, 21, 22, 24, 25, 29, 30, 31], "60": [17, 20, 22], "600": 17, "6000": 18, "60000": 20, "6013": 19, "6017": 19, "6051": 19, "60579": 18, "606": 31, "607": 31, "60729": 18, "6076": 19, "6087": 19, "6096": 19, "61": 19, "6114": 19, "61173964": 31, "612": 31, "6135": 19, "6166": 19, "6175335252350447": 20, "6177": 19, "6194": 19, "6196": 19, "6199": 19, "62": 22, "621": 31, "6223": 19, "625": 24, "6265": 19, "628": 19, "638": [19, 20], "6393": 20, "64": [0, 1, 18, 21, 22, 23], "6406": 24, "6411": 19, "642": 19, "64202727": 31, "6423": 19, "645": 18, "6464": 19, "65": [19, 20], "650": 18, "6500": 18, "65000": 20, "6514": 19, "652": 20, "6531856900705275": 20, "6555": 19, "66": [19, 20], "6612294775126752": 20, "664": [19, 31], "6654": 19, "6659": 19, "666": 31, "6692703950843093": 20, "67": [0, 1, 4, 19, 20], "67534827": 31, "68": 31, "682": 18, "6834": [19, 31], "6843": 19, "6880": 19, "69": 19, "6925": 19, "695": 31, "6955": 19, "6gb": 16, "6pt": [0, 1], "7": [3, 4, 16, 17, 19, 20, 24, 25, 26, 30, 31], "70": [17, 20], "7000": 18, "70000": 20, "7046": 20, "7086": 19, "709": 20, "70b": 25, "71": 20, "7110": 19, "7121": 19, "713": 31, "716": 31, "716580436309544": 20, "7169": 19, "7172": 19, "7179": 19, "7180": 20, "72": [17, 19, 20, 31], "724": 20, "726918229927053": 20, "7288": 19, "7293": 19, "7298": [19, 24], "73": [20, 31], "7308": 20, "738": [30, 31], "73959792": 31, "74": [20, 31], "740": 19, "743693795963553": 20, "7454": 19, "746094297468178": 20, "7494": 19, "7496": 19, "75": [0, 1, 20, 27, 31], "7500": [18, 19], "75000": 20, "7501": 19, "7502": 19, "7523": 19, "7530": 19, "7552": 19, "76": [3, 19, 28], "7634": 16, "7650": 19, "765625": 24, "7672": 17, "768": [22, 25, 27], "77": 19, "7734": 19, "7734375": 24, "7743": 19, "7748951742793246": 20, "7764": 19, "7767": 19, "78": [3, 31], "7873": 19, "79754031778924": 20, "798": 31, "7b": [2, 22, 26], "8": [16, 17, 20, 24, 25, 31], "80": [16, 17, 20], "8000": 18, "80000": 20, "8005": 19, "8015": 31, "8022": 19, "8029": 20, "8063146353260925e": 31, "8089478089254367": 20, "8123": 19, "816": 19, "8176": 19, "819": 31, "8191": 19, "819255000074138": 20, "82": 19, "8224": 19, "8238": 24, "8264": 19, "83": [0, 1, 19], "8325": 20, "8344": 20, "8362": 31, "83683439539813": 20, "8398610504968342": 20, "8415": 19, "843": 31, "84375": 24, "8441": 19, "8467": 20, "84765625": 24, "85": 20, "8500": 18, "85000": 20, "8540": 19, "8546": 19, "85546875": 24, "857054710388184": 20, "8589": 19, "859375": 24, "863": 31, "864": 31, "8666": 19, "8668": 19, "8697": 19, "87": [17, 19], "879318062464732": 20, "88": [19, 31], "89": [19, 22, 31], "892": 20, "8970": 19, "8981": 19, "8gb": 16, "9": [5, 16, 17, 20, 24, 31], "90": [17, 19, 20], "9000": 18, "90000": 20, "9023": 19, "9025": 19, "90373899401307": 20, "9046": 19, "905": 31, "9068": 17, "9079": 19, "908905029296875": 20, "909": 31, "91": [0, 1, 31], "9101": 19, "9163": 19, "9164": 19, "9166837202752751": 20, "9185": 19, "9190526549711127": 20, "921": 31, "9245": 19, "9253905269010243": 20, "94": [19, 20], "9408": 20, "941": 20, "943814170795518": 20, "9443": 17, "9444": 19, "9450": 19, "945132093597879": 20, "9468": 19, "9476": 19, "95": 20, "9500": 18, "95000": 20, "9520": 19, "9521": 19, "9536": 19, "9538": 19, "9543": 16, "955": 31, "9574": 19, "959": 19, "96": 22, "9640": 19, "9653": 19, "9675": 20, "97": 30, "975": 18, "975641382951965": 20, "976": 18, "977": 18, "979": 18, "9820": 31, "9830674364599212": 20, "98336813": 31, "984375": 24, "986": 18, "987": [19, 31], "988": 18, "989767319373302": 20, "99": 20, "991": 20, "9920": 19, "9964": 19, "9989984954101563": 18, "9994": 19, "9999999999999994": 20, "A": [0, 1, 2, 3, 4, 6, 11, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31], "AND": [0, 1, 4], "And": [17, 26], "As": [11, 19, 21, 22, 24, 25, 26, 27, 28, 29], "At": [22, 26], "Be": 3, "Being": 18, "But": [17, 24, 26], "By": [18, 22, 25], "FOR": 4, "For": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "IT": [0, 1, 26], "If": [0, 1, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 29, 30], "In": [0, 2, 3, 4, 5, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "It": [3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "Its": [17, 25], "NOT": [1, 3, 16, 21, 25, 26, 29], "Not": [11, 20, 26], "Of": [24, 25, 26], "On": [0, 1, 14, 16, 21, 24], "One": [16, 20, 23, 25, 26, 27, 28, 29, 30], "Or": 17, "Such": [16, 28], "THE": 28, "TO": [0, 1], "That": [16, 19, 21, 22, 25, 29], "The": [0, 1, 2, 3, 4, 5, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "Their": [9, 30], "Then": [3, 22, 23], "There": [0, 1, 2, 5, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30], "These": [3, 16, 19, 20, 21, 22, 24, 25, 26, 28, 29, 30], "To": [2, 3, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "With": [0, 1, 17, 21, 24], "_": [3, 25, 30], "__dict__": 22, "__future__": 20, "__getitem__": [1, 19], "__init__": [1, 19, 20, 22, 27, 30], "__len__": [1, 19], "_backward_hook": 22, "_backward_pre_hook": 22, "_buffer": 22, "_forward_hook": 22, "_forward_hooks_always_cal": 22, "_forward_hooks_with_kwarg": 22, "_forward_pre_hook": 22, "_forward_pre_hooks_with_kwarg": 22, "_is_full_backward_hook": 22, "_is_hf_initi": 22, "_load_state_dict_post_hook": 22, "_load_state_dict_pre_hook": 22, "_modul": 22, "_non_persistent_buffers_set": 22, "_paramet": 22, "_qkv_same_embed_dim": 22, "_state_dict_hook": 22, "_state_dict_pre_hook": 22, "a_i": 24, "a_list": 17, "ab": [1, 18, 19, 28], "abbrevi": 21, "abil": 29, "abise": 3, "abl": [0, 1, 16, 17, 20, 21, 22, 23, 25, 29, 30], "about": [0, 2, 3, 4, 5, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29], "abov": [0, 1, 2, 3, 4, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "absenc": 29, "absolut": [21, 22, 25, 27], "abstract": [16, 21, 25, 29], "ac": 19, "acccess": 22, "acceler": [0, 1, 2, 3, 21, 25], "accept": [0, 1, 4, 26], "access": [1, 3, 16, 19, 21, 22, 24, 25, 27, 30], "accid": 2, "accompani": 30, "accomplish": [16, 21, 26], "accord": [0, 1, 16, 22, 29], "accordingli": 24, "account": [16, 21, 26], "accumul": [0, 1, 18], "accur": 3, "accuraci": [0, 1, 2, 4, 23, 27, 28, 29], "achiev": [2, 24, 25], "acquir": [0, 1, 16], "across": [3, 4, 15, 27, 28], "act": [21, 22, 30], "action": [3, 25], "activ": [0, 1, 15, 18, 19, 20, 21, 25], "activations_": 30, "actual": [0, 1, 2, 3, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "acycl": 19, "ad": [16, 18, 21, 22, 23, 24, 26], "adam": [19, 20, 27], "adamw": [0, 1], "adapt": 30, "add": [16, 17, 19, 20, 22, 26, 30], "add_hook": 30, "add_mid_attn_hook": 30, "add_zero_attn": 22, "addit": [3, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28], "additioanli": 21, "additioanlli": [0, 1], "addition": [0, 1, 3, 16, 20, 25, 27, 29], "additional_dim": 21, "address": [24, 27, 28], "adequ": 16, "adher": 16, "adjust": [16, 21, 22, 24, 29], "admir": 25, "advanc": [3, 5, 16, 21, 24], "advantag": [3, 16, 23, 25, 26, 28], "affect": [3, 24, 25, 30], "afford": 11, "after": [0, 1, 16, 18, 19, 21, 22, 23, 24, 25, 30], "again": [16, 18, 19, 22, 23, 24, 25, 26, 30], "against": [3, 20, 23, 28], "agent": [1, 5, 25], "agent_executor": 26, "agent_hf": 26, "agent_hf_executor": 26, "agent_with_tool": 26, "agentexecutor": 26, "aggress": 18, "agnet": 26, "agre": [4, 20], "agreement": 4, "ahead": 16, "ahn": 11, "ahv": 27, "ai": [3, 5, 14, 25], "aim": [28, 29], "aimia": 16, "airplan": 2, "airport": 2, "aka": 15, "al": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 22, 24, 25, 27, 28, 29, 30], "algebra": 17, "algorithm": [3, 4, 22, 23, 24, 25, 29, 30], "alic": 25, "alien": 25, "align": [5, 25], "all": [0, 1, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "all_hidden_st": 27, "all_lett": 20, "all_loss": 20, "alloc": 20, "allow": [0, 1, 2, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 30], "allrecip": 26, "almost": [16, 24, 26], "along": 24, "alpha": 19, "alphabet": [16, 22], "alreadi": [3, 16, 17, 21, 22, 24, 25, 26, 28, 29, 30], "also": [0, 1, 2, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "alter": 20, "altern": [16, 17, 20, 21, 23, 25, 27, 28], "although": [16, 24, 25, 28, 29], "alwai": [0, 1, 16, 20, 24, 26, 28, 30], "am": 26, "american": 4, "amnes": 12, "among": 5, "amount": [16, 20], "an": [0, 1, 2, 3, 4, 5, 6, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "anaconda3": [0, 1, 16, 21, 22, 30], "analog": 4, "analys": 2, "analysi": [4, 15, 23, 30], "anaphor_gender_agr": 4, "ander": 28, "anderen": 28, "andrej": [5, 8], "ani": [0, 1, 2, 4, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30], "animate_subject_pass": 4, "annot": [16, 25, 27, 29, 30], "anoth": [2, 4, 19, 20, 21, 22, 23, 27, 28, 29, 30], "another_tensor": 17, "answer": [1, 2, 3, 4, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "answer_id": 30, "answer_kei": 4, "answer_log_prob": 24, "answer_opt": [0, 1, 4, 28], "answer_options_list": [0, 1, 28], "answer_options_str": [0, 1], "answer_prob": 30, "answer_scor": 28, "answer_scores_bloom": 4, "answer_scores_gpt2": 4, "answerkei": [0, 1, 28], "anthrop": 25, "anticip": 16, "anymor": 20, "anyth": [0, 1, 16, 19, 22, 25], "apart": 18, "apect": 25, "api": [21, 26, 27], "api_wrapp": 16, "appar": 29, "append": [0, 1, 3, 20, 21, 22, 24, 25, 28, 30], "appet": 26, "appetizer_chain": 26, "appli": [16, 17, 19, 20, 21, 22, 23, 27, 28, 30, 31], "applic": [1, 3, 19, 20, 21, 22, 23, 27, 28, 29], "approach": [3, 4, 5, 16, 22, 23, 24, 25, 26, 27, 28, 29], "appropi": [4, 16], "appropri": [4, 23, 28], "approxim": [16, 24, 28], "ar": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "arab": 20, "arang": 22, "arc": 29, "architectur": [1, 2, 5, 16, 19, 20, 21, 22, 23, 25, 26, 27, 30], "architecture_quirk": 1, "architecture_typ": 1, "archiv": 16, "area": [16, 25, 29], "aren": 22, "arg": [3, 16, 21, 22], "argmax": [24, 28], "argsort": 30, "arguabl": [16, 28], "argument": [0, 1, 17, 21, 22, 23, 25, 27, 28, 29], "aris": 23, "arithmet": 15, "around": [0, 1, 2, 16, 18, 19, 20, 21, 22, 24, 25, 26], "arrai": [17, 19, 27, 30, 31], "arriv": [0, 1, 27, 30], "art": [0, 1, 2, 5, 16, 21, 22, 24, 25], "articl": [3, 16], "artifici": 7, "arxiv": [1, 25, 28], "as_query_engin": 3, "ascii": [20, 22], "ascii_lett": 20, "ask": [3, 4, 16, 19, 21, 25, 28, 29, 30], "aspect": [4, 16, 22, 24, 25, 27, 28, 30], "aspet": 4, "assert": 27, "assess": [2, 4, 16, 27, 29, 30], "assign": [1, 4, 5, 16, 18, 20, 22, 23, 24, 25, 28, 29, 30], "assisst": 28, "assist": [3, 10, 22, 25], "assit": 29, "associ": [15, 18, 24], "asssess": 0, "assum": [0, 1, 21, 22, 23, 24], "assumpt": [28, 30], "atom": 29, "attempt": [27, 29], "attend": [2, 21, 22, 23], "attent": [0, 1, 8, 16, 19, 24, 25, 30, 31], "attention_bia": 0, "attention_dropout": 0, "attention_mask": [0, 1, 16, 21, 22, 23, 24], "attic": 2, "attiont": 27, "attn": [22, 30], "attn_": 30, "attn_dropout": 22, "attn_weight": 30, "attribut": [5, 22, 28, 30], "attribute_target": 27, "attributed_fn": 27, "attribution_model": 27, "audio": 21, "author": [4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "auto": [0, 1, 3, 16, 21, 22, 25], "autoag": 11, "autoclass": [21, 23], "autom": [21, 28], "automat": [0, 1, 3, 11, 19, 21, 22, 23, 26, 28], "automodelforcausallm": [0, 1, 21, 23, 24, 25, 28, 30], "automodelforcausallmwithvaluehead": 3, "automodelforseq2seqlm": 27, "automodelforsequenceclassif": 25, "autonom": 11, "autonotebook": [0, 1, 16, 21], "autotoken": [0, 1, 3, 16, 21, 22, 23, 24, 25, 27, 28, 30], "auxiliari": [20, 27], "avail": [0, 1, 2, 3, 4, 16, 17, 21, 24, 25, 26, 27, 28], "averag": [0, 1, 4, 16, 20, 24, 28], "average_tweet_length": 16, "avoid": [0, 3, 22, 23, 24, 25, 26, 30], "aw": 24, "awai": [16, 22], "awak": 2, "awar": [25, 29], "awesom": 24, "axi": [0, 1, 31], "b": [0, 1, 3, 4, 16, 17, 19, 22, 25, 27, 28], "b_f": 31, "baai": 3, "bachelor": 5, "back": [7, 17, 21, 22, 24, 30], "backbon": [3, 23, 25, 26], "backend": [0, 1, 4, 16, 21, 24, 27, 28], "background": [2, 3, 4, 10, 21], "backpropag": [7, 8, 27], "backward": [0, 1, 18, 19, 20, 21, 27], "bad": [16, 18, 25], "baden": 16, "bag": 2, "baggag": 2, "bai": [10, 25], "balanc": 23, "bank": 16, "bar": [4, 29], "barplot": 4, "base": [0, 1, 2, 3, 4, 5, 9, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "baselin": 3, "basic": [6, 16, 17, 18, 19, 20, 21, 26], "batch": [0, 1, 3, 16, 19, 21, 22, 23, 25, 27, 30], "batch_first": 22, "batch_label": 27, "batch_repr": 27, "batch_siz": [0, 1, 3, 19, 21, 27], "bay": 20, "bayesian": [9, 23], "bbq": 29, "bc": 19, "bd": 19, "bd0xbfgjkt": 16, "beam": [2, 24], "bear": 29, "becam": [28, 29], "becaus": [0, 1, 3, 16, 18, 19, 20, 21, 22, 23, 25, 28, 30], "becom": [18, 19, 28], "been": [3, 4, 16, 21, 22, 23, 24, 25, 27, 28, 29, 30], "befor": [0, 1, 2, 3, 4, 16, 19, 20, 21, 25, 26, 28, 30], "begin": [16, 21, 22, 24, 25, 31], "behav": 30, "behavior": [3, 4, 11, 12, 19, 24, 25, 29], "behind": [16, 18, 19, 22, 25, 26, 27, 28, 30], "behvaior": 29, "being": [0, 1, 3, 18, 21, 23, 24, 25, 29, 30], "beings": 24, "believ": 29, "belong": 21, "below": [1, 3, 4, 5, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "bench": [28, 29], "benchmark": [4, 13, 16, 24], "bender": 29, "benefici": 29, "benefit": 23, "bengio": [2, 7], "berlin": 27, "bert": [2, 8, 19, 21, 22, 23, 27], "bert_tok": 23, "bertmodel": 27, "berttoken": 27, "bertviz": [16, 27], "besid": 2, "best": [2, 3, 18, 23, 24, 25, 28], "beta": [28, 31], "better": [2, 5, 16, 18, 20, 22, 26, 28], "between": [2, 3, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 30], "beyond": [9, 16, 22, 28, 29], "bfloat16": 17, "bge": 3, "bia": [4, 15, 19, 22, 25, 28, 29, 31], "bias": [16, 19, 21, 25, 28, 29], "bias_k": 22, "bias_v": 22, "bidirect": [2, 8, 23], "big": [2, 28, 29], "bigger": 19, "bigram": 28, "bigscienc": 4, "billion": 26, "bin": 16, "binari": [23, 25, 28], "biologi": 29, "bird": [0, 24], "bit": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20], "bite": 26, "bitsandbyt": 3, "black": 16, "blackbox": [21, 28, 30], "blank": 20, "bleu": 28, "bleu_scor": 28, "blimp": 4, "blob": [25, 30], "block": [3, 16, 19, 21, 22, 25, 26, 27, 30], "blog": [3, 24, 25], "blogpost": [10, 11, 15, 19, 25, 28, 29], "bloom": 4, "bloom_predict": 4, "bloom_scor": 4, "bloomtokenizerfast": 30, "blueprint": 21, "bmatrix": [22, 31], "bnb_4bit_compute_dtyp": 25, "bnb_4bit_quant_typ": 25, "bnb_4bit_use_double_qu": 25, "bnc": 16, "bo": [22, 24, 31], "boe": 16, "boi": 2, "bommasani": 14, "bonu": 3, "book": [1, 5, 16], "bool": 17, "boolean": 17, "boolq": 28, "boredom": 2, "born": 4, "borrow": 20, "bos_token_id": 0, "bot": 16, "both": [3, 4, 5, 16, 17, 18, 20, 21, 22, 23, 25, 28, 29], "bottl": 30, "bottleneck": 26, "bpe": 1, "braun": 22, "break": 26, "brian": 5, "bridg": 2, "brief": [0, 1, 2, 4, 6, 24], "briefli": [2, 3, 4, 22, 23, 25], "bright": 2, "bring": 4, "british": 16, "broad": 25, "broadli": 25, "broken": 2, "brown": [16, 22, 23, 27], "brows": 21, "bruckner": 20, "brun": 27, "brush": 25, "btig": 16, "bug": 3, "bui": 16, "build": [2, 4, 8, 16, 17, 19, 21, 22, 24, 25, 26, 27, 28], "build_classifi": 27, "build_dataset": 3, "bullet": 25, "bullish": 16, "bye": 4, "bynd": 16, "byte": 22, "bytest": 23, "c": [0, 1, 3, 4, 17, 19, 20, 22, 25, 28], "c_attn": 22, "c_fc": 22, "c_proj": 22, "cach": 30, "cage": 26, "calcul": [0, 1, 3, 4, 19, 20, 22, 25, 28, 30, 31], "calculu": 19, "calibr": 28, "call": [3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "came": 4, "camera": 2, "can": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "candid": 18, "cannot": [2, 16, 21, 22, 27, 28], "cap": [16, 19], "capabl": [28, 29], "capac": 25, "capit": [24, 27, 30], "caption": 22, "captur": [4, 20, 21, 23, 25], "carcass": 21, "care": [2, 3, 16, 17, 21, 26, 28, 30], "carefulli": [0, 1, 2, 22, 27], "caribbean": 16, "carniv": 16, "carperai": 25, "carri": [16, 22], "case": [0, 1, 3, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 30], "cashier": 4, "cast": 17, "cat": [0, 1, 17, 20, 21], "catastroph": 25, "categori": [1, 4, 20, 23, 25, 28], "category_tensor": 20, "category_tensor_": 20, "cauliflow": 26, "caus": 4, "causal": [0, 1, 15, 21, 22, 23, 24, 27, 28, 30], "causallm": 23, "cc": 16, "ccl": 16, "cdot": 28, "ce": 19, "cell": [0, 3, 4, 16, 21, 23, 30], "celoss": 21, "cemex": 16, "center": 24, "central": 16, "ceo": 16, "certain": [4, 16, 18, 19, 21, 22, 23, 24, 27, 28, 30], "cfg": 30, "cg": 19, "chain": [0, 1, 9, 19, 24, 26, 29], "challeng": 29, "chanc": 28, "chang": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 21, 23, 24, 25, 27, 28, 29], "char": [16, 17, 31], "charact": [16, 17, 22, 23], "character": 15, "charactersitc": 1, "chat": [3, 9, 22, 25, 26], "chatgpt": 10, "chatopenai": 26, "cheat": 6, "check": [2, 3, 4, 16, 17, 19, 22, 23, 24, 25, 27, 28, 29, 30], "checkpoint": [21, 28], "chek": 22, "chen": 11, "chicago": 24, "chien": 27, "childhood": 29, "children": [2, 29], "chimnei": 28, "chines": 20, "chip": 16, "choic": [0, 1, 3, 4, 16, 21, 23, 24, 25, 26, 28, 29], "chollet": 29, "choos": [16, 18, 20, 23, 24, 25, 28, 30], "chop": 3, "chosen": [3, 24, 25, 28], "christian": 5, "chunk": [16, 28], "ci": 4, "circuit": 15, "cite": 3, "citi": [2, 23, 24], "cl": 27, "claim": 1, "class": [0, 1, 2, 3, 6, 9, 10, 11, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30], "classif": [2, 10, 16, 19, 21, 23, 25, 28], "classifi": [2, 20, 21, 27], "claus": 4, "clean": [0, 1, 2, 16, 19, 30], "clean_cach": 30, "clean_logit": 30, "clean_logit_diff": 30, "clean_prompt": 30, "clean_resid_pr": 30, "clean_token": 30, "clean_tweet": 16, "cleaned_dataset": 16, "cleaned_dataset_split": 16, "cleaned_tweet": 16, "cleanest": 28, "clear": 19, "clear_output": 3, "click": [16, 17, 18, 19, 20, 21, 23, 25, 27], "clip": [19, 23], "clip_grad_value_": 19, "clone": 25, "close": [21, 23, 24, 25, 28], "closer": [19, 22, 24, 26, 29], "cloth": 2, "cnn": 3, "cnn_dailymail": 3, "co": [3, 16, 22], "code": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "coeffici": [3, 4], "coffe": 2, "cognit": [5, 28], "cogsci": 5, "col": 17, "col_vector": 17, "colab": [0, 1, 2, 3, 4, 21, 24, 25, 27], "cold": 2, "collabor": 16, "collat": [0, 3, 21], "collate_fn": 0, "collect": [1, 16, 20, 21, 25], "color": [2, 19, 25, 27], "color_continuous_midpoint": 30, "color_continuous_scal": 30, "column": [0, 1, 16, 20, 21, 28], "column_nam": [16, 21, 23], "com": [20, 25, 30], "comaprison": 28, "combin": [0, 1, 16, 20, 22, 23, 24, 28], "come": [2, 4, 16, 20, 21, 22, 24, 25, 26, 28, 29], "comfort": 16, "commend": 0, "comment": [0, 1, 3, 4, 16, 21, 22], "commerici": 25, "commit": 16, "common": [0, 1, 3, 16, 19, 21, 22, 23, 24, 25, 28, 29], "commonli": [3, 16, 19, 21, 22, 23, 25, 28, 29], "commonsens": [0, 1, 9], "commonsense_qa": [0, 1, 28], "commonsenseqa": [0, 1, 24, 28, 29], "commonsenseqadataset": 1, "commun": [16, 21, 25, 26, 29], "comp": [0, 1], "compact": 3, "compani": 28, "compar": [0, 1, 2, 3, 4, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 30], "comparis": [24, 26], "comparison": [1, 2, 25, 28, 29, 30], "compelt": 4, "competit": 2, "complementari": 24, "complet": [0, 1, 3, 4, 16, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30], "completion_to_prompt": 3, "complex": [17, 24, 26], "complex_np_island": 4, "complic": [19, 22], "compon": [0, 2, 3, 15, 19, 22, 25, 26], "composed_chain": 26, "composed_result": 26, "composit": 29, "comprehens": 1, "compulsori": 5, "comput": [0, 1, 3, 5, 9, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31], "compute_loss": 21, "con": 24, "concaten": [17, 24, 27], "concentr": 26, "concept": [3, 5, 7, 17, 19, 21, 22, 23, 24, 25, 29, 30], "conceptu": [0, 1, 2, 3, 4, 5, 21, 22, 23, 25, 28, 29, 30], "concern": 4, "concis": 3, "conclud": 29, "conclus": 29, "concpetu": 0, "concret": [2, 18, 21, 22, 25, 26], "cond_prob_nam": 20, "conda": [16, 19], "condens": 19, "condit": [4, 16, 18, 20, 28], "conditional_scor": [4, 28], "conduct": 5, "confid": [4, 24, 28], "config": [0, 3, 21, 23], "configr": 0, "configur": [1, 2, 3, 21, 22, 24, 25], "configut": [0, 1], "connect": [16, 19, 29, 30, 31], "consecut": 20, "consent": 1, "consequ": 24, "consid": [0, 1, 2, 4, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29], "consist": [3, 4, 5, 9, 16, 18, 19, 20, 21, 22, 25, 28, 30], "constitu": 16, "constitut": [19, 21, 25], "constraint": 28, "construct": [0, 1, 3, 4, 17, 19, 20, 21, 24, 25, 26, 28, 29], "construct_test_sampl": [0, 1], "contain": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29], "contamin": 28, "content": [2, 16, 21, 22, 25, 29], "context": [0, 2, 3, 4, 5, 9, 10, 12, 16, 17, 19, 21, 22, 23, 24, 25, 28, 29, 30], "context_input_id": 24, "context_prompt": 24, "context_window": 3, "contextev": 27, "contextu": [0, 12, 22], "continu": [4, 20, 21, 23, 27, 28], "contradict": 2, "contrast": [4, 21, 22, 27, 28, 29], "contrast_prob_diff": 27, "contrast_target": 27, "contribut": [1, 16, 22, 27, 30], "control": 26, "conv1d": 22, "conveni": [19, 21], "convent": 16, "converg": [23, 25], "convers": [22, 25], "converst": [0, 1], "convert": [0, 1, 3, 16, 17, 21, 22, 27, 28], "convert_ids_to_token": 27, "cook": 25, "core": [0, 3, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30], "corner": 2, "coronaviru": 16, "corpor": 2, "corpora": [16, 28, 29], "corpu": [0, 1, 16, 21, 22, 29], "correct": [0, 1, 2, 22, 23, 24, 25, 26, 28, 29, 30], "correct_answ": 30, "correct_index": 30, "correcti": 28, "correctli": [3, 19, 20, 21, 22, 23, 25, 28], "correl": [4, 27, 28], "correspond": [0, 1, 4, 19, 21, 22, 23, 25, 27, 28], "corrupt": 30, "corrupted_logit": 30, "corrupted_logit_diff": 30, "corrupted_prompt": 30, "corrupted_token": 30, "cosin": [19, 21, 22, 23, 25], "cosinesimilar": 19, "cost": 23, "costli": [21, 25], "cot": 2, "cotterel": 5, "could": [3, 4, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30], "count": [28, 29], "counterfactu": 12, "countri": [2, 20], "country2idx": 20, "cours": [1, 6, 16, 21, 24, 25, 26, 30], "court": 24, "couru": 27, "courvil": 7, "cover": [0, 5, 9, 10, 11, 16, 21, 23, 24, 28], "coverag": 28, "cpu": [0, 1, 3, 4, 16, 17, 21, 24, 25, 27, 28, 30], "craft": 20, "crawl": [16, 28], "creat": [0, 1, 3, 4, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30], "create_react_ag": 26, "creation": 25, "creativ": [2, 24], "credit": 16, "crisp": 16, "criteria": [16, 29], "criterion": [20, 27], "critic": [2, 3, 5, 16, 19, 21, 27, 28, 29, 30], "cross": [23, 27], "cross_attent": 27, "crossentropi": 23, "crossentropyloss": [19, 21, 27], "crowd": 2, "crucial": [16, 27, 28], "csv": [1, 4, 24, 28], "cuda": [0, 1, 3, 4, 16, 21, 24, 25, 27, 28, 30], "cultur": 4, "cumbersom": 25, "cumul": 20, "curat": [21, 28], "curiou": [22, 24, 30], "current": [1, 19, 20, 22, 25, 27, 30], "current_loss": 19, "curs": 2, "curv": [0, 1], "custom": [0, 1, 3, 19, 21, 25, 27], "customiz": 16, "cut": 16, "cv": 21, "cx": 16, "cycl": 18, "czech": 20, "d": [0, 1, 3, 17, 19, 20, 21, 23, 25, 28], "d83d2b": 25, "d_h": 31, "d_model": 22, "d_wide": 19, "dai": 24, "daili": 16, "danger": 2, "data": [0, 1, 2, 3, 4, 21, 22, 23, 25, 27, 28, 29], "data_col": [3, 21, 23], "data_dir": 27, "data_pref": 27, "data_typ": 27, "databas": [3, 25], "datacollatorforlanguagemodel": [0, 21, 23], "datafil": 20, "datafram": [3, 19, 20, 21], "dataload": [0, 1, 3, 16, 19, 21], "datapoint": [20, 23], "datas": 17, "dataset": [0, 1, 3, 4, 19, 20, 21, 23, 25, 28, 29], "dataset_batch_s": 25, "dataset_df": 3, "dataset_nam": 3, "dataset_s": 16, "dataset_split": 1, "datatyp": 17, "datset": 3, "daughter": 2, "db": 3, "de": [16, 19], "deactiv": 20, "deadli": 2, "deadlin": [0, 1, 2, 3, 4], "deadlock": 30, "deal": [5, 19, 22, 28], "debat": [14, 16, 28], "debug": [24, 30], "debugg": 30, "decad": 23, "decai": 21, "decid": 25, "decim": 31, "declar": 17, "decod": [0, 1, 2, 3, 20, 21, 22, 25, 27, 28], "decoder_attent": 27, "decoder_token": 27, "decompos": [26, 29], "decreas": [0, 1, 19, 21, 23, 25], "dedic": [2, 21], "deem": 27, "deep": [2, 5, 7, 8, 16, 23], "deeper": [2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 22, 29], "deepli": 4, "def": [0, 1, 3, 16, 19, 20, 21, 22, 23, 25, 27, 28, 30, 31], "default": [1, 17, 18, 20, 21, 22, 25, 26, 27, 28, 30], "defin": [0, 1, 3, 16, 17, 18, 21, 22, 23, 24, 25, 26, 27, 28, 30], "definit": [16, 20, 21, 22, 24], "degre": 18, "deliber": 9, "delin": 22, "deliv": 19, "demo": [26, 30], "demonstr": [9, 16, 25, 27], "den": 22, "densiti": [2, 18], "depedn": 25, "depend": [0, 1, 16, 17, 20, 21, 22, 23, 25, 26, 27, 29], "deploi": 3, "deploy": [25, 28], "depnd": 3, "deprec": 30, "depth": 21, "der": 22, "deriv": [18, 19], "descend": 30, "descent": 18, "describ": [0, 1, 3, 4, 16, 20, 21, 24, 25, 28, 29], "descript": [0, 1, 3, 4, 26], "design": [19, 28], "desir": [16, 17, 22, 23, 25, 29], "dessert": 26, "dessert_chain": 26, "detach": [17, 19, 20, 30], "detail": [3, 16, 21, 22, 23, 24, 25, 26, 28, 29], "detect": 29, "determin": [16, 17, 19, 20, 22, 23, 28], "determiner_noun_agreement_with_adjective_1": 4, "determinisit": 24, "determinist": 20, "detial": 24, "develop": [0, 1, 6, 18, 20, 21, 22, 23, 25, 26, 27, 29], "deviat": 18, "devic": [0, 1, 3, 4, 16, 17, 21, 24, 25, 27, 28, 30], "device_map": [3, 25], "devlin": [2, 8], "df": 4, "df_boolq": 28, "dh": 19, "di": [16, 26], "diagnos": 12, "diagram": 24, "dialogu": [25, 29], "dict": [0, 1, 3, 16, 20, 27, 28], "dict_kei": [0, 1], "dictionari": [1, 20, 22], "did": [0, 1, 3, 16, 19, 21, 23, 24, 25, 30], "diff": 18, "differ": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "differenti": 19, "difficult": [4, 16, 19, 25, 28], "difficulti": [4, 16, 24], "dig": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19], "digit": 16, "digraph": 19, "dim": [20, 21, 22, 30, 31], "dim_feedforward": 22, "dimens": [0, 1, 16, 17, 19, 21, 22, 23, 25], "dimension": [2, 17, 22], "dimes": 17, "ding": 10, "dinner": 26, "dinnerplan": 26, "direct": [18, 19, 25], "directli": [3, 16, 17, 22, 23], "directori": [21, 27], "disabl": 30, "disadvantag": 3, "disclaim": [26, 29], "discov": 25, "discuss": [2, 4, 13, 14, 15, 16, 21, 22, 24, 25, 26, 27, 28, 29, 30], "dish": 3, "disk": 16, "displai": 3, "dissect": 2, "dissid": 16, "dissoci": 14, "distilbert": 25, "distinct": 25, "distinctli": 29, "distinguish": [20, 23, 28, 29], "distractor": 28, "distribut": [19, 20, 23, 24, 28], "div_term": 22, "dive": [3, 21, 22, 29], "diverg": [3, 23], "divers": [16, 28], "diviat": 16, "divid": [28, 31], "divis": [17, 20], "dm": 20, "do": [0, 1, 2, 3, 4, 9, 11, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "do_sampl": [0, 1, 3, 21, 24], "doc": [3, 17, 20, 21, 25, 26, 28], "docstr": [16, 22], "document": [2, 3, 17, 19, 20, 21, 22, 23, 24, 26, 28], "documet": 17, "doe": [0, 1, 3, 4, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "doesn": [21, 23, 24, 25, 28, 30], "dog": [0, 1, 22, 23, 27], "domain": [21, 22, 28, 29], "don": [0, 1, 3, 4, 16, 19, 20, 21, 22, 24, 25, 26, 28, 30], "done": [16, 21, 22, 23, 24, 28, 29, 30], "dot": [17, 23, 27], "dotenv": 16, "doubl": 27, "doubt": 21, "doveski": 20, "down": [0, 1, 2, 16, 19, 22, 25, 27], "downaload": [0, 1], "download": [0, 1, 3, 4, 16, 21, 22, 23, 26, 27, 30], "downstream": 30, "draw": [19, 24, 28, 29], "drawn": 17, "drawstr": 2, "dream": 2, "dreamwork": 2, "drink": 2, "drive": [2, 16], "driven": 29, "drop": [16, 22, 24, 27], "dropout": [20, 22], "dropout1": 22, "dropout2": 22, "dropout3": 22, "dtype": [17, 18, 22], "du": 22, "due": [4, 16, 30], "duplic": [20, 30], "dure": [1, 2, 3, 4, 16, 18, 20, 22, 23, 25, 28, 30], "dust": 2, "dutch": 20, "dv": 19, "dw": 19, "dx": 19, "dy": 19, "dynam": 21, "dz": 19, "e": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "each": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30, 31], "ear": 20, "earli": [7, 23, 25, 27], "earlier": [25, 27], "eas": 27, "easi": [19, 21, 28], "easier": [21, 25, 30], "easiest": 4, "easili": [16, 21, 28, 30], "eat": 24, "ect": 5, "edg": 19, "edit": 15, "educ": [8, 16], "ef": 19, "effect": [16, 19, 21, 25, 28, 30], "effici": [3, 9, 10, 19, 21, 25], "effienc": 20, "eighth": 13, "either": [4, 16, 23, 26, 30], "elazar": 12, "electron": 16, "element": [17, 20], "elementari": 29, "elementwise_affin": 22, "eleutherai": [0, 24], "elhag": 15, "elicit": [4, 9, 24, 25, 29], "elif": [0, 1, 4, 16, 21, 24, 27, 28, 30, 31], "els": [0, 1, 3, 4, 16, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31], "elsewher": 20, "email": [1, 16], "emb": 22, "emb_dim": 27, "embed": [3, 16, 19, 20, 22, 24, 27, 28, 29, 30, 31], "embed_dim": 22, "embed_model": 3, "emerg": 28, "emoji": [16, 22], "empir": 18, "empirical_mean": 18, "emploi": [28, 29], "employe": 2, "empti": [20, 26], "en": [0, 1, 3, 16, 21, 27], "enabl": [19, 22, 26], "enable_nested_tensor": 22, "enc1": 22, "enc2": 22, "enc3": 22, "encod": [3, 16, 20, 21, 22, 25, 27, 28, 30], "encoder_attent": 27, "encoder_lay": 22, "encoder_token": 27, "encoding_d": 28, "encoding_en": 28, "encount": 23, "encourag": [5, 16], "end": [0, 1, 3, 17, 20, 22, 23, 24, 25, 28, 29, 30, 31], "endofsequ": 22, "endors": 29, "endpoint": [24, 26, 27], "engin": [3, 16, 19, 22, 23, 26, 28, 30], "english": [16, 20, 27, 28], "eniron": 25, "enrich": 16, "ensur": [16, 22], "entail": [2, 23], "entir": [0, 4, 16, 19, 21, 22, 23, 26], "entiti": 23, "entor": 1, "entropi": 23, "enumer": [3, 19, 20, 30, 31], "env": [0, 1, 16, 21, 22, 26, 30], "environ": [0, 1, 3, 16, 21, 25, 30], "eo": [20, 21, 24, 31], "eos_tensor": 21, "eos_token": [0, 1, 3, 21], "eos_token_id": [0, 3, 21, 24], "eosindex": 20, "ep": 22, "epoch": [0, 1, 3, 16, 19, 21, 23, 25, 27], "epsilon": 31, "eq": 27, "equal": [17, 20, 28], "equip": [5, 16, 22, 23], "equival": [16, 24], "eras": 18, "error": [0, 1, 7, 16, 21, 25, 30], "especi": [0, 1, 16, 20, 25, 28, 29], "ess": 16, "essenti": [16, 20, 21, 22, 23, 30], "essentiali": 21, "establish": 16, "estat": 16, "et": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 22, 24, 25, 27, 28, 29, 30], "etc": [0, 1, 3, 16, 19, 21, 22, 23, 27, 28, 29], "ethic": [4, 29], "eval": [0, 1, 30], "eval_dataset": 21, "eval_loss": 21, "eval_step": 21, "eval_strategi": 21, "evalu": [0, 1, 3, 5, 21, 23, 25], "evalut": 28, "evas": 3, "even": [16, 17, 19, 21, 23, 25, 26, 27, 28], "eventu": 19, "everi": [0, 1, 16, 19, 20, 21, 22, 23, 24, 25, 27], "everyth": 25, "evid": [4, 28], "evolv": 2, "ex": [1, 2, 3, 23], "ex1": 17, "ex1_col": 17, "ex1_col_tran": 17, "ex1_row": 17, "exact": 19, "exactli": [20, 21, 22, 24, 25, 26, 30], "exam": [5, 29], "exampl": [0, 1, 2, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "examples_df": 24, "exce": [16, 23, 24], "exceed": 24, "excel": [5, 8, 16, 30], "except": [20, 28, 30], "exclud": [0, 21], "exclus": [5, 19, 20], "execis": [0, 1], "execut": [0, 1, 2, 3, 4, 16, 25, 26, 30], "exemplifi": [23, 28], "exercis": [16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30], "exercise1a": 17, "exercise1b": 17, "exercise2": 17, "exercise3": 17, "exerpt": 28, "exhaust": [20, 23, 24, 29], "exhibit": [4, 23, 28, 29], "exist": [16, 19], "existential_there_object_rais": 4, "exp": [20, 22, 24, 28, 31], "expect": [0, 1, 3, 16, 20, 21, 24, 25, 26, 27, 28], "experi": [5, 16, 24, 25, 26, 27], "experienc": 24, "experiment": 28, "expert": 29, "explain": [0, 2, 3, 4, 19, 20, 25], "explan": [3, 4, 9, 12, 21, 25, 27, 28], "explanatori": 20, "explicit": [21, 22, 29], "explicit_train": 21, "explicitli": [16, 17, 21, 30], "explor": [0, 1, 2, 3, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27], "express": 30, "extend": [3, 16, 17, 19, 29], "extens": [0, 16, 26], "extent": 28, "extern": 16, "extract": [16, 22, 23, 27], "extrem": 25, "f": [0, 1, 3, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "f1": 28, "f1_score": 28, "f_": 28, "face": [27, 28, 29], "facebook": 25, "facet": 27, "fact": [22, 29], "facto": 16, "factscor": 29, "factual": [15, 28, 29], "fail": 23, "fair": 29, "faith": 29, "fals": [0, 3, 17, 19, 20, 21, 22, 24, 25, 27, 28, 30], "false_neg": 28, "false_posit": 28, "famili": 24, "familiar": [3, 16, 17, 20, 21, 26, 27, 28, 29], "far": [16, 21, 23, 25, 29], "fashion": 2, "fast": 24, "faul": 22, "favor": 20, "favour": 16, "favourit": 24, "fct": 16, "featur": [16, 20, 26, 27], "fed": [16, 20], "feed": [19, 22, 24], "feedback": [10, 25], "feel": [0, 1, 2, 4, 18, 21, 22, 24, 25], "few": [0, 1, 2, 5, 6, 9, 16, 17, 20, 21, 23, 24, 25, 26, 27, 28], "few_shot_predict": 24, "few_shot_prompt": 24, "few_shot_templ": 24, "fewer": 25, "ffn": [30, 31], "ffnn": 30, "fg": 19, "field": [4, 16, 25, 29], "fifth": 10, "fig": 4, "figur": [3, 19, 20, 23, 25, 26], "file": [0, 1, 2, 3, 4, 16, 20, 21, 22, 23, 24, 26, 27, 28], "file_download": 30, "fill": [4, 17, 26], "filter": [16, 25], "filterwarn": [18, 19, 20], "final": [0, 1, 5, 16, 18, 20, 21, 24, 25, 27, 28, 29], "final_lay": 30, "financi": 16, "find": [1, 3, 16, 18, 19, 20, 21, 22, 23, 24, 26, 28, 29], "fine": [5, 9, 16, 21, 24, 26, 27, 28, 29], "finetun": [3, 25], "finetuning_data": 1, "finetuning_data_s": 1, "finetuning_typ": 1, "finish": [19, 22], "finit": 22, "first": [0, 1, 3, 6, 7, 8, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30], "first_top": 30, "firt": 26, "fit": [18, 19, 21, 23, 25, 28], "five": 22, "fix": [0, 18, 20, 21, 25, 28, 30], "flan": [27, 28], "flask_serv": 30, "flatten": [17, 19], "flaw": 20, "flexibl": [19, 22], "flexibli": [17, 23], "float": [17, 18, 22, 30], "float16": [3, 17, 24, 25, 30], "float32": [0, 17, 18], "float64": [17, 18], "floattensor": 27, "floor": 20, "flow": [2, 19, 30], "flu": 2, "fluenci": 28, "fluent": [16, 21, 28], "fnko": 16, "focu": [22, 25, 28, 29], "focus": [0, 1, 21, 25, 26, 28], "fold": 25, "follow": [0, 1, 2, 3, 4, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "fonder": 29, "food": [24, 26], "footbal": 2, "forc": [24, 27, 30], "force_download": 30, "forget": [0, 1, 19, 21, 25], "fork": 30, "form": [0, 1, 2, 3, 16, 17, 25, 28, 29], "formal": [0, 1, 22, 25, 29], "format": [0, 1, 3, 4, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28], "formatt": 16, "formatting_func": 25, "formatting_prompts_func": 25, "former": 23, "formul": [0, 1, 2, 4], "formula": 22, "forsequenceclassif": 23, "forum": 2, "forward": [0, 1, 19, 20, 21, 22, 27, 30, 31], "forwat": [0, 1], "foster": 16, "found": [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28], "foundat": [9, 14, 16, 29], "four": [0, 1, 24], "fourth": 9, "fox": [22, 23, 31], "fp16": 21, "frac": [23, 24, 25, 27, 28], "fraction": 27, "framework": [11, 15, 24, 25, 26], "franc": [27, 30], "frank": [5, 17, 18, 19, 20, 24], "free": [0, 1, 2, 4, 16, 21, 22, 24, 25, 28], "freeli": 21, "freez": [25, 30], "french": [20, 27], "freq_of_first_el": 22, "freq_of_pair": 22, "freq_of_second_el": 22, "frequenc": 22, "frequent": [16, 17, 21, 22], "fresh": 20, "freuqenc": 22, "fridai": 16, "fridg": 26, "friendli": 22, "from": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "from_dict": 20, "from_docu": 3, "from_pretrain": [0, 1, 3, 16, 21, 22, 23, 24, 25, 27, 28, 30], "from_prtetrain": 21, "front": 1, "frozen": [21, 25, 28], "ftfy": 27, "fuch": 22, "fulfil": 25, "full": [3, 16, 17, 19, 22, 23, 24, 27, 30], "full_prompt": 24, "fuller": 28, "fulli": [16, 21, 27], "fun": [1, 2], "function": [0, 1, 3, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 30], "functool": 30, "funko": 16, "further": [0, 1, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 30], "furthermor": [2, 4, 8, 16, 19, 20, 27, 28, 29, 30], "futur": [21, 24, 25], "futurewarn": 30, "fwd_hook": 30, "fyi": 16, "g": [0, 1, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "gain": [2, 16, 23, 25, 27], "game": 2, "gamma": 31, "gao": [16, 25], "garbag": [2, 25], "gaussian": [18, 19], "gave": 30, "gavin124": 3, "ge": 19, "gebru": 16, "gelu": 19, "gender": [15, 29], "gener": [0, 1, 4, 5, 6, 7, 8, 9, 11, 13, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "generate_kwarg": 3, "generated_text": 27, "generation_kwarg": 3, "ger": 4, "german": [0, 1, 2, 3, 4, 20, 22, 28], "germani": 4, "get": [0, 1, 2, 3, 4, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "get_act_nam": 30, "get_activ": 30, "get_cont": 3, "get_data": 27, "get_devic": 30, "get_lay": 30, "get_layers_w_attn": 30, "get_model_and_token": 27, "get_past_lay": 30, "get_pos_data": 27, "get_pre_wo_activ": 30, "get_prob": 20, "get_sentence_repr": 27, "get_surprisal_dataset": 20, "get_surprisal_item": 20, "getpass": 26, "giagant": 25, "giant": 13, "git": 16, "github": [16, 25, 30], "githubusercont": 20, "give": [2, 3, 16, 17, 24, 25, 26, 27, 30], "given": [0, 1, 2, 3, 4, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "glare": 2, "glimps": 16, "glue": 28, "go": [0, 1, 3, 16, 17, 18, 21, 22, 24, 25, 28, 29], "goal": [0, 1, 3, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "goal_fun": 19, "goe": [20, 25, 28], "gold": [2, 3, 16, 19, 20, 28], "gone": 18, "good": [2, 3, 4, 16, 18, 20, 21, 24, 25, 26, 28, 29], "goodfellow": 7, "googl": [16, 27, 28], "got": [29, 30], "govern": 2, "gpt": [2, 3, 4, 5, 8, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "gpt2": [1, 3, 4, 16, 21, 22, 23, 25, 27, 28, 30], "gpt2_lm": 22, "gpt2_model": 25, "gpt2_predict": 4, "gpt2_scorer": 4, "gpt2attent": 22, "gpt2block": 22, "gpt2doubleheadsmodel": 23, "gpt2forsequenceclassif": 23, "gpt2fortokenclassif": 23, "gpt2lmheadmodel": [0, 1, 21, 22, 23], "gpt2mlp": 22, "gpt2model": 22, "gpt2token": [0, 1, 21], "gpt2wrapper": 30, "gpt35": 1, "gpt_metaphor_result": 28, "gpu": [0, 1, 2, 3, 4, 16, 17, 21, 24, 30], "grad": [18, 25], "grad_fn": 18, "grade": [0, 1], "gradient": [0, 1, 19, 20, 23, 25, 27], "gradient_accumulation_step": 21, "gram": 16, "gramamt": [4, 16], "grammar": 28, "grammat": 28, "grammatical_log_prob": 28, "grammatical_sent": 28, "grammaticality_df": 28, "grammaticality_predict": 28, "grammaticality_test": 28, "graph": 20, "graphic": 1, "graphviz": 19, "great": [0, 1, 16, 19, 28], "greedi": [20, 21, 24], "greek": 20, "greet": 4, "grid": 23, "ground": [0, 1, 2, 3, 11, 19, 25, 28], "group": 5, "grow": 29, "gru": 19, "grucel": 19, "gsm8k": 29, "guess": [19, 20, 21, 23], "guid": [4, 16, 21, 30], "guidelin": 16, "h": [19, 22, 25, 30], "h1": 19, "h2": 19, "h3": 19, "ha": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "had": [2, 25], "hallmark": 29, "hand": [0, 3, 5, 16, 20, 24, 26, 27], "handi": 16, "handl": [19, 20, 21], "happen": [0, 1, 20, 21, 26, 28], "harm": [25, 29], "harmless": [3, 10, 25, 29], "harmon": 28, "haskel": 16, "hasn": 29, "have": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "haven": [3, 25], "haystack": 26, "he": [2, 23], "head": [0, 2, 3, 4, 17, 21, 25, 27, 28], "head_and_tail": 17, "head_dim": 22, "head_view": 27, "heard": [16, 28], "heart": 29, "heavi": [3, 21, 26, 29], "heavili": 21, "heck": 3, "heimersheim": 15, "held": [16, 23], "hellaswag": 29, "hello": [4, 17], "hello_tensor": 17, "helm": 13, "help": [3, 10, 16, 19, 23, 24, 25, 26, 27, 28, 29, 30], "helper": [0, 1, 21, 23, 28, 30], "here": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "heurist": 12, "hf": [0, 1, 2, 3, 19, 21, 22, 23, 24, 26, 27], "hi": [2, 22, 24], "hidden": [0, 1, 19, 20, 23, 30], "hidden_act": 0, "hidden_s": [0, 20, 27], "hidden_st": [27, 30], "hide": [16, 22], "high": [2, 3, 16, 17, 21, 23, 24, 25, 27, 28, 29], "higher": [4, 16, 17, 18, 20, 21, 22, 23, 25, 29, 30], "highest": [4, 24, 28], "highlevel": 21, "highli": [5, 25], "highlight": [21, 29], "hint": [0, 1, 3, 4, 16, 19, 21, 22, 23, 24, 28, 29], "hist": 16, "histogram": 16, "histori": [6, 21, 29], "hit": 16, "hoc": 27, "hochreit": 7, "hold": 4, "holist": [13, 18, 19], "homework": [5, 16, 25, 28], "honest": [25, 29], "honesti": 29, "hood": [16, 21, 22, 23, 27], "hook": [27, 30], "hookedtransform": 30, "hookpoint": 30, "hors": [2, 19], "host": [5, 16, 21], "hot": [20, 22, 31], "hour": 24, "hous": [2, 28], "how": [0, 1, 2, 3, 5, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "howard": 10, "howev": [3, 16, 18, 19, 21, 22, 23, 25, 28, 29], "html": [0, 1, 16, 17, 21, 27], "http": [0, 1, 3, 16, 17, 20, 21, 25, 27, 28, 30], "httpstcobdxbfgjkt": 16, "httpstcogymzyzi": 16, "httpstcoyfehvc": 16, "httpstcozzaplmfa": 16, "hu": 28, "hub": [21, 26], "hue": 19, "hug": 27, "huggingfac": [0, 1, 3, 10, 16, 22, 25, 26, 27, 30], "huggingface_hub": [3, 30], "huggingface_model_id": 1, "huggingfaceembed": 3, "huggingfaceendpoint": 26, "huggingfacehub_api_token": 26, "huggingfacellm": 3, "human": [3, 10, 11, 16, 21, 22, 24, 25, 26, 27, 28, 29], "human_metaphor": 28, "humanev": 29, "hund": 22, "hungarian": 16, "hungri": 21, "hw": 28, "hw1": [23, 28], "hw1_model2group_assign": 1, "hw2": 28, "hwchase17": 26, "hyperparam": 1, "hyperparamet": [0, 16, 23, 25, 26], "hypothes": [15, 28], "hypothesi": 4, "i": [0, 1, 2, 3, 4, 5, 8, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "i2h": 20, "i2o": 20, "icon": 16, "id": [16, 21, 22, 23, 24, 27, 28, 30], "id_var": 19, "idea": [1, 4, 16, 19, 20, 23, 24, 25, 26, 27, 28, 30], "ideal": [16, 19, 21, 22, 23, 25, 28], "ident": 18, "identif": [15, 30], "identifi": [22, 23, 25, 27, 28, 29, 30], "idx": [1, 19, 22], "ignor": [18, 19, 20, 24], "illeg": 2, "illustr": 23, "imag": [3, 16, 21, 22, 23], "imagenet": 21, "imagin": 2, "imbal": 4, "imdb": [21, 23, 25], "imdb_gpt2": 21, "imdbtrain": 21, "immedi": 16, "impact": 28, "implement": [0, 1, 2, 3, 7, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "implic": 4, "implicit": [9, 21], "implicitli": [17, 19, 25], "import": [0, 1, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "importantli": [0, 1, 16, 25, 28], "imposs": 25, "impress": [16, 25, 28], "improv": [0, 1, 3, 9, 16, 19, 20, 21, 24], "imshow": 30, "in_": 30, "in_featur": 22, "in_proj_bia": 22, "in_proj_weight": 22, "in_sln": 30, "in_sln_": 30, "inappropri": 4, "incld": 21, "includ": [0, 2, 3, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29], "inclus": 20, "incom": 22, "incompat": 27, "inconsist": [24, 29], "incorpor": 28, "incorrect": [27, 28, 30], "incorrect_answ": 30, "incorrect_index": 30, "increas": [2, 18, 20, 22, 23, 28], "increasingli": [3, 29], "incrementallmscor": [4, 28], "inde": 29, "indent": 16, "index": [0, 1, 3, 16, 19, 20, 22, 23, 28, 30], "indic": [0, 1, 4, 20, 21, 22, 24, 25, 27, 28, 29], "indirect": [15, 30], "individu": [0, 1, 2, 3, 4, 27], "inf": 31, "infer": [0, 2, 3, 9, 12, 16, 18, 21, 22, 24, 26, 28], "infix": 17, "inflat": 28, "influenc": [4, 18], "influenti": 28, "info": 3, "infor": 16, "inform": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "infrastructur": [16, 21], "ing": [18, 22], "ingredi": [3, 26], "inherit": [16, 19], "init": [0, 1, 22], "init_hidden": 20, "init_weight": 27, "initi": [0, 1, 3, 4, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28], "initial_sequ": 20, "initialis": 17, "initialize": 23, "initializer_rang": 0, "inject": [22, 30], "injur": 4, "innat": 28, "inner": 16, "innov": 25, "inoffici": 24, "inp_id": 30, "inpid": 30, "inplac": 22, "inpsect": 3, "input": [0, 1, 3, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "input_combin": 20, "input_dim": 27, "input_emb": 22, "input_id": [0, 1, 3, 16, 21, 22, 23, 24, 27, 28, 30], "input_ids_instruct": 25, "input_ids_lm": 25, "input_line_tensor": 20, "input_neg": 25, "input_po": 25, "input_s": 20, "input_tensor": 20, "input_text": [0, 1, 21, 23, 24, 27], "input_token": [27, 28], "input_vari": 26, "ins": 3, "inscrut": 30, "inseq": 27, "insert": [3, 4, 26], "insid": [21, 22], "insight": [16, 27, 28], "inspect": [0, 1, 3, 4, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30], "inspir": [2, 4, 20, 21, 22, 24, 25, 26, 28], "instal": [0, 1, 3, 17, 19, 21, 25, 26, 27, 28, 30], "instanc": [4, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "instanti": [0, 1, 18, 19, 20, 21, 22, 23, 26], "instati": [19, 21], "instead": [16, 19, 21, 23, 25, 26, 27, 28, 30], "institut": 2, "instruct": [0, 1, 2, 3, 10, 16, 17, 25, 26, 27, 28], "instruction_text": 25, "instructions_menu_summari": 26, "instructions_text_appet": 26, "instructions_text_dessert": 26, "instructions_text_main": 26, "int": [1, 16, 17], "int64": 17, "intang": 16, "integ": [17, 22], "integr": [16, 19, 21, 24, 25, 26, 27], "integrated_gradi": 27, "intellig": 29, "intend": [16, 18, 23, 25, 26, 29], "intens": [16, 29], "inter": 16, "interact": [2, 11, 27], "intercept": 19, "interchang": [16, 24, 25], "interconnect": 4, "interdisciplinari": 5, "interest": [3, 5, 18, 26, 27, 28, 29], "interestingli": 29, "interfac": [3, 19, 21, 26], "intermedi": [0, 1, 9, 28, 29, 30], "intermediate_residual_": 30, "intermediate_s": 0, "intern": 16, "internet": [16, 28], "interpret": [0, 1, 3, 4, 5, 20, 27, 28, 29], "intersect": 28, "interv": [4, 17], "interven": 30, "intervent": 30, "intric": 29, "intro": [2, 3], "introduc": [0, 1, 2, 5, 7, 8, 9, 16, 17, 18, 20, 22, 23, 24, 25, 28, 29], "introduct": [5, 6, 16, 22, 24], "intuit": [2, 3, 4, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29], "intuititv": 4, "invers": 19, "investig": [1, 4, 20, 28], "invok": 26, "involv": [16, 22], "io": [0, 1, 3, 16, 21], "ioi": 30, "ioi_patching_result": 30, "iprogress": [0, 1, 16, 21], "ipynb": [0, 1, 2, 3, 4], "ipython": 3, "ipywidget": [0, 1, 16, 21, 27], "irish": 20, "iron": 29, "is_avail": [0, 1, 3, 4, 16, 21, 24, 25, 27, 28, 30], "is_correct": 28, "is_grammat": 28, "is_top_at_end": 30, "is_tru": 28, "isalpha": 16, "isdigit": 31, "ish": 30, "isol": [4, 28], "isspac": 16, "issu": [0, 3, 16, 23, 26, 28, 29], "itali": 24, "italian": [20, 24, 26], "italien": 26, "item": [0, 1, 4, 17, 18, 19, 20, 22, 24, 27, 28, 30], "item_id": 28, "item_surpr": 20, "itemnum": 28, "iter": [0, 1, 4, 16, 18, 19, 20, 24, 25, 28], "iterrow": [3, 28], "ith": 28, "its": [0, 1, 2, 4, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30], "itself": [18, 20, 25, 26], "j": [0, 1, 16, 28], "jackson": 20, "jaffrai": 16, "japanes": 20, "jewelri": 2, "jo": 16, "job": [0, 1, 3, 16, 19, 24, 28], "john": 30, "join": [0, 1, 16, 24, 27, 28], "joint": 17, "jpg": 1, "jpmorgan": 16, "json": [0, 1, 20, 21, 30], "judgement": 16, "juic": 2, "juli": 4, "jump": [2, 22, 23, 31], "june": [2, 3], "jupyt": [0, 1, 16, 21], "jurafski": 6, "just": [0, 1, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 30], "justext": 16, "justif": 4, "justifi": 27, "k": [17, 20, 22, 24, 30, 31], "k_2": 0, "k_proj_weight": 22, "k_q": 24, "k_x": 31, "kadavath": 28, "kaplan": 6, "karpathi": [5, 8], "kdeplot": 18, "kdim": 22, "keep": [0, 16, 18, 20, 21, 24, 25], "kei": [0, 1, 2, 3, 16, 19, 20, 21, 22, 23, 25, 26, 27, 30, 31], "kept": 25, "kernel": [0, 1, 21], "kind": [0, 1, 2, 3, 16, 19, 21, 22, 23, 24, 25, 27], "kindli": 16, "kl": 3, "kn1g4awfib": 16, "know": [4, 16, 18, 19, 21, 22, 24, 25, 26, 27, 29, 30], "knowledg": [4, 5, 9, 24, 25, 27, 28], "knowledge_exampl": 24, "knowledge_examples_chain": 24, "knowledge_examples_chain_incorrect": 24, "knowledge_stat": 24, "known": [4, 16, 18, 21, 22, 25, 27, 28], "kojima": 9, "korean": 20, "krakauer": 14, "kwarg": [26, 30], "l": [20, 25, 27, 30, 31], "l57": 30, "lab": 5, "label": [0, 1, 2, 3, 16, 19, 20, 21, 23, 24, 25, 27, 28, 30], "label2index": 27, "ladi": 2, "lambada": 29, "lambd": 30, "lambda": [0, 1, 16, 28], "lambdalay": 30, "lampinen": 9, "langaug": 2, "langchain": [16, 24], "langchain_commun": [16, 26], "langchain_cor": 26, "langchain_nvidia_ai_endpoint": 16, "langchain_openai": 26, "langchainhub": 26, "languag": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 28, 29], "laptop": 16, "larg": [1, 5, 9, 10, 14, 16, 21, 22, 23, 25, 26, 27, 28, 29, 30], "larger": [4, 16, 17, 26, 27, 28], "last": [4, 16, 18, 19, 20, 21, 23, 25, 27, 28, 29, 30], "last_past": 30, "lastli": 23, "later": [3, 16, 19, 20, 30], "latest": [1, 27], "latg": 28, "latter": [16, 21, 23, 26, 27, 29], "law": [6, 20, 25, 29], "lawsuit": 16, "layer": [0, 1, 20, 21, 22, 23, 25, 27, 30, 31], "layer_decod": 30, "layer_logit": 30, "layer_past": 30, "layer_residual_": 30, "layernorm": 22, "layers_to_unfreez": 25, "layout": 28, "lazi": [22, 23], "ldquo": 25, "le": 27, "lead": [2, 20, 24, 25, 28, 30], "leader": 2, "learn": [0, 1, 3, 4, 5, 7, 8, 9, 10, 12, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "learnabl": 28, "learner": 8, "learning_r": [3, 18, 20, 21], "least": [17, 21, 24, 25, 26], "leav": 20, "lectur": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "led": 25, "left": [0, 1, 3, 21, 22, 26], "leg": 24, "legend": 21, "len": [1, 15, 16, 19, 20, 24, 25, 27, 28, 30], "lend": 25, "lenght": 16, "length": [0, 1, 4, 16, 17, 19, 20, 22, 24, 25, 28], "lens": 4, "less": [17, 19, 22, 24], "lesson": 16, "let": [0, 1, 2, 3, 16, 17, 18, 20, 22, 23, 25, 26, 28], "letter": [20, 22], "letter_index": 20, "level": [21, 22, 23, 27, 29], "levi": 28, "lharri": 16, "li": [20, 28], "liang": 5, "lib": [0, 1, 16, 21, 22, 30], "librari": [0, 2, 3, 17, 22, 25, 30], "light": [27, 28], "like": [0, 1, 2, 3, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "likelihood": [18, 20, 28], "limb": 24, "limit": [16, 20, 22, 24, 26, 28, 29], "line": [0, 1, 3, 16, 19, 20, 21, 22, 23, 27], "linear": [0, 1, 17, 20, 22, 23, 27, 30], "linear1": [19, 22], "linear2": [19, 22], "linear3": 19, "linear4": 19, "lineplot": 19, "ling": 16, "linguist": [4, 5, 16, 27, 28, 29], "lingusit": 16, "link": [0, 1, 3, 4, 26], "linspac": 19, "list": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 30], "list_decod": 30, "liter": 28, "literari": 16, "literatur": [2, 16], "littl": [24, 26], "liu": [9, 24], "live": 28, "ll": 27, "llama": [2, 3, 5, 9, 16, 21, 22, 25, 29], "llama_index": 3, "llamaindex": 3, "llm": [2, 6, 16, 23, 25, 28, 29, 30], "llm_hf": 26, "llok": 24, "lm": [0, 1, 3, 4, 13, 16, 22, 23, 24, 25, 27, 28, 29, 30], "lm_head": [22, 30], "lm_scorer": [4, 28], "lmhead": 23, "lmql": 26, "ln_1": [22, 30], "ln_2": [22, 30], "ln_f": [22, 25, 30], "lnaguag": 13, "load": [0, 1, 2, 3, 4, 16, 17, 21, 22, 23, 24, 25, 26, 27, 28, 30], "load_dataset": [0, 1, 3, 4, 16, 21, 23, 25, 28], "load_dotenv": 26, "load_gpt2": 30, "load_in_4bit": 25, "load_in_8bit": 3, "load_model": 27, "load_tool": 26, "loader": [0, 1], "loc": [18, 19, 24], "local": [0, 1, 17, 20, 21, 24, 25, 26, 27, 30], "locat": [15, 17, 18, 23, 24, 27], "log": [0, 1, 3, 4, 20, 21, 22, 24, 25, 28, 30], "log_histori": 21, "log_p": 24, "log_prob": [18, 20], "log_stat": 3, "logging_step": 21, "logic": 29, "logit": [15, 21, 23, 30, 31], "logits_to_logit_diff": 30, "logsoftmax": [19, 20], "logspac": 20, "long": [1, 3, 7, 16, 21, 23, 24, 27, 28, 29], "longer": [18, 22, 25, 28], "longtensor": 20, "look": [0, 1, 3, 4, 5, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "loop": [0, 1, 3, 19, 20, 21, 23, 26], "lora": 25, "loss": [0, 1, 3, 19, 20, 21, 22, 23, 24, 25, 27, 28], "loss_funct": 19, "lot": [3, 16, 24, 25], "love": 4, "low": [24, 25], "lower": [16, 18, 20, 22, 24, 25], "lowest": 28, "lr": [0, 1, 18, 19, 20], "lr_scheduler_typ": 21, "lstm": [7, 23], "luckili": [19, 21, 23], "lvwerra": 25, "ly": 17, "m": [0, 1, 17, 20, 22, 24, 27], "m1": 16, "m3hrdadfi": 3, "m_1": [0, 1], "m_coef": 30, "m_out": 31, "mac": 16, "machin": [16, 17, 19, 21, 23, 25, 29], "made": [2, 16, 18, 19, 21], "magnitud": [19, 27], "mahowald": 14, "mai": [0, 1, 3, 4, 18, 22, 24, 26, 28], "main": [1, 3, 4, 18, 19, 20, 25, 26, 29], "main_chain": 26, "main_cours": 26, "mainli": [16, 19], "major": 16, "make": [0, 1, 3, 4, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "make_df": 20, "man": 2, "manag": [4, 20], "mani": [0, 1, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "manipul": [4, 17], "manner": [16, 17], "manual": [18, 19, 21, 22], "map": [0, 1, 3, 16, 19, 20, 21, 22, 23, 27, 28, 30], "mari": [28, 30], "markup": 16, "martin": 6, "mask": [1, 16, 21, 24, 27, 28], "masked_label": 24, "massag": [0, 1, 16, 18, 21], "massage_input_text": [0, 1, 28], "massaged_dataset": [0, 1], "massaged_dataset_v": 28, "master": 5, "match": [2, 3, 4, 16, 20, 22, 27, 28], "materi": 16, "math": [19, 20, 22, 28, 29], "mathbb": 25, "mathc": 28, "mathemat": [0, 1, 6, 15, 17, 22, 29], "matmul": [17, 30], "matplotlib": [0, 1, 16, 18, 19, 20, 21], "matric": [0, 1, 17, 19, 21, 22, 25], "matrix": [0, 1, 16, 20, 22, 25, 30, 31], "matrix1": 17, "matrix2": 17, "matrixprod": 17, "max": [2, 22, 23, 24, 27], "max_len": 22, "max_length": [0, 1, 3, 20, 21, 23], "max_new_token": [0, 1, 3, 24, 26], "max_ord": 28, "max_position_embed": 0, "max_prob_idx": 24, "max_seq_length": 25, "max_token": 26, "maxim": [1, 2, 3, 4, 16, 18, 21, 23, 24, 25], "maximum": [18, 25], "mayb": [21, 25, 30], "mccoi": 12, "mcdonnel": 9, "mcyftsxc2n": 16, "mdoel": 30, "mdp": 25, "me": 26, "mean": [3, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 31], "meaning": 30, "meant": [16, 18], "measur": [3, 4, 18, 22, 28], "meat": 16, "mechan": [15, 21, 25, 27, 30], "mechanist": 5, "mediat": 15, "medic": 25, "medium": 30, "meet": 29, "mega002": 30, "meinung": 28, "meister": 24, "melt": 19, "memor": 23, "memori": [0, 1, 3, 7, 16, 17, 20], "meng": 15, "mention": [3, 6, 9, 15, 22, 23, 24, 27, 28, 29], "menu": 26, "merg": 22, "merullo": [15, 30], "messag": [18, 26], "meta": [0, 22], "metaphor": 28, "metaphor_results_gpt": 28, "metaphor_results_human": 28, "meteor": 28, "method": [1, 3, 5, 15, 16, 19, 21, 25, 28, 29, 30], "methodolog": [25, 28], "metric": [3, 4, 20, 21, 29, 30], "michael": [5, 17, 18, 19, 20, 24], "microsoft": [3, 25, 26], "mid": [20, 24, 28], "mid_attn_": 30, "middl": [2, 22, 23], "might": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "mikolov": 6, "militari": 2, "milk": 30, "million": [23, 25], "min": [9, 23], "min_length": 3, "mind": [16, 25, 26, 28], "mini": [3, 19, 25], "mini_batch_s": 3, "minicon": [4, 28], "minim": [0, 1, 4, 16, 18, 19, 22, 26, 29], "minimum": [23, 25], "minist": 4, "minut": 20, "mismatch": 4, "misrepresent": 16, "miss": [16, 29], "mistak": 24, "mistral": 26, "mistralai": 26, "mitchel": 14, "mix": [16, 17], "mix2": 17, "mix3": 17, "mix4": 17, "mix5": 17, "mix6": 17, "mix7": 17, "mix8": 17, "mixtur": [1, 16], "ml": [16, 29], "mll": 4, "mlm": [0, 21], "mlm_probabl": 23, "mlp": [22, 30], "mlp_": 30, "mlp_19": 30, "mlp_condens": 19, "mlp_explicit": 19, "mlpcondens": 19, "mlpexplicit": 19, "mmlu": [28, 29], "mode": [0, 1, 3, 25, 28], "model": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 22, 24, 26, 27, 28, 29, 30], "model_": 28, "model_instruct": 25, "model_kwarg": 3, "model_lm": 25, "model_nam": [1, 3, 27], "model_s": [0, 1], "model_t5": [27, 28], "model_typ": 22, "model_view": 27, "model_xl": 28, "modelout": 21, "modelwrapp": 30, "modern": [2, 26, 28], "modifi": [0, 4, 16, 17, 26], "modul": [20, 22, 27, 30], "module_guid": 3, "modulelist": 22, "moment": [24, 25], "monitor": [0, 1, 16, 20], "monolingu": 4, "moodl": [0, 1, 2, 3, 4], "moral": 29, "more": [2, 3, 4, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "morgan": 16, "morphologi": 4, "most": [4, 16, 20, 21, 22, 24, 25, 28, 29], "mostli": [4, 16, 19, 21, 23, 25, 29], "motiv": [27, 28], "mous": 1, "move": [0, 1, 28, 30], "movi": [3, 21, 25], "mp": [0, 1, 4, 16, 21, 24, 27, 28], "mrr": 30, "mse": 23, "mseloss": 19, "mtx": 31, "much": [16, 17, 19, 21, 22, 24, 25, 27, 28, 30], "multi": [16, 19, 29], "multihead_attn": 22, "multiheadattent": 22, "multilanguag": 16, "multilingu": 4, "multipl": [4, 16, 19, 22, 23, 24, 28, 29], "multipli": [16, 17, 23, 31], "multitask": 8, "must": [16, 18, 19, 22, 24, 29], "my": [16, 24, 26], "m\u00fcll": 20, "m\u00fcller": 20, "n": [3, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 31], "n_categori": 20, "n_hidden": 19, "n_input": 19, "n_item": 20, "n_iter": 20, "n_layer": 30, "n_letter": 20, "n_name": 20, "n_ob": [18, 19], "n_output": 19, "n_train_step": 19, "n_training_step": 18, "naiv": 25, "name": [0, 1, 2, 3, 4, 5, 16, 18, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31], "named_paramet": 25, "names_data": 20, "nanda": 15, "nanswer": [0, 1], "nappet": 26, "nation": 16, "nativ": [21, 30], "natur": [2, 3, 12, 16, 21, 24, 25, 28, 30], "naturalqa": 29, "navig": [0, 1, 2, 3, 4, 16], "nb": [16, 17, 18, 19, 21], "ndessert": 26, "neat": 26, "neatli": 19, "necess": [22, 26], "necessari": [22, 25, 26, 30], "necessarili": [0, 1, 18, 25], "need": [0, 1, 2, 3, 8, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "neg": [18, 20, 23, 25, 28], "negative_sent": 25, "negbackward0": 18, "ner": 23, "net": [7, 19, 20, 21, 22], "network": [0, 1, 5, 7, 8, 19, 21, 22, 23, 26, 27], "neural": [0, 1, 5, 6, 7, 8, 15, 19, 20, 21, 22, 23], "neural_pragmatic_nlg": 20, "neuron": [0, 1, 27], "neutral": [2, 16, 23, 24], "never": [16, 20], "nevertheless": 16, "new": [0, 1, 3, 16, 17, 20, 21, 22, 25, 30], "new_tensor": 17, "newer": 28, "newgeluactiv": 22, "newli": 21, "next": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "nf": 22, "nf4": 25, "nhead": 22, "nhid": 22, "nice": [21, 22], "nightmar": 2, "ninp": 22, "ninth": 14, "nlayer": 22, "nlg": [5, 24, 28], "nll": 28, "nllloss": 20, "nlp": [0, 1, 2, 5, 6, 15, 16, 21, 23, 28], "nmain": 26, "nmean": 20, "nn": [20, 21, 22, 23, 27, 30], "no_grad": [0, 1, 20, 27], "noce": 24, "node": [3, 19, 23], "nois": 19, "nomura": 16, "non": [16, 20, 23, 24, 27], "nondynamicallyquantizablelinear": 22, "none": [1, 18, 19, 21, 22, 23, 30], "nonetheless": [16, 26], "nonlinearregressiondata": 19, "nonliter": 28, "nonsens": [4, 25], "noodl": 3, "norm": [22, 30], "norm1": 22, "norm2": 22, "norm3": 22, "normal": [18, 19, 22, 23, 30], "normalis": 31, "notabl": 19, "notat": [6, 17], "note": [0, 1, 3, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30], "notebook": [0, 1, 4, 16, 18, 20, 21, 25, 27, 30], "notebook_tqdm": [0, 1, 16, 21], "notic": [17, 18, 20, 24], "notion": [16, 20], "noun": [4, 25], "now": [18, 19, 20, 22, 23, 25, 27, 28, 29], "nowadai": 16, "np": [0, 1, 17, 19, 20, 24, 27, 28, 30, 31], "np_arrai": 17, "np_array_to_tensor": 17, "np_conv": 31, "npi_present_1": 4, "npleas": 26, "npnlg": 20, "ntoken": 22, "nuber": 23, "nudg": 25, "null": 0, "num": [0, 1, 19, 30], "num_attention_head": 0, "num_class": 21, "num_correct": 27, "num_decoder_lay": 22, "num_encoder_lay": 22, "num_epoch": 27, "num_head": 22, "num_hidden_lay": 0, "num_items_in_batch": 21, "num_key_value_head": 0, "num_label": 27, "num_lay": [27, 30], "num_posit": 30, "num_process": 3, "num_test_step": [0, 1], "num_token": 30, "num_tot": 27, "num_train_epoch": 21, "num_word": 27, "number": [0, 1, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28], "number_training_token": 1, "numel": [0, 1, 25], "numer": [16, 17, 18, 22, 25], "numpi": [0, 1, 17, 19, 20, 24, 27, 28, 30, 31], "numpydoc": 16, "nwhich": 26, "nye": 9, "nyu": 4, "o": [3, 19, 20, 26, 27, 28, 29, 31], "o2o": 20, "o_citi": 30, "object": [1, 3, 4, 15, 16, 17, 18, 19, 20, 21, 23, 25, 30], "obscur": 27, "observ": [3, 4, 19, 23, 24, 26, 27, 30], "obtain": [16, 17, 18, 20, 24, 25, 29], "obvious": 2, "occupi": [16, 17], "occur": [4, 16, 19, 23, 28], "odd": 3, "off": [2, 16], "offer": [5, 25, 26, 27], "often": [0, 1, 3, 16, 17, 21, 22, 23, 24, 25, 28, 29, 30], "oftentim": 26, "old": 17, "older": 2, "ollama": 3, "ollamaembed": 3, "ommit": 16, "onc": [16, 19, 21, 22, 25], "one": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31], "ones": [16, 17, 18, 19, 25, 30], "ones_lik": 24, "onli": [0, 1, 2, 3, 4, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "onlin": [21, 24, 25], "onto": [16, 19, 22, 28, 30], "onward": 19, "open": [1, 3, 4, 9, 16, 20, 21, 24, 25, 26, 27, 28], "openai": [10, 21, 25, 26], "openai_api_kei": 26, "openai_summarize_tldr": 25, "oper": [19, 22, 30], "operation": [4, 30], "opinion": [28, 29], "opportun": [14, 19], "oppos": [16, 20], "opprotun": 29, "opt": [0, 1, 16, 18, 21, 22, 25, 30], "optim": [0, 1, 3, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27], "optima": 23, "optimis": 25, "option": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 21, 24, 26, 27, 28, 29, 30], "orang": 2, "orc": 4, "ord": 17, "order": [3, 16, 17, 19, 21, 22, 23, 25, 26, 27, 28, 29], "ordereddict": 22, "ordin": 25, "org": [1, 17, 25, 27, 28], "orient": 28, "origin": [8, 16, 20, 25, 28, 30], "original_summari": 3, "other": [2, 4, 5, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "otherwis": [0, 1, 3, 16, 18, 21, 24, 25, 28], "our": [0, 1, 3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 28, 30], "ourselv": [16, 21, 22, 26, 27], "out": [0, 1, 3, 4, 5, 8, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "out_contrast": 27, "out_featur": 22, "out_intermediate_residual_": 30, "out_proj": 22, "out_with_gener": 27, "outcom": [25, 29, 30], "outdoor": 2, "outlier": 16, "outlin": 29, "outlook": [16, 24], "output": [0, 1, 3, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31], "output_": 28, "output_attent": [27, 30], "output_combin": 20, "output_dim": 27, "output_dir": 21, "output_hidden_st": [27, 30], "output_max_length": 3, "output_pars": 26, "output_s": 20, "output_text": 25, "output_xl": 28, "outset": 18, "outsid": 2, "ouyang": 10, "over": [0, 1, 2, 3, 4, 14, 16, 18, 19, 22, 23, 24, 25, 26, 28, 30, 31], "overal": [3, 18, 22, 24, 26, 27, 28], "overfit": [21, 23, 24], "overlap": [16, 28], "overoptim": 25, "overrepres": 4, "overris": 21, "overview": [10, 13, 16, 19, 21, 23, 24, 25, 26, 29], "overwhelm": 21, "own": [3, 4, 16, 19, 20, 21, 22, 24, 25, 26], "p": [0, 1, 16, 17, 20, 22, 23, 24, 25], "p_": [20, 24, 28], "p_categori": 20, "p_name": 20, "pack": 19, "pack_padded_sequ": 19, "packag": [0, 1, 2, 3, 16, 21, 22, 24, 25, 26, 27, 28, 29, 30], "pad": [0, 1, 3, 16, 19, 21, 22, 23, 24], "pad_packed_sequ": 19, "pad_sequ": 19, "pad_token": [0, 1, 3, 21], "pad_token_id": [0, 1, 3, 21, 23, 24], "padding_sid": [0, 1, 3, 21], "page": [16, 26], "pai": 19, "pain": 19, "pair": [0, 1, 4, 16, 19, 20, 22, 25, 28], "panda": [3, 4, 19, 20, 24, 28], "paper": [1, 2, 3, 6, 7, 8, 10, 11, 13, 14, 15, 16, 22, 23, 24, 25, 28, 29, 30], "paper_url": 1, "paradigm": [9, 28], "parallel": [16, 21, 22, 24, 30], "parallelis": 22, "param": [19, 25], "paramet": [0, 1, 2, 3, 10, 16, 21, 22, 23, 24, 25, 26, 27, 28, 30], "parameter": 21, "paramt": [3, 24], "paraphras": 28, "parenthes": 4, "pari": [27, 30], "park": 11, "parrot": 29, "part": [3, 4, 16, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29], "partial": [1, 25, 30], "particip": [5, 28], "particular": [0, 1, 2, 3, 4, 5, 16, 20, 21, 22, 25, 26, 27, 29], "particularli": 19, "particulat": 24, "pass": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 30, 31], "passag": 23, "passs": 26, "past_key_valu": 30, "past_layer_": 30, "patch": 15, "patched_logit": 30, "patched_logit_diff": 30, "path": [16, 24, 27], "patient": 26, "pattern": [23, 27, 29, 30], "pavlick": [9, 29], "paywal": 26, "pd": [3, 4, 19, 24, 28], "pdf": 25, "pe": 22, "peak": 16, "peft": [10, 21], "penguin": 24, "penn": 28, "peopl": [2, 4, 16, 28], "pep8": 16, "per": [2, 16, 20, 21, 23, 24, 25, 27], "per_device_eval_batch_s": 21, "per_device_train_batch_s": 21, "percentag": 29, "perceptron": 19, "perci": 5, "perez": 4, "perfect": [20, 28], "perform": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "perhap": [23, 25, 28], "permut": 21, "perpetu": 29, "perplex": [20, 28], "perplexity_": 28, "perplexity_xl": 28, "perplxti": 20, "perplxty_dict": 20, "person": [2, 16, 23], "perspect": [5, 28, 29], "perturb": 27, "phenomena": 4, "phenomenon": [4, 28, 29], "phi": [3, 25], "phrase": 4, "physic": 29, "pick": [0, 1, 16, 22, 25, 30], "pictur": [0, 20, 22, 24], "piec": [16, 22, 26, 28], "pile": [16, 21], "pilot": 4, "pinecon": 3, "pip": [0, 1, 3, 16, 21, 25, 26, 27, 30], "pipe_output": 21, "pipelin": [0, 1, 3, 16, 21, 24], "piper": 16, "pizza": 24, "pizzeria": 24, "place": [3, 24], "placement": 3, "plai": [0, 1, 2, 18, 20, 21, 22, 24, 25, 26, 29], "plan": 26, "platform": [16, 21], "plausibl": 29, "pleas": [0, 1, 2, 3, 4, 16, 19, 21, 22, 24, 25, 26, 27, 28], "plot": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 23, 29], "plot_everi": 20, "plotli": 30, "plt": [0, 1, 16, 18, 19, 20, 21], "plu": [20, 22, 27], "plural": 4, "png": 1, "po": [22, 23, 27], "point": [16, 19, 22, 23, 24, 25, 26, 28], "pointer": 22, "pointwis": 16, "pol_tok": 30, "poland": 30, "poland_id": 30, "poland_text": 30, "polici": 3, "polina": [16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "polish": 20, "polit": 29, "poor": 16, "popul": 17, "popular": [3, 21, 23, 26, 29], "pork": 3, "portugues": 20, "pos_encod": 22, "posencod": 22, "posit": [17, 22, 23, 24, 25, 28, 30], "positionalencod": 22, "positive_sent": 25, "possess": 29, "possibl": [4, 16, 17, 22, 23, 24, 25, 26, 28, 29, 30], "possibli": [16, 22, 25], "post": [2, 3, 24, 25, 27], "potenit": 28, "potenti": [16, 23, 24, 25, 26, 27, 28], "power": [11, 19, 28], "pp": 4, "ppl": 28, "ppl_": 28, "ppo": 3, "ppo_epoch": 3, "ppo_train": 3, "ppoconfig": 3, "ppotrain": 3, "practic": [0, 1, 5, 19, 21, 22, 23, 24, 28], "practition": 2, "pragmat": [5, 28], "prder": 17, "pre": [0, 2, 8, 10, 16, 19, 20, 21, 22, 27, 30], "pre_wo_attn": 30, "preced": [16, 22, 23, 24], "precis": [17, 28], "pred": [24, 27], "predict": [0, 1, 2, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "predicted_answ": 28, "predicted_d": 28, "predicted_decoded_d": 28, "predicted_label": 28, "prediction_instruct": 25, "prediction_lm": 25, "prefer": [3, 4, 10, 16, 25], "prefix": [22, 28], "preliminari": 5, "prep": [0, 1], "prepair": 16, "prepar": [0, 1, 3, 16, 18, 21], "prepend": 22, "preposit": 4, "preprocess": [0, 1, 16, 22], "preprocessed_train_dataset": 16, "present": [2, 19, 20, 29], "presid": 2, "press": 16, "presuppos": 28, "pretrain": [0, 1, 3, 16, 17, 21, 25, 26, 30], "pretrainedtokenizerbas": 21, "pretraining_data_s": 1, "prevent": [2, 21, 24], "previou": [19, 20, 21, 22, 23, 24, 26, 28, 29, 30], "price": 16, "primarili": 29, "primit": 19, "principl": [0, 21, 22], "principle_a_case_1": 4, "print": [0, 1, 3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31], "print_everi": 20, "print_funct": 20, "print_top": 30, "prior": [5, 29], "priori": 22, "pro": 24, "prob": [20, 31], "prob_of_answ": 30, "probabl": [0, 1, 3, 4, 16, 18, 19, 20, 22, 23, 24, 25, 28, 30], "probe": [5, 12, 20], "probing_dir": 27, "problem": [3, 5, 9, 16, 28], "problemat": [3, 29], "probs_t": 31, "procedur": [3, 18, 24, 28], "proces": [0, 1], "process": [0, 1, 4, 6, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30], "prodcut": 17, "produc": [16, 19, 20, 21, 30], "product": [17, 25, 27], "program": [5, 9, 23], "progress": [2, 23], "project": [5, 16, 30, 31], "promin": [16, 22], "promot": 30, "prompt": [3, 4, 5, 16, 20, 22, 25, 26, 27, 28, 29, 30], "prompt_input_id": 24, "prompt_template_appet": 26, "prompt_template_dessert": 26, "prompt_template_main": 26, "prompt_template_summari": 26, "prompttempl": 26, "propag": 7, "propens": 29, "proper": 20, "properli": 26, "properti": [1, 17], "proport": [4, 16, 20, 28], "proprietari": 3, "propto": 24, "provd": 29, "proven": 25, "provid": [0, 1, 2, 3, 4, 6, 13, 14, 15, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "proxim": [3, 25], "pseudo": [4, 21, 28], "psuchologi": 28, "pt": [0, 1, 3, 16, 21, 23, 24, 25, 27, 28, 30], "publicli": 26, "publish": 16, "pull": 26, "punctuat": [0, 1, 16, 22], "pure": [21, 24], "purpos": [3, 16, 17, 19, 21, 25, 26, 27], "push": [16, 21], "push_to_hub": 21, "put": [0, 1, 3, 21, 27, 28, 30], "puzzl": 29, "px": 30, "py": [0, 1, 16, 21, 22, 25, 30], "pyplot": [0, 1, 16, 18, 19, 20, 21], "pythia": [2, 4, 24], "python": [5, 16, 19, 27, 28], "python3": [0, 1, 16, 21, 22, 30], "pytorch": [16, 18, 20, 21, 23, 27, 30], "q": [3, 22, 24, 30, 31], "q_2": 0, "q_proj_weight": 22, "q_x": 31, "qa": [0, 23, 25], "qlora": 25, "qquestion": [0, 1], "qualiti": [16, 23, 28], "quantifi": 23, "quantit": 4, "queri": [3, 16, 22, 24, 26, 27, 31], "query_engin": 3, "query_tensor": 3, "question": [1, 2, 3, 4, 16, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30], "quick": [20, 22, 23], "quickstart": 27, "quiet": 20, "quit": [16, 21, 25, 26, 28, 29, 30], "quot": 29, "r": [0, 1, 3, 16, 25, 28, 31], "r_": 25, "radford": 8, "rafailov": 25, "rag": 3, "rag_respons": 3, "rais": [27, 28, 30], "ram": 16, "ran": 27, "rand": [16, 17, 19], "randint": 20, "random": [3, 17, 20, 23, 24, 27, 30], "random_choic": 20, "random_training_exampl": 20, "random_training_pair": 20, "random_weight": 27, "randomli": [16, 20, 23], "rang": [0, 1, 4, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30], "rank": [25, 30], "rare": 29, "rate": [0, 1, 16, 18, 20, 21, 23, 24, 25], "rather": [10, 16, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30], "raw": [16, 20, 22, 28], "rcl": 16, "rdbu": 30, "rdquo": 25, "re": [22, 23, 26], "reach": [22, 23], "react": 26, "read": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 30], "read_csv": [4, 24, 28], "readabl": [16, 21, 22], "reader": 30, "readi": 18, "readlin": 27, "readm": 16, "readthedoc": [0, 1, 16, 21], "real": [26, 29], "realis": 30, "realiti": 2, "realiz": [20, 29], "realli": 9, "realtoxicityprompt": [28, 29], "reason": [0, 1, 2, 9, 12, 25, 28], "recal": [15, 26, 28, 30], "recap": [25, 28], "receiv": [3, 16, 25, 27], "recent": [2, 4, 16, 22, 24, 28, 29], "recevi": 25, "recip": [3, 25, 26], "recipe_nlg_lit": 3, "recipi": 26, "reciproc": 30, "recognit": 23, "recommend": [5, 16, 20], "record": [3, 16, 28], "recov": 30, "recurr": [7, 20, 21], "recycl": 17, "red": [2, 29], "reduc": [22, 24], "reduct": 20, "reel": 16, "ref_model": 3, "refer": [2, 3, 4, 8, 11, 16, 19, 21, 23, 24, 25, 27, 28, 29, 30], "reflect": [4, 16, 29], "reformat": 16, "regard": [2, 16, 20, 25, 28, 29], "regex": 28, "regim": 20, "register_buff": 22, "register_forward_hook": 30, "regress": 22, "regular": 27, "reimplement": 22, "reinforc": [10, 25], "reject": 25, "rel": [4, 16, 21, 22, 25], "relat": [2, 5, 10, 16, 18, 20, 22, 28, 29], "relev": [3, 5, 16, 18, 21, 23, 25, 26, 28, 29], "reli": [16, 22, 23, 27, 29], "reliabl": [24, 28, 29], "reload": [0, 1, 21], "relu": [0, 1, 19, 20], "remain": [21, 29], "rememb": [19, 20, 24], "remind": [21, 24, 27], "remov": [16, 17, 20, 22, 30], "remove_column": [0, 21, 23], "render": [4, 30], "repeat": [18, 22, 24], "replac": 30, "replic": [17, 24], "repo_id": 26, "report": [2, 16, 18, 20, 25], "report_to": 21, "repositori": [16, 21, 25, 30], "repres": [2, 4, 16, 17, 19, 20, 21, 22, 25, 27, 28, 30], "represen": 27, "represent": [0, 3, 7, 12, 16, 17, 19, 20, 22, 23, 27, 30], "representation_dim": 27, "reproduc": 16, "req_res_oop": 30, "request": [20, 24], "requir": [0, 1, 3, 5, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "requires_grad": [18, 22, 25], "research": [2, 16, 23, 25, 26, 28, 29], "reserach": 28, "reset": 20, "reset_activ": 30, "reshap": [19, 20], "resid_dropout": 22, "resid_pr": 30, "residu": 31, "residual_stream_patching_hook": 30, "resourc": [0, 1, 2, 3, 4, 8, 16, 21, 23, 24, 25, 26, 29], "respect": [3, 4, 16, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29], "respond": 28, "respons": [1, 3, 4, 22, 28], "response_mod": 3, "response_rag": 3, "response_synthes": 3, "response_tensor": 3, "response_vanilla": 3, "responsinbl": 30, "rest": [4, 16, 21, 23, 25], "restrict": [16, 24], "result": [3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "resum": 30, "resume_download": 30, "rethink": 9, "retreiv": [0, 1, 26, 28], "retriev": [1, 16, 17, 20, 21, 22, 24, 25, 27, 28, 30], "retrieved_node_scor": 3, "retrieved_node_text": 3, "return": [0, 1, 3, 16, 17, 19, 20, 21, 22, 23, 25, 27, 28, 30, 31], "return_dict": 27, "return_output": 21, "return_tensor": [0, 1, 3, 16, 21, 23, 24, 25, 27, 28, 30], "reus": [3, 15, 19, 24, 25], "reusabl": 19, "revers": 30, "revert": 18, "review": [3, 21, 25], "reward": [3, 29], "reward_fn": 3, "reward_model": 25, "reward_neg": 25, "reward_po": 25, "reward_token": 25, "reynold": 9, "right": [0, 1, 12, 19, 21, 22, 24, 26, 29], "rigor": 15, "rise": [16, 29], "risk": [14, 29], "rlaif": 25, "rlhf": [1, 16, 25, 29], "rm_hook": 30, "rms_norm_ep": 0, "rnn": [19, 22, 23], "robot": [10, 11], "robust": [20, 28, 29], "rocm": 16, "role": [9, 22, 30], "rolling_mean": 20, "rome": 15, "root": 28, "rope_sc": 0, "rope_theta": 0, "roug": [3, 25, 28], "rouge1": 3, "rouge_scor": 3, "roughli": 19, "round": [19, 20, 27, 31], "row": [22, 25], "royal": 16, "rr": 30, "rr_per_lay": 30, "rt": 4, "rtain": 21, "ruff": 16, "rule": [0, 1, 19, 20, 22], "rumelhart": 7, "run": [0, 1, 3, 16, 19, 21, 24, 25, 27, 28, 30], "run_with_cach": 30, "run_with_hook": 30, "runtim": [0, 1, 2, 3, 4, 16, 24], "russian": 20, "ryan": 5, "safe": 2, "safer": 16, "safeti": 29, "sai": [3, 4, 11, 16, 24, 29, 30], "said": 24, "sake": 26, "salazar": 28, "salienc": 27, "same": [2, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "sampl": [0, 1, 2, 3, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28], "santurkar": 29, "satisfii": 26, "satoshi": 20, "save": [0, 1, 2, 3, 4, 16, 19, 20, 23, 30], "save_step": 21, "saw": 30, "scalabl": [28, 29], "scalar": [3, 17, 19, 25], "scale": [0, 3, 6, 10, 18, 19, 25, 28, 31], "scan": 0, "scari": 2, "scatterplot": 19, "scenario": 28, "scene": [18, 19], "schedul": [21, 23, 25], "scheme": [2, 3, 21], "schmidhub": 7, "schnell": 22, "school": 2, "scienc": [5, 28, 29], "scientif": 25, "scope": 20, "score": [3, 4, 22, 23, 24, 25, 27, 28, 31], "scorer": [4, 28], "scottish": 20, "scratch": [8, 21, 23], "scratchpad": 9, "script": 25, "scrub": 15, "seaborn": [18, 19], "seamlessli": [16, 26], "search": [2, 3, 16, 23, 24, 26], "searchabl": 3, "searhc": 26, "second": [0, 2, 3, 4, 7, 16, 17, 19, 22, 27], "secretli": 25, "section": [2, 4, 16, 25, 28, 29], "see": [0, 1, 2, 3, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "seed": 24, "seek": 18, "seem": [16, 19, 20, 24, 25, 27, 28], "seen": [17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "segmented_token": 27, "select": [4, 16, 19, 21, 23, 24, 25, 27, 28, 29], "self": [0, 1, 9, 19, 20, 21, 22, 25, 27, 30], "self_attn": 22, "sell": 1, "semant": [4, 28], "semest": 16, "seminar": 5, "send": 21, "sens": [0, 1, 3, 20, 21, 22, 24, 25, 29], "sensibl": [16, 21, 25], "sensit": [27, 29], "sentenc": [0, 1, 2, 3, 4, 12, 16, 21, 22, 23, 24, 25, 27, 28, 30, 31], "sentence1": 28, "sentence2": 28, "sentiment": [2, 16, 21, 23, 24, 25, 28], "sep": [24, 27], "separ": [0, 1, 3, 4, 19, 22, 24, 25, 28], "seq2seq": [23, 27], "sequenc": [0, 1, 19, 22, 23, 24, 26, 27, 30], "sequence_length": 27, "sequence_scor": 28, "sequenti": [19, 20], "seri": [8, 18, 21, 23], "serious": 20, "serv": [3, 24, 26], "server": [16, 21], "servic": 16, "session": [16, 21, 24, 25], "set": [0, 1, 3, 4, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "set_format": [3, 16, 21], "settl": 16, "setup": 21, "seventh": 12, "sever": [0, 1, 16, 20, 22, 23, 26, 28], "sft": [3, 25], "sfttrainer": 25, "sgd": 18, "shape": [16, 17, 20, 21, 22, 24, 27, 29, 30, 31], "share": [16, 19, 25, 26], "sharehold": 16, "sharpen": 29, "she": [2, 28], "shed": 28, "sheet": [0, 1, 2, 3, 4, 6], "shift": [2, 17, 21], "shima": 20, "ship": [0, 1, 21, 22], "shirt": 2, "shop": [2, 24], "short": [3, 7, 16, 17, 19, 20, 21, 25, 29], "shorter": [16, 19], "shot": [2, 9, 24], "should": [0, 1, 3, 4, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28], "shouldn": 2, "show": [1, 3, 4, 9, 18, 19, 20, 21, 22, 23, 25, 27, 30], "shown": [3, 20, 25, 28, 29], "shuffl": [0, 1, 16, 19, 20], "shy": 16, "side": [0, 1, 16, 21, 22], "sidewalk": 2, "sigma": 25, "sign": [16, 22, 26], "signal": [3, 16, 19, 22, 25], "signific": [2, 16], "significantli": 16, "silu": 0, "sim": 25, "similar": [2, 3, 4, 18, 19, 22, 24, 25, 27, 28, 29, 30], "similarity_top_k": 3, "similarli": [17, 21, 28], "simpl": [1, 4, 15, 18, 19, 20, 22, 24, 25, 26, 27, 28, 29, 30], "simplest": 22, "simpli": [22, 25, 27], "simplif": 24, "simplifi": [21, 24], "simulacra": 11, "simultan": [3, 16], "sin": [19, 22], "sinc": [0, 1, 3, 16, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "sine": 22, "sing": [0, 1], "singl": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 30], "singular": 4, "sit": 2, "site": [0, 1, 16, 21, 22, 30], "situat": 16, "sixth": 11, "size": [0, 1, 3, 16, 17, 19, 20, 21, 22, 23, 25, 26, 28, 30], "skate": 2, "skateboard": 2, "skill": [0, 1, 2, 3, 4, 19, 29], "skim": 29, "skip": 30, "skip_special_token": [0, 1, 24, 25, 28], "sklearn": 28, "sleep": 1, "slide": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 21, 24, 25, 27], "slight": 20, "slightli": [16, 17, 19, 23, 27, 28, 30], "slip": 16, "slope": 19, "slot": 16, "slow": 30, "slowdown": 4, "slowli": 18, "small": [1, 2, 3, 5, 15, 16, 18, 21, 22, 25, 27, 28, 30], "smaller": [0, 1, 16, 19, 21, 28], "smart": 2, "smile": 2, "smoothen": 24, "sn": [18, 19], "sneez": 0, "so": [0, 3, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "social": [4, 28], "societi": 5, "sociocultur": 16, "soft": [24, 30], "softmax": [20, 24, 30, 31], "softwar": [16, 29], "sold": 24, "solut": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 23, 25, 29], "solv": [0, 1, 2, 3, 4, 9, 16, 18, 28], "some": [0, 1, 2, 3, 4, 8, 10, 11, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "somehow": 26, "someth": [0, 1, 4, 18, 19, 20, 25, 29, 30], "sometim": [16, 21, 22, 23, 24, 25, 26, 29], "somewhat": [1, 19, 21, 24, 26, 28], "soon": 23, "sophist": 2, "sort": 25, "sorted_prob": 30, "sosindex": 20, "sota": [22, 25, 28, 29], "sound": [20, 24, 25, 29], "soup": 3, "sourc": [3, 4, 5, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29], "source_nod": 3, "space": [0, 1, 2, 3, 16, 20, 25, 27, 28, 30], "spaci": 27, "span": [23, 25], "spanish": 20, "spars": 1, "speak": [17, 20], "speaker": 20, "spec": 16, "special": [3, 19, 20, 21, 23, 24, 25, 26, 27, 28], "specicif": 30, "specif": [0, 1, 2, 3, 4, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "specifi": [1, 16, 17, 19, 21, 22, 23, 25, 26, 27], "speech": [6, 27, 28], "speed": [0, 1, 2, 3, 4, 16, 19, 25], "spend": 2, "split": [0, 1, 3, 16, 19, 21, 22, 23, 25, 27, 28], "split_percentag": 20, "spoiler": 24, "sponsor": 26, "spot": [0, 1, 21], "sprang": 22, "spuriou": 27, "sqrt": [19, 23, 31], "squeez": [3, 17, 19, 20, 30], "src": 4, "src_mask": 22, "ss": 5, "stabil": [18, 23, 25], "stabl": [0, 1, 3, 16, 17, 19, 21, 23], "stack": [17, 19, 30], "stage": 23, "stai": [9, 10, 11, 12, 13, 14, 15, 30], "stand": [16, 28], "standard": [3, 16, 18, 23, 25, 28], "stanford": 8, "stanfordnlp": [21, 23], "stanlei": 2, "start": [0, 3, 16, 19, 20, 22, 23, 24, 25, 26, 29, 30], "starter": 4, "startofsequ": 22, "startswith": [25, 27], "stat": 3, "state": [0, 1, 2, 5, 16, 18, 20, 21, 22, 25, 27, 30], "stateless": 26, "statement": 24, "static": 22, "statist": [16, 19], "stdv": 19, "step": [0, 1, 3, 4, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 29, 30], "step_scor": 27, "stepwis": 26, "stereotyp": 29, "stick": 16, "still": [16, 18, 20, 21, 22, 24, 28], "stochast": [18, 20, 29], "stock": 16, "stop": [16, 19, 22, 23, 27], "stopword": 16, "storag": [3, 16], "store": [2, 3, 4, 17, 18, 19, 20, 21, 28, 30], "stori": 25, "storycloz": 29, "str": [0, 1, 3, 16, 28, 30, 31], "str_tok": 30, "straightforward": 3, "stranger": 4, "strategi": [9, 16, 28, 29], "stream": 26, "street": [16, 24], "stress": 2, "strictli": 17, "string": [0, 1, 4, 16, 17, 20, 21, 22, 27, 28, 30], "strip": [3, 27], "strong": [16, 25], "strongli": [16, 29], "stroutputpars": 26, "structur": [2, 4, 12, 16, 17, 19, 21, 26, 28], "student": [0, 1, 5, 25], "studi": [16, 18, 20, 25, 26, 28], "studio": 16, "stumbl": 25, "style": [2, 15, 16, 25], "sualli": 16, "sub": [16, 17, 26, 27], "subclass": 21, "subject": [4, 5, 25], "submiss": [0, 1, 2, 3, 4], "submit": [0, 1, 2, 3, 4, 16], "subplot": 23, "subsampled_dataset": [21, 23], "subsect": 20, "subsequ": [18, 19, 20, 25, 29, 30], "subset": [21, 25], "substep": [21, 26], "subtl": 19, "subtract": [17, 19, 30, 31], "subword": 22, "success": [2, 3, 21, 22, 23, 25], "successfulli": [16, 23], "suffici": [0, 21], "sufficintli": 25, "suggest": [4, 8, 16, 20, 26], "suiss": 16, "suit": [4, 25, 28], "suitabl": [16, 25], "sum": [0, 1, 16, 18, 20, 22, 24, 25, 27, 28], "sum_": 28, "summar": [21, 23, 25, 28], "summari": [1, 2, 3, 25, 26, 28], "summaris": 25, "summend": 24, "super": [19, 20, 22, 27, 30], "super_glue_boolq": 28, "superglu": 28, "superlative_quantifiers_1": 4, "supermarket": 4, "supervis": [10, 27, 29], "supplement": [3, 28], "supplementari": [8, 9, 10, 11, 12, 13, 14, 15], "suppli": [3, 16, 19, 20], "support": [16, 17, 27, 29], "supporting_modul": 3, "suppos": [3, 16, 21, 25, 28], "suppress": 18, "sure": [0, 1, 2, 4, 16, 19, 20, 21, 22, 24, 25, 27, 28, 30], "surnam": [1, 20], "surname_firstname_hw1": [0, 1], "surname_firstname_hw2": 2, "surname_firstname_hw3": 3, "surname_firstname_hw4": 4, "surp_avg": 20, "surp_avg_dict": 20, "surp_dict": 20, "surp_scal": 20, "surpris": [0, 1, 20], "surprisal_test": 20, "surprisal_train": 20, "surprisl": 20, "surprisl_dict": 20, "survei": 6, "sva_data": 4, "swap": 21, "switch": 23, "swoop": 19, "sy": 27, "symbol": [16, 22], "symmetr": 28, "syntact": [4, 12, 13, 27, 28], "syntax": [4, 17], "syntaxgym": 13, "system": [2, 4, 18, 22, 23, 25, 26, 28, 29], "systemat": 5, "t": [0, 1, 2, 3, 4, 16, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31], "t5": [23, 27, 28], "t5forconditionalgener": 28, "t5token": 28, "tabl": [2, 4, 16], "tag": [16, 23, 27, 28], "tail": 17, "take": [0, 1, 2, 3, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "taken": [4, 21, 27, 28, 29, 30], "talk": [8, 26], "talmor": [0, 1], "tandem": 28, "tap": 4, "target": [16, 18, 19, 20, 21, 25, 27, 28, 29], "target_id": 27, "target_line_tensor": 20, "target_out": 21, "target_tensor": 20, "task": [0, 1, 2, 3, 4, 15, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "tau": [0, 1, 24, 28], "teach": 25, "teacher": 4, "team": [16, 29], "technic": [5, 28], "techniqu": [2, 3, 19, 24, 25, 27, 29, 30], "tediou": 19, "televis": 2, "tell": [0, 2, 3, 17, 18, 19, 20, 25, 28], "temp_hook_fn": 30, "temperatur": [0, 1, 3, 24, 26], "templat": 26, "tempor": 20, "temporari": 30, "ten": 25, "tend": 25, "tendenc": 20, "tennei": [12, 27], "tenni": 4, "tensor": [0, 1, 3, 16, 18, 19, 20, 21, 22, 24, 27, 30, 31], "tensor1": 17, "tensor2": 17, "tensor3": 17, "tensor4": 17, "tensor5": 17, "tensor_0d": 17, "tensor_1": 17, "tensor_1_transpos": 17, "tensor_2": 17, "tensor_2d": 17, "tensor_from_list": 17, "tenth": 15, "tep": 3, "term": [4, 7, 16, 21, 22, 24, 25, 28], "terminologi": [26, 28], "termn": [0, 1], "terribl": 24, "test": [0, 1, 2, 3, 4, 13, 15, 16, 19, 21, 23, 24, 25, 26, 27, 29, 30], "test_accuraci": 27, "test_data": 20, "test_dataload": 1, "test_dataset": 1, "test_df": 3, "test_indic": 20, "test_label": 27, "test_labels_al": 27, "test_layer_represent": 27, "test_loss": [1, 21, 27], "test_output": [0, 1], "test_queri": 3, "test_represent": 27, "test_representations_al": 27, "test_sampl": [0, 1], "test_sent": 27, "test_sentence_represent": 27, "test_siz": [16, 20], "test_split": 1, "testabl": 4, "testset": 20, "tex": 0, "text": [0, 1, 2, 3, 10, 16, 17, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "text1": 22, "text2": 22, "text3": 22, "text_d": 28, "text_en": 28, "textbook": [6, 7, 8], "textual": [3, 28], "th": [2, 3, 4, 22], "than": [0, 2, 4, 10, 16, 22, 23, 25, 26, 27, 28, 30], "thei": [2, 3, 4, 5, 16, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30], "thelik": 22, "them": [0, 1, 2, 3, 4, 5, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28], "themselv": 5, "theorem": 25, "theoret": [26, 28], "theori": 28, "therebi": [22, 28], "therefor": [0, 1, 3, 4, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "theta": 25, "thi": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "thing": [16, 18, 19, 20, 21, 22, 23, 26, 30], "think": [0, 1, 2, 3, 5, 16, 17, 19, 20, 22, 23, 24, 25, 27, 28, 29], "third": [3, 4, 8, 17, 19, 22, 26, 27], "those": [20, 21, 22, 24, 27, 28, 29], "though": [16, 24], "thought": [2, 9, 14, 17, 21, 24, 29], "thousand": [25, 28], "three": [0, 1, 3, 16, 17, 20, 22, 23, 26], "threshold": 24, "through": [0, 1, 16, 17, 18, 20, 21, 22, 24, 25, 27, 30], "throughout": [0, 1, 16, 21, 29, 30], "thu": [5, 19, 28], "tidi": 16, "tie_word_embed": 0, "tightli": 23, "tile": 27, "time": [0, 1, 2, 3, 4, 16, 17, 18, 20, 21, 22, 23, 26, 28], "time_sinc": 20, "times5": [0, 1], "timestamp": 19, "tiramiu": 26, "titl": 30, "tmobil": 16, "to_numpi": 30, "to_single_token": 30, "to_str_token": 30, "to_token": 30, "todo": 17, "tofu": 25, "togeth": [3, 4, 21, 22, 24, 26, 27, 30], "tok": 22, "tokein": 16, "token": [0, 1, 2, 3, 16, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31], "token_label": 30, "tokenized_dataset": [0, 21, 23], "tokenized_input": [1, 21, 23], "tokenizer_gpt2": 16, "tokenizer_instruct": 25, "tokenizer_lm": 25, "tokenizer_nam": 3, "tokenizer_t5": 28, "tokenizer_typ": 1, "tokenizers_parallel": 30, "told": 18, "tomato": 26, "too": [3, 21, 23, 28], "tooken": 16, "tool": 16, "top": [16, 24, 26, 27, 30], "top_k": [3, 21, 24], "top_p": [3, 24], "topi": 20, "topic": [1, 5, 10, 11, 16, 22, 23, 24, 28, 29], "topk": [20, 30], "topk_per_lay": 30, "topv": 20, "torch": [0, 1, 3, 4, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 30, 31], "torch1": 17, "torch2": 17, "torch_dtyp": [0, 3, 24, 30], "torchrl": 16, "torchtext": 28, "total": [3, 20, 25], "total_loss": [20, 27], "total_s": 20, "touvron": [9, 25], "toward": 25, "town": 28, "toxic": [16, 28, 29], "tqdm": [0, 1, 3, 16, 21, 30], "tqdmwarn": [0, 1, 16, 21], "tra": 16, "trace": 27, "track": [0, 1, 18, 20, 21, 28], "tradit": 16, "train": [0, 1, 2, 3, 4, 5, 7, 8, 10, 17, 21, 22, 24, 28, 29, 30], "train_accuraci": 27, "train_data": [18, 20], "train_dataload": 19, "train_dataset": [0, 1, 21, 25], "train_indic": 20, "train_label": 27, "train_labels_al": 27, "train_layer_represent": 27, "train_loss": [21, 27], "train_represent": 27, "train_representations_al": 27, "train_sent": 27, "train_sentence_represent": 27, "train_siz": [16, 20], "train_split": 1, "train_step": [0, 1], "train_test_split": 16, "trainabl": [0, 1, 18, 19, 25], "trainer": [21, 25], "training_data": 1, "training_data_cutoff": 1, "trainingargu": 21, "tram": 2, "transfer": 29, "transform": [0, 1, 2, 3, 5, 15, 16, 19, 24, 25, 26, 27, 28, 30], "transformer_len": 30, "transformer_model": 22, "transformerdecod": 22, "transformerdecoderlay": 22, "transformerencod": 22, "transformerencoderlay": 22, "transformermodel": 22, "translat": [23, 27, 28], "transpos": [16, 20, 22], "treat": [17, 19, 21, 27], "tree": [2, 9, 24], "treebank": 28, "trend": 6, "tri": [2, 23, 26], "trial": [4, 25, 28], "trian": [0, 1], "trick": [19, 23], "tricki": [23, 29, 30], "trigram": 28, "triplet": 20, "trivial": 25, "triviaqa": 29, "trl": [3, 25], "troubl": 2, "trough": 16, "true": [0, 1, 3, 4, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30], "true_answ": 28, "true_dist": 18, "true_loc": 18, "true_logit": 30, "true_posit": 28, "truncat": [0, 1, 3, 21, 23], "trust_remote_cod": [3, 24], "truth": [0, 1, 3, 19, 25, 28], "truthfulqa": 29, "try": [0, 1, 4, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "tsvilodub": [16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "tuck": 16, "tue": 5, "tune": [2, 5, 9, 11, 12, 13, 14, 15, 16, 18, 21, 23, 24, 26, 27, 28, 29], "tupl": [0, 1], "turbo": [26, 28], "turn": [19, 25], "tutor": 25, "tutori": [0, 1, 16, 18, 19, 20, 21, 22, 23], "tweet": 16, "tweet_length": 16, "twice": [3, 30], "twitter": [1, 16], "two": [0, 1, 2, 3, 4, 7, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29], "txt": [16, 27], "type": [0, 1, 2, 3, 4, 16, 21, 22, 23, 25, 26, 29, 30], "typic": [4, 19, 20, 24, 25], "u": [3, 4, 16, 17, 18, 19, 20, 21, 25, 26, 28, 29], "ud": 27, "ud_en_pref": 27, "ultim": 25, "umbrella": 21, "un": 25, "unanim": 24, "unclear": [19, 25], "uncom": [0, 1, 3, 16, 21, 25], "under": [0, 1, 4, 16, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29], "underfit": 23, "undergo": [22, 30], "undergon": 2, "underli": [3, 21, 28], "underpin": 25, "understand": [2, 3, 8, 9, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "understanding_llm": [0, 1, 16, 21, 22, 30], "understood": 16, "undesir": [16, 25, 29], "unembed": 30, "unexpect": 24, "unexpectedli": 28, "unfortun": 16, "unfortunatelli": 26, "unfrozen": 25, "ungrammat": 28, "ungrammatical_log_prob": 28, "ungrammatical_sent": 28, "uni": 16, "unicod": 22, "unicode_liter": 20, "uniform": 19, "uniform_": 19, "uniformli": 17, "unigram": [22, 28], "union": 27, "uniqu": [1, 16, 20, 22, 27], "unique_label": 27, "unit": [4, 16, 17, 20, 22], "univers": 10, "unk": 22, "unknown": [16, 22, 25], "unless": [0, 1, 16], "unnecessari": 22, "unpack": 19, "unrecogn": 27, "unsaf": 29, "unseen": 16, "unsolv": 28, "unsqueez": [17, 21, 22, 30], "unsqueeze_": 20, "unstructur": 3, "unsupervis": [8, 25], "unsurpris": 16, "until": [3, 22, 23, 24], "up": [0, 1, 2, 3, 4, 19, 21, 24, 25, 26, 27, 28, 29, 30], "upcom": 16, "updat": [0, 1, 16, 19, 21, 23, 25, 26, 30], "upload": [0, 1, 2, 3, 4, 21, 27], "upon": 25, "urg": 16, "url": 20, "urllib": 20, "urlopen": 20, "us": [0, 1, 2, 3, 4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "usa": 4, "usabl": [17, 25], "usag": 16, "usage_custom": 3, "use_cach": [0, 30], "use_mps_devic": 21, "use_nested_tensor": 22, "user": [16, 22, 23, 25, 26, 28, 29], "user_instal": [0, 1, 16, 21], "userwarn": 22, "using_llm": 3, "usual": [0, 1, 4, 16, 17, 20, 21, 22, 23, 25, 26, 28], "util": [0, 1, 3, 16, 21, 24, 27, 30], "v": [0, 1, 4, 19, 21, 22, 28, 30, 31], "v0": 26, "v1": [3, 28], "v2": 3, "v_0": 31, "v_1": 31, "v_2": 0, "v_4": 31, "v_proj_weight": 22, "v_x": 31, "val_loss": 0, "valid": [0, 1, 3, 16, 22, 23, 25, 26, 28], "validation_dataload": 0, "validation_dataset": 0, "validation_loss": 0, "valu": [3, 19, 20, 21, 22, 23, 24, 25, 27, 28, 30, 31], "valuabl": 16, "value_var": 19, "valueerror": 27, "vanilla": [3, 25], "vanilla_respons": 3, "vanish": 19, "var": 31, "vari": [24, 25], "variabl": [0, 1, 16, 18, 19, 20, 26, 28, 30], "varianc": 20, "variant": 19, "variat": 4, "varieti": [16, 26, 28], "variou": [2, 3, 5, 16, 17, 23, 24, 25, 26, 27, 28, 29, 30], "vast": [19, 26], "vaswani": 8, "vdim": 22, "ve": 23, "vec": 31, "vecor": 27, "vector": [3, 15, 16, 19, 20, 22, 27, 30], "vector_store_index": 3, "vectorstor": 3, "vectorstorageindex": 3, "vectorstoreindex": 3, "vegetarian": 26, "verb": 4, "verbos": [3, 26], "veri": [2, 3, 16, 20, 21, 22, 23, 24, 25, 26, 28], "versa": [22, 25], "version": [1, 2, 16, 19, 22, 25, 26, 30], "vf_coef": 3, "via": [0, 1, 2, 3, 4, 16, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30], "vice": [22, 25], "vicuna": 2, "video": [5, 8, 16], "vietnames": 20, "view": [26, 27], "vig": 15, "vignett": 4, "vision": [21, 23, 29], "visual": [3, 4, 16, 22, 24, 29], "vivid": 2, "vocab": [22, 31], "vocab_s": [0, 22], "vocabulari": [0, 1, 16, 19, 20, 22, 23, 24, 30], "vocabulary_s": 1, "vram": 16, "w_": 24, "w_f": 31, "w_i": 24, "wa": [0, 1, 2, 3, 4, 16, 20, 21, 22, 24, 25, 26, 28, 29, 30], "wai": [0, 1, 2, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30], "wait": 2, "walk": [4, 27], "wall": 16, "walmart": [2, 16], "wandb": 21, "wang": [9, 15], "want": [0, 1, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "waren": 28, "warm": 25, "warn": [18, 19, 20, 22, 25, 30], "warsaw": 30, "wash": 19, "wave": 2, "we": [0, 1, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "weak": 16, "weaker": 28, "wear": 2, "web": 16, "webbbook": 5, "webbook": 24, "webook": 16, "websit": [1, 21, 22, 26], "webson": [9, 29], "week": [16, 21, 23], "weekli": 5, "wei": 9, "weigh": 3, "weight": [0, 1, 16, 17, 19, 21, 22, 23, 25, 27, 28, 30], "weight_decai": 21, "weight_norm": 19, "welcom": 28, "well": [0, 1, 2, 3, 4, 6, 16, 20, 21, 22, 23, 25, 27, 28, 30], "went": 30, "were": [2, 3, 9, 16, 22, 24, 25, 28, 29, 30], "weren": 22, "what": [0, 1, 2, 3, 4, 5, 9, 12, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "when": [0, 1, 3, 4, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30], "whenev": 16, "where": [0, 1, 2, 3, 4, 5, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "wherein": [3, 28], "whether": [0, 1, 2, 4, 16, 17, 21, 23, 25, 27, 28, 29, 30], "which": [0, 1, 2, 3, 4, 5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "while": [0, 1, 2, 3, 16, 19, 20, 21, 22, 23, 24, 25, 28], "white": 2, "whitespac": [16, 22], "who": [5, 16, 22, 23], "whole": [26, 28], "whose": [23, 25, 29], "why": [2, 3, 4, 16, 19, 20, 22, 24, 25, 27, 28, 29, 30], "why_not_sparsity_fast_path": 22, "wide": [25, 28], "widespread": 22, "width": [17, 20], "wiggl": 19, "wikipedia": [16, 26, 28], "wikipediaapiwrapp": 16, "wikipediaqueryrun": 16, "wikitext": 28, "wilcox": 4, "wild": 15, "window": [0, 3, 16, 27, 28], "wing": 24, "winogend": 28, "winogrand": 29, "wise": [17, 23], "within": [3, 16, 21, 22, 24, 28, 30], "without": [0, 1, 16, 17, 21, 24, 26, 28, 30], "witin": 0, "wkipedia": 28, "wo": 30, "woman": 2, "women": 2, "word": [0, 1, 2, 3, 12, 16, 19, 21, 22, 23, 24, 25, 27, 29], "word2vec": [6, 15, 16], "wordpiec": 22, "work": [0, 1, 2, 3, 4, 5, 9, 16, 17, 18, 19, 20, 22, 23, 24, 25, 28, 30], "worker": 16, "workflow": 21, "worksheet": 5, "world": [17, 29], "worri": 28, "wors": [23, 25], "worthwhil": 19, "would": [0, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "wouldn": 22, "wpe": 22, "wrangl": [0, 1, 21, 28], "wrap": 21, "wrapper": [16, 21, 22, 30], "write": [0, 1, 2, 4, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30], "written": [0, 2, 3, 25, 28], "wrong": [12, 29], "wrongfuldeath": 16, "wte": 22, "www": 3, "w\u00fcrttemberg": 16, "x": [0, 1, 4, 5, 16, 17, 19, 20, 22, 24, 25, 27, 30, 31], "x_": 28, "x_0": 28, "x_1": [0, 1], "x_2": [0, 1], "x_i": 28, "x_n": 28, "x_ob": 19, "x_test": [0, 1], "xaxi": 30, "xie": 9, "xl": 28, "xlabel": [0, 1, 16, 21], "xxx": 1, "y": [4, 16, 17, 19, 24, 30, 31], "y_1": [0, 1, 25], "y_2": [0, 1, 25], "y_3": [0, 1], "y_nois": 19, "y_normal": 19, "y_ob": 19, "y_pred": 19, "yao": 9, "yaxi": 30, "ye": [3, 20, 21, 27, 29], "year": [2, 16], "yet": [3, 16, 20, 21, 25, 27], "ygjpt2red3": 16, "yield": 17, "ylabel": [0, 1, 21], "you": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "your": [0, 1, 2, 3, 4, 9, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30], "your_api_kei": 26, "yourself": [0, 1, 3, 16, 19, 20, 21, 22, 23, 24, 30], "youself": 19, "yu": 15, "z": [16, 19, 31], "z1": 16, "z2": 16, "z37ijmcqzb": 16, "z_0": 31, "zero": [0, 1, 2, 9, 17, 18, 19, 20, 22, 23, 28, 30], "zero_grad": [18, 19, 20, 27], "zeroshot": 16, "zhao": 6, "ziegler": 3, "zip": [0, 1, 3, 4, 27, 28], "zoom": [2, 3, 4, 27, 29], "\u00fcber": 22}, "titles": ["Homework 1: Language models (58 points)", "Homework 1: Language models (50 points)", "Homework 2: Prompting &amp; Generation with LMs (50 points)", "Homework 3: LLM agents &amp; RL fine-tuning", "Homework 4: LLM evaluation", "Course overview: Understanding LMs", "Background", "PyTorch, ANNs &amp; LMs", "LSTMs &amp; Transformers", "Prompting &amp; Current LMs", "Fine-tuning and RLHF", "LLM systems &amp; agents", "Attribution methods", "Evaluation &amp; behavioral assessment", "Implications, Understanding &amp; Philosophy", "Mechanistic Interpretability", "Sheet 1.1: Practical set-up &amp; Training data", "Sheet 2.1: PyTorch essentials", "Sheet 2.2: ML-estimation", "Sheet 2.3: Non-linear regression (MLP w/ PyTorch modules)", "Sheet 2.4: Character-level sequence modeling w/ RNNs", "Sheet 2.5: Introduction to HuggingFace &amp; LMs", "Sheet 3.1: Tokenization &amp; Transformers", "Sheet 3.2: Transformer configurations &amp; Training utilities", "Sheet 3.3: Prompting &amp; Decoding", "Sheet 4.1 Supervised fine-tuning and RL fine-tuning", "Sheet 5.1 LLM agents", "Sheet 6.1 LLM probing &amp; attribution", "Sheet 7.1: Behavioral assessment &amp; Evaluation", "Sheet 7.2: Advanced evaluation", "Sheet 8.1: Mechanistic interpretability", "&lt;no title&gt;"], "titleterms": {"": [4, 19], "1": [0, 1, 2, 3, 4, 16, 17, 18, 22, 24, 25, 26, 27, 28, 30], "10": 4, "12": [0, 1], "13": 4, "14": 2, "15": [0, 1, 3], "16": 2, "2": [0, 1, 2, 3, 4, 17, 18, 19, 20, 21, 23, 24, 26, 29], "20": 2, "22": 4, "23": [0, 1], "3": [0, 1, 2, 3, 4, 18, 19, 22, 23, 24], "30": 3, "4": [0, 4, 18, 20, 25], "5": [3, 4, 18, 21, 26], "50": [1, 2], "58": 0, "6": 27, "7": [28, 29], "8": [0, 30], "activ": 30, "addit": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "advanc": [2, 19, 29], "agent": [3, 11, 26], "ann": 7, "answer": 0, "api": 16, "ar": 4, "arithmet": 17, "aspect": [3, 29], "assess": [13, 17, 28], "assist": 29, "attent": [22, 27], "attribut": [12, 17, 27], "audienc": 5, "augment": 3, "autograd": 19, "background": 6, "backprop": 18, "backpropag": 18, "behavior": [13, 28], "benchmark": [28, 29], "best": 16, "bias": 4, "bpe": 22, "broadcast": 17, "build": 3, "built": 19, "bwjupyt": 16, "capabl": 4, "charact": 20, "choic": 2, "code": 16, "colab": 16, "column": 17, "comput": [18, 19], "concept": 16, "concis": 19, "configur": [0, 23], "consist": 29, "core": 16, "cours": 5, "creat": 17, "current": [9, 18], "data": [16, 17, 18, 19, 20], "dataset": 16, "decod": [24, 30], "defin": [19, 20], "definit": 19, "distribut": 18, "document": 16, "dynam": 23, "earli": 30, "eo": 22, "error": 18, "essenti": 17, "estim": 18, "evalu": [4, 13, 20, 27, 28, 29], "excercis": 26, "exercis": [0, 1, 2, 3, 4, 23, 24], "explicit": 19, "extract": 1, "fine": [0, 1, 3, 10, 25], "fingerprint": 1, "first": 2, "flavour": 25, "formalia": 5, "function": 20, "further": 5, "gener": [2, 3, 20], "global": [19, 20], "gpt": 1, "gradient": 18, "grammat": 4, "graph": 19, "hallucin": 29, "handl": 26, "head": 23, "helper": 20, "homework": [0, 1, 2, 3, 4], "how": 4, "huggingfac": 21, "human": 4, "implic": 14, "index": 17, "infer": 20, "inform": 18, "inspect": 20, "instal": 16, "intend": 5, "interpret": [15, 23, 30], "introduct": 21, "invert": 20, "iter": 5, "join": 17, "just": 17, "knowledg": 29, "langchain": 26, "languag": [0, 1], "layer": 19, "level": 20, "like": 4, "linear": 19, "llama": 4, "llm": [0, 1, 3, 4, 11, 26, 27], "lm": [2, 5, 7, 9, 21], "load": 20, "local": 16, "logist": [0, 1, 2, 3, 4], "loop": 18, "loss": 18, "lstm": 8, "machin": 28, "main": 16, "mask": [22, 23], "materi": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "matrix": 17, "mechanist": [15, 30], "memori": 26, "method": [12, 27], "metric": 28, "ml": [18, 21], "mlm": 23, "mlp": 19, "model": [0, 1, 19, 20, 21, 23, 25], "modul": 19, "more": 19, "multipl": [2, 17], "network": 20, "neural": 2, "nli": 2, "nn": 19, "non": 19, "nvidia": 16, "oper": 17, "optim": 18, "option": [19, 22, 23, 25], "outlook": [19, 21, 22, 23, 25, 28], "output": 26, "overview": 5, "packag": [18, 19, 20], "paramet": [18, 19, 20], "pars": 26, "part": 18, "patch": 30, "peft": 25, "philosophi": 14, "point": [0, 1, 2, 3, 4], "polici": 25, "ppo": 25, "practic": [16, 25], "predict": 18, "prepar": 19, "pretrain": 22, "previou": 5, "probe": 27, "problem": 29, "process": [16, 29], "prompt": [2, 9, 24], "psychologi": 28, "pythia": 0, "pytorch": [7, 17, 19, 22], "qa": [1, 2], "question": 0, "reason": 29, "regress": 19, "requir": 16, "reset": 18, "reshap": 17, "residu": 30, "retriev": 3, "reward": 25, "rl": [3, 25], "rlhf": [3, 10], "rnn": 20, "row": 17, "schedul": 5, "scheme": 24, "sequenc": 20, "set": 16, "sheet": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30], "signal": 18, "slice": 17, "social": 29, "societ": 4, "solv": 29, "special": 22, "split": 20, "step": 16, "strategi": [2, 24], "stream": 30, "summar": 3, "supervis": 25, "surpris": 4, "system": [3, 11], "tensor": 17, "test": [20, 28], "token": 22, "tool": 26, "train": [16, 18, 19, 20, 23, 25, 27], "transform": [8, 21, 22, 23], "transpos": 17, "true": [18, 19], "tune": [0, 1, 3, 10, 25], "type": 17, "understand": [0, 1, 4, 5, 14, 16], "up": 16, "updat": 18, "us": 19, "util": [19, 23], "valu": [17, 18], "vector": 17, "verifi": 16, "via": 21, "visual": 27, "w": [19, 20], "work": 21, "write": 16}})