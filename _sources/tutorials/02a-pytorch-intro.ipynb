{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet 2.1: PyTorch essentials\n",
    "=============================\n",
    "\n",
    "**Author:** Michael Franke\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This work sheet introduces the basics of PyTorch.\n",
    "If you want to install PyTorch locally on your machine, follow [these instructions](https://pytorch.org/get-started/locally/).\n",
    "If installed, import the library to make it usable:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.235388Z",
     "start_time": "2025-04-17T08:39:31.160409Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are the default data structure used for the representation of\n",
    "numbers in PyTorch. In mathematics (algebra), a tensor is a\n",
    "generalization of the concept of a matrix. For our purposes, let&rsquo;s think\n",
    "of a tensor as basically an $n$-dimensional array of numbers.\n",
    "\n",
    "For example, a single scalar (a single number) is a zero-dimensional\n",
    "array. An $n$-dimensional vector is a one-dimensional array of $n$\n",
    "numbers. An $n \\times m$ matrix is a two-dimensional array with $n$\n",
    "rows and $m$ columns. All of these -scalars, vectors and matrices- are\n",
    "tensors. But *tensors also include even more high-dimensional objects*.\n",
    "For instance, an $k \\times n \\times m$ tensor is a three-dimensional\n",
    "array, which includes $k$ matrices, each of which has $n$ rows and\n",
    "$m$ columns. And so on.\n",
    "\n",
    "Full documetation for the `torch.Tensor` class can be found here:\n",
    "[https://pytorch.org/docs/stable/tensors.html](https://pytorch.org/docs/stable/tensors.html)\n",
    "\n",
    "![img](./pics/03-scalars-vectors-matrices-tensors.png){width=300px}\n",
    "\n",
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.1: Dimensions of tensors</span></strong>\n",
    ">\n",
    "> What are the dimensions of the following tensors?\n",
    ">\n",
    "> 1. $1$\n",
    "> 2. $[1,2,3]$\n",
    "> 3. $[[1,2], [3,4]]$\n",
    "> 4. $[[1,2], [3,4], [5,6]]$\n",
    "> 5. $[[[1,2], [3,4], [5,6]]]$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.1: Dimensions of tensors</span></strong>\n",
    ">\n",
    "> What are the dimensions of the following tensors?\n",
    ">\n",
    "> 1. $1$ -> 0 Dimensions\n",
    "> 2. $[1,2,3]$ -> 1 Dimension\n",
    "> 3. $[[1,2], [3,4]]$ -> 2 Dimensions\n",
    "> 4. $[[1,2], [3,4], [5,6]]$ -> 2 Dimensions\n",
    "> 5. $[[[1,2], [3,4], [5,6]]]$ -> 3 Dimensions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.252161Z",
     "start_time": "2025-04-17T08:39:32.236543Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[[1, 2],\n",
      "         [3, 4],\n",
      "         [5, 6]]])\n",
      "torch.Size([])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "########## Exercise 2.1.1 #################\n",
    "tensor1 = torch.tensor(1) \n",
    "tensor2 = torch.tensor([1,2,3])\n",
    "tensor3 = torch.tensor([[1,2], [3,4]])\n",
    "tensor4 = torch.tensor([[1,2], [3,4], [5,6]])\n",
    "tensor5 = torch.tensor([[[1,2], [3,4], [5,6]]])\n",
    "\n",
    "print(tensor1)\n",
    "print(tensor2)\n",
    "print(tensor3)\n",
    "print(tensor4)\n",
    "print(tensor5)\n",
    "\n",
    "# you can use .shape in prder to check the dimensions\n",
    "print(tensor1.shape)\n",
    "print(tensor3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various ways to create a tensor in PyTorch.\n",
    "We will go through a few examples here.\n",
    "\n",
    "Tensors can be initialised from a list:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.256508Z",
     "start_time": "2025-04-17T08:39:32.252998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_list = [1, 2, 3, 4]\n",
    "tensor_from_list = torch.tensor(a_list)\n",
    "tensor_from_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or directly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.260296Z",
     "start_time": "2025-04-17T08:39:32.257935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = torch.tensor([1, 2, 3, 4])\n",
    "new_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor construction will replicate shape and dimensionality of the data\n",
    "passed to it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.263184Z",
     "start_time": "2025-04-17T08:39:32.260814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_0d = torch.tensor(1)\n",
    "tensor_0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.266513Z",
     "start_time": "2025-04-17T08:39:32.263983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "tensor_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can also be constructed from numpy arrays:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.281338Z",
     "start_time": "2025-04-17T08:39:32.267152Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.zeros((2, 2))\n",
    "np_array_to_tensor = torch.tensor(np_array)\n",
    "np_array_to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with build-in torch functionality:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.287443Z",
     "start_time": "2025-04-17T08:39:32.282048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros((2, 2))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.297945Z",
     "start_time": "2025-04-17T08:39:32.288071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones((2, 3))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.302829Z",
     "start_time": "2025-04-17T08:39:32.299913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 5, 5],\n",
       "        [5, 5, 5],\n",
       "        [5, 5, 5],\n",
       "        [5, 5, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled = torch.full((4, 3), 5)\n",
    "filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we might also want to fill tensors with random numbers.\n",
    "The function `torch.rand()` populates a tensor of the given size with random numbers drawn uniformly from the unit interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.307588Z",
     "start_time": "2025-04-17T08:39:32.303413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2205, 0.1811, 0.7672],\n",
       "        [0.5473, 0.5995, 0.3073]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.2: Creating tensors</span></strong>\n",
    ">\n",
    "> 1. Create a PyTorch tensor storing the following matrices:\n",
    ">\n",
    ">   a. $[[1,2], [3,4], [5,6]]$\n",
    ">\n",
    ">   b. $[[[1,2], [3,4], [5,6]], [[10,20], [30,40], [50,60]]]$\n",
    ">\n",
    "> 2. Create a PyTorch tensor of size $3 \\times 2 \\times 4$ filled with the number 3.\n",
    ">\n",
    ">\n",
    ">\n",
    "> 3. Create a PyTorch vector with 6 random numbers (lying between 0 and 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.312322Z",
     "start_time": "2025-04-17T08:39:32.308381Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[[ 1,  2],\n",
      "         [ 3,  4],\n",
      "         [ 5,  6]],\n",
      "\n",
      "        [[10, 20],\n",
      "         [30, 40],\n",
      "         [50, 60]]])\n",
      "tensor([[[3, 3, 3, 3],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[3, 3, 3, 3],\n",
      "         [3, 3, 3, 3]],\n",
      "\n",
      "        [[3, 3, 3, 3],\n",
      "         [3, 3, 3, 3]]])\n",
      "tensor([0.9068, 0.5336, 0.5489, 0.9443, 0.3523, 0.0721])\n"
     ]
    }
   ],
   "source": [
    "########## Exercise 2.1.2 Task 1 #################\n",
    "exercise1a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "print(exercise1a)\n",
    "exercise1b = torch.tensor([[[1,2],[3,4],[5,6]],[[10,20],[30,40],[50,60]]])\n",
    "print(exercise1b)\n",
    "\n",
    "########## Exercise 2.1.2 Task 3 #################\n",
    "exercise2 = torch.full((3, 2, 4), 3)\n",
    "print(exercise2)\n",
    "\n",
    "########## Exercise 2.1.2 Task 3 #################\n",
    "exercise3 = torch.rand((6))\n",
    "print(exercise3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row & column vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-dimensional tensor can be thought of as a vector in linear algebra.\n",
    "But there is an important different.\n",
    "There are two types of vectors in linear algebra: row and column vectors.\n",
    "In PyTorch, a one-dimensional tensor are vector for which it is, in a manner of speaking, flexibly determined in context whether it is a row or a column vector. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.315609Z",
     "start_time": "2025-04-17T08:39:32.313130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1,  10, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1, 10, 100])\n",
    "print(vector)\n",
    "print(vector.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, strictly speaking, there are no row or column vectors in PyTorch.\n",
    "If we need a column vector, we would define a matrix with one column:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.318386Z",
     "start_time": "2025-04-17T08:39:32.316332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1],\n",
      "        [ 10],\n",
      "        [100]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "col_vector = torch.tensor([[1], [10], [100]])\n",
    "print(col_vector)\n",
    "print(col_vector.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor data types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor-supported data types are:\n",
    "\n",
    "-   numeric: float, int\n",
    "-   boolean\n",
    "-   complex numbers\n",
    "\n",
    "We can retrieve the type of a tensor with `.dtype`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.321623Z",
     "start_time": "2025-04-17T08:39:32.318921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.5, 2.1]).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we construct a tensor with an integer, its type will be integer.\n",
    "Compare:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.324407Z",
     "start_time": "2025-04-17T08:39:32.322357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(5).dtype)\n",
    "print(torch.tensor(5.0).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to declare the type explicitly, when constructing a tensor:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.327507Z",
     "start_time": "2025-04-17T08:39:32.325213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.bool\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor(5, dtype=torch.float64).dtype)\n",
    "print(torch.tensor(1.0, dtype=torch.bool).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the values in the same tensor are of the same data type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.330711Z",
     "start_time": "2025-04-17T08:39:32.328257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "torch.bool\n"
     ]
    }
   ],
   "source": [
    "true = torch.tensor([True, True])\n",
    "print(true)\n",
    "print(true.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful: PyTorch will implicitly cast data types.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.333391Z",
     "start_time": "2025-04-17T08:39:32.331379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "mix = torch.tensor([True, 1])\n",
    "print(mix)\n",
    "print(mix.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about strings? PyTorch tensors have no character or string data\n",
    "type support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.336541Z",
     "start_time": "2025-04-17T08:39:32.333913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 72, 101, 108, 108, 111,  32,  87, 111, 114, 108, 100,  33])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = \"Hello World!\"\n",
    "hello_tensor = torch.tensor([ord(char) for char in hello])\n",
    "hello_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: weights of a language model are, at the end, also represented as tensors. The data type of a tensor determines how much memory the tensor occupies. In the context of a language model, this means that, depending on the data type of the weights, more or less memory (e.g., on the GPU) is required in order to be able to use the model. Note that often weights of pretrained available models (i.e., weights of an already trained model that can be used to predict text) are available in `torch.float16` or `torch.bfloat16`. We will see where to see this and how to change the dtype when loading a pretrained model in the next sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes of a tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors have attributes, which store information about some of their important properties.\n",
    "Here are some important examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.339331Z",
     "start_time": "2025-04-17T08:39:32.337309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of tensor         : torch.int64\n",
      "Shape of tensor            : torch.Size([12])\n",
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Datatype of tensor         : {hello_tensor.dtype}\")\n",
    "print(f\"Shape of tensor            : {hello_tensor.shape}\")\n",
    "print(f\"Device tensor is stored on : {hello_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen `dtype` already.\n",
    "The property `shape` gives equal output as a call to function `.size()`.\n",
    "The property assessed with `.device` tells us where the tensor is stored and manipulated.\n",
    "The default is the CPU.\n",
    "If your machine allows you can also shift all your tensors to a GPU.\n",
    "The syntax for doing this is slightly different on different machines. **NOTE:** the tensors have to be on the same machine in order to perform joint operations on them.\n",
    "\n",
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.3: Tensor attributes & types </span></strong>\n",
    ">\n",
    "> 1. Inspect the tensor type with `.dtype` for tensors created from a list containing two different data types supported by PyTorch (int, float, Boolean).\n",
    ">\n",
    "> 2. Use `.shape` or `.size()` to inspect the shape of a (row) vector, a single column matrix, and a $2 \\times 3$ matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.345021Z",
     "start_time": "2025-04-17T08:39:32.339942Z"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "torch.int64\n",
      "torch.Size([2])\n",
      "tensor([1.0000, 1.2000])\n",
      "torch.float32\n",
      "tensor([1.0000, 1.2000])\n",
      "torch.float32\n",
      "tensor([1.2000, 1.0000])\n",
      "torch.float32\n",
      "tensor([1, 1])\n",
      "torch.int64\n",
      "tensor([1.2000, 1.0000])\n",
      "torch.float32\n",
      "tensor([[1.2000, 1.0000],\n",
      "        [2.0000, 1.2000],\n",
      "        [0.0000, 2.0000]])\n",
      "torch.float32\n",
      "torch.Size([3, 2])\n",
      "tensor([[1.2000],\n",
      "        [2.0000],\n",
      "        [0.0000]])\n",
      "torch.float32\n",
      "torch.Size([3, 1])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "########## Exercise 2.1.3 Task 1 and 2 #################\n",
    "\n",
    "mix = torch.tensor([True, 1])\n",
    "print(mix)\n",
    "print(mix.dtype)\n",
    "print(mix.shape)\n",
    "\n",
    "mix2 = torch.tensor([True, 1.2])\n",
    "print(mix2)\n",
    "print(mix2.dtype)\n",
    "\n",
    "mix3 = torch.tensor([1, 1.2])\n",
    "print(mix3)\n",
    "print(mix3.dtype)\n",
    "\n",
    "mix4 = torch.tensor([1.2, 1])\n",
    "print(mix4)\n",
    "print(mix4.dtype)\n",
    "\n",
    "mix5 = torch.tensor([1, True])\n",
    "print(mix5)\n",
    "print(mix5.dtype)\n",
    "\n",
    "mix6 = torch.tensor([1.2, True])\n",
    "print(mix6)\n",
    "print(mix6.dtype)\n",
    "\n",
    "mix7 = torch.tensor([[1.2, True],[2, 1.2],[False, 2]])\n",
    "print(mix7)\n",
    "print(mix7.dtype)\n",
    "print(mix7.shape)\n",
    "\n",
    "mix8 = torch.tensor([[1.2],[2],[False]])\n",
    "print(mix8)\n",
    "print(mix8.dtype)\n",
    "print(mix8.shape)\n",
    "print(mix8.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{toggle}\n",
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Answers Exercise 2.1.3: Tensor attributes & types </span></strong>\n",
    ">\n",
    ">1. You see the code above for both sub-exercises. \n",
    "> The datasize importance is as follows: float32 > int64 > bool\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and slicing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing & slicing works in the way familiar from numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.352529Z",
     "start_time": "2025-04-17T08:39:32.345774Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor(6)\n",
      "tensor([7, 8, 9])\n",
      "tensor([7, 8, 9])\n",
      "tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(matrix)\n",
    "print(matrix[1, 2])  # single element\n",
    "print(matrix[2, :])  # third row\n",
    "print(matrix[2])  # third row (alternative)\n",
    "print(matrix[:, 1])  # second column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can concatenate tensor like so:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.356864Z",
     "start_time": "2025-04-17T08:39:32.353246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "head = torch.tensor([1, 2, 3])\n",
    "tail = torch.tensor([4, 5, 6])\n",
    "head_and_tail = torch.cat([head, tail])\n",
    "print(head_and_tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to add a dimension?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.360247Z",
     "start_time": "2025-04-17T08:39:32.357532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([head, tail]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `torch.reshape()` is a frequently used way of returning a tensor in the\n",
    "specified shape.\n",
    "Its input are the desired output dimensions.\n",
    "NB: the reshaping returns a new tensor and does not modify the old tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.363505Z",
     "start_time": "2025-04-17T08:39:32.360952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_2 = tensor_1.reshape(4, 1)\n",
    "print(tensor_1)\n",
    "print(tensor_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.367297Z",
     "start_time": "2025-04-17T08:39:32.364182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3]])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[0, 1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0, 1], [2, 3]])\n",
    "b = torch.reshape(a, (-1,))  # to vector\n",
    "c = torch.reshape(a, (-1, 1))  # to one col matrix (~ col vector)\n",
    "d = torch.reshape(a, (1, -1))  # to one row matrix\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also the functions `.squeeze()` and `.unsqueeze()` that remove or add the dimension of size 1 at a given location of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.374672Z",
     "start_time": "2025-04-17T08:39:32.370741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[0],\n",
      "         [1],\n",
      "         [2],\n",
      "         [3]]])\n",
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "e = b.unsqueeze(1)\n",
    "print(e)\n",
    "f = e.unsqueeze(0)\n",
    "print(f)\n",
    "# we can remove dimension of size 1 at a given position\n",
    "print(f.squeeze(0))\n",
    "# or remove all dimensions of size 1\n",
    "print(f.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the function `.flatten()` which returns all elements of a tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.378203Z",
     "start_time": "2025-04-17T08:39:32.375258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[0, 1], [2, 3]], [[4, 5], [6, 7]]])\n",
    "print(a)\n",
    "print(torch.flatten(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to transpose a tensor (with a dimension at least 2) by specified dimesions using the\n",
    "function: `torch.transpose()`,\n",
    "This function takes the dimensions which are to be transposed as an argument.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.383008Z",
     "start_time": "2025-04-17T08:39:32.378926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10, 20, 30],\n",
      "         [40, 50, 60],\n",
      "         [70, 80, 90]],\n",
      "\n",
      "        [[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]]])\n",
      "tensor([[[10, 40, 70],\n",
      "         [20, 50, 80],\n",
      "         [30, 60, 90]],\n",
      "\n",
      "        [[ 1,  4,  7],\n",
      "         [ 2,  5,  8],\n",
      "         [ 3,  6,  9]]])\n"
     ]
    }
   ],
   "source": [
    "tensor_1 = torch.tensor(\n",
    "    [[[10, 20, 30], [40, 50, 60], [70, 80, 90]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]]\n",
    ")\n",
    "tensor_1_transpose = torch.transpose(tensor_1, 1, 2)\n",
    "print(tensor_1)\n",
    "print(tensor_1_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor arithmetic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual infix notation for arithmetic functions works element-wise on tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.390059Z",
     "start_time": "2025-04-17T08:39:32.383694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  6, 11])\n",
      "tensor([ 0, -2, -5])\n",
      "tensor([ 1,  8, 24])\n",
      "tensor([1.0000, 0.5000, 0.3750])\n",
      "tensor([  1,  16, 512])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([1, 4, 8])\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)\n",
    "print(y**x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we apply these operations to tensors of different sizes, PyTorch will try to broadcast the input.\n",
    "\n",
    "For example, if we multiply a vector with a scalar, the scalar is broadcasted (extended) to a vector of the same length.\n",
    "The result is that each element in the vector is multiplied by that scalar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.392998Z",
     "start_time": "2025-04-17T08:39:32.390836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4,  8, 12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "print(x * 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for higher dimensions.\n",
    "With the usual arithmetic operations, a vector will be recycled, e.g., to apply to each row of a matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.395707Z",
     "start_time": "2025-04-17T08:39:32.393534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication:\n",
      " tensor([[ 1, 20],\n",
      "        [ 3, 40]])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1, 10])\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"multiplication:\\n\", matrix * vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.398264Z",
     "start_time": "2025-04-17T08:39:32.396194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "division:\n",
      " tensor([[1.0000, 0.2000],\n",
      "        [3.0000, 0.4000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"division:\\n\", matrix / vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.400669Z",
     "start_time": "2025-04-17T08:39:32.398784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addition:\n",
      " tensor([[ 2, 12],\n",
      "        [ 4, 14]])\n",
      "subtraction:\n",
      " tensor([[ 0, -8],\n",
      "        [ 2, -6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"addition:\\n\", matrix + vector)\n",
    "print(\"subtraction:\\n\", matrix - vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precise documentation of broadcasting is [here](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a matrix multiplications on tensors, we use the function\n",
    "`torch.matmul(tensor1, tensor2)`, or its short-form notation `tensor1 @ tensor2`.\n",
    "If `tensor1` is an $(n×m)$ tensor, and `tensor2` is an $(m×p)$ tensor, the\n",
    "output will be an $(n×p)$ tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:39:32.406223Z",
     "start_time": "2025-04-17T08:39:32.401328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 12, 200],\n",
      "        [ 34, 400],\n",
      "        [ 56, 600]])\n",
      "tensor([[ 12, 200],\n",
      "        [ 34, 400],\n",
      "        [ 56, 600]])\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "tensor2 = torch.tensor([[10, 0], [1, 100]])\n",
    "print(torch.matmul(tensor1, tensor2))\n",
    "print(tensor1 @ tensor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function `torch.matmul()` implicitly converts and broadcasts and so also flexibly yields a dot-product, a matrix-vector product or a vector-matrix product.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T08:41:58.027659Z",
     "start_time": "2025-04-17T08:41:58.009168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([ 1, 10])\n",
      "tensor(101)\n",
      "tensor([21, 43])\n",
      "tensor([31, 42])\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "vector = torch.tensor([1, 10])\n",
    "print(matrix)\n",
    "print(vector)\n",
    "print(vector @ vector)  # dot prodcut\n",
    "print(matrix @ vector)  # matrix-vector product (vector is treated as a column vector)\n",
    "print(vector @ matrix)  # vector-matrix product (vector is treated as a row vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full documentation of `torch.matmul()` is [here](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing just the values of a tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tensor.item()` function returns the value of a single-item tensor without any further information, which is often useful for inspection or plotting of results:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(tensor[1, 1])\n",
    "print(tensor[1, 1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert a larger tensor back to numpy (e.g., for plotting) you can do this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "another_tensor.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.1.4: Operations on tensors</span></strong>\n",
    ">\n",
    "> 1. Define a tensor for matrix $[[[1,2], [3,4], [5,6]]]$. Create new tensors obtained by reshaping this matrix into (1) a vector (row vector), (2) a one-column matrix. Also, create its transpose. TODO: define two step solution with reshape -1\n",
    ">\n",
    "> 2. Compute the dot product between $[1,3,5]$ and $[1,10,100]$.\n",
    ">\n",
    "> 3. Compute the matrix product between PyTorch tensors $[[1], [2], [3]]$ and $[[1,10,100]]$. Convert the result to a numpy array.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click below to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "########## Exercise 2.1.4 Task 1 #################\n",
    "\n",
    "ex1 = torch.tensor([[[1,2],[3,4],[5,6]]])\n",
    "print(ex1)\n",
    "# 1\n",
    "ex1_row = torch.flatten(ex1)\n",
    "print(ex1_row)\n",
    "# 2\n",
    "ex1_col = torch.reshape(ex1, (-1, 1))\n",
    "print(ex1_col)\n",
    "ex1_col_trans = torch.transpose(ex1_col, 0, -1)\n",
    "print(ex1_col_trans)\n",
    "\n",
    "########## Exercise 2.1.4 Task 2 #################\n",
    "torch1 = torch.tensor([1,3,5])\n",
    "torch2 = torch.tensor([1,10,100])\n",
    "dot = torch1 @ torch2\n",
    "print(dot)\n",
    "\n",
    "########## Exercise 2.1.4 Task 3 #################\n",
    "\n",
    "matrix1 = torch.tensor([[1],[2],[3]])\n",
    "matrix2 = torch.tensor([[1,10,100]])\n",
    "matrixProd = matrix1 @matrix2\n",
    "print(matrixProd.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
