{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical set-up & Training data\n",
    "\n",
    "This page will contains materials for the first tutorial session (April 19th).\n",
    "\n",
    "The learning goals for the first tutorial are:\n",
    "\n",
    "* preparing the Python requirements for practical exercises in the upcoming tutorials,\n",
    "* test-running a few lines of code,\n",
    "* familiarization with a few coding best practices,\n",
    "* understanding key processing steps and terms of the first building block for training any language model -- the training data.\n",
    "\n",
    "**Please try to complete the first block of this tutorial sheet (i.e., installation of requirements) AHEAD of the tutorial session**, ideally, while you have a stable internet connection. This way we can try to solve any problems that might have come up with the installation during the tutorial on Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing requirements\n",
    "\n",
    "Throughout the semester, we will use Python, PyTorch and various packages for practical work. Both the in-tutorial exercise sheets and homework will require you to execute Python code yourself.\n",
    "Please follow the steps below to set up the requirements (i.e., most packages required for completing exercises) that we will use in the course. We will most likely install more packages as we go during the semester, though.\n",
    "\n",
    "You can do so either on your own machine, or by using [Google Colab](https://colab.research.google.com/). You can easily access the latter option by pressing the Colab icon at the top of the webook's page. Depending on your choice, please follow the respective requirement installation steps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab\n",
    "\n",
    "The advantage of using Colab is that you don't need to install software on your own machine; i.e., it is a safer option if you are not very comfortable with using Python on your own machine. Colab is a  platform provided by Google for free, and it also provides limited access to GPU computation (which will be useful fpor working with actual language models). Using it only requires a Google account.\n",
    "\n",
    "For using a GPU on Colab, before executing your code, navigate to Runtime > Change runtime type > GPU > Save. Please note that the provided Colab computational resources are free, so please be mindful when using them. Further, Colab monitors GPU usage, so if it is used a lot very frequently, the user might not be able to access GPU run times for a while. \n",
    "\n",
    "Colab already provides Python as well as a number of basic packages. If you choose to use it, you will only need to install the more specific packages. Note that you will have to so *every time* you open a new Colab runtime. To test that you can access requirements for the class, please open this notebook in Colab (see above), uncomment and run the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets langchain torchrl llama-index bertviz wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local installation\n",
    "\n",
    "Using your computer for local execution of all practical exercises might be a more advanced option. If you do so, we strongly encourage you to create an environment (e.g., with Conda) before installing any packages. Furthermore, ideally, check if you have a GPU suitable for deep learning because using a GPU will significantly speed up the work with language models. You can do so by checking your computer specs and finding out whether your GPU works with CUDA, MPS or ROCm. If you don't have a suitable GPU, you can use Colab for tasks that require GPU access. Finally, please note that we will download some pretrained models and some datasets which will occupy some of your local storage.\n",
    "\n",
    "If you choose to use your own machine, please do the following steps:\n",
    "* install Python >= 3.9\n",
    "* create an environment (optional but recommended)\n",
    "* download the requirements file [here](https://github.com/CogSciPrag/Understanding-LLMs-course/tree/main/understanding-llms/tutorials/files/requirements.txt)\n",
    "* if you have a deep learning supporting GPU: \n",
    "  * please check [here](https://pytorch.org/get-started/locally/) which PyTorch version you need in order to use the GPU\n",
    "  * please modify the first line of the requirements file to reflect the PyTorch version suitable for your machine (if needed)\n",
    "  * please install the requirements from the requirements file (e.g., run: `pip install -r requirements.txt` once pip is available in your environment; adjust path to file if needed)\n",
    "* if you do NOT have a deep learning supporting GPU:\n",
    "  * please install the requirements from the requirements file (e.g., run: `pip install -r requirements.txt` once pip is available in your environment; adjust path to file if needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying requirement installation\n",
    "\n",
    "Please run the following code cells to make sure that the key requirements were installed successfully. If you errors occur and you cannot solve them ahead of the tutorial, please don't be shy and let us know in the first tutorial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28f8c617f504b7f8540013b980362b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# check available computation device\n",
    "# if you have a local GPU or if you are using a GPU on Colab, the following code should return \"CUDA\"\n",
    "# if you are on Mac and have an > M1 chip, the following code should return \"MPS\"\n",
    "# otherwise, it should return \"CPU\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Device: {device}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7460, 0.7034, 0.8912],\n",
      "        [0.2328, 0.4722, 0.5892],\n",
      "        [0.0167, 0.5969, 0.5472],\n",
      "        [0.4784, 0.8627, 0.7594],\n",
      "        [0.8009, 0.5393, 0.1019]])\n",
      "Shape of tensor x: torch.Size([5, 3])\n",
      "Device of tensor x: cpu\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.7460, 0.7034, 0.8912],\n",
      "        [0.2328, 0.4722, 0.5892],\n",
      "        [0.0167, 0.5969, 0.5472],\n",
      "        [0.4784, 0.8627, 0.7594],\n",
      "        [0.8009, 0.5393, 0.1019]])\n"
     ]
    }
   ],
   "source": [
    "# test PyTorch\n",
    "\n",
    "# randomly initialize a tensor of shape (5, 3)\n",
    "x = torch.rand(5, 3).to(device)\n",
    "print(x)\n",
    "print(\"Shape of tensor x:\", x.shape)\n",
    "print(\"Device of tensor x:\", x.device)\n",
    "\n",
    "# initialize a tensor of shape (5, 3) with ones\n",
    "y = torch.ones(5, 3).to(device)\n",
    "print(y)\n",
    "\n",
    "# multiply x and y\n",
    "z = x * y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Attention Is All You Need\\nSummary: \"Attention Is All You Need\" is a landmark 2017 research paper by Google. Authored by eight scientists, it was responsible for expanding 2014 attention mechanisms proposed by Bahdanau et. al. into a new deep learning architecture known as the transformer. The paper is considered by some to be a founding document for modern artificial intelligence, as transformers became the main architecture of large language models. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but even in their paper the authors saw the potential for other tasks like question answering and for what is now called multimodal Generative AI.\\nThe paper\\'s title is a reference to the song \"All You Need Is Love\" by the Beatles.As of 2024, the paper has been cited more than 100,000 times.\\n\\n\\n\\nPage: All You Need Is Kill\\nSummary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\\nA manga adaptation, written by Ryōsuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha\\'s Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title.\\nThe novel was Sakurazaka\\'s breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and Chōhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\\n\\nPage: All You Need Is Love\\nSummary: \"All You Need Is Love\" is a song by the English rock band the Beatles that was released as a non-album single in July 1967. It was written by John Lennon and credited to the Lennon–McCartney partnership. The song was Britain\\'s contribution to Our World, the first live global television link, for which the band were filmed performing it at EMI Studios in London on 25 June. The programme was broadcast via satellite and seen by an audience of over 400 million in 25 countries. Lennon\\'s lyrics were deliberately simplistic, to allow for the show\\'s international audience, and captured the utopian ideals associated with the Summer of Love. The single topped sales charts in Britain, the United States and many other countries, and became an anthem for the counterculture\\'s embrace of flower power philosophy.\\nOur World coincided with the height of the Beatles\\' popularity and influence, following the release of their album Sgt. Pepper\\'s Lonely Hearts Club Band. Rather than perform the song entirely live, the group played to a pre-recorded backing track. With an orchestral arrangement by George Martin, the song begins with a portion of the French national anthem and ends with musical quotations from works such as Glenn Miller\\'s \"In the Mood\", \"Greensleeves\", Bach\\'s Invention No. 8 in F major, and the Beatles\\' 1963 hit \"She Loves You\". Adding to the broadcast\\'s festive atmosphere, the studio was adorned with signs and streamers and filled with guests dressed in psychedelic attire, including members of the Rolling Stones, the Who and the Small Faces. Brian Epstein, the Beatles\\' manager, '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing LangChain\n",
    "\n",
    "# run a Wikipedia query, searching for the article \"Attention is all you need\"\n",
    "# NB: requires an internet connection\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "wikipedia.run(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs: {'input_ids': tensor([[8086, 1463,  318,  477,  345,  761]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# testing the package transformers which provides pre-trained language models\n",
    "# and excellent infrastructure around them\n",
    "\n",
    "# download (if not available yet) and load GPT-2 tokenizer\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "text = \"Attention is all you need\"\n",
    "# tokenize the text (i.e., convert the string into a tensor of token IDs)\n",
    "input_ids = tokenizer_gpt2(\n",
    "    text,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "print(\"Input IDs:\", input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices for writing code\n",
    "\n",
    "There is a lot of debate around best practices for writing, documenting and formatting Python code and their actual implementation in daily practice, and many people have different personal preferences. We are not committing to a particular side in this debate, but we do care about a few general aspects: \n",
    "* working with clean code \n",
    "* working with understandable code (i.e., commented, with understandable variable names etc)\n",
    "* producing well-documented projects (e.g., supplied with relevant READMEs etc). Think: your work should be structured such that you could look at it in a year and be able to immediately what you did, how and why.\n",
    "\n",
    "There are a few de facto standard *formatting* practices that help to keep Python code crisp and clean. Please take a look at these and adhere to these as much as you can (as so will we):\n",
    "* [PEP8](https://pep8.org/): style guide for Python code defining e.g., variable naming conventions, how many spaces to use for indentation, how long single lines should be etc.\n",
    "  * Here is an overview [video](https://www.youtube.com/watch?v=D4_s3q038I0) of some of the PEP8 conventions\n",
    "  * There is handy software that reformats your code for you according to some of these conventions. Such software is often seamlessly integrated in IDEs. This includes for instance *Black* or *Ruff* Python formatters. They can be installed as extensions in, e.g., Visual Studio Code.\n",
    "* doc-string writing\n",
    "  * numpydoc style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: bad formatting\n",
    "\n",
    "def add(a,b):\n",
    "    return a+b\n",
    "\n",
    "# example: good formatting\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# example: bad docstring\n",
    "\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "# example: good docstring\n",
    "\n",
    "def add(a, b):\n",
    "    \"\"\"\n",
    "    Add two numbers.\n",
    "\n",
    "    Args:\n",
    "        a (int): First number.\n",
    "        b (int): Second number.\n",
    "\n",
    "    Returns:\n",
    "        int: Sum of a and b.\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some hints regarding structuring larger projects and e.g. GitHub repositories (just fyi):\n",
    "* \n",
    "\n",
    "These best practices will be useful to you beyond this class and possibly even beyond your studies when collaborating on other coding projects within teams or even by yourself. We do our best to stick to these guidelines ourselves and kindly urge you to do the same when submitting assignments and possibly projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding training data\n",
    "\n",
    "Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* corpus:\n",
    "* training data:\n",
    "  * dataset:\n",
    "  * test / validation data\n",
    "* vocabulary\n",
    "  * embedding (cf word2vec)\n",
    "* batches:\n",
    "* preprocessing:\n",
    "* epochs:\n",
    "* tokens:\n",
    "  * see more details relevant to modern LLMs in a few sessions\n",
    "* annotation\n",
    "* EOS & concept of tight language models? (maybe next session)\n",
    "  * re: smoothing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
