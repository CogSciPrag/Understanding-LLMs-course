{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "Sheet 2.2: ML-estimation\n========================\n\n**Author:** Michael Franke\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "This tutorial is meant to introduce some basics of PyTorch by looking at a simple case study: how to find the best-fitting parameter for the mean of a normal (Gaussian) distribution.\nThe training data is a set of samples from a &ldquo;true&rdquo; distribution.\nThe loss function is the negative likelihood that a candidate parameter value for the &ldquo;true mean&rdquo; assigns to the training data.\nBy using stochastic gradient descent to minimize the loss, we seek the parameter value that maximizes the likelihood of the training data.\nThis is, therefore, a **maximum likelihood estimation**.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Packages\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "We will need to import the \\`torch\\` package for the main functionality.\nWe also will use \\`seaborn\\` for plotting, and \\`matplotlib\\` for showing the plots.\nFinally, we use the \\`warnings\\` package to suppress all warning messages in the notebook.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "import torch\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## True distribution & training data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "The &ldquo;true distribution&rdquo; that generates the data is a normal distribution with a mean (location) stored in the variable \\`trueLocation\\`.\n(We keep the scale parameter (standard deviation) fixed at a known value of 1.)\nThe \\`torch.distributions\\` package contains ready-made probability distributions for sampling.\nSo, here we define the true distribution, and take \\`nObs\\` samples from it, the set of which we call &ldquo;training data&rdquo;.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "nObs           = 10000\ntrueLocation   = 0 # mean of a normal\ntrueDist       = torch.distributions.Normal(loc=trueLocation, scale=1.0)\ntrainData      = trueDist.sample([nObs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "The mean of the training data is the so-called **empirical mean**.\nThe empirical mean need not be identical to the true mean!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Empirical mean (mean of training data): 0.00001"
        }
      ],
      "source": [
        "empirical_mean = torch.mean(trainData)\nprint('Empirical mean (mean of training data): %.5f' % empirical_mean.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Here is a density plot of the training data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "data": {
            "image/png": "",
            "text/plain": "<matplotlib.figure.Figure>"
          },
          "metadata": {
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.kdeplot(trainData)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Optimizing a parameter: gradients, optimizers, loss & backprop\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "We want an estimate of the true mean of the training data.\nFor that, we define a &ldquo;trainable&rdquo; parameter in PyTorch, which we set to some initial value.\nSubsequently, we will update the value of this parameter in a series of training steps, so that it will become &ldquo;better&rdquo; over time.\nBeing &ldquo;good&rdquo; means having a small &ldquo;loss&rdquo;.\nThe loss function we are interested in is the likelihood of the training data.\n\nTo being with, we define the parameter which is to be trained.\nSince we want to &ldquo;massage it&rdquo; through updating, we must tell PyTorch that it should compute the gradient for this parameter (and the ones derived from it).\n(NB: For numerical stability we require this parameter to be a 64 bit float. You may try out the exercises below with the default float32 format and compare.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor(1., requires_grad=True)"
        }
      ],
      "source": [
        "location = torch.tensor(1.0, requires_grad=True, dtype=torch.float64)\nprint( location)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "To prepare for training, we first instantiate an **optimizer**, which will do the updating behind the scenes.\nHere, we choose the stochastic gradient descent (SGD) optimizer.\nTo instantiate it, we need to tell it two things:\n\n1.  which parameters to optimize;\n2.  how aggressively to update (=> the so-called **learning rate**)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "learningRate = 0.0000001\nopt          = torch.optim.SGD([location], lr=learningRate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Let us now go manually through a single training step.\nA training step consists of the following parts:\n\n1.  compute the predictions for the current parameter(s)\n    -   what do we predict in the current state?\n2.  compute the loss for this prediction\n    -   how good is this prediction (for the training data)?\n3.  backpropagate the error (using the gradients)\n    -   in which direction would we need to change the relevant parameters to make the prediction better?\n4.  update step\n    -   change the parameters (to a certain degree, the so-called learning rate) in the direction that should make them better\n5.  zero the gradient\n    -   reset the information about &ldquo;which direction to tune&rdquo; for the next training step\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "### Part 1: Compute the predictions for current parameter value\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "The prediction for the current parameter value is a Gaussian with the location parameter set to our current parameter value.\nWe obtain our &ldquo;current best model&rdquo; by instantiating a distribution like so:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "prediction = torch.distributions.Normal(loc=location, scale=1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "### Part 2: Computing the loss for the current prediction\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "How good is our current model?\nGoodness can be measured in many ways.\nHere we consider the likelihood: how likely is the training data under the current model?\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "tensor([-1.6429, -2.2677, -0.9448,  ..., -1.3587, -0.9517, -0.9194],\n       grad_fn=<SubBackward0>)"
        }
      ],
      "source": [
        "loss     = -torch.sum(prediction.log_prob(trainData))\nprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Notice that the \\`loss\\` variable is a single-numbered tensor (containing the information how bad (we want to minimize it) the current parameter value is).\nNotice that PyTorch has also added information on how to compute gradients, i.e., it keeps track of way in which values for the variable \\`location\\` influence the values for the variable \\`loss\\`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "### Part 3: Backpropagate the error signal\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "In the next step, we will use the information stored about the functional relation between \\`location\\` and \\`loss\\` to infer how the \\`location\\` parameter would need to be changed to make \\`loss\\` higher or lower.\nThis is the so-called backpropagation step.\n\nConcretely, at the outset, the gradient information for \\`location\\` is &ldquo;NONE&rdquo;.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Value (initial)                = 1.0\nGradient information (initial) = None"
        }
      ],
      "source": [
        "print(f\"Value (initial)                = { location.item()}\")\nprint(f\"Gradient information (initial) = { location.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "We must actively tell the system to backpropagate the information in the gradients, like so:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Value (after backprop)                = 1.0\nGradient information (after backprop) = 9800.26171875"
        }
      ],
      "source": [
        "loss.backward()\nprint(f\"Value (after backprop)                = { location.item()}\")\nprint(f\"Gradient information (after backprop) = { location.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "### Part 4: Update the parameter values\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Next, we use the information in the gradient to actually update the trainable parameter values.\nThis is what the optimizer does.\nIt knows which parameters to update (we told it), so the relevant update function is one associated with the optimizer itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Value (after step)                = 0.999019980430603\nGradient information (after step) = 9800.26171875"
        }
      ],
      "source": [
        "opt.step()\nprint(f\"Value (after step)                = { location.item()}\")\nprint(f\"Gradient information (after step) = { location.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "### Part 5: Reset the gradient information\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "If we want to repeat the updating process, we need to erase information about gradients for the last prediction.\nThis is because otherwise information would just accumulate in the gradients.\nThis zero-ing of the gradients is again something we do holistically (for all parameters to train) through the optimizer object:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Value (after zero-ing)                = 0.999019980430603\nGradient information (after zero-ing) = 0.0"
        }
      ],
      "source": [
        "opt.zero_grad()\nprint(f\"Value (after zero-ing)                = { location.item()}\")\nprint(f\"Gradient information (after zero-ing) = { location.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Training loop\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "After having gone through our cycle of parameter updating step-by-step, let&rsquo;s iterate this in a training loop consisting of \\`nTrainingSteps\\`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "#+begin_example\n\n step                     loss        estimate    diff. target\n  500                16027.112         0.60699         0.60698\n 1000                14862.321         0.36807         0.36806\n 1500                14434.033         0.22319         0.22318\n 2000                14276.555         0.13534         0.13533\n 2500                14218.649         0.08207         0.08206\n 3000                14197.358         0.04977         0.04976\n 3500                14189.528         0.03018         0.03017\n 4000                14186.650         0.01830         0.01830\n 4500                14185.593         0.01110         0.01110\n 5000                14185.203         0.00673         0.00673\n 5500                14185.061         0.00409         0.00408\n 6000                14185.007         0.00248         0.00247\n 6500                14184.988         0.00151         0.00150\n 7000                14184.981         0.00092         0.00091\n 7500                14184.979         0.00056         0.00055\n 8000                14184.978         0.00034         0.00033\n 8500                14184.977         0.00021         0.00020\n 9000                14184.977         0.00013         0.00012\n 9500                14184.978         0.00008         0.00007\n10000                14184.977         0.00005         0.00005\n#+end_example"
        }
      ],
      "source": [
        "nTrainingSteps= 10000\nprint('\\n%5s %24s %15s %15s' %\n      (\"step\", \"loss\", \"estimate\", \"diff. target\") )\nfor i in range(nTrainingSteps):\n    prediction = torch.distributions.Normal(loc=location, scale=1.0)\n    loss       = -torch.sum(prediction.log_prob(trainData))\n    loss.backward()\n    if (i+1) % 500 == 0:\n        print('%5d %24.3f %15.5f %15.5f' %\n              (i + 1, loss.item(), location.item(),\n               abs(location.item() - empirical_mean) ) )\n    opt.step()\n    opt.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.2.1: Explore the optimization process</span></strong>\n>\n> This exercise is intended to make you play around with the parameters of the training procedure, namely \\`learningRate\\` and \\`nTrainingSteps\\`, and to develop a feeling for what they do. There is not necessarily a single &ldquo;true&rdquo; solution. Report the values that you found to work best for each of the following cases:\n>\n> 1. Change the initial value of the parameter \\`location\\` to -5000.\n>\n> 2. Revert to initial conditions. Change the true mean (parameter \\`trueLocation\\`) to 5000.\n>\n> 3. Revert to initial conditions. Use only 100 samples for the training set (using variable \\`nObs\\`).\n\n"
      ]
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
