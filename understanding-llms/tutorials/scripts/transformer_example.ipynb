{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def np_conv(name, mtx):\n",
    "    mtx = str(mtx)[1:-1]\n",
    "    out = f\"${name}\"\" = \\\\begin{bmatrix}\\n\"\n",
    "    for i, char in enumerate(mtx):\n",
    "        if char == '[':\n",
    "            out += \"\\t\"\n",
    "        elif char == ' ' and mtx[i-1].isdigit():\n",
    "            out += ' & '\n",
    "        elif char == ']':\n",
    "            out += \"\\\\\\\\\"\n",
    "        else:\n",
    "            out += char\n",
    "    out += \"\\n\\end{bmatrix}$\\\\\\\\\\\\\\\\\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embedding matrix\n",
    "E = np.array([\n",
    "    [0, 1, 2],\n",
    "    [6, 7, 1],\n",
    "    [3, 4, 5],\n",
    "    [0, 2, 1],\n",
    "    [1, 3, 0],\n",
    "    [3, 8, 6],\n",
    "    [2, 7, 5],\n",
    "    [6, 2, 1],\n",
    "    [9, 1, 3],\n",
    "    [0, 1, 1]])\n",
    "\n",
    "# Query matrix\n",
    "Q = np.array([\n",
    "    [1, 1, 7],\n",
    "    [2, 5, 1],\n",
    "    [2, 6, 9]])\n",
    "\n",
    "# Key matrix\n",
    "K = np.array([\n",
    "    [0, 4, 8],\n",
    "    [1, 6, 9],\n",
    "    [4, 2, 2]])\n",
    "\n",
    "# Value Matrix\n",
    "V = np.array([\n",
    "    [2, 1, 0],\n",
    "    [4, 3, 1],\n",
    "    [6, 5, 1]])\n",
    "\n",
    "# FFN matrix\n",
    "W_f = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 1, 1]])\n",
    "\n",
    "# FFN bias\n",
    "b_f = np.array([2, 1, 1]).T\n",
    "\n",
    "# Output projection matrix\n",
    "M_out = np.array([\n",
    "    [0, 2, 1, 1, 3, 1, 0, 0, 4, 1],\n",
    "    [1, 1, 3, 1, 0, 0, 4, 1, 0, 2],\n",
    "    [1, 4, 0, 0, 1, 3, 1, 1, 2, 0]])\n",
    "\n",
    "# one hot vecs for input sentence [BOS] the fox jumped [EOS]\n",
    "I = np.array([\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$X = \\begin{bmatrix}\n",
      "\t0 & 1 & 2\\\\\n",
      " \t0 & 2 & 1\\\\\n",
      " \t2 & 7 & 5\\\\\n",
      " \t6 & 2 & 1\\\\\n",
      " \t3 & 4 & 5\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$Q_x = \\begin{bmatrix}\n",
      "\t15 &  9 & 44 & 15 & 42\\\\\n",
      " \t 7 & 11 & 44 & 23 & 31\\\\\n",
      " \t24 & 21 & 91 & 33 & 75\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$K_x = \\begin{bmatrix}\n",
      "\t20 & 16 & 68 & 16 & 56\\\\\n",
      " \t24 & 21 & 89 & 27 & 72\\\\\n",
      " \t 6 &  6 & 32 & 30 & 30\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$V_x = \\begin{bmatrix}\n",
      "\t 1 &  2 & 11 & 14 & 10\\\\\n",
      " \t 5 &  7 & 34 & 31 & 29\\\\\n",
      " \t 7 & 11 & 52 & 47 & 43\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$S = \\begin{bmatrix}\n",
      "\t 612 &  531 & 2411 & 1149 & 2064\\\\\n",
      " \t 570 &  501 & 2263 & 1071 & 1926\\\\\n",
      " \t2482 & 2174 & 9820 & 4622 & 8362\\\\\n",
      " \t1050 &  921 & 4123 & 1851 & 3486\\\\\n",
      " \t2034 & 1773 & 8015 & 3759 & 6834\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "X = I@E\n",
    "print(np_conv('X', X))\n",
    "\n",
    "# Calculate Q, K and V for each input vec\n",
    "Q_x = Q@X.T\n",
    "print(np_conv('Q_x', Q_x))\n",
    "\n",
    "K_x = K@X.T\n",
    "print(np_conv('K_x', K_x))\n",
    "\n",
    "V_x = V@X.T\n",
    "print(np_conv('V_x', V_x))\n",
    "\n",
    "# compute attention scores\n",
    "S = (Q@X.T).T@(K@X.T)\n",
    "print(np_conv('S', S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$S = \\begin{bmatrix}\n",
      "\t 612.  -inf  -inf  -inf  -inf\\\\\n",
      " \t 570.  501.  -inf  -inf  -inf\\\\\n",
      " \t2482. 2174. 9820.  -inf  -inf\\\\\n",
      " \t1050.  921. 4123. 1851.  -inf\\\\\n",
      " \t2034. 1773. 8015. 3759. 6834.\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [0, -np.inf, -np.inf, -np.inf, -np.inf],\n",
    "    [0, 0, -np.inf, -np.inf, -np.inf],\n",
    "    [0, 0, 0, -np.inf, -np.inf],\n",
    "    [0, 0, 0, 0, -np.inf],\n",
    "    [0, 0, 0, 0, 0]])\n",
    "\n",
    "S = S + A\n",
    "print(np_conv('S', S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$S = \\begin{bmatrix}\n",
      "\t 353.33836474 &          -inf          -inf          -inf          -inf\\\\\n",
      " \t 329.08965344 &  289.25248486 &          -inf          -inf          -inf\\\\\n",
      " \t1432.98336813 & 1255.15948522 & 5669.57964344 &          -inf          -inf\\\\\n",
      " \t 606.21778265 &  531.73959792 & 2380.41515987 & 1068.67534827 &          -inf\\\\\n",
      " \t1174.33044753 & 1023.64202727 & 4627.46240755 & 2170.25966188 & 3945.61173964\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$S = \\begin{bmatrix}\n",
      "\t1. 0. 0. 0. 0.\\\\\n",
      " \t1. 0. 0. 0. 0.\\\\\n",
      " \t0. 0. 1. 0. 0.\\\\\n",
      " \t0. 0. 1. 0. 0.\\\\\n",
      " \t0. 0. 1. 0. 0.\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "2.8063146353260925e-13\n",
      "$R = \\begin{bmatrix}\n",
      "\t 1.  5.  7.\\\\\n",
      " \t 1.  5.  7.\\\\\n",
      " \t11. 34. 52.\\\\\n",
      " \t11. 34. 52.\\\\\n",
      " \t11. 34. 52.\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$R = \\begin{bmatrix}\n",
      "\t 1.  6.  9.\\\\\n",
      " \t 1.  7.  8.\\\\\n",
      " \t13. 41. 57.\\\\\n",
      " \t17. 36. 53.\\\\\n",
      " \t14. 38. 57.\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "# scale S by d_h\n",
    "S = np.divide(S, np.sqrt(Q.shape[0]))\n",
    "print(np_conv('S', S))\n",
    "\n",
    "# normalise with softmax\n",
    "S = np.round(np.array(torch.softmax(torch.tensor(S), dim=1)), decimals=5)\n",
    "print(np_conv('S', S))\n",
    "\n",
    "print(np.exp(520/1.73)/((np.exp(-np.inf/1.73)*3) + np.exp(570/1.73) + np.exp(520/1.73)))\n",
    "\n",
    "# multiply score matrix with value matrix (i.e. z_0 = a^0_0 x v_0 + a^0_1 x v_1 + ... + a^0_4 x v_4 for all z)\n",
    "R = S@V_x.T\n",
    "print(np_conv('R', R))\n",
    "\n",
    "# residual connection\n",
    "R = R + X\n",
    "print(np_conv('R', R))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$Y = \\begin{bmatrix}\n",
      "\t-1.313 & -1.402 & -1.32 &  -1.247 & -1.269\\\\\n",
      " \t 0.202 &  0.539 &  0.22 &   0.045 &  0.095\\\\\n",
      " \t 1.111 &  0.863 &  1.1 &    1.201 &  1.175\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$O = \\begin{bmatrix}\n",
      "\t1.798 & 2.313 & 1.   \\\\\n",
      " \t1.461 & 2.402 & 1.   \\\\\n",
      " \t1.78 &  2.32 &  1.   \\\\\n",
      " \t1.955 & 2.247 & 1.   \\\\\n",
      " \t1.905 & 2.269 & 1.   \\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$L = \\begin{bmatrix}\n",
      "\t 3.313 &  9.909 &  8.738 &  4.111 &  6.394 &  4.798 & 10.253 &  3.313 &  9.192 &  6.424\\\\\n",
      " \t 3.402 &  9.323 &  8.666 &  3.863 &  5.383 &  4.461 & 10.607 &  3.402 &  7.843 &  6.264\\\\\n",
      " \t 3.32 &   9.88 &   8.74 &   4.1 &    6.34 &   4.78 &  10.279 &  3.32 &   9.12 &   6.42 & \\\\\n",
      " \t 3.247 & 10.156 &  8.695 &  4.201 &  6.864 &  4.955 &  9.987 &  3.247 &  9.819 &  6.448\\\\\n",
      " \t 3.269 & 10.08 &   8.713 &  4.175 &  6.716 &  4.905 & 10.077 &  3.269 &  9.621 &  6.444\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n",
      "$probs_T = \\begin{bmatrix}\n",
      "\t0.    0.305 & 0.094 & 0.001 & 0.009 & 0.002 & 0.43 &  0.    0.149 & 0.009\\\\\n",
      " \t0.    0.184 & 0.095 & 0.001 & 0.004 & 0.001 & 0.664 & 0.    0.042 & 0.009\\\\\n",
      " \t0.    0.298 & 0.095 & 0.001 & 0.009 & 0.002 & 0.445 & 0.    0.14 &  0.009\\\\\n",
      " \t0.    0.349 & 0.081 & 0.001 & 0.013 & 0.002 & 0.295 & 0.    0.249 & 0.009\\\\\n",
      " \t0.    0.338 & 0.086 & 0.001 & 0.012 & 0.002 & 0.337 & 0.    0.214 & 0.009\\\\\n",
      "\\end{bmatrix}$\\\\\\\\\n"
     ]
    }
   ],
   "source": [
    "# layer normalisation\n",
    "epsilon = 0.00001\n",
    "gamma = 1\n",
    "beta = 0\n",
    "Y = np.divide((np.subtract(R.T, np.mean(R, axis=1))), np.sqrt((np.var(R, axis=1) + epsilon))) * gamma + beta\n",
    "print(np_conv('Y', np.round(Y, decimals = 3)))\n",
    "\n",
    "# FFN forward pass\n",
    "O = (W_f@Y).T + b_f\n",
    "print(np_conv('O', np.round(O, decimals=3)))\n",
    "\n",
    "# calculate logits over vocab\n",
    "L = M_out.T@O.T\n",
    "print(np_conv('L', np.round(L.T, decimals=3)))\n",
    "\n",
    "# apply softmax to predict next token\n",
    "probs = np.round(np.array(torch.softmax(torch.tensor(L), dim=0)), decimals=3)\n",
    "print(np_conv('probs_T', probs.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
